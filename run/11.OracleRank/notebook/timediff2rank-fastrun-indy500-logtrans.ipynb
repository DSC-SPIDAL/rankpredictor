{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timediff2Rank for event model\n",
    "\n",
    "basedon: 11.OracleRank/laptime_rank_timediff_dataset-oracle.ipynb\n",
    "\n",
    "rank prediction by timediff forecasting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "ERROR:fbprophet:Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "from scipy import stats\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pathlib import Path\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.distribution.multivariate_gaussian import MultivariateGaussianOutput\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.model.prophet import ProphetPredictor\n",
    "from gluonts.model.r_forecast import RForecastPredictor\n",
    "from indycar.model.NaivePredictor import NaivePredictor\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "GPUID = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def test_flag(a, bitflag):\n",
    "    return (a & bitflag) ==  bitflag\n",
    "\n",
    "#\n",
    "# remove NaN at the tail\n",
    "# there should be no nans in the middle of the ts\n",
    "COL_LAPTIME=0\n",
    "COL_RANK=1\n",
    "COL_TRACKSTATUS=2\n",
    "COL_LAPSTATUS=3\n",
    "COL_TIMEDIFF=4\n",
    "MODE_ORACLE = 0\n",
    "MODE_NOLAP = 1\n",
    "MODE_NOTRACK = 2\n",
    "MODE_TESTZERO = 4\n",
    "MODE_TESTCURTRACK = 8\n",
    "#MODE_STR={MODE_ORACLE:'oracle', MODE_NOLAP:'nolap',MODE_NOTRACK:'notrack',MODE_TEST:'test'}\n",
    "\n",
    "def make_dataset(runs, prediction_length, freq, \n",
    "                       useeid = False,\n",
    "                       run_ts=COL_LAPTIME, \n",
    "                       train_ratio = 0.8,\n",
    "                       use_global_dict = True,\n",
    "                       oracle_mode = MODE_ORACLE,\n",
    "                       test_cars = [],\n",
    "                       half_moving_win = True \n",
    "                ):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    oracle_mode: false to simulate prediction in real by \n",
    "        set the covariates of track and lap status as nan in the testset\n",
    "            \n",
    "    \n",
    "    \"\"\"    \n",
    "    start = pd.Timestamp(\"01-01-2019\", freq=freq)  # can be different for each time series\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #select run\n",
    "    if runs>=0:\n",
    "        _laptime_data = [laptime_data[runs].copy()]\n",
    "    else:\n",
    "        _laptime_data = laptime_data.copy()\n",
    "    \n",
    "   \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        \n",
    "        print(f'====event:{events[_data[0]]}, train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)}')\n",
    "                \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                print(f'a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                continue                \n",
    "            \n",
    "            if use_global_dict:\n",
    "                carno = _data[1][rowid]\n",
    "                carid = global_carids[_data[1][rowid]]\n",
    "            else:\n",
    "                #simulation dataset, todo, fix the carids as decoder\n",
    "                carno = rowid\n",
    "                carid = rowid\n",
    "\n",
    "            #eval on carids\n",
    "            if test_cars and (carno not in test_cars):\n",
    "                continue                \n",
    "            \n",
    "            if useeid:\n",
    "                static_cat = [carid, _data[0]]    \n",
    "            else:\n",
    "                static_cat = [carid]    \n",
    "                \n",
    "            # selection of features\n",
    "            if test_flag(oracle_mode, MODE_NOTRACK):                \n",
    "                rec[COL_TRACKSTATUS, :] = 0\n",
    "            if test_flag(oracle_mode, MODE_NOLAP):                \n",
    "                rec[COL_LAPSTATUS, :] = 0\n",
    "                \n",
    "            # split and add to dataset record\n",
    "            _train.append({'target': rec[run_ts,:train_len].astype(np.float32), \n",
    "                            'start': start, \n",
    "                            'feat_static_cat': static_cat,\n",
    "                            'feat_dynamic_real': [rec[COL_TRACKSTATUS,:train_len],\n",
    "                                   rec[COL_LAPSTATUS,:train_len]]\n",
    "                          }\n",
    "                          )\n",
    "            \n",
    "            # multiple test ts(rolling window as half of the prediction_length)\n",
    "            test_rec_cnt = 0\n",
    "            step = -int(prediction_length/2) if half_moving_win else -prediction_length\n",
    "            for endpos in range(totallen, train_len+prediction_length, step):\n",
    "                \n",
    "                track_rec = rec[COL_TRACKSTATUS, :endpos].copy()\n",
    "                lap_rec = rec[COL_LAPSTATUS, :endpos].copy()\n",
    "                \n",
    "                # test mode\n",
    "                if test_flag(oracle_mode, MODE_TESTCURTRACK):\n",
    "                    # since nan does not work, use cur-val instead\n",
    "                    track_rec[-prediction_length:] = track_rec[-prediction_length - 1]\n",
    "                    #track_rec[-prediction_length:] = random.randint(0,1)\n",
    "                    #lap_rec[-prediction_length:] = lap_rec[-prediction_length - 1]\n",
    "                    lap_rec[-prediction_length:] = 0\n",
    "                elif test_flag(oracle_mode, MODE_TESTZERO):\n",
    "                    #set prediction part as nan\n",
    "                    #track_rec[-prediction_length:] = np.nan\n",
    "                    #lap_rec[-prediction_length:] = np.nan\n",
    "                    track_rec[-prediction_length:] = 0\n",
    "                    lap_rec[-prediction_length:] = 0                    \n",
    "                \n",
    "                _test.append({'target': rec[run_ts,:endpos].astype(np.float32), \n",
    "                            'start': start, \n",
    "                            'feat_static_cat': static_cat,\n",
    "                            'feat_dynamic_real': [track_rec,lap_rec]\n",
    "                            #'feat_dynamic_real': [rec[COL_TRACKSTATUS,:endpos],\n",
    "                            #       rec[COL_LAPSTATUS,:endpos]] \n",
    "                             }\n",
    "                          )   \n",
    "                test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'prediction_length:{prediction_length},train len:{len(train_set)}, test len:{len(test_set)}')\n",
    "    \n",
    "    train_ds = ListDataset(train_set, freq=freq)\n",
    "    test_ds = ListDataset(test_set, freq=freq)    \n",
    "    \n",
    "    return train_ds, test_ds, train_set, test_set\n",
    "\n",
    "\n",
    "def make_dataset_byevent(runs, prediction_length, freq, \n",
    "                       useeid = False,\n",
    "                       run_ts=COL_LAPTIME, \n",
    "                       test_event = 'Indy500',\n",
    "                       test_cars = [],  \n",
    "                       use_global_dict = True,\n",
    "                       oracle_mode = MODE_ORACLE,\n",
    "                       half_moving_win = True,\n",
    "                       train_ratio=0.8\n",
    "                ):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    oracle_mode: false to simulate prediction in real by \n",
    "        set the covariates of track and lap status as nan in the testset\n",
    "            \n",
    "    \n",
    "    \"\"\"    \n",
    "    start = pd.Timestamp(\"01-01-2019\", freq=freq)  # can be different for each time series\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #select run\n",
    "    if runs>=0:\n",
    "        _laptime_data = [laptime_data[runs].copy()]\n",
    "    else:\n",
    "        _laptime_data = laptime_data.copy()\n",
    "    \n",
    "   \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        if events[_data[0]] == test_event:\n",
    "            test_mode = True\n",
    "        \n",
    "        else:\n",
    "            test_mode = False\n",
    "            \n",
    "            \n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        max_len = int(np.max(ts_len))\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        \n",
    "        \n",
    "        print(f'====event:{events[_data[0]]}, train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)}')\n",
    "                \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                print(f'a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                continue                \n",
    "            \n",
    "            if use_global_dict:\n",
    "                carno = _data[1][rowid]\n",
    "                carid = global_carids[_data[1][rowid]]\n",
    "            else:\n",
    "                #simulation dataset, todo, fix the carids as decoder\n",
    "                carno = rowid\n",
    "                carid = rowid\n",
    "                \n",
    "            \n",
    "            if useeid:\n",
    "                static_cat = [carid, _data[0]]    \n",
    "            else:\n",
    "                static_cat = [carid]    \n",
    "                \n",
    "            # selection of features\n",
    "            if test_flag(oracle_mode, MODE_NOTRACK):                \n",
    "                rec[COL_TRACKSTATUS, :] = 0\n",
    "            if test_flag(oracle_mode, MODE_NOLAP):                \n",
    "                rec[COL_LAPSTATUS, :] = 0\n",
    "\n",
    "            test_rec_cnt = 0\n",
    "            if not test_mode:\n",
    "                \n",
    "                # all go to train set\n",
    "                _train.append({'target': rec[run_ts,:].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [rec[COL_TRACKSTATUS,:],\n",
    "                                       rec[COL_LAPSTATUS,:]]\n",
    "                              }\n",
    "                              )\n",
    "            else:\n",
    "                # reset train_len\n",
    "                context_len = prediction_length*2\n",
    "                if context_len < 10:\n",
    "                    context_len = 10\n",
    "                \n",
    "                \n",
    "                # multiple test ts(rolling window as half of the prediction_length)\n",
    "\n",
    "                step = -int(prediction_length/2) if half_moving_win else -prediction_length\n",
    "                \n",
    "                #bug fix, fixed the split point for all cars/ts\n",
    "                for endpos in range(max_len, context_len+prediction_length, \n",
    "                                    step):\n",
    "\n",
    "                    #check if enough for this ts\n",
    "                    if endpos > totallen:\n",
    "                        continue\n",
    "                    \n",
    "                    track_rec = rec[COL_TRACKSTATUS, :endpos].copy()\n",
    "                    lap_rec = rec[COL_LAPSTATUS, :endpos].copy()\n",
    "\n",
    "                    # test mode\n",
    "                    if test_flag(oracle_mode, MODE_TESTCURTRACK):\n",
    "                        # since nan does not work, use cur-val instead\n",
    "                        track_rec[-prediction_length:] = track_rec[-prediction_length - 1]\n",
    "                        #track_rec[-prediction_length:] = random.randint(0,1)\n",
    "                        #lap_rec[-prediction_length:] = lap_rec[-prediction_length - 1]\n",
    "                        lap_rec[-prediction_length:] = 0\n",
    "                    elif test_flag(oracle_mode, MODE_TESTZERO):\n",
    "                        #set prediction part as nan\n",
    "                        #track_rec[-prediction_length:] = np.nan\n",
    "                        #lap_rec[-prediction_length:] = np.nan\n",
    "                        track_rec[-prediction_length:] = 0\n",
    "                        lap_rec[-prediction_length:] = 0                    \n",
    "\n",
    "                    _test.append({'target': rec[run_ts,:endpos].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [track_rec,lap_rec]\n",
    "                                #'feat_dynamic_real': [rec[COL_TRACKSTATUS,:endpos],\n",
    "                                #       rec[COL_LAPSTATUS,:endpos]] \n",
    "                                 }\n",
    "                              )   \n",
    "                    test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'train len:{len(train_set)}, test len:{len(test_set)}')\n",
    "    \n",
    "    train_ds = ListDataset(train_set, freq=freq)\n",
    "    test_ds = ListDataset(test_set, freq=freq)    \n",
    "    \n",
    "    return train_ds, test_ds, train_set, test_set\n",
    "\n",
    "def save_dataset(datafile,freq, prediction_length, cardinality, train_ds, test_ds):\n",
    "    with open(datafile, 'wb') as f:\n",
    "        #pack [global_carids, laptime_data]\n",
    "        savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "        #savedata = [freq, train_set, test_set]\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for Indy500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_ds,predictor):\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor=predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    return tss, forecasts\n",
    "\n",
    "def run_prediction(test_ds, prediction_length):\n",
    "    with mx.Context(mx.gpu(7)):    \n",
    "        pred_ret = {}\n",
    "\n",
    "        rootdir = '../models/remote/indy500-logtrans/'\n",
    "        # deepAR-Oracle\n",
    "        model_name = 'deepAR-Oracle-curtrack'\n",
    "        model=f'deepAR-Oracle-timediff-curtrack-indy-f1min-t{prediction_length}-e1000-r1_curtrack_t{prediction_length}'\n",
    "        modeldir = rootdir + model\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  Predictor.deserialize(Path(modeldir))\n",
    "        print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # deepAR-Oracle\n",
    "        model_name = 'deepAR-Oracle'\n",
    "        model=f'deepAR-Oracle-timediff-all-indy-f1min-t{prediction_length}-e1000-r1_oracle_t{prediction_length}'\n",
    "        modeldir = rootdir + model\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  Predictor.deserialize(Path(modeldir))\n",
    "        print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # deepAR\n",
    "        model_name = 'deepAR'\n",
    "        model=f'deepAR-timediff-all-indy-f1min-t{prediction_length}-e1000-r1_deepar_t{prediction_length}'\n",
    "        modeldir = rootdir + model\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  Predictor.deserialize(Path(modeldir))\n",
    "        print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # naive\n",
    "        model_name = 'naive'\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  NaivePredictor(freq= freq, prediction_length = prediction_length)\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # arima\n",
    "        model_name = 'arima'\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  RForecastPredictor(method_name='arima',freq= freq, \n",
    "                                        prediction_length = prediction_length,trunc_length=60)\n",
    "        #tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        return pred_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc rank\n",
    "def eval_rank_bytimediff(test_ds,tss,forecasts,prediction_length):\n",
    "    \"\"\"\n",
    "    timediff models\n",
    "    \n",
    "    works for one event only\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        #forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        \n",
    "        timediff_array = tss[idx].values.copy()\n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        forecasts_et[completed_laps][carno] = [timediff_array[-prediction_len:].copy(),\n",
    "                                                   forecast_laptime_mean.copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        time_diff = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            time_diff[0, carid, :] = forecasts_et[lap][carno][0].reshape((prediction_len))\n",
    "            time_diff[1, carid, :] = forecasts_et[lap][carno][1].reshape((prediction_len))\n",
    "\n",
    "        #calculate rank    \n",
    "        idx = np.argsort(time_diff[0], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        idx = np.argsort(time_diff[1], axis=0)\n",
    "        pred_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        rank_ret.append([lap, time_diff, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et\n",
    "    \n",
    "   \n",
    "   \n",
    "def get_acc(rank_ret,prediction_length):    \n",
    "    # evaluate\n",
    "    #top1 accuracy\n",
    "    top1acc = 0\n",
    "    top1acc_farmost = 0\n",
    "    top5acc = 0\n",
    "    top5acc_farmost = 0\n",
    "    tau = 0\n",
    "    rmse = 0.\n",
    "    \n",
    "    for rec in rank_ret:\n",
    "        trueRank = rec[2]\n",
    "        predRank = rec[3]\n",
    "\n",
    "        #top1 , rank = 0, first col is not prediction\n",
    "        top1acc += np.sum((trueRank==0) & (predRank==0)) \n",
    "        \n",
    "        top1acc_farmost += np.sum((trueRank[:,-1]==0) & (predRank[:,-1]==0))\n",
    "        \n",
    "        #top5\n",
    "        top5acc += np.sum((trueRank<5) & (predRank<5)) \n",
    "        \n",
    "        top5acc_farmost += np.sum((trueRank[:,-1]<5) & (predRank[:,-1]<5))\n",
    "        \n",
    "        # tau\n",
    "        tao, _ = stats.kendalltau(trueRank, predRank)\n",
    "        tau += tao\n",
    "        \n",
    "        #rmse\n",
    "        rmse += mean_squared_error(predRank,trueRank)\n",
    "        \n",
    "\n",
    "    print(f'total:{len(rank_ret)}, prediction_length:{prediction_length}') \n",
    "    print('top1acc=', top1acc *1.0/ (len(rank_ret)*prediction_length),\n",
    "          'top1acc_farmost=', top1acc_farmost *1.0/ (len(rank_ret)),\n",
    "          'top5acc=', top5acc *1.0/ (5*len(rank_ret)*prediction_length),\n",
    "          'top5acc_farmost=', top5acc_farmost *1.0/ (5*len(rank_ret)),\n",
    "         )\n",
    "    print('tau = ', tau/len(rank_ret),\n",
    "         'rmse = ', rmse/len(rank_ret))\n",
    "    \n",
    "def get_top1acc_farmost(rank_ret,prediction_len):    \n",
    "    # evaluate\n",
    "    #top1 accuracy\n",
    "    hitcnt = 0\n",
    "    for rec in rank_ret:\n",
    "        trueRank = rec[2]\n",
    "        predRank = rec[3]\n",
    "\n",
    "        #top1 , rank = 0, first col is not prediction\n",
    "        hitcnt += np.sum((trueRank[:,-1]==0) & (predRank[:,-1]==0)) \n",
    "\n",
    "    print('total:', hitcnt, 'top1acc_farmost=', hitcnt *1.0/ (len(rank_ret)*prediction_length))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(prediction_length, half_moving_win):\n",
    "    ### create test dataset\n",
    "    test_cars = []\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(-1, prediction_length,freq, \n",
    "                                         oracle_mode=MODE_TESTCURTRACK,\n",
    "                                         run_ts = COL_TIMEDIFF,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win)\n",
    "    pred_ret = run_prediction(test_ds, prediction_length)\n",
    "\n",
    "    models = ['deepAR-Oracle','deepAR-Oracle-curtrack','deepAR','naive','arima']\n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = pred_ret[model]\n",
    "\n",
    "        rank_ret,_ = eval_rank_bytimediff(test_ds,tss,forecasts,prediction_length)\n",
    "        get_acc(rank_ret,prediction_length)\n",
    "        \n",
    "    return pred_ret, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# parameters\n",
    "#\n",
    "#year = '2017'\n",
    "year = '2018'\n",
    "#event = 'Toronto'\n",
    "#https://www.racing-reference.info/season-stats/2018/O/#\n",
    "events_totalmiles=[256,500,372,268,500,310]\n",
    "events_laplen = [1.022,2.5,1.5,0.894,2.5,1.25]\n",
    "events = ['Phoenix','Indy500','Texas','Iowa','Pocono','Gateway']\n",
    "#events = ['Gateway']\n",
    "\n",
    "#events = ['Indy500']\n",
    "#events = ['Phoenix']\n",
    "events_id={key:idx for idx, key in enumerate(events)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from here\n",
    "import pickle\n",
    "with open('laptime_rank_timediff-oracle-%s.pickle'%year, 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    global_carids, laptime_data = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"1min\"\n",
    "#decode global_carids\n",
    "decode_carids={carid:carno for carno, carid in global_carids.items()}\n",
    "    \n",
    "#useeid = False\n",
    "#interpolate = False\n",
    "#ipstr = '-ip' if interpolate else '-noip'\n",
    "#ipstr = '%s-%s'%('ip' if interpolate else 'noip', 'eid' if useeid else 'noeid')\n",
    "#if useeid:\n",
    "#    cardinality = [len(global_carids), len(laptime_data)]\n",
    "#else:\n",
    "#    cardinality = [len(global_carids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====event:Phoenix, train_len=200, max_len=250, min_len=250\n",
      "carno:1, totallen:250, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:241, nancount:9, test_reccnt:0\n",
      "carno:5, totallen:250, nancount:0, test_reccnt:0\n",
      "carno:6, totallen:250, nancount:0, test_reccnt:0\n",
      "carno:9, totallen:250, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:229, nancount:21, test_reccnt:0\n",
      "a short ts: carid=12，len=154\n",
      "carno:14, totallen:250, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:250, nancount:0, test_reccnt:0\n",
      "carno:18, totallen:249, nancount:1, test_reccnt:0\n",
      "a short ts: carid=19，len=40\n",
      "carno:20, totallen:250, nancount:0, test_reccnt:0\n",
      "carno:21, totallen:249, nancount:1, test_reccnt:0\n",
      "carno:22, totallen:250, nancount:0, test_reccnt:0\n",
      "carno:23, totallen:248, nancount:2, test_reccnt:0\n",
      "carno:26, totallen:249, nancount:1, test_reccnt:0\n",
      "carno:27, totallen:250, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:250, nancount:0, test_reccnt:0\n",
      "carno:30, totallen:250, nancount:0, test_reccnt:0\n",
      "a short ts: carid=32，len=174\n",
      "carno:59, totallen:247, nancount:3, test_reccnt:0\n",
      "carno:88, totallen:249, nancount:1, test_reccnt:0\n",
      "carno:98, totallen:249, nancount:1, test_reccnt:0\n",
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:94\n",
      "a short ts: carid=3，len=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:90\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:94\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:94\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:87\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:93\n",
      "a short ts: carid=18，len=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:93\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:93\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:94\n",
      "a short ts: carid=24，len=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:93\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:94\n",
      "a short ts: carid=30，len=46\n",
      "a short ts: carid=32，len=110\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:93\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:94\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:94\n",
      "====event:Texas, train_len=198, max_len=248, min_len=248\n",
      "carno:1, totallen:244, nancount:4, test_reccnt:0\n",
      "a short ts: carid=3，len=2\n",
      "a short ts: carid=4，len=5\n",
      "carno:5, totallen:248, nancount:0, test_reccnt:0\n",
      "a short ts: carid=6，len=171\n",
      "a short ts: carid=7，len=2\n",
      "carno:9, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:204, nancount:44, test_reccnt:0\n",
      "a short ts: carid=14，len=31\n",
      "carno:15, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:18, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:19, totallen:205, nancount:43, test_reccnt:0\n",
      "a short ts: carid=20，len=168\n",
      "carno:21, totallen:247, nancount:1, test_reccnt:0\n",
      "carno:22, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:23, totallen:247, nancount:1, test_reccnt:0\n",
      "a short ts: carid=25，len=2\n",
      "carno:26, totallen:238, nancount:10, test_reccnt:0\n",
      "carno:27, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:30, totallen:248, nancount:0, test_reccnt:0\n",
      "a short ts: carid=47，len=2\n",
      "a short ts: carid=55，len=2\n",
      "a short ts: carid=57，len=2\n",
      "carno:59, totallen:247, nancount:1, test_reccnt:0\n",
      "a short ts: carid=60，len=2\n",
      "a short ts: carid=68，len=2\n",
      "a short ts: carid=73，len=2\n",
      "a short ts: carid=83，len=2\n",
      "carno:88, totallen:240, nancount:8, test_reccnt:0\n",
      "carno:98, totallen:244, nancount:4, test_reccnt:0\n",
      "====event:Iowa, train_len=240, max_len=300, min_len=300\n",
      "carno:1, totallen:300, nancount:0, test_reccnt:0\n",
      "a short ts: carid=4，len=41\n",
      "carno:5, totallen:300, nancount:0, test_reccnt:0\n",
      "carno:6, totallen:300, nancount:0, test_reccnt:0\n",
      "carno:9, totallen:296, nancount:4, test_reccnt:0\n",
      "carno:10, totallen:295, nancount:5, test_reccnt:0\n",
      "carno:12, totallen:299, nancount:1, test_reccnt:0\n",
      "carno:14, totallen:292, nancount:8, test_reccnt:0\n",
      "carno:15, totallen:299, nancount:1, test_reccnt:0\n",
      "carno:18, totallen:297, nancount:3, test_reccnt:0\n",
      "carno:19, totallen:291, nancount:9, test_reccnt:0\n",
      "carno:20, totallen:298, nancount:2, test_reccnt:0\n",
      "carno:21, totallen:300, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:299, nancount:1, test_reccnt:0\n",
      "carno:23, totallen:295, nancount:5, test_reccnt:0\n",
      "carno:26, totallen:279, nancount:21, test_reccnt:0\n",
      "carno:27, totallen:298, nancount:2, test_reccnt:0\n",
      "carno:28, totallen:283, nancount:17, test_reccnt:0\n",
      "carno:30, totallen:300, nancount:0, test_reccnt:0\n",
      "carno:59, totallen:294, nancount:6, test_reccnt:0\n",
      "a short ts: carid=88，len=100\n",
      "carno:98, totallen:293, nancount:7, test_reccnt:0\n",
      "====event:Pocono, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:199, nancount:1, test_reccnt:0\n",
      "carno:4, totallen:197, nancount:3, test_reccnt:0\n",
      "a short ts: carid=5，len=6\n",
      "a short ts: carid=6，len=6\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:197, nancount:3, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "a short ts: carid=14，len=16\n",
      "carno:15, totallen:196, nancount:4, test_reccnt:0\n",
      "carno:18, totallen:200, nancount:0, test_reccnt:0\n",
      "a short ts: carid=19，len=6\n",
      "carno:20, totallen:197, nancount:3, test_reccnt:0\n",
      "a short ts: carid=21，len=17\n",
      "carno:22, totallen:199, nancount:1, test_reccnt:0\n",
      "carno:23, totallen:198, nancount:2, test_reccnt:0\n",
      "carno:26, totallen:199, nancount:1, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "a short ts: carid=28，len=6\n",
      "a short ts: carid=30，len=6\n",
      "carno:59, totallen:196, nancount:4, test_reccnt:0\n",
      "carno:88, totallen:162, nancount:38, test_reccnt:0\n",
      "carno:98, totallen:199, nancount:1, test_reccnt:0\n",
      "====event:Gateway, train_len=198, max_len=248, min_len=248\n",
      "carno:1, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:246, nancount:2, test_reccnt:0\n",
      "carno:5, totallen:246, nancount:2, test_reccnt:0\n",
      "carno:9, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:246, nancount:2, test_reccnt:0\n",
      "carno:15, totallen:247, nancount:1, test_reccnt:0\n",
      "a short ts: carid=18，len=0\n",
      "carno:19, totallen:247, nancount:1, test_reccnt:0\n",
      "carno:20, totallen:247, nancount:1, test_reccnt:0\n",
      "carno:21, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:23, totallen:235, nancount:13, test_reccnt:0\n",
      "carno:26, totallen:248, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:248, nancount:0, test_reccnt:0\n",
      "a short ts: carid=28，len=173\n",
      "carno:30, totallen:247, nancount:1, test_reccnt:0\n",
      "carno:59, totallen:244, nancount:4, test_reccnt:0\n",
      "carno:88, totallen:242, nancount:6, test_reccnt:0\n",
      "carno:98, totallen:246, nancount:2, test_reccnt:0\n",
      "train len:92, test len:2334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting model=deepAR-Oracle-curtrack, plen=2\n"
     ]
    }
   ],
   "source": [
    "# test half moving win\n",
    "pred_ret2_nohalfwin, test_ds2 = run_exp(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ret2_halfwin, test_ds2h = run_exp(2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test half moving win\n",
    "pred_ret5_halfwin, test_ds5h = run_exp(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test half moving win\n",
    "pred_ret5_nohalfwin, test_ds5 = run_exp(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ret10_halfwin, test_ds10 = run_exp(10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ret10_nohalfwin, test_ds10h = run_exp(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plen = 10\n",
    "pred_ret10_halfwin, test_ds10 = run_exp(10, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'deepAR-Oracle'\n",
    "tss10, forecasts10 = pred_ret10_halfwin[model]\n",
    "rank_ret10, fet10 = eval_rank_bytimediff(test_ds10,tss10,forecasts10,plen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(fet10.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[rank_ret10[x][1].shape for x in range(0,len(rank_ret10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rank_ret10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'naive'\n",
    "ntss10, nforecasts10 = pred_ret10_halfwin[model]\n",
    "rank_ret10_naive,_ = eval_rank_bytimediff(test_ds10,ntss10,nforecasts10,plen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ret10_naive[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 0\n",
    "for idx, rr in enumerate(rank_ret10_naive):\n",
    "    x1 = rr[2][:,:]\n",
    "    x2 = rr[3][:,:]\n",
    "    \n",
    "    tao, _ = stats.kendalltau(x1, x2)\n",
    "    print(idx, tao)\n",
    "    tau += tao\n",
    "\n",
    "print(len(rank_ret10))\n",
    "print(tau/len(rank_ret10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_ds10), len(rank_ret10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[rank_ret10[x][1].shape for x in range(0,len(rank_ret10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ret2[15][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 0\n",
    "for rr in rank_ret:\n",
    "    x1 = rr[2][:,:]\n",
    "    x2 = rr[3][:,:]\n",
    "    \n",
    "    tao, _ = stats.kendalltau(x1, x2)\n",
    "    print(tao)\n",
    "    tau += tao\n",
    "\n",
    "print(len(rank_ret))\n",
    "print(tau/len(rank_ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts[0].samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
