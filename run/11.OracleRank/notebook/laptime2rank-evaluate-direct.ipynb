{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laptime2Rank-Evaluate\n",
    "\n",
    "based on: Laptime2Rank-indy500-incremental\n",
    "\n",
    "rank prediction by laptime forecasting models\n",
    "\n",
    "support:\n",
    "+ train/test split by ratio or event\n",
    "+ incremental training evaluation(adjust ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "ERROR:fbprophet:Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pathlib import Path\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.distribution.multivariate_gaussian import MultivariateGaussianOutput\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.model.prophet import ProphetPredictor\n",
    "from gluonts.model.r_forecast import RForecastPredictor\n",
    "from indycar.model.NaivePredictor import NaivePredictor\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/hpda/indycar/notebook/11.OracleRank'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "#GPUID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(event, year):\n",
    "    inputfile = '../data/final/C_'+ event +'-' + year + '-final.csv'\n",
    "    outputprefix = year +'-' + event + '-'\n",
    "    dataset = pd.read_csv(inputfile)\n",
    "    #dataset.info(verbose=True)    \n",
    "    \n",
    "    final_lap = max(dataset.completed_laps)\n",
    "    total_laps = final_lap + 1\n",
    "\n",
    "    # get records for the cars that finish the race\n",
    "    completed_car_numbers= dataset[dataset.completed_laps == final_lap].car_number.values\n",
    "    completed_car_count = len(completed_car_numbers)\n",
    "\n",
    "    print('count of completed cars:', completed_car_count)\n",
    "    print('completed cars:', completed_car_numbers)\n",
    "\n",
    "    #make a copy\n",
    "    alldata = dataset.copy()\n",
    "    dataset = dataset[dataset['car_number'].isin(completed_car_numbers)]\n",
    "    rankdata = alldata.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "    \n",
    "    cldata = make_cl_data(dataset)\n",
    "    acldata = make_cl_data(alldata)\n",
    "\n",
    "    return alldata, rankdata, acldata\n",
    "\n",
    "# make indy car completed_laps dataset\n",
    "# car_number, completed_laps, rank, elapsed_time, rank_diff, elapsed_time_diff \n",
    "def make_cl_data(dataset):\n",
    "\n",
    "    # pick up data with valid rank\n",
    "    rankdata = dataset.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "\n",
    "    # resort by car_number, lap\n",
    "    uni_ds = rankdata.sort_values(by=['car_number', 'completed_laps', 'elapsed_time'], ascending=True)    \n",
    "    #uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \"current_status\", \"track_status\", \"lap_status\",\n",
    "    #                  \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "    #                  \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "    \n",
    "    uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \n",
    "                      \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "                      \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "        \n",
    "    carnumber = set(uni_ds['car_number'])\n",
    "    print('cars:', carnumber)\n",
    "    print('#cars=', len(carnumber))\n",
    "   \n",
    "    # faster solution , uni_ds already sorted by car_number and lap\n",
    "    uni_ds['rank_diff'] = uni_ds['rank'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['rank_diff'][mask] = 0\n",
    "    \n",
    "    uni_ds['time_diff'] = uni_ds['elapsed_time'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['time_diff'][mask] = 0\n",
    "    \n",
    "    #df = uni_ds[['car_number','completed_laps','rank','elapsed_time','rank_diff','time_diff']]\n",
    "    df = uni_ds[['car_number','completed_laps','rank','elapsed_time',\n",
    "                 'rank_diff','time_diff',\"current_status\", \"track_status\", \"lap_status\"]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def test_flag(a, bitflag):\n",
    "    return (a & bitflag) ==  bitflag\n",
    "\n",
    "#\n",
    "# remove NaN at the tail\n",
    "# there should be no nans in the middle of the ts\n",
    "COL_LAPTIME=0\n",
    "COL_RANK=1\n",
    "COL_TRACKSTATUS=2\n",
    "COL_LAPSTATUS=3\n",
    "COL_TIMEDIFF=4\n",
    "MODE_ORACLE = 0\n",
    "MODE_NOLAP = 1\n",
    "MODE_NOTRACK = 2\n",
    "MODE_TESTZERO = 4\n",
    "MODE_TESTCURTRACK = 8\n",
    "#MODE_STR={MODE_ORACLE:'oracle', MODE_NOLAP:'nolap',MODE_NOTRACK:'notrack',MODE_TEST:'test'}\n",
    "\n",
    "def make_dataset(runs, prediction_length, freq, \n",
    "                       useeid = False,\n",
    "                       run_ts=COL_LAPTIME, \n",
    "                       train_ratio = 0.8,\n",
    "                       use_global_dict = True,\n",
    "                       oracle_mode = MODE_ORACLE,\n",
    "                       test_cars = [],\n",
    "                       half_moving_win = True \n",
    "                ):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    oracle_mode: false to simulate prediction in real by \n",
    "        set the covariates of track and lap status as nan in the testset\n",
    "            \n",
    "    \n",
    "    \"\"\"    \n",
    "    start = pd.Timestamp(\"01-01-2019\", freq=freq)  # can be different for each time series\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #select run\n",
    "    if runs>=0:\n",
    "        _laptime_data = [laptime_data[runs].copy()]\n",
    "    else:\n",
    "        _laptime_data = laptime_data.copy()\n",
    "    \n",
    "   \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        max_len = int(np.max(ts_len))\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        \n",
    "        print(f'====event:{events[_data[0]]}, train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)}')\n",
    "                \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                print(f'a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                continue                \n",
    "            \n",
    "            if use_global_dict:\n",
    "                carno = _data[1][rowid]\n",
    "                carid = global_carids[_data[1][rowid]]\n",
    "            else:\n",
    "                #simulation dataset, todo, fix the carids as decoder\n",
    "                carno = rowid\n",
    "                carid = rowid\n",
    "\n",
    "            #eval on carids\n",
    "            if test_cars and (carno not in test_cars):\n",
    "                continue                \n",
    "            \n",
    "            if useeid:\n",
    "                static_cat = [carid, _data[0]]    \n",
    "            else:\n",
    "                static_cat = [carid]    \n",
    "                \n",
    "            # selection of features\n",
    "            if test_flag(oracle_mode, MODE_NOTRACK):                \n",
    "                rec[COL_TRACKSTATUS, :] = 0\n",
    "            if test_flag(oracle_mode, MODE_NOLAP):                \n",
    "                rec[COL_LAPSTATUS, :] = 0\n",
    "                \n",
    "            # split and add to dataset record\n",
    "            _train.append({'target': rec[run_ts,:train_len].astype(np.float32), \n",
    "                            'start': start, \n",
    "                            'feat_static_cat': static_cat,\n",
    "                            'feat_dynamic_real': [rec[COL_TRACKSTATUS,:train_len],\n",
    "                                   rec[COL_LAPSTATUS,:train_len]]\n",
    "                          }\n",
    "                          )\n",
    "            \n",
    "            # multiple test ts(rolling window as half of the prediction_length)\n",
    "            test_rec_cnt = 0\n",
    "            step = -int(prediction_length/2) if half_moving_win else -prediction_length\n",
    "            for endpos in range(max_len, train_len+prediction_length, step):\n",
    "                \n",
    "                \n",
    "                #check if enough for this ts\n",
    "                if endpos > totallen:\n",
    "                    continue\n",
    "                        \n",
    "                track_rec = rec[COL_TRACKSTATUS, :endpos].copy()\n",
    "                lap_rec = rec[COL_LAPSTATUS, :endpos].copy()\n",
    "                \n",
    "                # test mode\n",
    "                if test_flag(oracle_mode, MODE_TESTCURTRACK):\n",
    "                    # since nan does not work, use cur-val instead\n",
    "                    track_rec[-prediction_length:] = track_rec[-prediction_length - 1]\n",
    "                    #track_rec[-prediction_length:] = random.randint(0,1)\n",
    "                    #lap_rec[-prediction_length:] = lap_rec[-prediction_length - 1]\n",
    "                    lap_rec[-prediction_length:] = 0\n",
    "                elif test_flag(oracle_mode, MODE_TESTZERO):\n",
    "                    #set prediction part as nan\n",
    "                    #track_rec[-prediction_length:] = np.nan\n",
    "                    #lap_rec[-prediction_length:] = np.nan\n",
    "                    track_rec[-prediction_length:] = 0\n",
    "                    lap_rec[-prediction_length:] = 0                    \n",
    "                \n",
    "                _test.append({'target': rec[run_ts,:endpos].astype(np.float32), \n",
    "                            'start': start, \n",
    "                            'feat_static_cat': static_cat,\n",
    "                            'feat_dynamic_real': [track_rec,lap_rec]\n",
    "                            #'feat_dynamic_real': [rec[COL_TRACKSTATUS,:endpos],\n",
    "                            #       rec[COL_LAPSTATUS,:endpos]] \n",
    "                             }\n",
    "                          )   \n",
    "                test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'prediction_length:{prediction_length},train len:{len(train_set)}, test len:{len(test_set)}')\n",
    "    \n",
    "    train_ds = ListDataset(train_set, freq=freq)\n",
    "    test_ds = ListDataset(test_set, freq=freq)    \n",
    "    \n",
    "    return train_ds, test_ds, train_set, test_set\n",
    "\n",
    "def make_dataset_byevent(runs, prediction_length, freq, \n",
    "                       useeid = False,\n",
    "                       run_ts=COL_LAPTIME, \n",
    "                       test_event = 'Indy500',\n",
    "                       test_cars = [],  \n",
    "                       use_global_dict = True,\n",
    "                       oracle_mode = MODE_ORACLE,\n",
    "                       half_moving_win = True,\n",
    "                       train_ratio=0.8\n",
    "                ):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    oracle_mode: false to simulate prediction in real by \n",
    "        set the covariates of track and lap status as nan in the testset\n",
    "            \n",
    "    \n",
    "    \"\"\"    \n",
    "    start = pd.Timestamp(\"01-01-2019\", freq=freq)  # can be different for each time series\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #select run\n",
    "    if runs>=0:\n",
    "        _laptime_data = [laptime_data[runs].copy()]\n",
    "    else:\n",
    "        _laptime_data = laptime_data.copy()\n",
    "    \n",
    "   \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        if events[_data[0]] == test_event:\n",
    "            test_mode = True\n",
    "        \n",
    "        else:\n",
    "            test_mode = False\n",
    "            \n",
    "            \n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        max_len = int(np.max(ts_len))\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        \n",
    "        \n",
    "        print(f'====event:{events[_data[0]]}, train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)}')\n",
    "                \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                print(f'a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                continue                \n",
    "            \n",
    "            if use_global_dict:\n",
    "                carno = _data[1][rowid]\n",
    "                carid = global_carids[_data[1][rowid]]\n",
    "            else:\n",
    "                #simulation dataset, todo, fix the carids as decoder\n",
    "                carno = rowid\n",
    "                carid = rowid\n",
    "                \n",
    "            \n",
    "            if useeid:\n",
    "                static_cat = [carid, _data[0]]    \n",
    "            else:\n",
    "                static_cat = [carid]    \n",
    "                \n",
    "            # selection of features\n",
    "            if test_flag(oracle_mode, MODE_NOTRACK):                \n",
    "                rec[COL_TRACKSTATUS, :] = 0\n",
    "            if test_flag(oracle_mode, MODE_NOLAP):                \n",
    "                rec[COL_LAPSTATUS, :] = 0\n",
    "\n",
    "            test_rec_cnt = 0\n",
    "            if not test_mode:\n",
    "                \n",
    "                # all go to train set\n",
    "                _train.append({'target': rec[run_ts,:].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [rec[COL_TRACKSTATUS,:],\n",
    "                                       rec[COL_LAPSTATUS,:]]\n",
    "                              }\n",
    "                              )\n",
    "            else:\n",
    "                # reset train_len\n",
    "                #context_len = prediction_length*2\n",
    "                #if context_len < 10:\n",
    "                #    context_len = 10\n",
    "                \n",
    "                context_len = train_len\n",
    "                \n",
    "                # multiple test ts(rolling window as half of the prediction_length)\n",
    "\n",
    "                step = -int(prediction_length/2) if half_moving_win else -prediction_length\n",
    "                \n",
    "                #bug fix, fixed the split point for all cars/ts\n",
    "                for endpos in range(max_len, context_len+prediction_length, \n",
    "                                    step):\n",
    "\n",
    "                    #check if enough for this ts\n",
    "                    if endpos > totallen:\n",
    "                        continue\n",
    "                    \n",
    "                    track_rec = rec[COL_TRACKSTATUS, :endpos].copy()\n",
    "                    lap_rec = rec[COL_LAPSTATUS, :endpos].copy()\n",
    "\n",
    "                    # test mode\n",
    "                    if test_flag(oracle_mode, MODE_TESTCURTRACK):\n",
    "                        # since nan does not work, use cur-val instead\n",
    "                        track_rec[-prediction_length:] = track_rec[-prediction_length - 1]\n",
    "                        #track_rec[-prediction_length:] = random.randint(0,1)\n",
    "                        #lap_rec[-prediction_length:] = lap_rec[-prediction_length - 1]\n",
    "                        lap_rec[-prediction_length:] = 0\n",
    "                    elif test_flag(oracle_mode, MODE_TESTZERO):\n",
    "                        #set prediction part as nan\n",
    "                        #track_rec[-prediction_length:] = np.nan\n",
    "                        #lap_rec[-prediction_length:] = np.nan\n",
    "                        track_rec[-prediction_length:] = 0\n",
    "                        lap_rec[-prediction_length:] = 0                    \n",
    "\n",
    "                    _test.append({'target': rec[run_ts,:endpos].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [track_rec,lap_rec]\n",
    "                                #'feat_dynamic_real': [rec[COL_TRACKSTATUS,:endpos],\n",
    "                                #       rec[COL_LAPSTATUS,:endpos]] \n",
    "                                 }\n",
    "                              )   \n",
    "                    test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'train len:{len(train_set)}, test len:{len(test_set)}')\n",
    "    \n",
    "    train_ds = ListDataset(train_set, freq=freq)\n",
    "    test_ds = ListDataset(test_set, freq=freq)    \n",
    "    \n",
    "    return train_ds, test_ds, train_set, test_set\n",
    "\n",
    "def save_dataset(datafile,freq, prediction_length, cardinality, train_ds, test_ds):\n",
    "    with open(datafile, 'wb') as f:\n",
    "        #pack [global_carids, laptime_data]\n",
    "        savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "        #savedata = [freq, train_set, test_set]\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for Indy500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_ds,predictor):\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor=predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    return tss, forecasts\n",
    "\n",
    "   \n",
    "def run_prediction(test_ds, prediction_length, trainid):\n",
    "    with mx.Context(mx.gpu(7)):    \n",
    "        pred_ret = {}\n",
    "\n",
    "        rootdir = f'../models/remote/laptime-{trainid}/'\n",
    "        # deepAR-Oracle\n",
    "        model_name = 'deepAR-Oracle-curtrack'\n",
    "        model=f'deepAR-Oracle-laptime-curtrack-indy-f1min-t{prediction_length}-e1000-r1_curtrack_t{prediction_length}'\n",
    "        modeldir = rootdir + model\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  Predictor.deserialize(Path(modeldir))\n",
    "        print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # deepAR-Oracle\n",
    "        model_name = 'deepAR-Oracle'\n",
    "        model=f'deepAR-Oracle-laptime-all-indy-f1min-t{prediction_length}-e1000-r1_oracle_t{prediction_length}'\n",
    "        modeldir = rootdir + model\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  Predictor.deserialize(Path(modeldir))\n",
    "        print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # deepAR\n",
    "        model_name = 'deepAR'\n",
    "        model=f'deepAR-laptime-all-indy-f1min-t{prediction_length}-e1000-r1_deepar_t{prediction_length}'\n",
    "        modeldir = rootdir + model\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  Predictor.deserialize(Path(modeldir))\n",
    "        print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # naive\n",
    "        model_name = 'naive'\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  NaivePredictor(freq= freq, prediction_length = prediction_length)\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # arima\n",
    "        model_name = 'arima'\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  RForecastPredictor(method_name='arima',freq= freq, \n",
    "                                        prediction_length = prediction_length,trunc_length=60)\n",
    "        #tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        return pred_ret    \n",
    "    \n",
    "def run_prediction_ex(test_ds, prediction_length, model_name,trainid):\n",
    "    with mx.Context(mx.gpu(7)):    \n",
    "        pred_ret = []\n",
    "\n",
    "        rootdir = f'../models/remote/rank-{trainid}/'\n",
    "        # deepAR-Oracle\n",
    "        if model_name == 'curtrack':\n",
    "            model=f'deepAR-Oracle-rank-curtrack-indy-f1min-t{prediction_length}-e1000-r1'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        elif model_name == 'zerotrack':\n",
    "            model=f'deepAR-Oracle-rank-nolap-zerotrack-indy-f1min-t{prediction_length}-e1000-r1'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "            \n",
    "        # deepAR-Oracle\n",
    "        elif model_name == 'oracle':\n",
    "            model=f'deepAR-Oracle-rank-all-indy-f1min-t{prediction_length}-e1000-r1'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        # deepAR\n",
    "        elif model_name == 'deepAR':\n",
    "            model=f'deepAR-rank-all-indy-f1min-t{prediction_length}-e1000-r1'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        # naive\n",
    "        elif model_name == 'naive':\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  NaivePredictor(freq= freq, prediction_length = prediction_length)\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        # arima\n",
    "        elif model_name == 'arima':\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  RForecastPredictor(method_name='arima',freq= freq, \n",
    "                                            prediction_length = prediction_length,trunc_length=60)\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "        else:\n",
    "            print(f'error: model {model_name} not support yet!')\n",
    "\n",
    "        return pred_ret     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc rank\n",
    "def eval_rank_bytimediff(test_ds,tss,forecasts,prediction_length):\n",
    "    \"\"\"\n",
    "    timediff models\n",
    "    \n",
    "    works for one event only\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        #forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        \n",
    "        timediff_array = tss[idx].values.copy()\n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        forecasts_et[completed_laps][carno] = [timediff_array[-prediction_len:].copy(),\n",
    "                                                   forecast_laptime_mean.copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        time_diff = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            time_diff[0, carid, :] = forecasts_et[lap][carno][0].reshape((prediction_len))\n",
    "            time_diff[1, carid, :] = forecasts_et[lap][carno][1].reshape((prediction_len))\n",
    "\n",
    "        #calculate rank    \n",
    "        #idx = np.argsort(time_diff[0], axis=0)\n",
    "        #true_rank = np.argsort(idx, axis=0)\n",
    "        true_rank = time_diff[0].astype(int)\n",
    "\n",
    "        #idx = np.argsort(time_diff[1], axis=0)\n",
    "        #pred_rank = np.argsort(idx, axis=0)\n",
    "        pred_rank = time_diff[1].astype(int)\n",
    "\n",
    "        rank_ret.append([lap, time_diff, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et\n",
    "    \n",
    "#calc rank\n",
    "def eval_rank(test_ds,tss,forecasts,prediction_length):\n",
    "    \"\"\"\n",
    "    dependency:\n",
    "        start_offset[]; for one specific event\n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        #start_offset is global var\n",
    "        #offset = start_offset[(start_offset['car_number']==carno)].elapsed_time.values[0] \n",
    "        #print('start_offset:', offset)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        #forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "\n",
    "        #laptime_array = tss[idx].values.copy()\n",
    "        #elapsed_time = np.cumsum(laptime_array) + offset\n",
    "        elapsed_time  = tss[idx].values.copy()\n",
    "\n",
    "        #laptime_array = tss[idx].values.copy()\n",
    "        #laptime_array[-prediction_len:] = forecast_laptime_mean \n",
    "        #elapsed_time_hat = np.cumsum(laptime_array) + offset\n",
    "        elapsed_time_hat = tss[idx].values.copy()\n",
    "        elapsed_time_hat[-prediction_len:] = forecast_laptime_mean \n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        #forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len-1:].copy(),\n",
    "        #                                           elapsed_time_hat[-prediction_len-1:].copy()]\n",
    "        forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len:].copy(),\n",
    "                                                   elapsed_time_hat[-prediction_len:].copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        #elapsed_time = np.zeros((2, len(carlist), prediction_len+1))\n",
    "        elapsed_time = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            elapsed_time[0, carid, :] = forecasts_et[lap][carno][0].reshape((prediction_len))\n",
    "            elapsed_time[1, carid, :] = forecasts_et[lap][carno][1].reshape((prediction_len))\n",
    "\n",
    "        #calculate rank    \n",
    "        idx = np.argsort(elapsed_time[0], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        idx = np.argsort(elapsed_time[1], axis=0)\n",
    "        pred_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        rank_ret.append([lap, elapsed_time, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et\n",
    "   \n",
    "def get_acc(rank_ret,prediction_length):    \n",
    "    # evaluate\n",
    "    #top1 accuracy\n",
    "    top1acc = 0\n",
    "    top1acc_farmost = 0\n",
    "    top5acc = 0\n",
    "    top5acc_farmost = 0\n",
    "    tau = 0\n",
    "    rmse = 0.\n",
    "    \n",
    "    for rec in rank_ret:\n",
    "        trueRank = rec[2]\n",
    "        predRank = rec[3]\n",
    "\n",
    "        #top1 , rank = 0, first col is not prediction\n",
    "        top1acc += np.sum((trueRank==0) & (predRank==0)) \n",
    "        \n",
    "        top1acc_farmost += np.sum((trueRank[:,-1]==0) & (predRank[:,-1]==0))\n",
    "        \n",
    "        #top5\n",
    "        top5acc += np.sum((trueRank<5) & (predRank<5)) \n",
    "        \n",
    "        top5acc_farmost += np.sum((trueRank[:,-1]<5) & (predRank[:,-1]<5))\n",
    "        \n",
    "        # tau\n",
    "        tao, _ = stats.kendalltau(trueRank, predRank)\n",
    "        tau += tao\n",
    "        \n",
    "        #rmse\n",
    "        rmse += mean_squared_error(predRank,trueRank)\n",
    "        \n",
    "\n",
    "    top1acc = top1acc *1.0/ (len(rank_ret)*prediction_length)\n",
    "    top1acc_farmost = top1acc_farmost *1.0/ (len(rank_ret))\n",
    "    top5acc = top5acc *1.0/ (5*len(rank_ret)*prediction_length)\n",
    "    top5acc_farmost = top5acc_farmost *1.0/ (5*len(rank_ret))\n",
    "    tau = tau/len(rank_ret)\n",
    "    rmse = rmse/len(rank_ret)\n",
    "    \n",
    "        \n",
    "    print(f'total:{len(rank_ret)}, prediction_length:{prediction_length}') \n",
    "    print('top1acc=', top1acc,\n",
    "          'top1acc_farmost=', top1acc_farmost,\n",
    "          'top5acc=', top5acc,\n",
    "          'top5acc_farmost=', top5acc_farmost,\n",
    "         )\n",
    "    print('tau = ', tau,\n",
    "         'rmse = ', rmse)\n",
    "    \n",
    "    return (top1acc,top1acc_farmost,top5acc,top5acc_farmost,tau,rmse)\n",
    "    \n",
    "def get_top1acc_farmost(rank_ret,prediction_len):    \n",
    "    # evaluate\n",
    "    #top1 accuracy\n",
    "    hitcnt = 0\n",
    "    for rec in rank_ret:\n",
    "        trueRank = rec[2]\n",
    "        predRank = rec[3]\n",
    "\n",
    "        #top1 , rank = 0, first col is not prediction\n",
    "        hitcnt += np.sum((trueRank[:,-1]==0) & (predRank[:,-1]==0)) \n",
    "\n",
    "    print('total:', hitcnt, 'top1acc_farmost=', hitcnt *1.0/ (len(rank_ret)*prediction_length))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp_old(prediction_length, half_moving_win, train_ratio=0.8):\n",
    "    ### create test dataset\n",
    "    test_cars = []\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_TESTCURTRACK,\n",
    "                                         run_ts = COL_LAPTIME,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    pred_ret = run_prediction(test_ds, prediction_length)\n",
    "\n",
    "    models = ['deepAR-Oracle','deepAR-Oracle-curtrack','deepAR','naive','arima']\n",
    "    retdf = []\n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = pred_ret[model]\n",
    "\n",
    "        rank_ret,_ = eval_rank(test_ds,tss,forecasts,prediction_length)\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win]\n",
    "        ret.extend(metrics)\n",
    "        retdf.append(ret)\n",
    "        \n",
    "    return pred_ret, test_ds, retdf\n",
    "\n",
    "def run_exp(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\"):\n",
    "    \"\"\"\n",
    "    dependency: test_event, test on one event only\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    test_cars = []\n",
    "    models = ['oracle','deepAR','naive']\n",
    "    #,'arima']\n",
    "    retdf = []\n",
    "    pred_ret = {}\n",
    "    ds_ret = {}\n",
    "    \n",
    "    ### create test dataset\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_ORACLE,\n",
    "                                         run_ts = COL_RANK,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "\n",
    "        rank_ret,_ = eval_rank(test_ds,tss,forecasts,prediction_length)\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,trainid]\n",
    "        ret.extend(metrics)\n",
    "        retdf.append(ret)\n",
    "    \n",
    "    # special model with test_ds\n",
    "    models = ['curtrack']        \n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_TESTCURTRACK,\n",
    "                                         run_ts = COL_RANK,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "        \n",
    "        rank_ret,_ = eval_rank(test_ds,tss,forecasts,prediction_length)\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,trainid]\n",
    "        ret.extend(metrics)\n",
    "        retdf.append(ret)\n",
    "\n",
    "    # zerotrack\n",
    "    models = ['zerotrack']        \n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_TESTZERO,\n",
    "                                         run_ts = COL_RANK,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "        \n",
    "        rank_ret,_ = eval_rank(test_ds,tss,forecasts,prediction_length)\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,trainid]\n",
    "        ret.extend(metrics)\n",
    "        retdf.append(ret)\n",
    "    \n",
    "        \n",
    "    return pred_ret, ds_ret, retdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# parameters\n",
    "#\n",
    "#year = '2017'\n",
    "year = '2018'\n",
    "#event = 'Toronto'\n",
    "#https://www.racing-reference.info/season-stats/2018/O/#\n",
    "events_totalmiles=[256,500,372,268,500,310]\n",
    "events_laplen = [1.022,2.5,1.5,0.894,2.5,1.25]\n",
    "events = ['Phoenix','Indy500','Texas','Iowa','Pocono','Gateway']\n",
    "#events = ['Gateway']\n",
    "\n",
    "#events = ['Indy500']\n",
    "#events = ['Phoenix']\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "#works for only one event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of completed cars: 11\n",
      "completed cars: [ 1  6 27  9 28  5 20 14 15 22 30]\n",
      "cars: {1, 5, 6, 9, 14, 15, 20, 22, 27, 28, 30}\n",
      "#cars= 11\n",
      "cars: {1, 4, 5, 6, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 32, 59, 88, 98}\n",
      "#cars= 23\n",
      "Phoenix: carno=23, lapnum=251\n",
      "count of completed cars: 18\n",
      "completed cars: [12 20  9 27 28 22 29  1  6 15 66 98  4 88 25 60 64 23]\n",
      "cars: {64, 1, 66, 98, 4, 6, 9, 12, 60, 15, 20, 22, 23, 88, 25, 27, 28, 29}\n",
      "#cars= 18\n",
      "cars: {1, 3, 4, 6, 7, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 59, 60, 64, 66, 88, 98}\n",
      "#cars= 33\n",
      "Indy500: carno=33, lapnum=201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/scratch/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of completed cars: 9\n",
      "completed cars: [ 9 22 27  5 28 15 30 18 10]\n",
      "cars: {5, 9, 10, 15, 18, 22, 27, 28, 30}\n",
      "#cars= 9\n",
      "cars: {1, 3, 4, 5, 6, 7, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 47, 55, 57, 59, 60, 68, 73, 83, 88, 98}\n",
      "#cars= 32\n",
      "Texas: carno=32, lapnum=249\n",
      "count of completed cars: 5\n",
      "completed cars: [ 5 21 30  1  6]\n",
      "cars: {1, 5, 6, 21, 30}\n",
      "#cars= 5\n",
      "cars: {1, 4, 5, 6, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 59, 88, 98}\n",
      "#cars= 22\n",
      "Iowa: carno=22, lapnum=301\n",
      "count of completed cars: 4\n",
      "completed cars: [27 12  9 18]\n",
      "cars: {9, 18, 27, 12}\n",
      "#cars= 4\n",
      "cars: {1, 4, 5, 6, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 59, 88, 98}\n",
      "#cars= 22\n",
      "Pocono: carno=22, lapnum=201\n",
      "count of completed cars: 8\n",
      "completed cars: [12 27  9 22 26 21  1 10]\n",
      "cars: {1, 9, 10, 12, 21, 22, 26, 27}\n",
      "#cars= 8\n",
      "cars: {1, 4, 5, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 59, 88, 98}\n",
      "#cars= 21\n",
      "Gateway: carno=21, lapnum=249\n"
     ]
    }
   ],
   "source": [
    "stagedata = {}\n",
    "global_carids = {}\n",
    "traindata = None\n",
    "cur_carid = 0\n",
    "for event in events:\n",
    "    #alldata, rankdata, acldata, flagdata\n",
    "    stagedata[event] = load_data(event, year)\n",
    "    \n",
    "    alldata, rankdata, acldata = stagedata[event]\n",
    "    carlist = set(acldata['car_number'])\n",
    "    laplist = set(acldata['completed_laps'])\n",
    "    print('%s: carno=%d, lapnum=%d'%(event, len(carlist), len(laplist)))\n",
    "\n",
    "    #build the carid map\n",
    "    for car in carlist:\n",
    "        if car not in global_carids:\n",
    "            global_carids[car] = cur_carid\n",
    "            cur_carid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "event='Indy500'\n",
    "test_event = event\n",
    "alldata, rankdata, acldata = stagedata[event]\n",
    "final_lap = max(rankdata.completed_laps)\n",
    "completed_car_numbers= rankdata[rankdata.completed_laps == final_lap].car_number.values\n",
    "\n",
    "start_offset = rankdata[rankdata['completed_laps']==0][['car_number','elapsed_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from here\n",
    "import pickle\n",
    "with open('laptime_rank_timediff-oracle-%s.pickle'%year, 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    global_carids, laptime_data = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"1min\"\n",
    "#decode global_carids\n",
    "decode_carids={carid:carno for carno, carid in global_carids.items()}\n",
    "    \n",
    "#useeid = False\n",
    "#interpolate = False\n",
    "#ipstr = '-ip' if interpolate else '-noip'\n",
    "#ipstr = '%s-%s'%('ip' if interpolate else 'noip', 'eid' if useeid else 'noeid')\n",
    "#if useeid:\n",
    "#    cardinality = [len(global_carids), len(laptime_data)]\n",
    "#else:\n",
    "#    cardinality = [len(global_carids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=3，len=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:15\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:12\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:18\n",
      "a short ts: carid=18，len=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:18\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:18\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=24，len=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:18\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=30，len=46\n",
      "a short ts: carid=32，len=110\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:18\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:19\n",
      "train len:0, test len:459\n",
      "model: oracle\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=459, forecasts len=459\n",
      "total:19, prediction_length:2\n",
      "top1acc= 0.7631578947368421 top1acc_farmost= 0.7368421052631579 top5acc= 0.9105263157894737 top5acc_farmost= 0.8631578947368421\n",
      "tau =  0.9051721583855785 rmse =  4.708682939232139\n",
      "model: deepAR\n",
      "predicting model=deepAR, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=459, forecasts len=459\n",
      "total:19, prediction_length:2\n",
      "top1acc= 0.6578947368421053 top1acc_farmost= 0.5789473684210527 top5acc= 0.9052631578947369 top5acc_farmost= 0.8526315789473684\n",
      "tau =  0.8998318390527972 rmse =  5.089914823290108\n",
      "model: naive\n",
      "predicting model=naive, plen=2\n",
      "tss len=459, forecasts len=459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n",
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total:19, prediction_length:2\n",
      "top1acc= 0.7105263157894737 top1acc_farmost= 0.631578947368421 top5acc= 0.9105263157894737 top5acc_farmost= 0.8631578947368421\n",
      "tau =  0.9194350253103112 rmse =  4.384855072463768\n",
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=3，len=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:15\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:12\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:18\n",
      "a short ts: carid=18，len=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:18\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:18\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=24，len=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:18\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=30，len=46\n",
      "a short ts: carid=32，len=110\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:18\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:19\n",
      "train len:0, test len:459\n",
      "model: curtrack\n",
      "predicting model=curtrack, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=459, forecasts len=459\n",
      "total:19, prediction_length:2\n",
      "top1acc= 0.6842105263157895 top1acc_farmost= 0.631578947368421 top5acc= 0.9105263157894737 top5acc_farmost= 0.8631578947368421\n",
      "tau =  0.902620069316125 rmse =  4.997405288583778\n",
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=3，len=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:15\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:12\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:18\n",
      "a short ts: carid=18，len=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:18\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:18\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=24，len=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:18\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:19\n",
      "a short ts: carid=30，len=46\n",
      "a short ts: carid=32，len=110\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:18\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:19\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:19\n",
      "train len:0, test len:459\n",
      "model: zerotrack\n",
      "predicting model=zerotrack, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=459, forecasts len=459\n",
      "total:19, prediction_length:2\n",
      "top1acc= 0.6842105263157895 top1acc_farmost= 0.631578947368421 top5acc= 0.9052631578947369 top5acc_farmost= 0.8526315789473684\n",
      "tau =  0.8968351369394577 rmse =  5.147213323162981\n",
      "==============================\n",
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=3，len=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:5\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:4\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:6\n",
      "a short ts: carid=18，len=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:6\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:6\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=24，len=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:6\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=30，len=46\n",
      "a short ts: carid=32，len=110\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:6\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:7\n",
      "train len:0, test len:165\n",
      "model: oracle\n",
      "predicting model=oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=165, forecasts len=165\n",
      "total:7, prediction_length:5\n",
      "top1acc= 0.5142857142857142 top1acc_farmost= 0.5714285714285714 top5acc= 0.76 top5acc_farmost= 0.6857142857142857\n",
      "tau =  0.785455333754055 rmse =  12.903929606625258\n",
      "model: deepAR\n",
      "predicting model=deepAR, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n",
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=165, forecasts len=165\n",
      "total:7, prediction_length:5\n",
      "top1acc= 0.4857142857142857 top1acc_farmost= 0.42857142857142855 top5acc= 0.7314285714285714 top5acc_farmost= 0.6\n",
      "tau =  0.758528644870333 rmse =  15.206451345755692\n",
      "model: naive\n",
      "predicting model=naive, plen=5\n",
      "tss len=165, forecasts len=165\n",
      "total:7, prediction_length:5\n",
      "top1acc= 0.4857142857142857 top1acc_farmost= 0.42857142857142855 top5acc= 0.7485714285714286 top5acc_farmost= 0.6571428571428571\n",
      "tau =  0.7882465192664682 rmse =  13.506451345755693\n",
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=3，len=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:5\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:4\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:6\n",
      "a short ts: carid=18，len=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:6\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:6\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=24，len=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:6\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=30，len=46\n",
      "a short ts: carid=32，len=110\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:6\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:7\n",
      "train len:0, test len:165\n",
      "model: curtrack\n",
      "predicting model=curtrack, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=165, forecasts len=165\n",
      "total:7, prediction_length:5\n",
      "top1acc= 0.4857142857142857 top1acc_farmost= 0.42857142857142855 top5acc= 0.7371428571428571 top5acc_farmost= 0.6285714285714286\n",
      "tau =  0.7526169167008042 rmse =  15.49391166321601\n",
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=3，len=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:5\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:4\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:6\n",
      "a short ts: carid=18，len=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:6\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:6\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=24，len=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:6\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=30，len=46\n",
      "a short ts: carid=32，len=110\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:6\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:7\n",
      "train len:0, test len:165\n",
      "model: zerotrack\n",
      "predicting model=zerotrack, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=165, forecasts len=165\n",
      "total:7, prediction_length:5\n",
      "top1acc= 0.45714285714285713 top1acc_farmost= 0.42857142857142855 top5acc= 0.7371428571428571 top5acc_farmost= 0.6285714285714286\n",
      "tau =  0.7571987422637039 rmse =  14.974023464458245\n",
      "==============================\n",
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=3，len=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:2\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:1\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:2\n",
      "a short ts: carid=18，len=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:2\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:2\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=24，len=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:2\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=30，len=46\n",
      "a short ts: carid=32，len=110\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:2\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:3\n",
      "train len:0, test len:67\n",
      "model: oracle\n",
      "predicting model=oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=67, forecasts len=67\n",
      "total:3, prediction_length:10\n",
      "top1acc= 0.23333333333333334 top1acc_farmost= 0.0 top5acc= 0.58 top5acc_farmost= 0.4\n",
      "tau =  0.6340442549966846 rmse =  21.64151851851852\n",
      "model: deepAR\n",
      "predicting model=deepAR, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n",
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=67, forecasts len=67\n",
      "total:3, prediction_length:10\n",
      "top1acc= 0.26666666666666666 top1acc_farmost= 0.0 top5acc= 0.5533333333333333 top5acc_farmost= 0.3333333333333333\n",
      "tau =  0.5966082504499385 rmse =  24.81214814814815\n",
      "model: naive\n",
      "predicting model=naive, plen=10\n",
      "tss len=67, forecasts len=67\n",
      "total:3, prediction_length:10\n",
      "top1acc= 0.4 top1acc_farmost= 0.3333333333333333 top5acc= 0.58 top5acc_farmost= 0.4\n",
      "tau =  0.6213473808847211 rmse =  23.556962962962967\n",
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=3，len=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:2\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:1\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:2\n",
      "a short ts: carid=18，len=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:2\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:2\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=24，len=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:2\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=30，len=46\n",
      "a short ts: carid=32，len=110\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:2\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:3\n",
      "train len:0, test len:67\n",
      "model: curtrack\n",
      "predicting model=curtrack, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=67, forecasts len=67\n",
      "total:3, prediction_length:10\n",
      "top1acc= 0.4 top1acc_farmost= 0.3333333333333333 top5acc= 0.58 top5acc_farmost= 0.4\n",
      "tau =  0.6207902244955954 rmse =  23.6842962962963\n",
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=3，len=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:2\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:1\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:2\n",
      "a short ts: carid=18，len=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:2\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:2\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=24，len=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:2\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=30，len=46\n",
      "a short ts: carid=32，len=110\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:2\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:3\n",
      "train len:0, test len:67\n",
      "model: zerotrack\n",
      "predicting model=zerotrack, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=67, forecasts len=67\n",
      "total:3, prediction_length:10\n",
      "top1acc= 0.23333333333333334 top1acc_farmost= 0.0 top5acc= 0.5333333333333333 top5acc_farmost= 0.26666666666666666\n",
      "tau =  0.5878853272710051 rmse =  25.592\n"
     ]
    }
   ],
   "source": [
    "half=[True, False]\n",
    "half=[False]\n",
    "#plens=[2,5,10,20,30]\n",
    "plens=[2,5,10]\n",
    "#trainids = [\"r0.5\",\"r0.6\",\"r0.7\"]\n",
    "trainids = [\"r0.8\"]\n",
    "#half=[True,False]\n",
    "#plens=[2]\n",
    "\n",
    "#exp_id='median-r0.8'\n",
    "exp_id='mean-splitbystage-direct'\n",
    "\n",
    "exp_data = []\n",
    "exp_result = []\n",
    "\n",
    "for halfmode in half:\n",
    "    for plen in plens:\n",
    "        for trainid in trainids:\n",
    "            print('='*30)\n",
    "            pred_ret, test_ds, metric_ret = run_exp(plen, halfmode, trainid=trainid)\n",
    "\n",
    "            #save \n",
    "            exp_data.append((pred_ret, test_ds))\n",
    "            exp_result.extend(metric_ret)\n",
    "        \n",
    "#save result\n",
    "result = pd.DataFrame(exp_result, columns = ['model' , 'prediction_length', 'halfmode',\n",
    "                                   'trainid',\n",
    "                                   'top1acc','top1acc_farmost','top5acc',\n",
    "                                   'top5acc_farmost','tau','rmse'])\n",
    "result.to_csv(f'laptime2rank-evaluate-indy500-{exp_id}-result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prediction_length</th>\n",
       "      <th>halfmode</th>\n",
       "      <th>trainid</th>\n",
       "      <th>top1acc</th>\n",
       "      <th>top1acc_farmost</th>\n",
       "      <th>top5acc</th>\n",
       "      <th>top5acc_farmost</th>\n",
       "      <th>tau</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oracle</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>r0.8</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.910526</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>4.708683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepAR</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>r0.8</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.899832</td>\n",
       "      <td>5.089915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>r0.8</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.910526</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.919435</td>\n",
       "      <td>4.384855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>curtrack</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>r0.8</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.910526</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.902620</td>\n",
       "      <td>4.997405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zerotrack</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>r0.8</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.896835</td>\n",
       "      <td>5.147213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  prediction_length  halfmode trainid   top1acc  top1acc_farmost  \\\n",
       "0     oracle                  2     False    r0.8  0.763158         0.736842   \n",
       "1     deepAR                  2     False    r0.8  0.657895         0.578947   \n",
       "2      naive                  2     False    r0.8  0.710526         0.631579   \n",
       "3   curtrack                  2     False    r0.8  0.684211         0.631579   \n",
       "4  zerotrack                  2     False    r0.8  0.684211         0.631579   \n",
       "\n",
       "    top5acc  top5acc_farmost       tau      rmse  \n",
       "0  0.910526         0.863158  0.905172  4.708683  \n",
       "1  0.905263         0.852632  0.899832  5.089915  \n",
       "2  0.910526         0.863158  0.919435  4.384855  \n",
       "3  0.910526         0.863158  0.902620  4.997405  \n",
       "4  0.905263         0.852632  0.896835  5.147213  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result[\"prediction_length\"]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forecasts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a49313c0a44d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforecasts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'forecasts' is not defined"
     ]
    }
   ],
   "source": [
    "forecasts[0].samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[3][:,:].shape for x in rank_ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ret[x][2][:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ret[1][3][:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ret.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts[0].samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result['prediction_length']==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
