{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laptime2Rank-incremental\n",
    "\n",
    "rank prediction by laptime forecasting models\n",
    "\n",
    "test if incremental training really helps prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "ERROR:fbprophet:Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pathlib import Path\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.distribution.multivariate_gaussian import MultivariateGaussianOutput\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.model.prophet import ProphetPredictor\n",
    "from gluonts.model.r_forecast import RForecastPredictor\n",
    "from indycar.model.NaivePredictor import NaivePredictor\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "GPUID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(event, year):\n",
    "    inputfile = '../data/final/C_'+ event +'-' + year + '-final.csv'\n",
    "    outputprefix = year +'-' + event + '-'\n",
    "    dataset = pd.read_csv(inputfile)\n",
    "    #dataset.info(verbose=True)    \n",
    "    \n",
    "    final_lap = max(dataset.completed_laps)\n",
    "    total_laps = final_lap + 1\n",
    "\n",
    "    # get records for the cars that finish the race\n",
    "    completed_car_numbers= dataset[dataset.completed_laps == final_lap].car_number.values\n",
    "    completed_car_count = len(completed_car_numbers)\n",
    "\n",
    "    print('count of completed cars:', completed_car_count)\n",
    "    print('completed cars:', completed_car_numbers)\n",
    "\n",
    "    #make a copy\n",
    "    alldata = dataset.copy()\n",
    "    dataset = dataset[dataset['car_number'].isin(completed_car_numbers)]\n",
    "    rankdata = alldata.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "    \n",
    "    cldata = make_cl_data(dataset)\n",
    "    acldata = make_cl_data(alldata)\n",
    "\n",
    "    return alldata, rankdata, acldata\n",
    "\n",
    "# make indy car completed_laps dataset\n",
    "# car_number, completed_laps, rank, elapsed_time, rank_diff, elapsed_time_diff \n",
    "def make_cl_data(dataset):\n",
    "\n",
    "    # pick up data with valid rank\n",
    "    rankdata = dataset.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "\n",
    "    # resort by car_number, lap\n",
    "    uni_ds = rankdata.sort_values(by=['car_number', 'completed_laps', 'elapsed_time'], ascending=True)    \n",
    "    #uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \"current_status\", \"track_status\", \"lap_status\",\n",
    "    #                  \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "    #                  \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "    \n",
    "    uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \n",
    "                      \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "                      \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "        \n",
    "    carnumber = set(uni_ds['car_number'])\n",
    "    print('cars:', carnumber)\n",
    "    print('#cars=', len(carnumber))\n",
    "   \n",
    "    # faster solution , uni_ds already sorted by car_number and lap\n",
    "    uni_ds['rank_diff'] = uni_ds['rank'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['rank_diff'][mask] = 0\n",
    "    \n",
    "    uni_ds['time_diff'] = uni_ds['elapsed_time'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['time_diff'][mask] = 0\n",
    "    \n",
    "    #df = uni_ds[['car_number','completed_laps','rank','elapsed_time','rank_diff','time_diff']]\n",
    "    df = uni_ds[['car_number','completed_laps','rank','elapsed_time',\n",
    "                 'rank_diff','time_diff',\"current_status\", \"track_status\", \"lap_status\"]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def test_flag(a, bitflag):\n",
    "    return (a & bitflag) ==  bitflag\n",
    "\n",
    "#\n",
    "# remove NaN at the tail\n",
    "# there should be no nans in the middle of the ts\n",
    "COL_LAPTIME=0\n",
    "COL_RANK=1\n",
    "COL_TRACKSTATUS=2\n",
    "COL_LAPSTATUS=3\n",
    "COL_TIMEDIFF=4\n",
    "MODE_ORACLE = 0\n",
    "MODE_NOLAP = 1\n",
    "MODE_NOTRACK = 2\n",
    "MODE_TESTZERO = 4\n",
    "MODE_TESTCURTRACK = 8\n",
    "#MODE_STR={MODE_ORACLE:'oracle', MODE_NOLAP:'nolap',MODE_NOTRACK:'notrack',MODE_TEST:'test'}\n",
    "\n",
    "def make_dataset(runs, prediction_length, freq, \n",
    "                       useeid = False,\n",
    "                       run_ts=COL_LAPTIME, \n",
    "                       train_ratio = 0.8,\n",
    "                       use_global_dict = True,\n",
    "                       oracle_mode = MODE_ORACLE,\n",
    "                       test_cars = [],\n",
    "                       half_moving_win = True \n",
    "                ):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    oracle_mode: false to simulate prediction in real by \n",
    "        set the covariates of track and lap status as nan in the testset\n",
    "            \n",
    "    \n",
    "    \"\"\"    \n",
    "    start = pd.Timestamp(\"01-01-2019\", freq=freq)  # can be different for each time series\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #select run\n",
    "    if runs>=0:\n",
    "        _laptime_data = [laptime_data[runs].copy()]\n",
    "    else:\n",
    "        _laptime_data = laptime_data.copy()\n",
    "    \n",
    "   \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        max_len = int(np.max(ts_len))\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        \n",
    "        print(f'====event:{events[_data[0]]}, train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)}')\n",
    "                \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                print(f'a short ts: carid={_data[1][rowid]}ï¼Œlen={totallen}')\n",
    "                continue                \n",
    "            \n",
    "            if use_global_dict:\n",
    "                carno = _data[1][rowid]\n",
    "                carid = global_carids[_data[1][rowid]]\n",
    "            else:\n",
    "                #simulation dataset, todo, fix the carids as decoder\n",
    "                carno = rowid\n",
    "                carid = rowid\n",
    "\n",
    "            #eval on carids\n",
    "            if test_cars and (carno not in test_cars):\n",
    "                continue                \n",
    "            \n",
    "            if useeid:\n",
    "                static_cat = [carid, _data[0]]    \n",
    "            else:\n",
    "                static_cat = [carid]    \n",
    "                \n",
    "            # selection of features\n",
    "            if test_flag(oracle_mode, MODE_NOTRACK):                \n",
    "                rec[COL_TRACKSTATUS, :] = 0\n",
    "            if test_flag(oracle_mode, MODE_NOLAP):                \n",
    "                rec[COL_LAPSTATUS, :] = 0\n",
    "                \n",
    "            # split and add to dataset record\n",
    "            _train.append({'target': rec[run_ts,:train_len].astype(np.float32), \n",
    "                            'start': start, \n",
    "                            'feat_static_cat': static_cat,\n",
    "                            'feat_dynamic_real': [rec[COL_TRACKSTATUS,:train_len],\n",
    "                                   rec[COL_LAPSTATUS,:train_len]]\n",
    "                          }\n",
    "                          )\n",
    "            \n",
    "            # multiple test ts(rolling window as half of the prediction_length)\n",
    "            test_rec_cnt = 0\n",
    "            step = -int(prediction_length/2) if half_moving_win else -prediction_length\n",
    "            for endpos in range(max_len, train_len+prediction_length, step):\n",
    "                \n",
    "                \n",
    "                #check if enough for this ts\n",
    "                if endpos > totallen:\n",
    "                    continue\n",
    "                        \n",
    "                track_rec = rec[COL_TRACKSTATUS, :endpos].copy()\n",
    "                lap_rec = rec[COL_LAPSTATUS, :endpos].copy()\n",
    "                \n",
    "                # test mode\n",
    "                if test_flag(oracle_mode, MODE_TESTCURTRACK):\n",
    "                    # since nan does not work, use cur-val instead\n",
    "                    track_rec[-prediction_length:] = track_rec[-prediction_length - 1]\n",
    "                    #track_rec[-prediction_length:] = random.randint(0,1)\n",
    "                    #lap_rec[-prediction_length:] = lap_rec[-prediction_length - 1]\n",
    "                    lap_rec[-prediction_length:] = 0\n",
    "                elif test_flag(oracle_mode, MODE_TESTZERO):\n",
    "                    #set prediction part as nan\n",
    "                    #track_rec[-prediction_length:] = np.nan\n",
    "                    #lap_rec[-prediction_length:] = np.nan\n",
    "                    track_rec[-prediction_length:] = 0\n",
    "                    lap_rec[-prediction_length:] = 0                    \n",
    "                \n",
    "                _test.append({'target': rec[run_ts,:endpos].astype(np.float32), \n",
    "                            'start': start, \n",
    "                            'feat_static_cat': static_cat,\n",
    "                            'feat_dynamic_real': [track_rec,lap_rec]\n",
    "                            #'feat_dynamic_real': [rec[COL_TRACKSTATUS,:endpos],\n",
    "                            #       rec[COL_LAPSTATUS,:endpos]] \n",
    "                             }\n",
    "                          )   \n",
    "                test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'prediction_length:{prediction_length},train len:{len(train_set)}, test len:{len(test_set)}')\n",
    "    \n",
    "    train_ds = ListDataset(train_set, freq=freq)\n",
    "    test_ds = ListDataset(test_set, freq=freq)    \n",
    "    \n",
    "    return train_ds, test_ds, train_set, test_set\n",
    "\n",
    "def save_dataset(datafile,freq, prediction_length, cardinality, train_ds, test_ds):\n",
    "    with open(datafile, 'wb') as f:\n",
    "        #pack [global_carids, laptime_data]\n",
    "        savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "        #savedata = [freq, train_set, test_set]\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for Indy500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_ds,predictor):\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor=predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    return tss, forecasts\n",
    "\n",
    "   \n",
    "def run_prediction(test_ds, prediction_length):\n",
    "    with mx.Context(mx.gpu(7)):    \n",
    "        pred_ret = {}\n",
    "\n",
    "        rootdir = '../models/remote/laptime-r0.8/'\n",
    "        # deepAR-Oracle\n",
    "        model_name = 'deepAR-Oracle-curtrack'\n",
    "        model=f'deepAR-Oracle-laptime-testcurtrack-indy-f1min-t{prediction_length}-e1000-r1'\n",
    "        modeldir = rootdir + model\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  Predictor.deserialize(Path(modeldir))\n",
    "        print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # deepAR-Oracle\n",
    "        model_name = 'deepAR-Oracle'\n",
    "        model=f'deepAR-Oracle-laptime-indy-f1min-t{prediction_length}-e1000-r1'\n",
    "        modeldir = rootdir + model\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  Predictor.deserialize(Path(modeldir))\n",
    "        print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # deepAR\n",
    "        model_name = 'deepAR'\n",
    "        model=f'deepAR-Oracle-laptime-indy-f1min-t{prediction_length}-e1000-r1'\n",
    "        modeldir = rootdir + model\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  Predictor.deserialize(Path(modeldir))\n",
    "        print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # naive\n",
    "        model_name = 'naive'\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  NaivePredictor(freq= freq, prediction_length = prediction_length)\n",
    "        tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        # arima\n",
    "        model_name = 'arima'\n",
    "        print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "        predictor =  RForecastPredictor(method_name='arima',freq= freq, \n",
    "                                        prediction_length = prediction_length,trunc_length=60)\n",
    "        #tss, forecasts = predict(test_ds,predictor)\n",
    "        pred_ret[model_name] = [tss, forecasts]\n",
    "\n",
    "        return pred_ret    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc rank\n",
    "def eval_rank_bytimediff(test_ds,tss,forecasts,prediction_length):\n",
    "    \"\"\"\n",
    "    timediff models\n",
    "    \n",
    "    works for one event only\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        #forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        \n",
    "        timediff_array = tss[idx].values.copy()\n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        forecasts_et[completed_laps][carno] = [timediff_array[-prediction_len:].copy(),\n",
    "                                                   forecast_laptime_mean.copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        time_diff = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            time_diff[0, carid, :] = forecasts_et[lap][carno][0].reshape((prediction_len))\n",
    "            time_diff[1, carid, :] = forecasts_et[lap][carno][1].reshape((prediction_len))\n",
    "\n",
    "        #calculate rank    \n",
    "        idx = np.argsort(time_diff[0], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        idx = np.argsort(time_diff[1], axis=0)\n",
    "        pred_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        rank_ret.append([lap, time_diff, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et\n",
    "    \n",
    "#calc rank\n",
    "def eval_rank(test_ds,tss,forecasts,prediction_length):\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        offset = start_offset[(start_offset['car_number']==carno)].elapsed_time.values[0] \n",
    "        #print('start_offset:', offset)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        #forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "\n",
    "        laptime_array = tss[idx].values.copy()\n",
    "        elapsed_time = np.cumsum(laptime_array) + offset\n",
    "\n",
    "        laptime_array = tss[idx].values.copy()\n",
    "        laptime_array[-prediction_len:] = forecast_laptime_mean \n",
    "        elapsed_time_hat = np.cumsum(laptime_array) + offset\n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len-1:].copy(),\n",
    "                                                   elapsed_time_hat[-prediction_len-1:].copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        elapsed_time = np.zeros((2, len(carlist), prediction_len+1))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            elapsed_time[0, carid, :] = forecasts_et[lap][carno][0]\n",
    "            elapsed_time[1, carid, :] = forecasts_et[lap][carno][1]\n",
    "\n",
    "        #calculate rank    \n",
    "        idx = np.argsort(elapsed_time[0], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        idx = np.argsort(elapsed_time[1], axis=0)\n",
    "        pred_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        rank_ret.append([lap, elapsed_time, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et\n",
    "   \n",
    "def get_acc(rank_ret,prediction_length):    \n",
    "    # evaluate\n",
    "    #top1 accuracy\n",
    "    top1acc = 0\n",
    "    top1acc_farmost = 0\n",
    "    top5acc = 0\n",
    "    top5acc_farmost = 0\n",
    "    tau = 0\n",
    "    rmse = 0.\n",
    "    \n",
    "    for rec in rank_ret:\n",
    "        trueRank = rec[2]\n",
    "        predRank = rec[3]\n",
    "\n",
    "        #top1 , rank = 0, first col is not prediction\n",
    "        top1acc += np.sum((trueRank==0) & (predRank==0)) \n",
    "        \n",
    "        top1acc_farmost += np.sum((trueRank[:,-1]==0) & (predRank[:,-1]==0))\n",
    "        \n",
    "        #top5\n",
    "        top5acc += np.sum((trueRank<5) & (predRank<5)) \n",
    "        \n",
    "        top5acc_farmost += np.sum((trueRank[:,-1]<5) & (predRank[:,-1]<5))\n",
    "        \n",
    "        # tau\n",
    "        tao, _ = stats.kendalltau(trueRank, predRank)\n",
    "        tau += tao\n",
    "        \n",
    "        #rmse\n",
    "        rmse += mean_squared_error(predRank,trueRank)\n",
    "        \n",
    "\n",
    "    print(f'total:{len(rank_ret)}, prediction_length:{prediction_length}') \n",
    "    print('top1acc=', top1acc *1.0/ (len(rank_ret)*prediction_length),\n",
    "          'top1acc_farmost=', top1acc_farmost *1.0/ (len(rank_ret)),\n",
    "          'top5acc=', top5acc *1.0/ (5*len(rank_ret)*prediction_length),\n",
    "          'top5acc_farmost=', top5acc_farmost *1.0/ (5*len(rank_ret)),\n",
    "         )\n",
    "    print('tau = ', tau/len(rank_ret),\n",
    "         'rmse = ', rmse/len(rank_ret))\n",
    "    \n",
    "    \n",
    "def get_top1acc_farmost(rank_ret,prediction_len):    \n",
    "    # evaluate\n",
    "    #top1 accuracy\n",
    "    hitcnt = 0\n",
    "    for rec in rank_ret:\n",
    "        trueRank = rec[2]\n",
    "        predRank = rec[3]\n",
    "\n",
    "        #top1 , rank = 0, first col is not prediction\n",
    "        hitcnt += np.sum((trueRank[:,-1]==0) & (predRank[:,-1]==0)) \n",
    "\n",
    "    print('total:', hitcnt, 'top1acc_farmost=', hitcnt *1.0/ (len(rank_ret)*prediction_length))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(prediction_length, half_moving_win):\n",
    "    ### create test dataset\n",
    "    test_cars = []\n",
    "    train_ds, test_ds,_,_ = make_dataset(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_TESTCURTRACK,\n",
    "                                         run_ts = COL_LAPTIME,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win)\n",
    "    pred_ret = run_prediction(test_ds, prediction_length)\n",
    "\n",
    "    models = ['deepAR-Oracle','deepAR-Oracle-curtrack','deepAR','naive','arima']\n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = pred_ret[model]\n",
    "\n",
    "        rank_ret,_ = eval_rank(test_ds,tss,forecasts,prediction_length)\n",
    "        get_acc(rank_ret,prediction_length)\n",
    "        \n",
    "    return pred_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# parameters\n",
    "#\n",
    "#year = '2017'\n",
    "year = '2018'\n",
    "#event = 'Toronto'\n",
    "#https://www.racing-reference.info/season-stats/2018/O/#\n",
    "events_totalmiles=[256,500,372,268,500,310]\n",
    "events_laplen = [1.022,2.5,1.5,0.894,2.5,1.25]\n",
    "events = ['Phoenix','Indy500','Texas','Iowa','Pocono','Gateway']\n",
    "#events = ['Gateway']\n",
    "\n",
    "#events = ['Indy500']\n",
    "#events = ['Phoenix']\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "#works for only one event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of completed cars: 11\n",
      "completed cars: [ 1  6 27  9 28  5 20 14 15 22 30]\n",
      "cars: {1, 5, 6, 9, 14, 15, 20, 22, 27, 28, 30}\n",
      "#cars= 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/scratch/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars: {1, 4, 5, 6, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 32, 59, 88, 98}\n",
      "#cars= 23\n",
      "Phoenix: carno=23, lapnum=251\n",
      "count of completed cars: 18\n",
      "completed cars: [12 20  9 27 28 22 29  1  6 15 66 98  4 88 25 60 64 23]\n",
      "cars: {64, 1, 66, 98, 4, 6, 9, 12, 60, 15, 20, 22, 23, 88, 25, 27, 28, 29}\n",
      "#cars= 18\n",
      "cars: {1, 3, 4, 6, 7, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 59, 60, 64, 66, 88, 98}\n",
      "#cars= 33\n",
      "Indy500: carno=33, lapnum=201\n",
      "count of completed cars: 9\n",
      "completed cars: [ 9 22 27  5 28 15 30 18 10]\n",
      "cars: {5, 9, 10, 15, 18, 22, 27, 28, 30}\n",
      "#cars= 9\n",
      "cars: {1, 3, 4, 5, 6, 7, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 47, 55, 57, 59, 60, 68, 73, 83, 88, 98}\n",
      "#cars= 32\n",
      "Texas: carno=32, lapnum=249\n",
      "count of completed cars: 5\n",
      "completed cars: [ 5 21 30  1  6]\n",
      "cars: {1, 5, 6, 21, 30}\n",
      "#cars= 5\n",
      "cars: {1, 4, 5, 6, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 59, 88, 98}\n",
      "#cars= 22\n",
      "Iowa: carno=22, lapnum=301\n",
      "count of completed cars: 4\n",
      "completed cars: [27 12  9 18]\n",
      "cars: {9, 18, 27, 12}\n",
      "#cars= 4\n",
      "cars: {1, 4, 5, 6, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 59, 88, 98}\n",
      "#cars= 22\n",
      "Pocono: carno=22, lapnum=201\n",
      "count of completed cars: 8\n",
      "completed cars: [12 27  9 22 26 21  1 10]\n",
      "cars: {1, 9, 10, 12, 21, 22, 26, 27}\n",
      "#cars= 8\n",
      "cars: {1, 4, 5, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 59, 88, 98}\n",
      "#cars= 21\n",
      "Gateway: carno=21, lapnum=249\n"
     ]
    }
   ],
   "source": [
    "stagedata = {}\n",
    "global_carids = {}\n",
    "traindata = None\n",
    "cur_carid = 0\n",
    "for event in events:\n",
    "    #alldata, rankdata, acldata, flagdata\n",
    "    stagedata[event] = load_data(event, year)\n",
    "    \n",
    "    alldata, rankdata, acldata = stagedata[event]\n",
    "    carlist = set(acldata['car_number'])\n",
    "    laplist = set(acldata['completed_laps'])\n",
    "    print('%s: carno=%d, lapnum=%d'%(event, len(carlist), len(laplist)))\n",
    "\n",
    "    #build the carid map\n",
    "    for car in carlist:\n",
    "        if car not in global_carids:\n",
    "            global_carids[car] = cur_carid\n",
    "            cur_carid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "event='Indy500'\n",
    "test_event = event\n",
    "alldata, rankdata, acldata = stagedata[event]\n",
    "final_lap = max(rankdata.completed_laps)\n",
    "completed_car_numbers= rankdata[rankdata.completed_laps == final_lap].car_number.values\n",
    "\n",
    "start_offset = rankdata[rankdata['completed_laps']==0][['car_number','elapsed_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from here\n",
    "import pickle\n",
    "with open('laptime_rank_timediff-oracle-%s.pickle'%year, 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    global_carids, laptime_data = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"1min\"\n",
    "#decode global_carids\n",
    "decode_carids={carid:carno for carno, carid in global_carids.items()}\n",
    "    \n",
    "#useeid = False\n",
    "#interpolate = False\n",
    "#ipstr = '-ip' if interpolate else '-noip'\n",
    "#ipstr = '%s-%s'%('ip' if interpolate else 'noip', 'eid' if useeid else 'noeid')\n",
    "#if useeid:\n",
    "#    cardinality = [len(global_carids), len(laptime_data)]\n",
    "#else:\n",
    "#    cardinality = [len(global_carids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:1\n",
      "a short ts: carid=3ï¼Œlen=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:1\n",
      "a short ts: carid=10ï¼Œlen=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:1\n",
      "a short ts: carid=13ï¼Œlen=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:0\n",
      "a short ts: carid=18ï¼Œlen=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:0\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:1\n",
      "a short ts: carid=24ï¼Œlen=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:1\n",
      "a short ts: carid=30ï¼Œlen=46\n",
      "a short ts: carid=32ï¼Œlen=110\n",
      "a short ts: carid=33ï¼Œlen=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:0\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:1\n",
      "prediction_length:20,train len:25, test len:18\n",
      "predicting model=deepAR-Oracle-curtrack, plen=20\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=18, forecasts len=18\n",
      "predicting model=deepAR-Oracle, plen=20\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=18, forecasts len=18\n",
      "predicting model=deepAR, plen=20\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=18, forecasts len=18\n",
      "predicting model=naive, plen=20\n",
      "tss len=18, forecasts len=18\n",
      "predicting model=arima, plen=20\n",
      "model: deepAR-Oracle\n",
      "total:1, prediction_length:20\n",
      "top1acc= 0.65 top1acc_farmost= 0.0 top5acc= 0.8 top5acc_farmost= 0.6\n",
      "tau =  0.6591673706519644 rmse =  11.037037037037038\n",
      "model: deepAR-Oracle-curtrack\n",
      "total:1, prediction_length:20\n",
      "top1acc= 0.2 top1acc_farmost= 0.0 top5acc= 0.72 top5acc_farmost= 0.6\n",
      "tau =  0.6569294384420434 rmse =  9.70899470899471\n",
      "model: deepAR\n",
      "total:1, prediction_length:20\n",
      "top1acc= 0.65 top1acc_farmost= 0.0 top5acc= 0.81 top5acc_farmost= 0.8\n",
      "tau =  0.6568405139833711 rmse =  10.95238095238095\n",
      "model: naive\n",
      "total:1, prediction_length:20\n",
      "top1acc= 0.7 top1acc_farmost= 1.0 top5acc= 0.8 top5acc_farmost= 0.6\n",
      "tau =  0.603619225467965 rmse =  13.518518518518519\n",
      "model: arima\n",
      "total:1, prediction_length:20\n",
      "top1acc= 0.7 top1acc_farmost= 1.0 top5acc= 0.8 top5acc_farmost= 0.6\n",
      "tau =  0.603619225467965 rmse =  13.518518518518519\n"
     ]
    }
   ],
   "source": [
    "# test half moving win\n",
    "pred_ret2_nohalfwin = run_exp(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:2\n",
      "a short ts: carid=3ï¼Œlen=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:1\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:2\n",
      "a short ts: carid=10ï¼Œlen=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:2\n",
      "a short ts: carid=13ï¼Œlen=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:1\n",
      "a short ts: carid=18ï¼Œlen=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:1\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:1\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:2\n",
      "a short ts: carid=24ï¼Œlen=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:1\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:2\n",
      "a short ts: carid=30ï¼Œlen=46\n",
      "a short ts: carid=32ï¼Œlen=110\n",
      "a short ts: carid=33ï¼Œlen=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:1\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:2\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:2\n",
      "prediction_length:20,train len:25, test len:42\n",
      "predicting model=deepAR-Oracle-curtrack, plen=20\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=42, forecasts len=42\n",
      "predicting model=deepAR-Oracle, plen=20\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=42, forecasts len=42\n",
      "predicting model=deepAR, plen=20\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=42, forecasts len=42\n",
      "predicting model=naive, plen=20\n",
      "tss len=42, forecasts len=42\n",
      "predicting model=arima, plen=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: deepAR-Oracle\n",
      "total:2, prediction_length:20\n",
      "top1acc= 0.35 top1acc_farmost= 0.0 top5acc= 0.54 top5acc_farmost= 0.5\n",
      "tau =  0.5484146959911178 rmse =  24.35515873015873\n",
      "model: deepAR-Oracle-curtrack\n",
      "total:2, prediction_length:20\n",
      "top1acc= 0.1 top1acc_farmost= 0.0 top5acc= 0.545 top5acc_farmost= 0.5\n",
      "tau =  0.5556952249498833 rmse =  23.003968253968253\n",
      "model: deepAR\n",
      "total:2, prediction_length:20\n",
      "top1acc= 0.35 top1acc_farmost= 0.0 top5acc= 0.56 top5acc_farmost= 0.6\n",
      "tau =  0.5512018817188711 rmse =  24.149470899470902\n",
      "model: naive\n",
      "total:2, prediction_length:20\n",
      "top1acc= 0.375 top1acc_farmost= 0.5 top5acc= 0.53 top5acc_farmost= 0.4\n",
      "tau =  0.5363720367374003 rmse =  24.78108465608465\n",
      "model: arima\n",
      "total:2, prediction_length:20\n",
      "top1acc= 0.375 top1acc_farmost= 0.5 top5acc= 0.53 top5acc_farmost= 0.4\n",
      "tau =  0.5363720367374003 rmse =  24.78108465608465\n"
     ]
    }
   ],
   "source": [
    "pred_ret2_halfwin = run_exp(20, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:18\n",
      "a short ts: carid=3ï¼Œlen=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:14\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:18\n",
      "a short ts: carid=10ï¼Œlen=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:18\n",
      "a short ts: carid=13ï¼Œlen=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:11\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:17\n",
      "a short ts: carid=18ï¼Œlen=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:17\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:17\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:18\n",
      "a short ts: carid=24ï¼Œlen=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:17\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:18\n",
      "a short ts: carid=30ï¼Œlen=46\n",
      "a short ts: carid=32ï¼Œlen=110\n",
      "a short ts: carid=33ï¼Œlen=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:17\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:18\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:18\n",
      "prediction_length:5,train len:25, test len:434\n",
      "predicting model=deepAR-Oracle-curtrack, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=434, forecasts len=434\n",
      "predicting model=deepAR-Oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=434, forecasts len=434\n",
      "predicting model=deepAR, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=434, forecasts len=434\n",
      "predicting model=naive, plen=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=434, forecasts len=434\n",
      "predicting model=arima, plen=5\n",
      "model: deepAR-Oracle\n",
      "total:18, prediction_length:5\n",
      "top1acc= 0.6888888888888889 top1acc_farmost= 0.3888888888888889 top5acc= 0.9155555555555556 top5acc_farmost= 0.5555555555555556\n",
      "tau =  0.7632897994181974 rmse =  13.5233995348005\n",
      "model: deepAR-Oracle-curtrack\n",
      "total:18, prediction_length:5\n",
      "top1acc= 0.6111111111111112 top1acc_farmost= 0.2222222222222222 top5acc= 0.9066666666666666 top5acc_farmost= 0.5888888888888889\n",
      "tau =  0.762365181925663 rmse =  13.261843353014847\n",
      "model: deepAR\n",
      "total:18, prediction_length:5\n",
      "top1acc= 0.7 top1acc_farmost= 0.4444444444444444 top5acc= 0.9088888888888889 top5acc_farmost= 0.5555555555555556\n",
      "tau =  0.7572521399782932 rmse =  13.742563964931115\n",
      "model: naive\n",
      "total:18, prediction_length:5\n",
      "top1acc= 0.6333333333333333 top1acc_farmost= 0.3333333333333333 top5acc= 0.8844444444444445 top5acc_farmost= 0.5444444444444444\n",
      "tau =  0.6830451439021581 rmse =  22.689370191447484\n",
      "model: arima\n",
      "total:18, prediction_length:5\n",
      "top1acc= 0.6333333333333333 top1acc_farmost= 0.3333333333333333 top5acc= 0.8844444444444445 top5acc_farmost= 0.5444444444444444\n",
      "tau =  0.6830451439021581 rmse =  22.689370191447484\n"
     ]
    }
   ],
   "source": [
    "# test half moving win\n",
    "pred_ret5_halfwin = run_exp(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=3ï¼Œlen=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:5\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=10ï¼Œlen=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=13ï¼Œlen=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:4\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:6\n",
      "a short ts: carid=18ï¼Œlen=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:6\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:6\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=24ï¼Œlen=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:6\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:7\n",
      "a short ts: carid=30ï¼Œlen=46\n",
      "a short ts: carid=32ï¼Œlen=110\n",
      "a short ts: carid=33ï¼Œlen=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:6\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:7\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:7\n",
      "prediction_length:5,train len:25, test len:165\n",
      "predicting model=deepAR-Oracle-curtrack, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=165, forecasts len=165\n",
      "predicting model=deepAR-Oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=165, forecasts len=165\n",
      "predicting model=deepAR, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=165, forecasts len=165\n",
      "predicting model=naive, plen=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=165, forecasts len=165\n",
      "predicting model=arima, plen=5\n",
      "model: deepAR-Oracle\n",
      "total:7, prediction_length:5\n",
      "top1acc= 0.6 top1acc_farmost= 0.2857142857142857 top5acc= 0.8171428571428572 top5acc_farmost= 0.5142857142857142\n",
      "tau =  0.6730088292087439 rmse =  20.62533701403267\n",
      "model: deepAR-Oracle-curtrack\n",
      "total:7, prediction_length:5\n",
      "top1acc= 0.6 top1acc_farmost= 0.2857142857142857 top5acc= 0.84 top5acc_farmost= 0.6\n",
      "tau =  0.6807321356298337 rmse =  19.934452495974234\n",
      "model: deepAR\n",
      "total:7, prediction_length:5\n",
      "top1acc= 0.6 top1acc_farmost= 0.2857142857142857 top5acc= 0.8114285714285714 top5acc_farmost= 0.4857142857142857\n",
      "tau =  0.6797938402414107 rmse =  20.206510236945018\n",
      "model: naive\n",
      "total:7, prediction_length:5\n",
      "top1acc= 0.7142857142857143 top1acc_farmost= 0.5714285714285714 top5acc= 0.8285714285714286 top5acc_farmost= 0.5714285714285714\n",
      "tau =  0.6700670222707733 rmse =  21.601927766275594\n",
      "model: arima\n",
      "total:7, prediction_length:5\n",
      "top1acc= 0.7142857142857143 top1acc_farmost= 0.5714285714285714 top5acc= 0.8285714285714286 top5acc_farmost= 0.5714285714285714\n",
      "tau =  0.6700670222707733 rmse =  21.601927766275594\n"
     ]
    }
   ],
   "source": [
    "# test half moving win\n",
    "pred_ret5_nohalfwin = run_exp(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carno:1, totallen:200, nancount:0, test_reccnt:6\n",
      "a short ts: carid=3ï¼Œlen=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:4\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:6\n",
      "a short ts: carid=10ï¼Œlen=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:6\n",
      "a short ts: carid=13ï¼Œlen=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:3\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:5\n",
      "a short ts: carid=18ï¼Œlen=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:5\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:5\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:6\n",
      "a short ts: carid=24ï¼Œlen=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:5\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:6\n",
      "a short ts: carid=30ï¼Œlen=46\n",
      "a short ts: carid=32ï¼Œlen=110\n",
      "a short ts: carid=33ï¼Œlen=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:5\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:6\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:6\n",
      "prediction_length:10,train len:25, test len:140\n",
      "predicting model=deepAR-Oracle-curtrack, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=140, forecasts len=140\n",
      "predicting model=deepAR-Oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=140, forecasts len=140\n",
      "predicting model=deepAR, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=140, forecasts len=140\n",
      "predicting model=naive, plen=10\n",
      "tss len=140, forecasts len=140\n",
      "predicting model=arima, plen=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: deepAR-Oracle\n",
      "total:6, prediction_length:10\n",
      "top1acc= 0.36666666666666664 top1acc_farmost= 0.16666666666666666 top5acc= 0.66 top5acc_farmost= 0.36666666666666664\n",
      "tau =  0.5947989917991608 rmse =  23.48964353681745\n",
      "model: deepAR-Oracle-curtrack\n",
      "total:6, prediction_length:10\n",
      "top1acc= 0.4666666666666667 top1acc_farmost= 0.16666666666666666 top5acc= 0.6766666666666666 top5acc_farmost= 0.43333333333333335\n",
      "tau =  0.5962127535349409 rmse =  24.19393353828136\n",
      "model: deepAR\n",
      "total:6, prediction_length:10\n",
      "top1acc= 0.35 top1acc_farmost= 0.16666666666666666 top5acc= 0.68 top5acc_farmost= 0.4\n",
      "tau =  0.5906660245227386 rmse =  23.944445908358954\n",
      "model: naive\n",
      "total:6, prediction_length:10\n",
      "top1acc= 0.4666666666666667 top1acc_farmost= 0.16666666666666666 top5acc= 0.6333333333333333 top5acc_farmost= 0.36666666666666664\n",
      "tau =  0.5384335036583986 rmse =  28.17519030888596\n",
      "model: arima\n",
      "total:6, prediction_length:10\n",
      "top1acc= 0.4666666666666667 top1acc_farmost= 0.16666666666666666 top5acc= 0.6333333333333333 top5acc_farmost= 0.36666666666666664\n",
      "tau =  0.5384335036583986 rmse =  28.17519030888596\n"
     ]
    }
   ],
   "source": [
    "pred_ret10_halfwin = run_exp(10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====event:Indy500, train_len=160, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=3ï¼Œlen=146\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:2\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=10ï¼Œlen=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=13ï¼Œlen=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:1\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:2\n",
      "a short ts: carid=18ï¼Œlen=137\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:2\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:2\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=24ï¼Œlen=154\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:2\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:3\n",
      "a short ts: carid=30ï¼Œlen=46\n",
      "a short ts: carid=32ï¼Œlen=110\n",
      "a short ts: carid=33ï¼Œlen=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:2\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:3\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:3\n",
      "prediction_length:10,train len:25, test len:67\n",
      "predicting model=deepAR-Oracle-curtrack, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=67, forecasts len=67\n",
      "predicting model=deepAR-Oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=67, forecasts len=67\n",
      "predicting model=deepAR, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=67, forecasts len=67\n",
      "predicting model=naive, plen=10\n",
      "tss len=67, forecasts len=67\n",
      "predicting model=arima, plen=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: deepAR-Oracle\n",
      "total:3, prediction_length:10\n",
      "top1acc= 0.16666666666666666 top1acc_farmost= 0.0 top5acc= 0.48 top5acc_farmost= 0.2\n",
      "tau =  0.45468141854098615 rmse =  30.815993265993267\n",
      "model: deepAR-Oracle-curtrack\n",
      "total:3, prediction_length:10\n",
      "top1acc= 0.43333333333333335 top1acc_farmost= 0.3333333333333333 top5acc= 0.5533333333333333 top5acc_farmost= 0.4\n",
      "tau =  0.4488623583740999 rmse =  32.607373737373734\n",
      "model: deepAR\n",
      "total:3, prediction_length:10\n",
      "top1acc= 0.16666666666666666 top1acc_farmost= 0.0 top5acc= 0.4533333333333333 top5acc_farmost= 0.2\n",
      "tau =  0.4366097070840154 rmse =  32.364680134680135\n",
      "model: naive\n",
      "total:3, prediction_length:10\n",
      "top1acc= 0.43333333333333335 top1acc_farmost= 0.3333333333333333 top5acc= 0.47333333333333333 top5acc_farmost= 0.26666666666666666\n",
      "tau =  0.37662081561174804 rmse =  37.08387205387205\n",
      "model: arima\n",
      "total:3, prediction_length:10\n",
      "top1acc= 0.43333333333333335 top1acc_farmost= 0.3333333333333333 top5acc= 0.47333333333333333 top5acc_farmost= 0.26666666666666666\n",
      "tau =  0.37662081561174804 rmse =  37.08387205387205\n"
     ]
    }
   ],
   "source": [
    "pred_ret10_nohalfwin = run_exp(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ret = pred_ret2_halfwin\n",
    "model = 'deepAR-Oracle'\n",
    "tss, forecasts = pred_ret[model]\n",
    "rank_ret = eval_rank_bytimediff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss, forecasts = pred_ret5_halfwin['deepAR-Oracle']\n",
    "rank_ret = eval_rank_bytimediff(test_ds,tss,forecasts,5)\n",
    "get_acc(rank_ret,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ret[1][2][:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ret[1][3][:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss, forecasts = pred_ret['deepAR-Oracle-curtrack']\n",
    "forecasts[0].samples.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ret.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss, forecasts = 0, 0\n",
    "model = 'deepAR-Oracle-curtrack'\n",
    "\n",
    "tss, forecasts = pred_ret2[model]\n",
    "\n",
    "rank_ret = eval_rank_bytimediff()\n",
    "get_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts[0].samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
