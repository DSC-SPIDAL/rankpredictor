{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP-pitmodel\n",
    "\n",
    "test the new feature 'cur_cautionlaps'\n",
    "\n",
    "base: MLP-pitmodel-plen2\n",
    "\n",
    "build a pitstop dataset with <cautions_laps, pitage, gap2nextpit>\n",
    "gluonts interface of Dataset = Iterable[DataEntry], DataEntry = Dict(str, any)\n",
    "\n",
    "+ input pitstop dataset, remove pitstops with pit_oncaution = 1, refer to lapstatus_dataset-fastrun\n",
    "+ context_length = 1, prediction_length = 1\n",
    "+ target : gap to nextpit\n",
    "+ covariates are: cautions_laps, pitage, (carid, eid)\n",
    "+ modeling the distribution of nextpit-gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import random\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import inspect\n",
    "from scipy import stats\n",
    "from pathlib import Path \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pathlib import Path\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.distribution.neg_binomial import NegativeBinomialOutput\n",
    "from gluonts.distribution.student_t import StudentTOutput\n",
    "from gluonts.model.forecast import SampleForecast\n",
    "\n",
    "from indycar.model.mlp import MLPEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch_hdd/hpda/indycar/notebook/23.experiments'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def test_flag(a, bitflag):\n",
    "    return (a & bitflag) ==  bitflag\n",
    "\n",
    "#\n",
    "# remove NaN at the tail\n",
    "# there should be no nans in the middle of the ts\n",
    "COL_LAPTIME=0\n",
    "COL_RANK=1\n",
    "COL_TRACKSTATUS=2\n",
    "COL_LAPSTATUS=3\n",
    "COL_TIMEDIFF=4\n",
    "COL_CAUTION_LAPS_INSTINT=5\n",
    "COL_LAPS_INSTINT= 6\n",
    "COL_ELAPSED_TIME= 7\n",
    "COL_LAP2NEXTPIT = 8\n",
    "\n",
    "\n",
    "MODE_ORACLE = 0\n",
    "MODE_NOLAP = 1\n",
    "MODE_NOTRACK = 2\n",
    "MODE_TESTZERO = 4\n",
    "MODE_TESTCURTRACK = 8\n",
    "#MODE_STR={MODE_ORACLE:'oracle', MODE_NOLAP:'nolap',MODE_NOTRACK:'notrack',MODE_TEST:'test'}\n",
    "\n",
    "def split_ts(rec, carno, eid, include_end = False):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        ts\n",
    "    output:\n",
    "        nextpit records\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    pitstops = np.where(rec[COL_LAPSTATUS,:] == 1)[0]\n",
    "    \n",
    "    if len(pitstops)==0:\n",
    "        print('no pit ts')\n",
    "        return output\n",
    "    \n",
    "    #pit_oncaution = np.zeros_like((pitstops))\n",
    "    #for pit in pitstops:\n",
    "    #    if rec[COL_TRACKSTATUS,:] == 1:\n",
    "    #        pit_oncaution = 1\n",
    "    pit_oncaution = np.zeros_like((rec[COL_LAP2NEXTPIT,:]))\n",
    "    stint_len = np.zeros_like((rec[COL_LAP2NEXTPIT,:]))\n",
    "    pos = 0\n",
    "    for pit in pitstops:\n",
    "        if rec[COL_TRACKSTATUS,pit] == 1:\n",
    "            #next pit is oncaution\n",
    "            # set pos -> pit as oncaution\n",
    "            pit_oncaution[pos:pit] = 1\n",
    "        else:\n",
    "            pit_oncaution[pos:pit] = 0\n",
    "            \n",
    "        stint_len[pos:pit] = pit - pos\n",
    "        pos = pit\n",
    "        \n",
    "        \n",
    "    # calc cur_cautionlaps\n",
    "    # accumulate consecutive caution laps\n",
    "    trackstatus = rec[COL_TRACKSTATUS,:]\n",
    "    lapstatus = rec[COL_LAPSTATUS,:]\n",
    "    \n",
    "    #import pdb; pdb.set_trace()\n",
    "    \n",
    "    cur_cautionlaps = np.zeros_like(trackstatus)\n",
    "    cautionlaps_acc = 0\n",
    "    for idx in range(len(trackstatus)):\n",
    "        if (trackstatus[idx] == 0) or (lapstatus[idx] == 1):\n",
    "            #reset\n",
    "            cautionlaps_acc = 0\n",
    "        else:\n",
    "            cautionlaps_acc += 1\n",
    "            \n",
    "        #save state\n",
    "        cur_cautionlaps[idx] = cautionlaps_acc\n",
    "        \n",
    "            \n",
    "    #prepare output : lap2nextpit, CAUTION_LAPS_INSTINT,LAPS_INSTINT, pit_oncaution, carno, eid, lap, stintlen\n",
    "    if include_end:\n",
    "        #rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "        totallen = len(rec[COL_RANK, ~np.isnan(rec[COL_RANK,:])])\n",
    "    else:\n",
    "        totallen = pitstops[-1]\n",
    "        \n",
    "    # set the last stint target = 999, an invalid lap2nextpit\n",
    "    for idx in range(totallen):\n",
    "        output.append([ rec[COL_LAP2NEXTPIT ,idx] if idx < pitstops[-1] else 999\n",
    "                        ,rec[COL_CAUTION_LAPS_INSTINT ,idx]\n",
    "                        ,rec[COL_LAPS_INSTINT ,idx]\n",
    "                        ,pit_oncaution[idx]\n",
    "                        ,carno\n",
    "                        ,eid\n",
    "                        ,idx\n",
    "                        ,stint_len[idx]\n",
    "                        ,cur_cautionlaps[idx]\n",
    "                      ])\n",
    "        \n",
    "    return output\n",
    "\n",
    "def make_dataset_byevent(test_event = 'Indy500-2018', include_end = False):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    oracle_mode: false to simulate prediction in real by \n",
    "        set the covariates of track and lap status as nan in the testset\n",
    "            \n",
    "    \n",
    "    \"\"\"    \n",
    "    useeid = False\n",
    "    run_ts = COL_LAP2NEXTPIT\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        if events[_data[0]] == test_event:\n",
    "            test_mode = True\n",
    "        elif _data[0] in _train_events:\n",
    "            test_mode = False\n",
    "        else:\n",
    "            print('skip event:', events[_data[0]])\n",
    "            continue\n",
    "            \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            \n",
    "            carno = _data[1][rowid]\n",
    "            carid = global_carids[_data[1][rowid]]\n",
    "            \n",
    "            eid = _data[0]\n",
    "            \n",
    "            # all go to train set\n",
    "            output = split_ts(rec, carno, eid, include_end= include_end)\n",
    "            #if len(output) == 0:\n",
    "            #    continue\n",
    "            \n",
    "            test_rec_cnt = 0\n",
    "            if not test_mode:\n",
    "                _train.extend(output)\n",
    "                \n",
    "            else:\n",
    "                _test.extend(output)\n",
    "                test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'train len:{len(train_set)}, test len:{len(test_set)}')\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "def save_dataset(datafile,freq, prediction_length, cardinality, train_ds, test_ds):\n",
    "    with open(datafile, 'wb') as f:\n",
    "        #pack [global_carids, laptime_data]\n",
    "        savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "        #savedata = [freq, train_set, test_set]\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make gluonts\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "def makedb(data, scaler='standard', perm = True, feature_cnt=2):\n",
    "    db = []\n",
    "    start = pd.Timestamp(\"01-01-2019\", freq='1min')  # can be different for each time series\n",
    "    \n",
    "    scalers = {'minmax':MinMaxScaler(), 'standard':StandardScaler()}\n",
    "    \n",
    "    if isinstance(scaler, str):\n",
    "        if scaler in scalers:\n",
    "            scaler = scalers[scaler]\n",
    "            scaler.fit(data)\n",
    "            df = scaler.transform(data)\n",
    "        else:\n",
    "            # no scaler\n",
    "            df = data\n",
    "    else:\n",
    "        #use input scaler\n",
    "        #scaler.fit(data)\n",
    "        df = scaler.transform(data)\n",
    "        \n",
    "    \n",
    "    #permute\n",
    "    if perm:\n",
    "        perm = np.random.permutation(len(df))\n",
    "        df = df[perm]\n",
    "    \n",
    "    for x in df:\n",
    "        if feature_cnt == 3:\n",
    "            db.append({'target':np.array([x[0]]), 'feat':np.array([x[1],x[2],x[3]]),\n",
    "                  \"start\":start, 'forecast_start':start})\n",
    "        elif feature_cnt == 2:\n",
    "            db.append({'target':np.array([x[0]]), 'feat':np.array([x[1],x[2]]),\n",
    "                  \"start\":start, 'forecast_start':start})\n",
    "        else:\n",
    "            print('error _feature_cnt not support:', feature_cnt)\n",
    "            break\n",
    "        \n",
    "    return db, scaler, df\n",
    "\n",
    "\n",
    "def make_fulltestdb(scaler, maxgap=60, maxcautionlen=20, feature_cnt=2):\n",
    "    db = []\n",
    "    start = pd.Timestamp(\"01-01-2019\", freq='1min')  # can be different for each time series\n",
    "\n",
    "    data = []\n",
    "    for caution_lap in range(maxgap):\n",
    "        for pitage in range(caution_lap, maxgap):\n",
    "            if feature_cnt == 2:        \n",
    "                data.append([0.,caution_lap, pitage, 0])\n",
    "            elif feature_cnt == 3:        \n",
    "                for cur_cautionlap in range(0, caution_lap+1):\n",
    "                    data.append([0.,caution_lap, pitage, cur_cautionlap])\n",
    "    data = np.array(data)\n",
    "    \n",
    "    if not isinstance(scaler, str):\n",
    "        df = scaler.transform(data)\n",
    "    else:\n",
    "        df = data\n",
    "    \n",
    "    #data\n",
    "    print(f'make full testdb: {len(df)} records')\n",
    "    for x in df:\n",
    "        if feature_cnt == 3:        \n",
    "            db.append({'target':np.array([x[0]]), 'feat':np.array([x[1],x[2],x[3]]),\n",
    "                  \"start\":start, 'forecast_start':start})\n",
    "        elif feature_cnt == 2:\n",
    "            db.append({'target':np.array([x[0]]), 'feat':np.array([x[1],x[2]]),\n",
    "                  \"start\":start, 'forecast_start':start})\n",
    "        else:\n",
    "            print('error _feature_cnt not support:', feature_cnt)\n",
    "            break\n",
    "\n",
    "    #reset data, used by PitModel.save_model()\n",
    "    if feature_cnt == 2:\n",
    "        data = data[:,:3]            \n",
    "            \n",
    "    return db, scaler, df, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, layers=[10,10,5], output = 'student', dropout = .5, id='all', feature_cnt = 2):\n",
    "    distr_outputs ={'student':StudentTOutput(),  \n",
    "                    'negbin':NegativeBinomialOutput() \n",
    "                   }\n",
    "    if not output in distr_outputs:\n",
    "        print(f'distr_output: {output} not found error.')\n",
    "        return\n",
    "    \n",
    "    distr_output = distr_outputs[output]\n",
    "    \n",
    "    modelid = f'mlp-{trainrace}-d%s-f%d-e%s-l%s-%s-d%s'%(id, feature_cnt,\n",
    "                                            epochs, '-'.join([str(x) for x in layers]), output, dropout)\n",
    "    \n",
    "    estimator = MLPEstimator(\n",
    "        num_hidden_dimensions=layers,\n",
    "        prediction_length=1,\n",
    "        context_length=1,\n",
    "        freq='1min',\n",
    "        dropout = dropout,\n",
    "        distr_output = distr_output,\n",
    "        trainer=Trainer(ctx=\"gpu(0)\", \n",
    "                        batch_size = 32,\n",
    "                        epochs= epochs,\n",
    "                        learning_rate=1e-3,\n",
    "                        hybridize=False,\n",
    "                        num_batches_per_epoch=100\n",
    "                       )\n",
    "    )    \n",
    "\n",
    "    predictor = estimator.train(train_ds)\n",
    "\n",
    "    return predictor, modelid\n",
    "\n",
    "def eval_model(predictor, test_ds):\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset    \n",
    "        predictor=predictor,  # predictor                                  \n",
    "        num_samples=1000,  # number of sample paths we want for evaluation \n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)     \n",
    "    evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9]) \n",
    "    agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n",
    "    print(json.dumps(agg_metrics, indent=4)) \n",
    "    return tss, forecasts, agg_metrics\n",
    "\n",
    "\n",
    "def raw_eval(tss, forecasts):\n",
    "    \"\"\"\n",
    "    scaler\n",
    "    \"\"\"\n",
    "    #rec = np.zeros((_feature_cnt + 1))\n",
    "    rec = np.zeros((4))\n",
    "\n",
    "    truth, pred = [],[]\n",
    "    #go through the dataset\n",
    "    for idx in range(len(tss)):\n",
    "        rec[0] = list(tss[idx].values)[0]\n",
    "    \n",
    "        if isinstance(scaler, str):\n",
    "            truth.append(int(rec[0]))\n",
    "        else:\n",
    "            truth.append(int(scaler.inverse_transform(rec)[0]))\n",
    "    \n",
    "        rec[0] = np.mean(forecasts[idx].samples)\n",
    "        \n",
    "        if isinstance(scaler, str):\n",
    "            pred.append(int(rec[0]))    \n",
    "        else:\n",
    "            pred.append(int(scaler.inverse_transform(rec)[0]))        \n",
    "\n",
    "    #get mae\n",
    "    mae = mean_absolute_error(truth, pred)\n",
    "    print('mae = ', mae)\n",
    "    return mae\n",
    "\n",
    "def decode(tss, forecasts):\n",
    "    \"\"\"\n",
    "    scaler\n",
    "    \"\"\"\n",
    "    #rec = np.zeros((_feature_cnt + 1))\n",
    "    rec = np.zeros((4))\n",
    "\n",
    "    truth, pred = [],[]\n",
    "    sampleCnt = forecasts[0].samples.shape[0]\n",
    "    samples = np.zeros((sampleCnt, len(tss)))\n",
    "    \n",
    "    #go through the dataset\n",
    "    for idx in range(len(tss)):\n",
    "        rec[0] = list(tss[idx].values)[0]\n",
    "    \n",
    "        if isinstance(scaler, str):\n",
    "            truth.append(int(rec[0]))\n",
    "        else:\n",
    "            truth.append(int(scaler.inverse_transform(rec)[0]))\n",
    "    \n",
    "        #pred\n",
    "        rec[0] = np.mean(forecasts[idx].samples)\n",
    "        \n",
    "        if isinstance(scaler, str):\n",
    "            pred.append(int(rec[0]))    \n",
    "        else:\n",
    "            pred.append(int(scaler.inverse_transform(rec)[0]))        \n",
    "            \n",
    "        #samples\n",
    "        for sid in range(sampleCnt):\n",
    "            rec[0] = forecasts[idx].samples[sid]\n",
    "            if isinstance(scaler, str):\n",
    "                pred.append(int(rec[0]))    \n",
    "                samples[sid, idx] = int(rec[0])\n",
    "            else:\n",
    "                samples[sid, idx] = int(scaler.inverse_transform(rec)[0])        \n",
    "    \n",
    "    return truth, pred, samples\n",
    "\n",
    "def save_model(predictor, outdir):\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    \n",
    "    predictor.serialize(Path(outdir)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pitmodel\n",
    "class PitModel():\n",
    "    \"\"\"\n",
    "     <caution_lap, pitage> -> [distribution]    \n",
    "     distribution := sorted cdf [val:probability, val2:p2, ...]\n",
    "         [0,:] -> val\n",
    "         [1,:] -> cdf p\n",
    "         \n",
    "     no scaler, raw feat and target\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, modelfile=''):\n",
    "        self.model = {}\n",
    "        self.name = ''\n",
    "        \n",
    "        if modelfile:\n",
    "            self.load_model(modelfile)\n",
    "                \n",
    "    def load_model(self, modelfile):\n",
    "        with open(modelfile, 'rb') as f:\n",
    "            self.name, self.model = pickle.load(f, encoding='latin1')\n",
    "            print(f'init model:{self.name}')\n",
    "        \n",
    "    def save_model(self, modelname, test_ds, forecasts, scaler):\n",
    "        \n",
    "        model = {}\n",
    "        \n",
    "        #get the sclaer for the first column(lap2nextpit)\n",
    "        sc, scf = '', ''\n",
    "        if isinstance(scaler, StandardScaler):\n",
    "            sc = StandardScaler()\n",
    "            sc.scale_ = scaler.scale_[0]\n",
    "            sc.mean_ = scaler.mean_[0]\n",
    "            sc.var_ = scaler.var_[0]\n",
    "\n",
    "            scf = StandardScaler()\n",
    "            scf.scale_ = scaler.scale_[1:]\n",
    "            scf.mean_ = scaler.mean_[1:]\n",
    "            scf.var_ = scaler.var_[1:]\n",
    "\n",
    "        \n",
    "        for idx, rec in enumerate(test_ds):\n",
    "            feat = rec[1:]\n",
    "                \n",
    "            key = '-'.join([str(int(x)) for x in feat])\n",
    "            \n",
    "            if not key in model:\n",
    "            \n",
    "                samples = forecasts[idx].samples.reshape(-1)\n",
    "                \n",
    "                if not isinstance(sc, str):\n",
    "                    samples = sc.inverse_transform(samples)\n",
    "                \n",
    "                #force to prediction to be valid lap2nextpit\n",
    "                samples = samples.astype(int)\n",
    "                samples = samples[samples > 0]\n",
    "\n",
    "                #\n",
    "                valset = set(list(samples))\n",
    "                plen = len(valset)\n",
    "                distr = np.zeros((2, plen))\n",
    "                distr[0, :] = sorted(valset)\n",
    "                smap = {val:id for id, val in enumerate(distr[0, :])}\n",
    "                for s in samples:\n",
    "                    distr[1,smap[s]] += 1\n",
    "                tsum = np.sum(distr[1,:])\n",
    "                distr[1, :] /= tsum\n",
    "                distr[1, :] = np.cumsum(distr[1, :])\n",
    "\n",
    "                model[key] = distr\n",
    "                \n",
    "        #save model\n",
    "        self.model = model\n",
    "        self.name = modelname\n",
    "        with open(modelname, 'wb') as f:\n",
    "            savedata = [self.name, self.model]\n",
    "            pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)        \n",
    "        print(f'save model {modelname} with {len(self.model)} keys.')\n",
    "                \n",
    "    def predict(self, *args):\n",
    "        key = '-'.join([str(int(x)) for x in args])\n",
    "        #if key in self.model:\n",
    "        try:\n",
    "            distr = self.model[key]\n",
    "            \n",
    "            #[0, 1.)\n",
    "            p = np.random.random()  \n",
    "            i = np.sum(distr[1,:] < p)\n",
    "            \n",
    "            return distr[0,i]\n",
    "        except:\n",
    "            #exception\n",
    "            #todo, backto special model\n",
    "            print(f'ERROR: key {key} not found in model')\n",
    "                       \n",
    "    def forecast_ds(self, test_ds, forecasts):\n",
    "        \"\"\"\n",
    "        test_ds as testset, the unsclaed input\n",
    "        forecasts ; the template\n",
    "        \"\"\"\n",
    "        \n",
    "        plen = len(test_ds)\n",
    "        sample_cnt = forecasts[0].samples.shape[0]\n",
    "        assert(plen == len(forecasts))\n",
    "        \n",
    "\n",
    "        #build a new forecasts object\n",
    "        nf = []\n",
    "        for fc in forecasts:\n",
    "            nfc = SampleForecast(samples = np.zeros_like(fc.samples), \n",
    "                                 freq=fc.freq, start_date=fc.start_date)\n",
    "            nf.append(nfc)\n",
    "        \n",
    "        for idx, rec in enumerate(test_ds):\n",
    "            feat = rec[1:]\n",
    "                    \n",
    "            onecast = np.zeros((sample_cnt))\n",
    "            for i in range(sample_cnt):\n",
    "                #onecast[i] = self.predict(feat[0], feat[1],feat[2])\n",
    "                onecast[i] = self.predict(*feat)\n",
    "        \n",
    "            nf[idx].samples = onecast\n",
    "\n",
    "        return nf\n",
    "    \n",
    "    def forecast_onecar(self, test_ds, plen = 2, sample_cnt=100):\n",
    "        \"\"\"\n",
    "        long-prediction for a single car\n",
    "        \n",
    "        input:\n",
    "            test_df ; 'lap2nextpit','caution_laps','pitage','lap'\n",
    "        \"\"\"\n",
    "        \n",
    "        #assert for one car\n",
    "        totallen = len(test_ds)\n",
    "        start = pd.Timestamp(\"01-01-2019\", freq='1min')  # can be different for each time series\n",
    "        \n",
    "        #samples\n",
    "        #onecast = np.zeros((sample_cnt, totallen+plen))\n",
    "        onecast = np.zeros((sample_cnt, totallen))\n",
    "        #onecast = np.zeros((sample_cnt, maxlap))\n",
    "        tss = np.zeros((totallen+plen))\n",
    "        \n",
    "        for idx, rec in enumerate(test_ds[:-plen]):\n",
    "        #for idx in range(maxlap-plen):\n",
    "            \n",
    "            #if idx<len(test_ds):\n",
    "            #    rec = test_ds[idx]\n",
    "            #else:\n",
    "            #    #use the last rec\n",
    "            #    # target, cautionlaps, pitage, cur_curcautionlaps\n",
    "            #    rec = [0, ] \n",
    "                \n",
    "            target = rec[0]\n",
    "            feat = rec[1:]\n",
    "            \n",
    "            if target == plen:\n",
    "                tss[idx + plen] = 1\n",
    "            \n",
    "            for i in range(sample_cnt):\n",
    "                nextpit = self.predict(*feat)\n",
    "                                                    \n",
    "                if nextpit == plen:\n",
    "                    onecast[i, idx + plen] = 1\n",
    "                \n",
    "        forecast = SampleForecast(samples = onecast, \n",
    "                             freq='1min', start_date=start)\n",
    "\n",
    "        return forecast, tss\n",
    "    \n",
    "    \n",
    "def save_full_pitmodel(mid, scaler, maxgap=60, feature_cnt = 2):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        p[mid]; predictor\n",
    "        runid ; 'all' or 'sel' of the trainning set\n",
    "    \"\"\"\n",
    "    \n",
    "    #get scaler\n",
    "    #scaler = _data[runid][-1]\n",
    "\n",
    "    # make full test set\n",
    "    test_ds, _, _, test_all = make_fulltestdb(scaler, maxgap = maxgap, feature_cnt = feature_cnt)\n",
    "\n",
    "    tss,forecasts, _ = eval_model(p[mid], test_ds)\n",
    "\n",
    "    pitmodel = PitModel()\n",
    "    \n",
    "    featurecnt_str = 'withcurcautionlaps' if (feature_cnt==3) else 'nocurcautionlaps'\n",
    "\n",
    "    #pitmodel.save_model(f'pitmodel-m{maxgap}-{mid}.pickle', test_all, forecasts, scaler)\n",
    "    pitmodel.save_model(f'{dataOutputRoot}/pitmodel-m{maxgap}-{mid}-1k-{featurecnt_str}.pickle', test_all, forecasts, scaler)\n",
    "\n",
    "    return pitmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets(test_event, include_end, sel_stintlen, noshort_stintlen, feature_cnt=2):\n",
    "    \"\"\"\n",
    "    sel_stintlen, noshort_stintlen  ; lower bound of stint len\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _data = {}\n",
    "    \n",
    "    train, test =  make_dataset_byevent(test_event = test_event, include_end = include_end)\n",
    "    #prepare output : lap2nextpit, CAUTION_LAPS_INSTINT,LAPS_INSTINT, pit_oncaution, carno, eid, lap\n",
    "    df_train = pd.DataFrame(train,columns=['lap2nextpit', 'caution_laps','pitage', 'pit_oncaution', \n",
    "                     'carno','eid','lap','stint_len','cur_cautionlaps'])\n",
    "    df_test = pd.DataFrame(test,columns=['lap2nextpit', 'caution_laps','pitage', 'pit_oncaution', \n",
    "                     'carno','eid','lap','stint_len','cur_cautionlaps'])\n",
    "    \n",
    "    # select\n",
    "    train_sel = df_train[(df_train['pit_oncaution']==0) &(df_train['stint_len']>sel_stintlen)]\n",
    "    train_sel_2013_2017 = train_sel[train_sel['eid'].isin(_train_events)]\n",
    "    train_all_2013_2017 = df_train[df_train['eid'].isin(_train_events)]\n",
    "\n",
    "    print(len(train_all_2013_2017), len(train_sel_2013_2017))    \n",
    "\n",
    "    test_sel = df_test[(df_test['pit_oncaution']==0) &(df_test['stint_len']>sel_stintlen)]\n",
    "    test_all = df_test\n",
    "\n",
    "    train_sel_noshort = df_train[(df_train['stint_len']>noshort_stintlen)]\n",
    "    train_sel_noshort_2013_2017 = train_sel_noshort[train_sel_noshort['eid'].isin(_train_events)]\n",
    "    test_sel_noshort = df_test[(df_test['stint_len']>noshort_stintlen)]    \n",
    "    \n",
    "    \n",
    "    # selected db\n",
    "    trainset = train_sel_2013_2017[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "    testset = test_sel[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "    train_ds, scaler, _ = makedb(trainset, scaler='standard',feature_cnt=feature_cnt)\n",
    "    test_ds, _, _ = makedb(testset, scaler, perm=False,feature_cnt=feature_cnt)\n",
    "\n",
    "    _data['sel'] = [trainset, testset, train_ds, test_ds, scaler]\n",
    "\n",
    "\n",
    "    # selected db\n",
    "    trainset = train_all_2013_2017[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "    testset = test_all[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "    train_ds, scaler, _ = makedb(trainset, scaler='standard',feature_cnt=feature_cnt)\n",
    "    test_ds, _, _ = makedb(testset, scaler, perm=False,feature_cnt=feature_cnt)\n",
    "\n",
    "    _data['all'] = [trainset, testset, train_ds, test_ds, scaler]\n",
    "\n",
    "\n",
    "    # selected db\n",
    "    trainset = train_sel_noshort_2013_2017[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "    testset = test_sel_noshort[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "    train_ds, scaler, _ = makedb(trainset, scaler='standard',feature_cnt=feature_cnt)\n",
    "    test_ds, _, _ = makedb(testset, scaler, perm=False,feature_cnt=feature_cnt)\n",
    "\n",
    "    _data['noshort'] = [trainset, testset, train_ds, test_ds, scaler]    \n",
    "\n",
    "    # add normal (normal pit only, with short pits)\n",
    "    train_sel_normal = df_train[(df_train['pit_oncaution']==0)]\n",
    "    train_sel_normal_2013_2017 = train_sel_normal[train_sel_normal['eid'].isin(_train_events)]\n",
    "    test_sel_normal = df_test[(df_test['pit_oncaution']==0)]\n",
    "\n",
    "    trainset = train_sel_normal_2013_2017[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "    testset = test_sel_normal[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "\n",
    "    train_ds, scaler, _ = makedb(trainset, scaler='standard',feature_cnt=feature_cnt)\n",
    "    test_ds, _, _ = makedb(testset, scaler, perm=False,feature_cnt=feature_cnt)\n",
    "\n",
    "    _data['normal'] = [trainset, testset, train_ds, test_ds, scaler]\n",
    "    \n",
    "    # add caution pits\n",
    "    train_sel_caution = df_train[(df_train['pit_oncaution']==1)]\n",
    "    train_sel_caution_2013_2017 = train_sel_caution[train_sel_caution['eid'].isin(_train_events)]\n",
    "    test_sel_caution = df_test[(df_test['pit_oncaution']==1)]\n",
    "\n",
    "    trainset = train_sel_caution_2013_2017[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "    testset = test_sel_caution[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "\n",
    "    train_ds, scaler, _ = makedb(trainset, scaler='standard',feature_cnt=feature_cnt)\n",
    "    test_ds, _, _ = makedb(testset, scaler, perm=False,feature_cnt=feature_cnt)\n",
    "\n",
    "    _data['caution'] = [trainset, testset, train_ds, test_ds, scaler]\n",
    "    \n",
    "    # add plen=2\n",
    "    train_sel_plen2 = df_train[(df_train['lap2nextpit']==2)]\n",
    "    train_sel_plen2_2013_2017 = train_sel_caution[train_sel_caution['eid'].isin(_train_events)]\n",
    "    test_sel_plen2 = df_test[(df_test['lap2nextpit']==2)]\n",
    "\n",
    "    trainset = train_sel_plen2_2013_2017[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "    testset = test_sel_plen2[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "\n",
    "    train_ds, scaler, _ = makedb(trainset, scaler='standard',feature_cnt=feature_cnt)\n",
    "    test_ds, _, _ = makedb(testset, scaler, perm=False,feature_cnt=feature_cnt)\n",
    "\n",
    "    _data['plen2'] = [trainset, testset, train_ds, test_ds, scaler]\n",
    "        \n",
    "    \n",
    "    return df_train, df_test, _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#straight implementation of prisk\n",
    "def quantile_loss(target, quantile_forecast, q):\n",
    "    return 2.0 * np.nansum(\n",
    "        np.abs(\n",
    "            (quantile_forecast - target)\n",
    "            * ((target <= quantile_forecast) - q)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def abs_target_sum(target): \n",
    "    return np.nansum(np.abs(target)) \n",
    "\n",
    "def prisk_direct_bysamples(forecast, target, quantiles=[0.1,0.5,0.9], startid = 0, verbose=False):\n",
    "    \"\"\"\n",
    "    calculate prisk by <samples, tss> directly (equal to gluonts implementation)\n",
    "    \n",
    "    target: endrank\n",
    "    forecast: pred_endrank\n",
    "    item_id: <carno, startlap>\n",
    "    \"\"\"\n",
    "    \n",
    "    prisk = np.zeros((len(quantiles)))\n",
    "    target_sum = 0\n",
    "    aggrisk = np.zeros((len(quantiles)))\n",
    "    \n",
    "    #calc quantiles\n",
    "    # len(quantiles) x 1\n",
    "    quantile_forecasts = np.quantile(forecast, quantiles, axis=0)\n",
    "\n",
    "    for idx, q in enumerate(quantiles):\n",
    "        q_forecast = quantile_forecasts[idx]\n",
    "        prisk[idx] = quantile_loss(target[startid:], q_forecast[startid:], q)\n",
    "        target_sum = abs_target_sum(target[startid:])\n",
    "\n",
    "    if verbose==True and carno==3:\n",
    "        print('target:', target[startid:])\n",
    "        print('forecast:', q_forecast[startid:])\n",
    "        print('target_sum:', target_sum)\n",
    "\n",
    "        print('quantile_forecasts:', quantile_forecasts[:,startid:])\n",
    "        \n",
    "    #agg\n",
    "    #aggrisk = np.mean(prisk, axis=0)\n",
    "    #prisk_sum = np.nansum(prisk, axis=0)\n",
    "    prisk_sum = prisk\n",
    "    \n",
    "    if verbose==True:\n",
    "        print('prisk:',prisk)\n",
    "        print('prisk_sum:',prisk_sum)\n",
    "        print('target_sum:',target_sum)\n",
    "    for idx, q in enumerate(quantiles):\n",
    "        aggrisk[idx] = np.divide(prisk_sum[idx], target_sum)\n",
    "    \n",
    "    agg_metrics = {}\n",
    "    for idx, q in enumerate(quantiles):\n",
    "        agg_metrics[f'wQuantileLoss[{q}]'] = aggrisk[idx]\n",
    "        \n",
    "    print(agg_metrics.values())\n",
    "    \n",
    "    return agg_metrics, aggrisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pitmodel(lapcnts):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        lapcnts ; series of lapcnt\n",
    "    output:\n",
    "        pitmodel; {lapcnt: cnt}\n",
    "    \"\"\"\n",
    "    pitmodel = {}\n",
    "    \n",
    "    data = sorted(lapcnts)\n",
    "    for x in data:\n",
    "        if x in pitmodel:\n",
    "            pitmodel[x] += 1\n",
    "        else:\n",
    "            pitmodel[x] = 1\n",
    "            \n",
    "    #norm\n",
    "    for x in pitmodel.keys():\n",
    "        pitmodel[x] = pitmodel[x] / len(data)\n",
    "            \n",
    "    return pitmodel\n",
    "\n",
    "def plot_cdf(normal_dist, title):\n",
    "    #normal_dist = df.lap_cnt\n",
    "    lapcnt_model = make_pitmodel(normal_dist.values)\n",
    "    p = list(lapcnt_model.values())\n",
    "    k = list(lapcnt_model.keys())\n",
    "    lapcnt_cdf = np.cumsum(p) / np.sum(p)\n",
    "    plt.plot(k,lapcnt_cdf)\n",
    "    plt.xlabel('Laps')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.title(title)\n",
    "    \n",
    "    return lapcnt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load stage and laptime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load laptime and stage dataset: data//laptime_rank_timediff_pit-oracle-IndyCar_d31_v9_p0.pickle data//stagedata-IndyCar_d31_v9_p0.pickle\n"
     ]
    }
   ],
   "source": [
    "_inlap_status = 0\n",
    "_featureCnt = 9\n",
    "#\n",
    "# input data parameters\n",
    "#\n",
    "# event -> car#, maxlap\n",
    "_race_info = {}\n",
    "# the races have 7 years data \n",
    "races = ['Indy500', 'Texas','Iowa','Pocono']\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "\n",
    "events = []\n",
    "for race in races:\n",
    "    events.extend([f'{race}-{x}' for x in years])\n",
    "\n",
    "events.extend(['Phoenix-2018','Gateway-2018','Gateway-2019'])\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "\n",
    "# dataset shared\n",
    "dataOutputRoot = \"data/\"\n",
    "covergap = 1\n",
    "dbid = f'IndyCar_d{len(events)}_v{_featureCnt}_p{_inlap_status}'\n",
    "LAPTIME_DATASET = f'{dataOutputRoot}/laptime_rank_timediff_pit-oracle-{dbid}.pickle' \n",
    "STAGE_DATASET = f'{dataOutputRoot}/stagedata-{dbid}.pickle' \n",
    "PITCOVERED_DATASET = f'{dataOutputRoot}/pitcoveredlaps-{dbid}-g{covergap}.pickle'\n",
    "PITSTOP_DATASET = f'{dataOutputRoot}/pitstop-{dbid}.csv' \n",
    "    \n",
    "print('Load laptime and stage dataset:',LAPTIME_DATASET, STAGE_DATASET)\n",
    "with open(LAPTIME_DATASET, 'rb') as f:\n",
    "    global_carids, laptime_data = pickle.load(f, encoding='latin1') \n",
    "with open(STAGE_DATASET, 'rb') as f:\n",
    "    #stagedata = pickle.load(f, encoding='latin1') \n",
    "    stagedata, _race_info, _events, _events_id = pickle.load(f, encoding='latin1') \n",
    "pitstop_df = pd.read_csv(PITSTOP_DATASET)\n",
    "\n",
    "#check it\n",
    "if not _events == events:\n",
    "    print('Error, events mismatch at:', STAGE_DATASET)\n",
    "    sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_end = True\n",
    "includeend_str = '-includeend' if include_end else ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainrace = 'Indy500','Iowa','Pocono','Texas'\n",
    "trainrace = 'Pocono'\n",
    "\n",
    "stintlen_config = {\n",
    "    # sel_stintlen, sel_stintlen_caution, binsize, \n",
    "    'Indy500':(23,15, 50),\n",
    "    'Pocono':(23,15,50),\n",
    "    'Texas':(30,15, 70 ),\n",
    "    'Iowa':(40,15, 100)\n",
    "}\n",
    "\n",
    "if trainrace == 'Pocono':\n",
    "    # 2014, 2019 is bad\n",
    "    _train_years = ['2013','2015','2016','2017']\n",
    "    testevents = [f'{trainrace}-2018']\n",
    "else:\n",
    "    _train_years = ['2013','2014','2015','2016','2017']\n",
    "    testevents = [f'{trainrace}-2018',f'{trainrace}-2019']\n",
    "    \n",
    "_train_events = [events_id[x] for x in [f'{trainrace}-{x}' for x in _train_years]]\n",
    "\n",
    "dbid = f'{trainrace}_{_train_years[0]}_{_train_years[-1]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptime min: 45.34980000000042 max: 701.7171000000002 median: 60.22479999999996 mean: 76.99117525423726\n",
      "normal laps lapcnt min: 0 max: 40\n",
      "Caution laps lapcnt min: 0 max: 36\n"
     ]
    }
   ],
   "source": [
    "dfall = pitstop_df[pitstop_df['raceid']==trainrace]\n",
    "\n",
    "laptime = dfall['lap_time'].values\n",
    "print('laptime min:', np.min(laptime), 'max:', np.max(laptime), 'median:', np.median(laptime), 'mean:', np.mean(laptime))\n",
    "lapcnt = dfall[dfall['pit_oncaution']==0].lap_cnt\n",
    "print('normal laps lapcnt min:', np.min(lapcnt), 'max:', np.max(lapcnt))\n",
    "lapcnt = dfall[dfall['pit_oncaution']==1].lap_cnt\n",
    "print('Caution laps lapcnt min:', np.min(lapcnt), 'max:', np.max(lapcnt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:15: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(4, 3))\n",
    "#fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "\n",
    "# car 12, will power\n",
    "binsize = stintlen_config[trainrace][2]\n",
    "bins=np.arange(binsize)\n",
    "car12 = dfall\n",
    "#nlap = car12[car12['lap_time']<80].lap_cnt\n",
    "#nlap = car12.lap_cnt\n",
    "clap = car12[car12['pit_oncaution']==0].lap_cnt\n",
    "#clap2 = car12[(car12['pit_oncaution']==1) & (car12['lap_time']<80)].lap_cnt\n",
    "clap2 = car12[(car12['pit_oncaution']==1)].lap_cnt\n",
    "#plt.hist(nlap,bins= bins, label='all')\n",
    "axs.hist(clap,bins= bins,normed=1,  alpha=0.7,label='normal pit')\n",
    "axs.hist(clap2,bins= bins,normed=1,  alpha=0.7,label='caution pit')\n",
    "axs.set_xlabel('Laps')\n",
    "axs.set_ylabel('Frequence')\n",
    "axs.set_title('Stint Distance Histogram')\n",
    "axs.legend(prop={'size': 12})\n",
    "plt.tight_layout()\n",
    "plt.savefig('pitmodel_a.pdf')\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(4, 3))\n",
    "df = dfall\n",
    "df = df[(df['pit_oncaution']==0)]\n",
    "lapcnt_model = make_pitmodel(df.lap_cnt.values)\n",
    "p = list(lapcnt_model.values())\n",
    "k = list(lapcnt_model.keys())\n",
    "lapcnt_cdf = np.cumsum(p) / np.sum(p)\n",
    "axs.plot(k,lapcnt_cdf, label='normal pit(total = %d)'%(len(df)))\n",
    "\n",
    "df = dfall\n",
    "df = df[(df['pit_oncaution']==1)]\n",
    "lapcnt_model = make_pitmodel(df.lap_cnt.values)\n",
    "p = list(lapcnt_model.values())\n",
    "k = list(lapcnt_model.keys())\n",
    "lapcnt_cdf = np.cumsum(p) / np.sum(p)\n",
    "axs.plot(k,lapcnt_cdf, label='caution pit(total = %d)'%(len(df)))\n",
    "\n",
    "axs.set_xlabel('Laps')\n",
    "axs.set_ylabel('CDF')\n",
    "axs.set_title('Stint Distance CDF')\n",
    "#axs[1].legend(prop={'size': 10})\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figs/pitmodel_ab_{trainrace}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model store\n",
    "dataset = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip event: Indy500-2013\n",
      "skip event: Indy500-2014\n",
      "skip event: Indy500-2015\n",
      "skip event: Indy500-2016\n",
      "skip event: Indy500-2017\n",
      "skip event: Indy500-2018\n",
      "skip event: Indy500-2019\n",
      "skip event: Texas-2013\n",
      "skip event: Texas-2014\n",
      "skip event: Texas-2015\n",
      "skip event: Texas-2016\n",
      "skip event: Texas-2017\n",
      "skip event: Texas-2018\n",
      "skip event: Texas-2019\n",
      "skip event: Iowa-2013\n",
      "skip event: Iowa-2014\n",
      "skip event: Iowa-2015\n",
      "skip event: Iowa-2016\n",
      "skip event: Iowa-2017\n",
      "skip event: Iowa-2018\n",
      "skip event: Iowa-2019\n",
      "carno:1, totallen:120, nancount:40, test_reccnt:0\n",
      "carno:3, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:155, nancount:5, test_reccnt:0\n",
      "carno:5, totallen:103, nancount:57, test_reccnt:0\n",
      "no pit ts\n",
      "carno:6, totallen:1, nancount:159, test_reccnt:0\n",
      "carno:7, totallen:155, nancount:5, test_reccnt:0\n",
      "carno:9, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:11, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:60, nancount:100, test_reccnt:0\n",
      "carno:15, totallen:127, nancount:33, test_reccnt:0\n",
      "carno:16, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:18, totallen:127, nancount:33, test_reccnt:0\n",
      "carno:19, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:20, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:25, totallen:160, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:27, totallen:0, nancount:160, test_reccnt:0\n",
      "carno:55, totallen:127, nancount:33, test_reccnt:0\n",
      "carno:67, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:77, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:78, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:83, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:98, totallen:128, nancount:32, test_reccnt:0\n",
      "skip event: Pocono-2014\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:163, nancount:37, test_reccnt:0\n",
      "no pit ts\n",
      "carno:4, totallen:18, nancount:182, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:7, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:8, totallen:163, nancount:37, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:109, nancount:91, test_reccnt:0\n",
      "no pit ts\n",
      "carno:11, totallen:31, nancount:169, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:86, nancount:114, test_reccnt:0\n",
      "carno:18, totallen:170, nancount:30, test_reccnt:0\n",
      "carno:19, totallen:88, nancount:112, test_reccnt:0\n",
      "carno:20, totallen:155, nancount:45, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:25, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:133, nancount:67, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:41, totallen:69, nancount:131, test_reccnt:0\n",
      "carno:67, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:83, totallen:192, nancount:8, test_reccnt:0\n",
      "carno:98, totallen:196, nancount:4, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:62, nancount:138, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:7, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:8, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:11, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:14, totallen:0, nancount:200, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:19, totallen:174, nancount:26, test_reccnt:0\n",
      "carno:20, totallen:56, nancount:144, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:155, nancount:45, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:41, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:83, totallen:176, nancount:24, test_reccnt:0\n",
      "carno:88, totallen:175, nancount:25, test_reccnt:0\n",
      "carno:98, totallen:62, nancount:138, test_reccnt:0\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:5, totallen:116, nancount:84, test_reccnt:0\n",
      "carno:7, totallen:85, nancount:115, test_reccnt:0\n",
      "carno:8, totallen:128, nancount:72, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:18, totallen:22, nancount:178, test_reccnt:0\n",
      "carno:19, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:21, totallen:116, nancount:84, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:83, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:1, totallen:165, nancount:35, test_reccnt:1\n",
      "carno:4, totallen:183, nancount:17, test_reccnt:1\n",
      "no pit ts\n",
      "carno:5, totallen:0, nancount:200, test_reccnt:1\n",
      "no pit ts\n",
      "carno:6, totallen:0, nancount:200, test_reccnt:1\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:10, totallen:165, nancount:35, test_reccnt:1\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:14, totallen:15, nancount:185, test_reccnt:1\n",
      "carno:15, totallen:173, nancount:27, test_reccnt:1\n",
      "carno:18, totallen:200, nancount:0, test_reccnt:1\n",
      "no pit ts\n",
      "carno:19, totallen:0, nancount:200, test_reccnt:1\n",
      "carno:20, totallen:163, nancount:37, test_reccnt:1\n",
      "no pit ts\n",
      "carno:21, totallen:16, nancount:184, test_reccnt:1\n",
      "carno:22, totallen:164, nancount:36, test_reccnt:1\n",
      "carno:23, totallen:166, nancount:34, test_reccnt:1\n",
      "carno:26, totallen:166, nancount:34, test_reccnt:1\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:1\n",
      "no pit ts\n",
      "carno:28, totallen:0, nancount:200, test_reccnt:1\n",
      "no pit ts\n",
      "carno:30, totallen:0, nancount:200, test_reccnt:1\n",
      "carno:59, totallen:165, nancount:35, test_reccnt:1\n",
      "carno:88, totallen:161, nancount:39, test_reccnt:1\n",
      "carno:98, totallen:165, nancount:35, test_reccnt:1\n",
      "skip event: Pocono-2019\n",
      "skip event: Phoenix-2018\n",
      "skip event: Gateway-2018\n",
      "skip event: Gateway-2019\n",
      "train len:14402, test len:2651\n",
      "14402 8161\n",
      "skip event: Indy500-2013\n",
      "skip event: Indy500-2014\n",
      "skip event: Indy500-2015\n",
      "skip event: Indy500-2016\n",
      "skip event: Indy500-2017\n",
      "skip event: Indy500-2018\n",
      "skip event: Indy500-2019\n",
      "skip event: Texas-2013\n",
      "skip event: Texas-2014\n",
      "skip event: Texas-2015\n",
      "skip event: Texas-2016\n",
      "skip event: Texas-2017\n",
      "skip event: Texas-2018\n",
      "skip event: Texas-2019\n",
      "skip event: Iowa-2013\n",
      "skip event: Iowa-2014\n",
      "skip event: Iowa-2015\n",
      "skip event: Iowa-2016\n",
      "skip event: Iowa-2017\n",
      "skip event: Iowa-2018\n",
      "skip event: Iowa-2019\n",
      "carno:1, totallen:120, nancount:40, test_reccnt:0\n",
      "carno:3, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:155, nancount:5, test_reccnt:0\n",
      "carno:5, totallen:103, nancount:57, test_reccnt:0\n",
      "no pit ts\n",
      "carno:6, totallen:1, nancount:159, test_reccnt:0\n",
      "carno:7, totallen:155, nancount:5, test_reccnt:0\n",
      "carno:9, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:11, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:60, nancount:100, test_reccnt:0\n",
      "carno:15, totallen:127, nancount:33, test_reccnt:0\n",
      "carno:16, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:18, totallen:127, nancount:33, test_reccnt:0\n",
      "carno:19, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:20, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:25, totallen:160, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:27, totallen:0, nancount:160, test_reccnt:0\n",
      "carno:55, totallen:127, nancount:33, test_reccnt:0\n",
      "carno:67, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:77, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:78, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:83, totallen:160, nancount:0, test_reccnt:0\n",
      "carno:98, totallen:128, nancount:32, test_reccnt:0\n",
      "skip event: Pocono-2014\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:163, nancount:37, test_reccnt:0\n",
      "no pit ts\n",
      "carno:4, totallen:18, nancount:182, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:7, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:8, totallen:163, nancount:37, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:109, nancount:91, test_reccnt:0\n",
      "no pit ts\n",
      "carno:11, totallen:31, nancount:169, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:86, nancount:114, test_reccnt:0\n",
      "carno:18, totallen:170, nancount:30, test_reccnt:0\n",
      "carno:19, totallen:88, nancount:112, test_reccnt:0\n",
      "carno:20, totallen:155, nancount:45, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:25, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:133, nancount:67, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:41, totallen:69, nancount:131, test_reccnt:0\n",
      "carno:67, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:83, totallen:192, nancount:8, test_reccnt:0\n",
      "carno:98, totallen:196, nancount:4, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:62, nancount:138, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:7, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:8, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:11, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:14, totallen:0, nancount:200, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:19, totallen:174, nancount:26, test_reccnt:0\n",
      "carno:20, totallen:56, nancount:144, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:155, nancount:45, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:41, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:83, totallen:176, nancount:24, test_reccnt:0\n",
      "carno:88, totallen:175, nancount:25, test_reccnt:0\n",
      "carno:98, totallen:62, nancount:138, test_reccnt:0\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:5, totallen:116, nancount:84, test_reccnt:0\n",
      "carno:7, totallen:85, nancount:115, test_reccnt:0\n",
      "carno:8, totallen:128, nancount:72, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carno:10, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:18, totallen:22, nancount:178, test_reccnt:0\n",
      "carno:19, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:21, totallen:116, nancount:84, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:83, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:1, totallen:165, nancount:35, test_reccnt:1\n",
      "carno:4, totallen:183, nancount:17, test_reccnt:1\n",
      "no pit ts\n",
      "carno:5, totallen:0, nancount:200, test_reccnt:1\n",
      "no pit ts\n",
      "carno:6, totallen:0, nancount:200, test_reccnt:1\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:10, totallen:165, nancount:35, test_reccnt:1\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:14, totallen:15, nancount:185, test_reccnt:1\n",
      "carno:15, totallen:173, nancount:27, test_reccnt:1\n",
      "carno:18, totallen:200, nancount:0, test_reccnt:1\n",
      "no pit ts\n",
      "carno:19, totallen:0, nancount:200, test_reccnt:1\n",
      "carno:20, totallen:163, nancount:37, test_reccnt:1\n",
      "no pit ts\n",
      "carno:21, totallen:16, nancount:184, test_reccnt:1\n",
      "carno:22, totallen:164, nancount:36, test_reccnt:1\n",
      "carno:23, totallen:166, nancount:34, test_reccnt:1\n",
      "carno:26, totallen:166, nancount:34, test_reccnt:1\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:1\n",
      "no pit ts\n",
      "carno:28, totallen:0, nancount:200, test_reccnt:1\n",
      "no pit ts\n",
      "carno:30, totallen:0, nancount:200, test_reccnt:1\n",
      "carno:59, totallen:165, nancount:35, test_reccnt:1\n",
      "carno:88, totallen:161, nancount:39, test_reccnt:1\n",
      "carno:98, totallen:165, nancount:35, test_reccnt:1\n",
      "skip event: Pocono-2019\n",
      "skip event: Phoenix-2018\n",
      "skip event: Gateway-2018\n",
      "skip event: Gateway-2019\n",
      "train len:14402, test len:2651\n",
      "14402 8161\n"
     ]
    }
   ],
   "source": [
    "for testevent in testevents:\n",
    "    for feature_cnt in [2,3]:\n",
    "        \n",
    "        sel_stintlen, noshort_stintlen, binsize = stintlen_config[trainrace]\n",
    "        \n",
    "        df_train, df_test, _data= build_datasets(testevent, include_end, \n",
    "                                                 sel_stintlen, noshort_stintlen,\n",
    "                                                 feature_cnt=feature_cnt)\n",
    "\n",
    "        key = f'{testevent}-{feature_cnt}'\n",
    "        dataset[key] = [df_train, df_test, _data]\n",
    "        featurecnt_str = 'withcurcautionlaps' if (feature_cnt==3) else 'nocurcautionlaps'\n",
    "\n",
    "        #datafile = f'{dataOutputRoot}/pitstop_nextpit_dataset-{dbid}-t{testevent}-alldata-{featurecnt_str}{includeend_str}.pickle'\n",
    "        #with open(datafile, 'wb') as f:\n",
    "        #    print('save data:', datafile)\n",
    "        #    savedata = [df_train, df_test, events, testevent, _data]\n",
    "        #    pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save data: data//pitstop_nextpit_dataset-Pocono_2013_2017-alldata--includeend.pickle\n"
     ]
    }
   ],
   "source": [
    "datafile = f'{dataOutputRoot}/pitstop_nextpit_dataset-{dbid}-alldata-{includeend_str}.pickle'\n",
    "with open(datafile, 'wb') as f:\n",
    "    print('save data:', datafile)\n",
    "    savedata = dataset\n",
    "    pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start model training\n",
      "INFO:root:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]INFO:root:Number of parameters in MLPTrainingNetwork: 213\n",
      "100%|██████████| 100/100 [00:00<00:00, 146.75it/s, avg_epoch_loss=1.38]\n",
      "INFO:root:Epoch[0] Elapsed time 0.686 seconds\n",
      "INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=1.382459\n",
      "INFO:root:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 131.33it/s, avg_epoch_loss=0.685]\n",
      "INFO:root:Epoch[1] Elapsed time 0.763 seconds\n",
      "INFO:root:Epoch[1] Evaluation metric 'epoch_loss'=0.685129\n",
      "INFO:root:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.27it/s, avg_epoch_loss=0.442]\n",
      "INFO:root:Epoch[2] Elapsed time 0.863 seconds\n",
      "INFO:root:Epoch[2] Evaluation metric 'epoch_loss'=0.441985\n",
      "INFO:root:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.27it/s, avg_epoch_loss=0.382]\n",
      "INFO:root:Epoch[3] Elapsed time 0.861 seconds\n",
      "INFO:root:Epoch[3] Evaluation metric 'epoch_loss'=0.382397\n",
      "INFO:root:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 125.03it/s, avg_epoch_loss=0.306]\n",
      "INFO:root:Epoch[4] Elapsed time 0.802 seconds\n",
      "INFO:root:Epoch[4] Evaluation metric 'epoch_loss'=0.306347\n",
      "INFO:root:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.94it/s, avg_epoch_loss=0.266]\n",
      "INFO:root:Epoch[5] Elapsed time 1.034 seconds\n",
      "INFO:root:Epoch[5] Evaluation metric 'epoch_loss'=0.265567\n",
      "INFO:root:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.21it/s, avg_epoch_loss=0.258]\n",
      "INFO:root:Epoch[6] Elapsed time 0.918 seconds\n",
      "INFO:root:Epoch[6] Evaluation metric 'epoch_loss'=0.257663\n",
      "INFO:root:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 158.70it/s, avg_epoch_loss=0.236]\n",
      "INFO:root:Epoch[7] Elapsed time 0.632 seconds\n",
      "INFO:root:Epoch[7] Evaluation metric 'epoch_loss'=0.236027\n",
      "INFO:root:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 95.40it/s, avg_epoch_loss=0.207]\n",
      "INFO:root:Epoch[8] Elapsed time 1.059 seconds\n",
      "INFO:root:Epoch[8] Evaluation metric 'epoch_loss'=0.207019\n",
      "INFO:root:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 91.96it/s, avg_epoch_loss=0.181]\n",
      "INFO:root:Epoch[9] Elapsed time 1.089 seconds\n",
      "INFO:root:Epoch[9] Evaluation metric 'epoch_loss'=0.181401\n",
      "INFO:root:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.72it/s, avg_epoch_loss=0.173]\n",
      "INFO:root:Epoch[10] Elapsed time 1.457 seconds\n",
      "INFO:root:Epoch[10] Evaluation metric 'epoch_loss'=0.172911\n",
      "INFO:root:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 69.39it/s, avg_epoch_loss=0.144]\n",
      "INFO:root:Epoch[11] Elapsed time 1.452 seconds\n",
      "INFO:root:Epoch[11] Evaluation metric 'epoch_loss'=0.144467\n",
      "INFO:root:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.37it/s, avg_epoch_loss=0.153]\n",
      "INFO:root:Epoch[12] Elapsed time 0.855 seconds\n",
      "INFO:root:Epoch[12] Evaluation metric 'epoch_loss'=0.152912\n",
      "INFO:root:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 88.81it/s, avg_epoch_loss=0.111]\n",
      "INFO:root:Epoch[13] Elapsed time 1.140 seconds\n",
      "INFO:root:Epoch[13] Evaluation metric 'epoch_loss'=0.111057\n",
      "INFO:root:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 138.63it/s, avg_epoch_loss=0.116]\n",
      "INFO:root:Epoch[14] Elapsed time 0.741 seconds\n",
      "INFO:root:Epoch[14] Evaluation metric 'epoch_loss'=0.116096\n",
      "INFO:root:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.24it/s, avg_epoch_loss=0.112]\n",
      "INFO:root:Epoch[15] Elapsed time 0.641 seconds\n",
      "INFO:root:Epoch[15] Evaluation metric 'epoch_loss'=0.111816\n",
      "INFO:root:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 142.26it/s, avg_epoch_loss=0.132]\n",
      "INFO:root:Epoch[16] Elapsed time 0.709 seconds\n",
      "INFO:root:Epoch[16] Evaluation metric 'epoch_loss'=0.131524\n",
      "INFO:root:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.20it/s, avg_epoch_loss=0.0876]\n",
      "INFO:root:Epoch[17] Elapsed time 0.863 seconds\n",
      "INFO:root:Epoch[17] Evaluation metric 'epoch_loss'=0.087573\n",
      "INFO:root:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 100.82it/s, avg_epoch_loss=0.0818]\n",
      "INFO:root:Epoch[18] Elapsed time 0.993 seconds\n",
      "INFO:root:Epoch[18] Evaluation metric 'epoch_loss'=0.081809\n",
      "INFO:root:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 114.98it/s, avg_epoch_loss=0.097]\n",
      "INFO:root:Epoch[19] Elapsed time 0.872 seconds\n",
      "INFO:root:Epoch[19] Evaluation metric 'epoch_loss'=0.097005\n",
      "INFO:root:Epoch[20] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 153.56it/s, avg_epoch_loss=0.0624]\n",
      "INFO:root:Epoch[20] Elapsed time 0.653 seconds\n",
      "INFO:root:Epoch[20] Evaluation metric 'epoch_loss'=0.062445\n",
      "INFO:root:Epoch[21] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.14it/s, avg_epoch_loss=0.0658]\n",
      "INFO:root:Epoch[21] Elapsed time 1.043 seconds\n",
      "INFO:root:Epoch[21] Evaluation metric 'epoch_loss'=0.065820\n",
      "INFO:root:Epoch[22] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.43it/s, avg_epoch_loss=0.0629]\n",
      "INFO:root:Epoch[22] Elapsed time 0.890 seconds\n",
      "INFO:root:Epoch[22] Evaluation metric 'epoch_loss'=0.062874\n",
      "INFO:root:Epoch[23] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.03it/s, avg_epoch_loss=0.0629]\n",
      "INFO:root:Epoch[23] Elapsed time 0.929 seconds\n",
      "INFO:root:Epoch[23] Evaluation metric 'epoch_loss'=0.062904\n",
      "INFO:root:Epoch[24] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.77it/s, avg_epoch_loss=0.0522]\n",
      "INFO:root:Epoch[24] Elapsed time 0.885 seconds\n",
      "INFO:root:Epoch[24] Evaluation metric 'epoch_loss'=0.052160\n",
      "INFO:root:Epoch[25] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.03it/s, avg_epoch_loss=0.033]\n",
      "INFO:root:Epoch[25] Elapsed time 1.080 seconds\n",
      "INFO:root:Epoch[25] Evaluation metric 'epoch_loss'=0.032996\n",
      "INFO:root:Epoch[26] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 94.38it/s, avg_epoch_loss=0.0645]\n",
      "INFO:root:Epoch[26] Elapsed time 1.062 seconds\n",
      "INFO:root:Epoch[26] Evaluation metric 'epoch_loss'=0.064457\n",
      "INFO:root:Epoch[27] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 124.93it/s, avg_epoch_loss=0.0484]\n",
      "INFO:root:Epoch[27] Elapsed time 0.802 seconds\n",
      "INFO:root:Epoch[27] Evaluation metric 'epoch_loss'=0.048427\n",
      "INFO:root:Epoch[28] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 115.99it/s, avg_epoch_loss=0.0695]\n",
      "INFO:root:Epoch[28] Elapsed time 0.876 seconds\n",
      "INFO:root:Epoch[28] Evaluation metric 'epoch_loss'=0.069469\n",
      "INFO:root:Epoch[29] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.22it/s, avg_epoch_loss=0.0443]\n",
      "INFO:root:Epoch[29] Elapsed time 0.854 seconds\n",
      "INFO:root:Epoch[29] Evaluation metric 'epoch_loss'=0.044335\n",
      "INFO:root:Epoch[30] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.17it/s, avg_epoch_loss=0.0252]\n",
      "INFO:root:Epoch[30] Elapsed time 0.885 seconds\n",
      "INFO:root:Epoch[30] Evaluation metric 'epoch_loss'=0.025174\n",
      "INFO:root:Epoch[31] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 120.03it/s, avg_epoch_loss=0.0682]\n",
      "INFO:root:Epoch[31] Elapsed time 0.835 seconds\n",
      "INFO:root:Epoch[31] Evaluation metric 'epoch_loss'=0.068231\n",
      "INFO:root:Epoch[32] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.17it/s, avg_epoch_loss=0.0421]\n",
      "INFO:root:Epoch[32] Elapsed time 1.297 seconds\n",
      "INFO:root:Epoch[32] Evaluation metric 'epoch_loss'=0.042059\n",
      "INFO:root:Epoch[33] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 86.18it/s, avg_epoch_loss=0.0162]\n",
      "INFO:root:Epoch[33] Elapsed time 1.162 seconds\n",
      "INFO:root:Epoch[33] Evaluation metric 'epoch_loss'=0.016195\n",
      "INFO:root:Epoch[34] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 72.19it/s, avg_epoch_loss=0.0347]\n",
      "INFO:root:Epoch[34] Elapsed time 1.387 seconds\n",
      "INFO:root:Epoch[34] Evaluation metric 'epoch_loss'=0.034710\n",
      "INFO:root:Epoch[35] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.99it/s, avg_epoch_loss=0.00584]\n",
      "INFO:root:Epoch[35] Elapsed time 1.452 seconds\n",
      "INFO:root:Epoch[35] Evaluation metric 'epoch_loss'=0.005843\n",
      "INFO:root:Epoch[36] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 91.10it/s, avg_epoch_loss=0.00868]\n",
      "INFO:root:Epoch[36] Elapsed time 1.099 seconds\n",
      "INFO:root:Epoch[36] Evaluation metric 'epoch_loss'=0.008681\n",
      "INFO:root:Epoch[37] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 128.56it/s, avg_epoch_loss=-.0162]\n",
      "INFO:root:Epoch[37] Elapsed time 0.781 seconds\n",
      "INFO:root:Epoch[37] Evaluation metric 'epoch_loss'=-0.016235\n",
      "INFO:root:Epoch[38] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 136.74it/s, avg_epoch_loss=0.0338]\n",
      "INFO:root:Epoch[38] Elapsed time 0.737 seconds\n",
      "INFO:root:Epoch[38] Evaluation metric 'epoch_loss'=0.033802\n",
      "INFO:root:Epoch[39] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 127.05it/s, avg_epoch_loss=0.0344]\n",
      "INFO:root:Epoch[39] Elapsed time 0.798 seconds\n",
      "INFO:root:Epoch[39] Evaluation metric 'epoch_loss'=0.034372\n",
      "INFO:root:Epoch[40] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 145.81it/s, avg_epoch_loss=0.0233]\n",
      "INFO:root:Epoch[40] Elapsed time 0.687 seconds\n",
      "INFO:root:Epoch[40] Evaluation metric 'epoch_loss'=0.023292\n",
      "INFO:root:Epoch[41] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 79.97it/s, avg_epoch_loss=0.00287]\n",
      "INFO:root:Epoch[41] Elapsed time 1.252 seconds\n",
      "INFO:root:Epoch[41] Evaluation metric 'epoch_loss'=0.002867\n",
      "INFO:root:Epoch[42] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.95it/s, avg_epoch_loss=-.00486]\n",
      "INFO:root:Epoch[42] Elapsed time 1.039 seconds\n",
      "INFO:root:Epoch[42] Evaluation metric 'epoch_loss'=-0.004860\n",
      "INFO:root:Epoch[43] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 139.33it/s, avg_epoch_loss=0.0135]\n",
      "INFO:root:Epoch[43] Elapsed time 0.730 seconds\n",
      "INFO:root:Epoch[43] Evaluation metric 'epoch_loss'=0.013540\n",
      "INFO:root:Epoch[44] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 145.28it/s, avg_epoch_loss=0.0216]\n",
      "INFO:root:Epoch[44] Elapsed time 0.690 seconds\n",
      "INFO:root:Epoch[44] Evaluation metric 'epoch_loss'=0.021577\n",
      "INFO:root:Epoch[45] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 136.56it/s, avg_epoch_loss=0.00674]\n",
      "INFO:root:Epoch[45] Elapsed time 0.734 seconds\n",
      "INFO:root:Epoch[45] Evaluation metric 'epoch_loss'=0.006737\n",
      "INFO:root:Epoch[46] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.39it/s, avg_epoch_loss=0.0201]\n",
      "INFO:root:Epoch[46] Elapsed time 1.028 seconds\n",
      "INFO:root:Epoch[46] Evaluation metric 'epoch_loss'=0.020070\n",
      "INFO:root:Epoch[47] Learning rate is 0.001\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.40it/s, avg_epoch_loss=-.0151]\n",
      "INFO:root:Epoch[47] Elapsed time 0.960 seconds\n",
      "INFO:root:Epoch[47] Evaluation metric 'epoch_loss'=-0.015064\n",
      "INFO:root:Loading parameters from best epoch (37)\n",
      "INFO:root:Epoch[48] Learning rate is 0.0005\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.63it/s, avg_epoch_loss=0.0226]\n",
      "INFO:root:Epoch[48] Elapsed time 0.926 seconds\n",
      "INFO:root:Epoch[48] Evaluation metric 'epoch_loss'=0.022643\n",
      "INFO:root:Epoch[49] Learning rate is 0.0005\n",
      "100%|██████████| 100/100 [00:00<00:00, 118.11it/s, avg_epoch_loss=0.0201]\n",
      "INFO:root:Epoch[49] Elapsed time 0.848 seconds\n",
      "INFO:root:Epoch[49] Evaluation metric 'epoch_loss'=0.020065\n",
      "INFO:root:Epoch[50] Learning rate is 0.0005\n",
      "100%|██████████| 100/100 [00:00<00:00, 142.72it/s, avg_epoch_loss=-.00389]\n",
      "INFO:root:Epoch[50] Elapsed time 0.702 seconds\n",
      "INFO:root:Epoch[50] Evaluation metric 'epoch_loss'=-0.003894\n",
      "INFO:root:Epoch[51] Learning rate is 0.0005\n",
      "100%|██████████| 100/100 [00:00<00:00, 115.56it/s, avg_epoch_loss=0.00524]\n",
      "INFO:root:Epoch[51] Elapsed time 0.868 seconds\n",
      "INFO:root:Epoch[51] Evaluation metric 'epoch_loss'=0.005237\n",
      "INFO:root:Epoch[52] Learning rate is 0.0005\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.41it/s, avg_epoch_loss=0.0224]\n",
      "INFO:root:Epoch[52] Elapsed time 1.464 seconds\n",
      "INFO:root:Epoch[52] Evaluation metric 'epoch_loss'=0.022368\n",
      "INFO:root:Epoch[53] Learning rate is 0.0005\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.46it/s, avg_epoch_loss=0.0225]\n",
      "INFO:root:Epoch[53] Elapsed time 0.884 seconds\n",
      "INFO:root:Epoch[53] Evaluation metric 'epoch_loss'=0.022529\n",
      "INFO:root:Epoch[54] Learning rate is 0.0005\n",
      "100%|██████████| 100/100 [00:00<00:00, 149.12it/s, avg_epoch_loss=0.0222]\n",
      "INFO:root:Epoch[54] Elapsed time 0.687 seconds\n",
      "INFO:root:Epoch[54] Evaluation metric 'epoch_loss'=0.022157\n",
      "INFO:root:Epoch[55] Learning rate is 0.0005\n",
      "100%|██████████| 100/100 [00:00<00:00, 118.74it/s, avg_epoch_loss=0.0181]\n",
      "INFO:root:Epoch[55] Elapsed time 0.853 seconds\n",
      "INFO:root:Epoch[55] Evaluation metric 'epoch_loss'=0.018080\n",
      "INFO:root:Epoch[56] Learning rate is 0.0005\n",
      "100%|██████████| 100/100 [00:00<00:00, 115.16it/s, avg_epoch_loss=0.0041]\n",
      "INFO:root:Epoch[56] Elapsed time 0.877 seconds\n",
      "INFO:root:Epoch[56] Evaluation metric 'epoch_loss'=0.004096\n",
      "INFO:root:Epoch[57] Learning rate is 0.0005\n",
      "100%|██████████| 100/100 [00:01<00:00, 94.23it/s, avg_epoch_loss=-.00316]\n",
      "INFO:root:Epoch[57] Elapsed time 1.067 seconds\n",
      "INFO:root:Epoch[57] Evaluation metric 'epoch_loss'=-0.003162\n",
      "INFO:root:Loading parameters from best epoch (37)\n",
      "INFO:root:Epoch[58] Learning rate is 0.00025\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.92it/s, avg_epoch_loss=0.0209]\n",
      "INFO:root:Epoch[58] Elapsed time 0.850 seconds\n",
      "INFO:root:Epoch[58] Evaluation metric 'epoch_loss'=0.020867\n",
      "INFO:root:Epoch[59] Learning rate is 0.00025\n",
      "100%|██████████| 100/100 [00:00<00:00, 134.65it/s, avg_epoch_loss=0.0237]\n",
      "INFO:root:Epoch[59] Elapsed time 0.744 seconds\n",
      "INFO:root:Epoch[59] Evaluation metric 'epoch_loss'=0.023653\n",
      "INFO:root:Epoch[60] Learning rate is 0.00025\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.59it/s, avg_epoch_loss=-.0135]\n",
      "INFO:root:Epoch[60] Elapsed time 0.862 seconds\n",
      "INFO:root:Epoch[60] Evaluation metric 'epoch_loss'=-0.013546\n",
      "INFO:root:Epoch[61] Learning rate is 0.00025\n",
      "100%|██████████| 100/100 [00:00<00:00, 120.16it/s, avg_epoch_loss=0.00196]\n",
      "INFO:root:Epoch[61] Elapsed time 0.835 seconds\n",
      "INFO:root:Epoch[61] Evaluation metric 'epoch_loss'=0.001958\n",
      "INFO:root:Epoch[62] Learning rate is 0.00025\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.53it/s, avg_epoch_loss=0.0216]\n",
      "INFO:root:Epoch[62] Elapsed time 1.040 seconds\n",
      "INFO:root:Epoch[62] Evaluation metric 'epoch_loss'=0.021590\n",
      "INFO:root:Epoch[63] Learning rate is 0.00025\n",
      "100%|██████████| 100/100 [00:01<00:00, 87.72it/s, avg_epoch_loss=0.0159]\n",
      "INFO:root:Epoch[63] Elapsed time 1.142 seconds\n",
      "INFO:root:Epoch[63] Evaluation metric 'epoch_loss'=0.015919\n",
      "INFO:root:Epoch[64] Learning rate is 0.00025\n",
      "100%|██████████| 100/100 [00:00<00:00, 129.91it/s, avg_epoch_loss=0.00897]\n",
      "INFO:root:Epoch[64] Elapsed time 0.772 seconds\n",
      "INFO:root:Epoch[64] Evaluation metric 'epoch_loss'=0.008969\n",
      "INFO:root:Epoch[65] Learning rate is 0.00025\n",
      "100%|██████████| 100/100 [00:01<00:00, 79.82it/s, avg_epoch_loss=0.000597]\n",
      "INFO:root:Epoch[65] Elapsed time 1.255 seconds\n",
      "INFO:root:Epoch[65] Evaluation metric 'epoch_loss'=0.000597\n",
      "INFO:root:Epoch[66] Learning rate is 0.00025\n",
      "100%|██████████| 100/100 [00:01<00:00, 73.29it/s, avg_epoch_loss=6.7e-5]\n",
      "INFO:root:Epoch[66] Elapsed time 1.369 seconds\n",
      "INFO:root:Epoch[66] Evaluation metric 'epoch_loss'=0.000067\n",
      "INFO:root:Epoch[67] Learning rate is 0.00025\n",
      "100%|██████████| 100/100 [00:00<00:00, 137.93it/s, avg_epoch_loss=0.0146]\n",
      "INFO:root:Epoch[67] Elapsed time 0.729 seconds\n",
      "INFO:root:Epoch[67] Evaluation metric 'epoch_loss'=0.014639\n",
      "INFO:root:Loading parameters from best epoch (37)\n",
      "INFO:root:Epoch[68] Learning rate is 0.000125\n",
      "100%|██████████| 100/100 [00:00<00:00, 125.58it/s, avg_epoch_loss=0.0367]\n",
      "INFO:root:Epoch[68] Elapsed time 0.803 seconds\n",
      "INFO:root:Epoch[68] Evaluation metric 'epoch_loss'=0.036666\n",
      "INFO:root:Epoch[69] Learning rate is 0.000125\n",
      "100%|██████████| 100/100 [00:00<00:00, 118.77it/s, avg_epoch_loss=0.0224]\n",
      "INFO:root:Epoch[69] Elapsed time 0.843 seconds\n",
      "INFO:root:Epoch[69] Evaluation metric 'epoch_loss'=0.022352\n",
      "INFO:root:Epoch[70] Learning rate is 0.000125\n",
      "100%|██████████| 100/100 [00:00<00:00, 144.96it/s, avg_epoch_loss=-.00392]\n",
      "INFO:root:Epoch[70] Elapsed time 0.693 seconds\n",
      "INFO:root:Epoch[70] Evaluation metric 'epoch_loss'=-0.003924\n",
      "INFO:root:Epoch[71] Learning rate is 0.000125\n",
      "100%|██████████| 100/100 [00:00<00:00, 134.05it/s, avg_epoch_loss=0.0291]\n",
      "INFO:root:Epoch[71] Elapsed time 0.748 seconds\n",
      "INFO:root:Epoch[71] Evaluation metric 'epoch_loss'=0.029129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[72] Learning rate is 0.000125\n",
      "100%|██████████| 100/100 [00:01<00:00, 81.87it/s, avg_epoch_loss=0.0302]\n",
      "INFO:root:Epoch[72] Elapsed time 1.240 seconds\n",
      "INFO:root:Epoch[72] Evaluation metric 'epoch_loss'=0.030209\n",
      "INFO:root:Epoch[73] Learning rate is 0.000125\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.18it/s, avg_epoch_loss=-.00764]\n",
      "INFO:root:Epoch[73] Elapsed time 0.893 seconds\n",
      "INFO:root:Epoch[73] Evaluation metric 'epoch_loss'=-0.007638\n",
      "INFO:root:Epoch[74] Learning rate is 0.000125\n",
      "100%|██████████| 100/100 [00:01<00:00, 75.20it/s, avg_epoch_loss=0.0253]\n",
      "INFO:root:Epoch[74] Elapsed time 1.333 seconds\n",
      "INFO:root:Epoch[74] Evaluation metric 'epoch_loss'=0.025260\n",
      "INFO:root:Epoch[75] Learning rate is 0.000125\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.21it/s, avg_epoch_loss=0.00897]\n",
      "INFO:root:Epoch[75] Elapsed time 1.020 seconds\n",
      "INFO:root:Epoch[75] Evaluation metric 'epoch_loss'=0.008970\n",
      "INFO:root:Epoch[76] Learning rate is 0.000125\n",
      "100%|██████████| 100/100 [00:01<00:00, 84.53it/s, avg_epoch_loss=-.00186]\n",
      "INFO:root:Epoch[76] Elapsed time 1.185 seconds\n",
      "INFO:root:Epoch[76] Evaluation metric 'epoch_loss'=-0.001860\n",
      "INFO:root:Epoch[77] Learning rate is 0.000125\n",
      "100%|██████████| 100/100 [00:01<00:00, 73.30it/s, avg_epoch_loss=0.0248]\n",
      "INFO:root:Epoch[77] Elapsed time 1.366 seconds\n",
      "INFO:root:Epoch[77] Evaluation metric 'epoch_loss'=0.024776\n",
      "INFO:root:Loading parameters from best epoch (37)\n",
      "INFO:root:Epoch[78] Learning rate is 6.25e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 84.94it/s, avg_epoch_loss=0.011]\n",
      "INFO:root:Epoch[78] Elapsed time 1.179 seconds\n",
      "INFO:root:Epoch[78] Evaluation metric 'epoch_loss'=0.011027\n",
      "INFO:root:Epoch[79] Learning rate is 6.25e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 140.74it/s, avg_epoch_loss=0.0236]\n",
      "INFO:root:Epoch[79] Elapsed time 0.712 seconds\n",
      "INFO:root:Epoch[79] Evaluation metric 'epoch_loss'=0.023572\n",
      "INFO:root:Epoch[80] Learning rate is 6.25e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 121.20it/s, avg_epoch_loss=0.00464]\n",
      "INFO:root:Epoch[80] Elapsed time 0.827 seconds\n",
      "INFO:root:Epoch[80] Evaluation metric 'epoch_loss'=0.004643\n",
      "INFO:root:Epoch[81] Learning rate is 6.25e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 123.64it/s, avg_epoch_loss=0.0243]\n",
      "INFO:root:Epoch[81] Elapsed time 0.826 seconds\n",
      "INFO:root:Epoch[81] Evaluation metric 'epoch_loss'=0.024341\n",
      "INFO:root:Epoch[82] Learning rate is 6.25e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 83.23it/s, avg_epoch_loss=0.00846]\n",
      "INFO:root:Epoch[82] Elapsed time 1.224 seconds\n",
      "INFO:root:Epoch[82] Evaluation metric 'epoch_loss'=0.008458\n",
      "INFO:root:Epoch[83] Learning rate is 6.25e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 122.25it/s, avg_epoch_loss=0.0294]\n",
      "INFO:root:Epoch[83] Elapsed time 0.828 seconds\n",
      "INFO:root:Epoch[83] Evaluation metric 'epoch_loss'=0.029425\n",
      "INFO:root:Epoch[84] Learning rate is 6.25e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 92.93it/s, avg_epoch_loss=0.0167]\n",
      "INFO:root:Epoch[84] Elapsed time 1.085 seconds\n",
      "INFO:root:Epoch[84] Evaluation metric 'epoch_loss'=0.016729\n",
      "INFO:root:Epoch[85] Learning rate is 6.25e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.37it/s, avg_epoch_loss=0.00419]\n",
      "INFO:root:Epoch[85] Elapsed time 0.961 seconds\n",
      "INFO:root:Epoch[85] Evaluation metric 'epoch_loss'=0.004191\n",
      "INFO:root:Epoch[86] Learning rate is 6.25e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 121.24it/s, avg_epoch_loss=0.0342]\n",
      "INFO:root:Epoch[86] Elapsed time 0.829 seconds\n",
      "INFO:root:Epoch[86] Evaluation metric 'epoch_loss'=0.034177\n",
      "INFO:root:Epoch[87] Learning rate is 6.25e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.08it/s, avg_epoch_loss=0.0199]\n",
      "INFO:root:Epoch[87] Elapsed time 0.902 seconds\n",
      "INFO:root:Epoch[87] Evaluation metric 'epoch_loss'=0.019928\n",
      "INFO:root:Loading parameters from best epoch (37)\n",
      "INFO:root:Epoch[88] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.32it/s, avg_epoch_loss=0.0343]\n",
      "INFO:root:Epoch[88] Elapsed time 0.855 seconds\n",
      "INFO:root:Epoch[88] Evaluation metric 'epoch_loss'=0.034343\n",
      "INFO:root:Epoch[89] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.12it/s, avg_epoch_loss=0.031]\n",
      "INFO:root:Epoch[89] Elapsed time 0.974 seconds\n",
      "INFO:root:Epoch[89] Evaluation metric 'epoch_loss'=0.030976\n",
      "INFO:root:Epoch[90] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.85it/s, avg_epoch_loss=0.0296]\n",
      "INFO:root:Epoch[90] Elapsed time 0.966 seconds\n",
      "INFO:root:Epoch[90] Evaluation metric 'epoch_loss'=0.029624\n",
      "INFO:root:Epoch[91] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.74it/s, avg_epoch_loss=0.0222]\n",
      "INFO:root:Epoch[91] Elapsed time 0.884 seconds\n",
      "INFO:root:Epoch[91] Evaluation metric 'epoch_loss'=0.022227\n",
      "INFO:root:Epoch[92] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 52.87it/s, avg_epoch_loss=0.00843]\n",
      "INFO:root:Epoch[92] Elapsed time 1.894 seconds\n",
      "INFO:root:Epoch[92] Evaluation metric 'epoch_loss'=0.008427\n",
      "INFO:root:Epoch[93] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 119.38it/s, avg_epoch_loss=0.0225]\n",
      "INFO:root:Epoch[93] Elapsed time 0.839 seconds\n",
      "INFO:root:Epoch[93] Evaluation metric 'epoch_loss'=0.022481\n",
      "INFO:root:Epoch[94] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.81it/s, avg_epoch_loss=-.0163]\n",
      "INFO:root:Epoch[94] Elapsed time 0.931 seconds\n",
      "INFO:root:Epoch[94] Evaluation metric 'epoch_loss'=-0.016273\n",
      "INFO:root:Epoch[95] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 90.29it/s, avg_epoch_loss=0.0447]\n",
      "INFO:root:Epoch[95] Elapsed time 1.122 seconds\n",
      "INFO:root:Epoch[95] Evaluation metric 'epoch_loss'=0.044654\n",
      "INFO:root:Epoch[96] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 82.81it/s, avg_epoch_loss=0.00558]\n",
      "INFO:root:Epoch[96] Elapsed time 1.227 seconds\n",
      "INFO:root:Epoch[96] Evaluation metric 'epoch_loss'=0.005576\n",
      "INFO:root:Epoch[97] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.87it/s, avg_epoch_loss=0.0284]\n",
      "INFO:root:Epoch[97] Elapsed time 0.930 seconds\n",
      "INFO:root:Epoch[97] Evaluation metric 'epoch_loss'=0.028427\n",
      "INFO:root:Epoch[98] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 105.99it/s, avg_epoch_loss=-.00128]\n",
      "INFO:root:Epoch[98] Elapsed time 0.945 seconds\n",
      "INFO:root:Epoch[98] Evaluation metric 'epoch_loss'=-0.001285\n",
      "INFO:root:Epoch[99] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 92.79it/s, avg_epoch_loss=0.0254]\n",
      "INFO:root:Epoch[99] Elapsed time 1.089 seconds\n",
      "INFO:root:Epoch[99] Evaluation metric 'epoch_loss'=0.025428\n",
      "INFO:root:Epoch[100] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 129.65it/s, avg_epoch_loss=0.00772]\n",
      "INFO:root:Epoch[100] Elapsed time 0.782 seconds\n",
      "INFO:root:Epoch[100] Evaluation metric 'epoch_loss'=0.007718\n",
      "INFO:root:Epoch[101] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.86it/s, avg_epoch_loss=-.00862]\n",
      "INFO:root:Epoch[101] Elapsed time 0.964 seconds\n",
      "INFO:root:Epoch[101] Evaluation metric 'epoch_loss'=-0.008616\n",
      "INFO:root:Epoch[102] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 152.56it/s, avg_epoch_loss=0.0332]\n",
      "INFO:root:Epoch[102] Elapsed time 0.657 seconds\n",
      "INFO:root:Epoch[102] Evaluation metric 'epoch_loss'=0.033178\n",
      "INFO:root:Epoch[103] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.23it/s, avg_epoch_loss=0.00494]\n",
      "INFO:root:Epoch[103] Elapsed time 0.642 seconds\n",
      "INFO:root:Epoch[103] Evaluation metric 'epoch_loss'=0.004943\n",
      "INFO:root:Epoch[104] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 157.28it/s, avg_epoch_loss=-.0148]\n",
      "INFO:root:Epoch[104] Elapsed time 0.638 seconds\n",
      "INFO:root:Epoch[104] Evaluation metric 'epoch_loss'=-0.014843\n",
      "INFO:root:Epoch[105] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 128.84it/s, avg_epoch_loss=0.0045]\n",
      "INFO:root:Epoch[105] Elapsed time 0.778 seconds\n",
      "INFO:root:Epoch[105] Evaluation metric 'epoch_loss'=0.004501\n",
      "INFO:root:Epoch[106] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 157.08it/s, avg_epoch_loss=0.000673]\n",
      "INFO:root:Epoch[106] Elapsed time 0.638 seconds\n",
      "INFO:root:Epoch[106] Evaluation metric 'epoch_loss'=0.000673\n",
      "INFO:root:Epoch[107] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 106.20it/s, avg_epoch_loss=0.0123]\n",
      "INFO:root:Epoch[107] Elapsed time 0.943 seconds\n",
      "INFO:root:Epoch[107] Evaluation metric 'epoch_loss'=0.012308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[108] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 114.90it/s, avg_epoch_loss=0.0164]\n",
      "INFO:root:Epoch[108] Elapsed time 0.872 seconds\n",
      "INFO:root:Epoch[108] Evaluation metric 'epoch_loss'=0.016361\n",
      "INFO:root:Epoch[109] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.64it/s, avg_epoch_loss=0.0173]\n",
      "INFO:root:Epoch[109] Elapsed time 0.899 seconds\n",
      "INFO:root:Epoch[109] Evaluation metric 'epoch_loss'=0.017277\n",
      "INFO:root:Epoch[110] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 146.75it/s, avg_epoch_loss=0.00338]\n",
      "INFO:root:Epoch[110] Elapsed time 0.683 seconds\n",
      "INFO:root:Epoch[110] Evaluation metric 'epoch_loss'=0.003383\n",
      "INFO:root:Epoch[111] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.90it/s, avg_epoch_loss=-.00174]\n",
      "INFO:root:Epoch[111] Elapsed time 0.896 seconds\n",
      "INFO:root:Epoch[111] Evaluation metric 'epoch_loss'=-0.001739\n",
      "INFO:root:Epoch[112] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.02it/s, avg_epoch_loss=-.00603]\n",
      "INFO:root:Epoch[112] Elapsed time 1.033 seconds\n",
      "INFO:root:Epoch[112] Evaluation metric 'epoch_loss'=-0.006033\n",
      "INFO:root:Epoch[113] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 94.71it/s, avg_epoch_loss=0.00838]\n",
      "INFO:root:Epoch[113] Elapsed time 1.059 seconds\n",
      "INFO:root:Epoch[113] Evaluation metric 'epoch_loss'=0.008382\n",
      "INFO:root:Epoch[114] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.76it/s, avg_epoch_loss=0.0133]\n",
      "INFO:root:Epoch[114] Elapsed time 0.919 seconds\n",
      "INFO:root:Epoch[114] Evaluation metric 'epoch_loss'=0.013320\n",
      "INFO:root:Epoch[115] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 132.81it/s, avg_epoch_loss=0.0191]\n",
      "INFO:root:Epoch[115] Elapsed time 0.755 seconds\n",
      "INFO:root:Epoch[115] Evaluation metric 'epoch_loss'=0.019069\n",
      "INFO:root:Epoch[116] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.31it/s, avg_epoch_loss=0.0139]\n",
      "INFO:root:Epoch[116] Elapsed time 0.961 seconds\n",
      "INFO:root:Epoch[116] Evaluation metric 'epoch_loss'=0.013949\n",
      "INFO:root:Epoch[117] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 114.81it/s, avg_epoch_loss=0.0106]\n",
      "INFO:root:Epoch[117] Elapsed time 0.880 seconds\n",
      "INFO:root:Epoch[117] Evaluation metric 'epoch_loss'=0.010631\n",
      "INFO:root:Epoch[118] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 105.07it/s, avg_epoch_loss=0.0124]\n",
      "INFO:root:Epoch[118] Elapsed time 0.969 seconds\n",
      "INFO:root:Epoch[118] Evaluation metric 'epoch_loss'=0.012423\n",
      "INFO:root:Epoch[119] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 115.87it/s, avg_epoch_loss=0.018]\n",
      "INFO:root:Epoch[119] Elapsed time 0.868 seconds\n",
      "INFO:root:Epoch[119] Evaluation metric 'epoch_loss'=0.018007\n",
      "INFO:root:Epoch[120] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.19it/s, avg_epoch_loss=0.0279]\n",
      "INFO:root:Epoch[120] Elapsed time 0.901 seconds\n",
      "INFO:root:Epoch[120] Evaluation metric 'epoch_loss'=0.027922\n",
      "INFO:root:Epoch[121] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.55it/s, avg_epoch_loss=0.0195]\n",
      "INFO:root:Epoch[121] Elapsed time 0.898 seconds\n",
      "INFO:root:Epoch[121] Evaluation metric 'epoch_loss'=0.019520\n",
      "INFO:root:Epoch[122] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.44it/s, avg_epoch_loss=-.000379]\n",
      "INFO:root:Epoch[122] Elapsed time 0.856 seconds\n",
      "INFO:root:Epoch[122] Evaluation metric 'epoch_loss'=-0.000379\n",
      "INFO:root:Epoch[123] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.49it/s, avg_epoch_loss=-.00201]\n",
      "INFO:root:Epoch[123] Elapsed time 0.915 seconds\n",
      "INFO:root:Epoch[123] Evaluation metric 'epoch_loss'=-0.002010\n",
      "INFO:root:Epoch[124] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 92.32it/s, avg_epoch_loss=-.00138]\n",
      "INFO:root:Epoch[124] Elapsed time 1.104 seconds\n",
      "INFO:root:Epoch[124] Evaluation metric 'epoch_loss'=-0.001378\n",
      "INFO:root:Epoch[125] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.28it/s, avg_epoch_loss=0.00221]\n",
      "INFO:root:Epoch[125] Elapsed time 0.895 seconds\n",
      "INFO:root:Epoch[125] Evaluation metric 'epoch_loss'=0.002211\n",
      "INFO:root:Epoch[126] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 101.35it/s, avg_epoch_loss=0.00325]\n",
      "INFO:root:Epoch[126] Elapsed time 0.992 seconds\n",
      "INFO:root:Epoch[126] Evaluation metric 'epoch_loss'=0.003250\n",
      "INFO:root:Epoch[127] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.15it/s, avg_epoch_loss=-.00675]\n",
      "INFO:root:Epoch[127] Elapsed time 0.901 seconds\n",
      "INFO:root:Epoch[127] Evaluation metric 'epoch_loss'=-0.006755\n",
      "INFO:root:Epoch[128] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.56it/s, avg_epoch_loss=0.0299]\n",
      "INFO:root:Epoch[128] Elapsed time 1.007 seconds\n",
      "INFO:root:Epoch[128] Evaluation metric 'epoch_loss'=0.029863\n",
      "INFO:root:Epoch[129] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.55it/s, avg_epoch_loss=-.00902]\n",
      "INFO:root:Epoch[129] Elapsed time 1.018 seconds\n",
      "INFO:root:Epoch[129] Evaluation metric 'epoch_loss'=-0.009019\n",
      "INFO:root:Epoch[130] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 137.14it/s, avg_epoch_loss=0.00643]\n",
      "INFO:root:Epoch[130] Elapsed time 0.731 seconds\n",
      "INFO:root:Epoch[130] Evaluation metric 'epoch_loss'=0.006430\n",
      "INFO:root:Epoch[131] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 130.38it/s, avg_epoch_loss=-.00474]\n",
      "INFO:root:Epoch[131] Elapsed time 0.768 seconds\n",
      "INFO:root:Epoch[131] Evaluation metric 'epoch_loss'=-0.004738\n",
      "INFO:root:Epoch[132] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 105.87it/s, avg_epoch_loss=-.00944]\n",
      "INFO:root:Epoch[132] Elapsed time 0.948 seconds\n",
      "INFO:root:Epoch[132] Evaluation metric 'epoch_loss'=-0.009443\n",
      "INFO:root:Epoch[133] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 79.67it/s, avg_epoch_loss=-.00339]\n",
      "INFO:root:Epoch[133] Elapsed time 1.257 seconds\n",
      "INFO:root:Epoch[133] Evaluation metric 'epoch_loss'=-0.003392\n",
      "INFO:root:Epoch[134] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 87.92it/s, avg_epoch_loss=0.00234]\n",
      "INFO:root:Epoch[134] Elapsed time 1.145 seconds\n",
      "INFO:root:Epoch[134] Evaluation metric 'epoch_loss'=0.002336\n",
      "INFO:root:Epoch[135] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.49it/s, avg_epoch_loss=0.00583]\n",
      "INFO:root:Epoch[135] Elapsed time 0.969 seconds\n",
      "INFO:root:Epoch[135] Evaluation metric 'epoch_loss'=0.005831\n",
      "INFO:root:Epoch[136] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 83.24it/s, avg_epoch_loss=0.027]\n",
      "INFO:root:Epoch[136] Elapsed time 1.213 seconds\n",
      "INFO:root:Epoch[136] Evaluation metric 'epoch_loss'=0.026981\n",
      "INFO:root:Epoch[137] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 91.33it/s, avg_epoch_loss=-.0309]\n",
      "INFO:root:Epoch[137] Elapsed time 1.113 seconds\n",
      "INFO:root:Epoch[137] Evaluation metric 'epoch_loss'=-0.030864\n",
      "INFO:root:Epoch[138] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 75.83it/s, avg_epoch_loss=0.0132]\n",
      "INFO:root:Epoch[138] Elapsed time 1.324 seconds\n",
      "INFO:root:Epoch[138] Evaluation metric 'epoch_loss'=0.013172\n",
      "INFO:root:Epoch[139] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.00it/s, avg_epoch_loss=0.026]\n",
      "INFO:root:Epoch[139] Elapsed time 1.034 seconds\n",
      "INFO:root:Epoch[139] Evaluation metric 'epoch_loss'=0.025988\n",
      "INFO:root:Epoch[140] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 65.88it/s, avg_epoch_loss=-.00778]\n",
      "INFO:root:Epoch[140] Elapsed time 1.520 seconds\n",
      "INFO:root:Epoch[140] Evaluation metric 'epoch_loss'=-0.007785\n",
      "INFO:root:Epoch[141] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.29it/s, avg_epoch_loss=0.0132]\n",
      "INFO:root:Epoch[141] Elapsed time 1.048 seconds\n",
      "INFO:root:Epoch[141] Evaluation metric 'epoch_loss'=0.013159\n",
      "INFO:root:Epoch[142] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 123.24it/s, avg_epoch_loss=0.00765]\n",
      "INFO:root:Epoch[142] Elapsed time 0.814 seconds\n",
      "INFO:root:Epoch[142] Evaluation metric 'epoch_loss'=0.007651\n",
      "INFO:root:Epoch[143] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 121.21it/s, avg_epoch_loss=0.00719]\n",
      "INFO:root:Epoch[143] Elapsed time 0.827 seconds\n",
      "INFO:root:Epoch[143] Evaluation metric 'epoch_loss'=0.007185\n",
      "INFO:root:Epoch[144] Learning rate is 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 128.13it/s, avg_epoch_loss=0.00467]\n",
      "INFO:root:Epoch[144] Elapsed time 0.782 seconds\n",
      "INFO:root:Epoch[144] Evaluation metric 'epoch_loss'=0.004666\n",
      "INFO:root:Epoch[145] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 64.22it/s, avg_epoch_loss=0.0225]\n",
      "INFO:root:Epoch[145] Elapsed time 1.559 seconds\n",
      "INFO:root:Epoch[145] Evaluation metric 'epoch_loss'=0.022533\n",
      "INFO:root:Epoch[146] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.83it/s, avg_epoch_loss=0.0114]\n",
      "INFO:root:Epoch[146] Elapsed time 0.852 seconds\n",
      "INFO:root:Epoch[146] Evaluation metric 'epoch_loss'=0.011391\n",
      "INFO:root:Epoch[147] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 87.71it/s, avg_epoch_loss=-.014]\n",
      "INFO:root:Epoch[147] Elapsed time 1.142 seconds\n",
      "INFO:root:Epoch[147] Evaluation metric 'epoch_loss'=-0.013969\n",
      "INFO:root:Epoch[148] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 73.49it/s, avg_epoch_loss=-.00275]\n",
      "INFO:root:Epoch[148] Elapsed time 1.362 seconds\n",
      "INFO:root:Epoch[148] Evaluation metric 'epoch_loss'=-0.002747\n",
      "INFO:root:Epoch[149] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 58.62it/s, avg_epoch_loss=0.0156]\n",
      "INFO:root:Epoch[149] Elapsed time 1.707 seconds\n",
      "INFO:root:Epoch[149] Evaluation metric 'epoch_loss'=0.015582\n",
      "INFO:root:Epoch[150] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 95.26it/s, avg_epoch_loss=0.0157]\n",
      "INFO:root:Epoch[150] Elapsed time 1.052 seconds\n",
      "INFO:root:Epoch[150] Evaluation metric 'epoch_loss'=0.015689\n",
      "INFO:root:Epoch[151] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 81.76it/s, avg_epoch_loss=-.00264]\n",
      "INFO:root:Epoch[151] Elapsed time 1.234 seconds\n",
      "INFO:root:Epoch[151] Evaluation metric 'epoch_loss'=-0.002643\n",
      "INFO:root:Epoch[152] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 127.88it/s, avg_epoch_loss=0.00171]\n",
      "INFO:root:Epoch[152] Elapsed time 0.786 seconds\n",
      "INFO:root:Epoch[152] Evaluation metric 'epoch_loss'=0.001712\n",
      "INFO:root:Epoch[153] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 100.85it/s, avg_epoch_loss=-.0218]\n",
      "INFO:root:Epoch[153] Elapsed time 0.995 seconds\n",
      "INFO:root:Epoch[153] Evaluation metric 'epoch_loss'=-0.021760\n",
      "INFO:root:Epoch[154] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 102.47it/s, avg_epoch_loss=0.00552]\n",
      "INFO:root:Epoch[154] Elapsed time 0.978 seconds\n",
      "INFO:root:Epoch[154] Evaluation metric 'epoch_loss'=0.005518\n",
      "INFO:root:Epoch[155] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.44it/s, avg_epoch_loss=0.0263]\n",
      "INFO:root:Epoch[155] Elapsed time 0.650 seconds\n",
      "INFO:root:Epoch[155] Evaluation metric 'epoch_loss'=0.026287\n",
      "INFO:root:Epoch[156] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 119.06it/s, avg_epoch_loss=-.00476]\n",
      "INFO:root:Epoch[156] Elapsed time 0.842 seconds\n",
      "INFO:root:Epoch[156] Evaluation metric 'epoch_loss'=-0.004760\n",
      "INFO:root:Epoch[157] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.58it/s, avg_epoch_loss=-.00163]\n",
      "INFO:root:Epoch[157] Elapsed time 1.077 seconds\n",
      "INFO:root:Epoch[157] Evaluation metric 'epoch_loss'=-0.001630\n",
      "INFO:root:Epoch[158] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 124.19it/s, avg_epoch_loss=-.00336]\n",
      "INFO:root:Epoch[158] Elapsed time 0.808 seconds\n",
      "INFO:root:Epoch[158] Evaluation metric 'epoch_loss'=-0.003359\n",
      "INFO:root:Epoch[159] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 133.30it/s, avg_epoch_loss=0.00527]\n",
      "INFO:root:Epoch[159] Elapsed time 0.754 seconds\n",
      "INFO:root:Epoch[159] Evaluation metric 'epoch_loss'=0.005270\n",
      "INFO:root:Epoch[160] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 94.98it/s, avg_epoch_loss=0.0209]\n",
      "INFO:root:Epoch[160] Elapsed time 1.055 seconds\n",
      "INFO:root:Epoch[160] Evaluation metric 'epoch_loss'=0.020916\n",
      "INFO:root:Epoch[161] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 118.23it/s, avg_epoch_loss=0.00341]\n",
      "INFO:root:Epoch[161] Elapsed time 0.848 seconds\n",
      "INFO:root:Epoch[161] Evaluation metric 'epoch_loss'=0.003411\n",
      "INFO:root:Epoch[162] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 119.00it/s, avg_epoch_loss=0.0249]\n",
      "INFO:root:Epoch[162] Elapsed time 0.852 seconds\n",
      "INFO:root:Epoch[162] Evaluation metric 'epoch_loss'=0.024868\n",
      "INFO:root:Epoch[163] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.15it/s, avg_epoch_loss=-7.81e-5]\n",
      "INFO:root:Epoch[163] Elapsed time 0.935 seconds\n",
      "INFO:root:Epoch[163] Evaluation metric 'epoch_loss'=-0.000078\n",
      "INFO:root:Epoch[164] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 128.92it/s, avg_epoch_loss=0.0197]\n",
      "INFO:root:Epoch[164] Elapsed time 0.777 seconds\n",
      "INFO:root:Epoch[164] Evaluation metric 'epoch_loss'=0.019748\n",
      "INFO:root:Epoch[165] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 148.19it/s, avg_epoch_loss=0.00804]\n",
      "INFO:root:Epoch[165] Elapsed time 0.676 seconds\n",
      "INFO:root:Epoch[165] Evaluation metric 'epoch_loss'=0.008035\n",
      "INFO:root:Epoch[166] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.60it/s, avg_epoch_loss=0.0131]\n",
      "INFO:root:Epoch[166] Elapsed time 1.026 seconds\n",
      "INFO:root:Epoch[166] Evaluation metric 'epoch_loss'=0.013065\n",
      "INFO:root:Epoch[167] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 92.65it/s, avg_epoch_loss=-.00426]\n",
      "INFO:root:Epoch[167] Elapsed time 1.083 seconds\n",
      "INFO:root:Epoch[167] Evaluation metric 'epoch_loss'=-0.004258\n",
      "INFO:root:Epoch[168] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 82.48it/s, avg_epoch_loss=-.000882]\n",
      "INFO:root:Epoch[168] Elapsed time 1.224 seconds\n",
      "INFO:root:Epoch[168] Evaluation metric 'epoch_loss'=-0.000882\n",
      "INFO:root:Epoch[169] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 91.43it/s, avg_epoch_loss=-.00525]\n",
      "INFO:root:Epoch[169] Elapsed time 1.096 seconds\n",
      "INFO:root:Epoch[169] Evaluation metric 'epoch_loss'=-0.005246\n",
      "INFO:root:Epoch[170] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.37it/s, avg_epoch_loss=-.00904]\n",
      "INFO:root:Epoch[170] Elapsed time 1.278 seconds\n",
      "INFO:root:Epoch[170] Evaluation metric 'epoch_loss'=-0.009042\n",
      "INFO:root:Epoch[171] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 71.72it/s, avg_epoch_loss=-.0102]\n",
      "INFO:root:Epoch[171] Elapsed time 1.396 seconds\n",
      "INFO:root:Epoch[171] Evaluation metric 'epoch_loss'=-0.010160\n",
      "INFO:root:Epoch[172] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 81.90it/s, avg_epoch_loss=0.00142]\n",
      "INFO:root:Epoch[172] Elapsed time 1.223 seconds\n",
      "INFO:root:Epoch[172] Evaluation metric 'epoch_loss'=0.001421\n",
      "INFO:root:Epoch[173] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 84.84it/s, avg_epoch_loss=-.000119]\n",
      "INFO:root:Epoch[173] Elapsed time 1.182 seconds\n",
      "INFO:root:Epoch[173] Evaluation metric 'epoch_loss'=-0.000119\n",
      "INFO:root:Epoch[174] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.86it/s, avg_epoch_loss=0.00842]\n",
      "INFO:root:Epoch[174] Elapsed time 0.900 seconds\n",
      "INFO:root:Epoch[174] Evaluation metric 'epoch_loss'=0.008419\n",
      "INFO:root:Epoch[175] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 118.28it/s, avg_epoch_loss=-.00352]\n",
      "INFO:root:Epoch[175] Elapsed time 0.850 seconds\n",
      "INFO:root:Epoch[175] Evaluation metric 'epoch_loss'=-0.003516\n",
      "INFO:root:Epoch[176] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.70it/s, avg_epoch_loss=0.0124]\n",
      "INFO:root:Epoch[176] Elapsed time 0.881 seconds\n",
      "INFO:root:Epoch[176] Evaluation metric 'epoch_loss'=0.012426\n",
      "INFO:root:Epoch[177] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 90.33it/s, avg_epoch_loss=-.0151]\n",
      "INFO:root:Epoch[177] Elapsed time 1.109 seconds\n",
      "INFO:root:Epoch[177] Evaluation metric 'epoch_loss'=-0.015142\n",
      "INFO:root:Epoch[178] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.35it/s, avg_epoch_loss=-.0037]\n",
      "INFO:root:Epoch[178] Elapsed time 0.797 seconds\n",
      "INFO:root:Epoch[178] Evaluation metric 'epoch_loss'=-0.003699\n",
      "INFO:root:Epoch[179] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.06it/s, avg_epoch_loss=0.0253]\n",
      "INFO:root:Epoch[179] Elapsed time 0.795 seconds\n",
      "INFO:root:Epoch[179] Evaluation metric 'epoch_loss'=0.025260\n",
      "INFO:root:Epoch[180] Learning rate is 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 107.38it/s, avg_epoch_loss=-.0164]\n",
      "INFO:root:Epoch[180] Elapsed time 0.934 seconds\n",
      "INFO:root:Epoch[180] Evaluation metric 'epoch_loss'=-0.016383\n",
      "INFO:root:Epoch[181] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 135.47it/s, avg_epoch_loss=0.0145]\n",
      "INFO:root:Epoch[181] Elapsed time 0.741 seconds\n",
      "INFO:root:Epoch[181] Evaluation metric 'epoch_loss'=0.014514\n",
      "INFO:root:Epoch[182] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 148.69it/s, avg_epoch_loss=-.00639]\n",
      "INFO:root:Epoch[182] Elapsed time 0.689 seconds\n",
      "INFO:root:Epoch[182] Evaluation metric 'epoch_loss'=-0.006386\n",
      "INFO:root:Epoch[183] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 128.12it/s, avg_epoch_loss=-.00328]\n",
      "INFO:root:Epoch[183] Elapsed time 0.782 seconds\n",
      "INFO:root:Epoch[183] Evaluation metric 'epoch_loss'=-0.003281\n",
      "INFO:root:Epoch[184] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 102.06it/s, avg_epoch_loss=0.0117]\n",
      "INFO:root:Epoch[184] Elapsed time 0.985 seconds\n",
      "INFO:root:Epoch[184] Evaluation metric 'epoch_loss'=0.011653\n",
      "INFO:root:Epoch[185] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.11it/s, avg_epoch_loss=0.00928]\n",
      "INFO:root:Epoch[185] Elapsed time 0.863 seconds\n",
      "INFO:root:Epoch[185] Evaluation metric 'epoch_loss'=0.009282\n",
      "INFO:root:Epoch[186] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 136.47it/s, avg_epoch_loss=0.00588]\n",
      "INFO:root:Epoch[186] Elapsed time 0.736 seconds\n",
      "INFO:root:Epoch[186] Evaluation metric 'epoch_loss'=0.005881\n",
      "INFO:root:Epoch[187] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 91.89it/s, avg_epoch_loss=0.00304]\n",
      "INFO:root:Epoch[187] Elapsed time 1.090 seconds\n",
      "INFO:root:Epoch[187] Evaluation metric 'epoch_loss'=0.003037\n",
      "INFO:root:Epoch[188] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.67it/s, avg_epoch_loss=0.0069]\n",
      "INFO:root:Epoch[188] Elapsed time 1.018 seconds\n",
      "INFO:root:Epoch[188] Evaluation metric 'epoch_loss'=0.006897\n",
      "INFO:root:Epoch[189] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 83.89it/s, avg_epoch_loss=0.00708]\n",
      "INFO:root:Epoch[189] Elapsed time 1.193 seconds\n",
      "INFO:root:Epoch[189] Evaluation metric 'epoch_loss'=0.007081\n",
      "INFO:root:Epoch[190] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.85it/s, avg_epoch_loss=-.00377]\n",
      "INFO:root:Epoch[190] Elapsed time 1.013 seconds\n",
      "INFO:root:Epoch[190] Evaluation metric 'epoch_loss'=-0.003774\n",
      "INFO:root:Epoch[191] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.08it/s, avg_epoch_loss=-.00271]\n",
      "INFO:root:Epoch[191] Elapsed time 1.080 seconds\n",
      "INFO:root:Epoch[191] Evaluation metric 'epoch_loss'=-0.002712\n",
      "INFO:root:Epoch[192] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.84it/s, avg_epoch_loss=-.0171]\n",
      "INFO:root:Epoch[192] Elapsed time 1.024 seconds\n",
      "INFO:root:Epoch[192] Evaluation metric 'epoch_loss'=-0.017105\n",
      "INFO:root:Epoch[193] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 119.03it/s, avg_epoch_loss=-.00145]\n",
      "INFO:root:Epoch[193] Elapsed time 0.842 seconds\n",
      "INFO:root:Epoch[193] Evaluation metric 'epoch_loss'=-0.001448\n",
      "INFO:root:Epoch[194] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.28it/s, avg_epoch_loss=0.00667]\n",
      "INFO:root:Epoch[194] Elapsed time 1.467 seconds\n",
      "INFO:root:Epoch[194] Evaluation metric 'epoch_loss'=0.006667\n",
      "INFO:root:Epoch[195] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 106.31it/s, avg_epoch_loss=0.0167]\n",
      "INFO:root:Epoch[195] Elapsed time 0.952 seconds\n",
      "INFO:root:Epoch[195] Evaluation metric 'epoch_loss'=0.016721\n",
      "INFO:root:Epoch[196] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.15it/s, avg_epoch_loss=-.0118]\n",
      "INFO:root:Epoch[196] Elapsed time 0.859 seconds\n",
      "INFO:root:Epoch[196] Evaluation metric 'epoch_loss'=-0.011752\n",
      "INFO:root:Epoch[197] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 92.72it/s, avg_epoch_loss=0.0148]\n",
      "INFO:root:Epoch[197] Elapsed time 1.080 seconds\n",
      "INFO:root:Epoch[197] Evaluation metric 'epoch_loss'=0.014844\n",
      "INFO:root:Epoch[198] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.44it/s, avg_epoch_loss=-.00804]\n",
      "INFO:root:Epoch[198] Elapsed time 0.968 seconds\n",
      "INFO:root:Epoch[198] Evaluation metric 'epoch_loss'=-0.008043\n",
      "INFO:root:Epoch[199] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 137.85it/s, avg_epoch_loss=0.00309]\n",
      "INFO:root:Epoch[199] Elapsed time 0.727 seconds\n",
      "INFO:root:Epoch[199] Evaluation metric 'epoch_loss'=0.003091\n",
      "INFO:root:Epoch[200] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.58it/s, avg_epoch_loss=0.0134]\n",
      "INFO:root:Epoch[200] Elapsed time 0.958 seconds\n",
      "INFO:root:Epoch[200] Evaluation metric 'epoch_loss'=0.013387\n",
      "INFO:root:Epoch[201] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 138.48it/s, avg_epoch_loss=0.0352]\n",
      "INFO:root:Epoch[201] Elapsed time 0.737 seconds\n",
      "INFO:root:Epoch[201] Evaluation metric 'epoch_loss'=0.035185\n",
      "INFO:root:Epoch[202] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.40it/s, avg_epoch_loss=0.0209]\n",
      "INFO:root:Epoch[202] Elapsed time 0.931 seconds\n",
      "INFO:root:Epoch[202] Evaluation metric 'epoch_loss'=0.020886\n",
      "INFO:root:Epoch[203] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.42it/s, avg_epoch_loss=-.00173]\n",
      "INFO:root:Epoch[203] Elapsed time 1.029 seconds\n",
      "INFO:root:Epoch[203] Evaluation metric 'epoch_loss'=-0.001732\n",
      "INFO:root:Epoch[204] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.94it/s, avg_epoch_loss=0.00479]\n",
      "INFO:root:Epoch[204] Elapsed time 0.857 seconds\n",
      "INFO:root:Epoch[204] Evaluation metric 'epoch_loss'=0.004791\n",
      "INFO:root:Epoch[205] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.24it/s, avg_epoch_loss=-.0182]\n",
      "INFO:root:Epoch[205] Elapsed time 0.962 seconds\n",
      "INFO:root:Epoch[205] Evaluation metric 'epoch_loss'=-0.018239\n",
      "INFO:root:Epoch[206] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.28it/s, avg_epoch_loss=0.0124]\n",
      "INFO:root:Epoch[206] Elapsed time 1.009 seconds\n",
      "INFO:root:Epoch[206] Evaluation metric 'epoch_loss'=0.012389\n",
      "INFO:root:Epoch[207] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 120.85it/s, avg_epoch_loss=0.0219]\n",
      "INFO:root:Epoch[207] Elapsed time 0.831 seconds\n",
      "INFO:root:Epoch[207] Evaluation metric 'epoch_loss'=0.021863\n",
      "INFO:root:Epoch[208] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 134.00it/s, avg_epoch_loss=-.000351]\n",
      "INFO:root:Epoch[208] Elapsed time 0.750 seconds\n",
      "INFO:root:Epoch[208] Evaluation metric 'epoch_loss'=-0.000351\n",
      "INFO:root:Epoch[209] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.82it/s, avg_epoch_loss=0.00584]\n",
      "INFO:root:Epoch[209] Elapsed time 1.079 seconds\n",
      "INFO:root:Epoch[209] Evaluation metric 'epoch_loss'=0.005844\n",
      "INFO:root:Epoch[210] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.12it/s, avg_epoch_loss=0.00238]\n",
      "INFO:root:Epoch[210] Elapsed time 0.920 seconds\n",
      "INFO:root:Epoch[210] Evaluation metric 'epoch_loss'=0.002380\n",
      "INFO:root:Epoch[211] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.88it/s, avg_epoch_loss=0.00823]\n",
      "INFO:root:Epoch[211] Elapsed time 1.067 seconds\n",
      "INFO:root:Epoch[211] Evaluation metric 'epoch_loss'=0.008234\n",
      "INFO:root:Epoch[212] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.29it/s, avg_epoch_loss=5.56e-5]\n",
      "INFO:root:Epoch[212] Elapsed time 0.902 seconds\n",
      "INFO:root:Epoch[212] Evaluation metric 'epoch_loss'=0.000056\n",
      "INFO:root:Epoch[213] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.13it/s, avg_epoch_loss=-.000591]\n",
      "INFO:root:Epoch[213] Elapsed time 0.795 seconds\n",
      "INFO:root:Epoch[213] Evaluation metric 'epoch_loss'=-0.000591\n",
      "INFO:root:Epoch[214] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 134.29it/s, avg_epoch_loss=-.00728]\n",
      "INFO:root:Epoch[214] Elapsed time 0.751 seconds\n",
      "INFO:root:Epoch[214] Evaluation metric 'epoch_loss'=-0.007276\n",
      "INFO:root:Epoch[215] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 124.17it/s, avg_epoch_loss=0.0063]\n",
      "INFO:root:Epoch[215] Elapsed time 0.807 seconds\n",
      "INFO:root:Epoch[215] Evaluation metric 'epoch_loss'=0.006298\n",
      "INFO:root:Epoch[216] Learning rate is 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 111.13it/s, avg_epoch_loss=-.0202]\n",
      "INFO:root:Epoch[216] Elapsed time 0.914 seconds\n",
      "INFO:root:Epoch[216] Evaluation metric 'epoch_loss'=-0.020188\n",
      "INFO:root:Epoch[217] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.20it/s, avg_epoch_loss=0.00913]\n",
      "INFO:root:Epoch[217] Elapsed time 0.926 seconds\n",
      "INFO:root:Epoch[217] Evaluation metric 'epoch_loss'=0.009129\n",
      "INFO:root:Epoch[218] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.25it/s, avg_epoch_loss=0.00447]\n",
      "INFO:root:Epoch[218] Elapsed time 0.909 seconds\n",
      "INFO:root:Epoch[218] Evaluation metric 'epoch_loss'=0.004470\n",
      "INFO:root:Epoch[219] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 142.76it/s, avg_epoch_loss=-.0178]\n",
      "INFO:root:Epoch[219] Elapsed time 0.711 seconds\n",
      "INFO:root:Epoch[219] Evaluation metric 'epoch_loss'=-0.017784\n",
      "INFO:root:Epoch[220] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 102.95it/s, avg_epoch_loss=0.0113]\n",
      "INFO:root:Epoch[220] Elapsed time 0.986 seconds\n",
      "INFO:root:Epoch[220] Evaluation metric 'epoch_loss'=0.011338\n",
      "INFO:root:Epoch[221] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 88.68it/s, avg_epoch_loss=-.0177]\n",
      "INFO:root:Epoch[221] Elapsed time 1.130 seconds\n",
      "INFO:root:Epoch[221] Evaluation metric 'epoch_loss'=-0.017725\n",
      "INFO:root:Epoch[222] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 106.42it/s, avg_epoch_loss=0.0183]\n",
      "INFO:root:Epoch[222] Elapsed time 0.941 seconds\n",
      "INFO:root:Epoch[222] Evaluation metric 'epoch_loss'=0.018269\n",
      "INFO:root:Epoch[223] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 148.54it/s, avg_epoch_loss=-.0147]\n",
      "INFO:root:Epoch[223] Elapsed time 0.676 seconds\n",
      "INFO:root:Epoch[223] Evaluation metric 'epoch_loss'=-0.014735\n",
      "INFO:root:Epoch[224] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 144.91it/s, avg_epoch_loss=-.00655]\n",
      "INFO:root:Epoch[224] Elapsed time 0.694 seconds\n",
      "INFO:root:Epoch[224] Evaluation metric 'epoch_loss'=-0.006552\n",
      "INFO:root:Epoch[225] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 134.05it/s, avg_epoch_loss=0.0279]\n",
      "INFO:root:Epoch[225] Elapsed time 0.747 seconds\n",
      "INFO:root:Epoch[225] Evaluation metric 'epoch_loss'=0.027939\n",
      "INFO:root:Epoch[226] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 90.28it/s, avg_epoch_loss=-.0174]\n",
      "INFO:root:Epoch[226] Elapsed time 1.109 seconds\n",
      "INFO:root:Epoch[226] Evaluation metric 'epoch_loss'=-0.017411\n",
      "INFO:root:Epoch[227] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 154.87it/s, avg_epoch_loss=-.000899]\n",
      "INFO:root:Epoch[227] Elapsed time 0.647 seconds\n",
      "INFO:root:Epoch[227] Evaluation metric 'epoch_loss'=-0.000899\n",
      "INFO:root:Epoch[228] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 151.77it/s, avg_epoch_loss=0.0138]\n",
      "INFO:root:Epoch[228] Elapsed time 0.661 seconds\n",
      "INFO:root:Epoch[228] Evaluation metric 'epoch_loss'=0.013818\n",
      "INFO:root:Epoch[229] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.70it/s, avg_epoch_loss=-.0101]\n",
      "INFO:root:Epoch[229] Elapsed time 0.645 seconds\n",
      "INFO:root:Epoch[229] Evaluation metric 'epoch_loss'=-0.010085\n",
      "INFO:root:Epoch[230] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 148.01it/s, avg_epoch_loss=0.0201]\n",
      "INFO:root:Epoch[230] Elapsed time 0.678 seconds\n",
      "INFO:root:Epoch[230] Evaluation metric 'epoch_loss'=0.020068\n",
      "INFO:root:Epoch[231] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.89it/s, avg_epoch_loss=-.00549]\n",
      "INFO:root:Epoch[231] Elapsed time 0.646 seconds\n",
      "INFO:root:Epoch[231] Evaluation metric 'epoch_loss'=-0.005486\n",
      "INFO:root:Epoch[232] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 118.34it/s, avg_epoch_loss=-.0168]\n",
      "INFO:root:Epoch[232] Elapsed time 0.848 seconds\n",
      "INFO:root:Epoch[232] Evaluation metric 'epoch_loss'=-0.016813\n",
      "INFO:root:Epoch[233] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 115.38it/s, avg_epoch_loss=0.0187]\n",
      "INFO:root:Epoch[233] Elapsed time 0.868 seconds\n",
      "INFO:root:Epoch[233] Evaluation metric 'epoch_loss'=0.018705\n",
      "INFO:root:Epoch[234] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 79.12it/s, avg_epoch_loss=0.0045]\n",
      "INFO:root:Epoch[234] Elapsed time 1.267 seconds\n",
      "INFO:root:Epoch[234] Evaluation metric 'epoch_loss'=0.004501\n",
      "INFO:root:Epoch[235] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.65it/s, avg_epoch_loss=0.027]\n",
      "INFO:root:Epoch[235] Elapsed time 1.085 seconds\n",
      "INFO:root:Epoch[235] Evaluation metric 'epoch_loss'=0.027039\n",
      "INFO:root:Epoch[236] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 91.35it/s, avg_epoch_loss=-.000677]\n",
      "INFO:root:Epoch[236] Elapsed time 1.106 seconds\n",
      "INFO:root:Epoch[236] Evaluation metric 'epoch_loss'=-0.000677\n",
      "INFO:root:Epoch[237] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 100.00it/s, avg_epoch_loss=-.0133]\n",
      "INFO:root:Epoch[237] Elapsed time 1.002 seconds\n",
      "INFO:root:Epoch[237] Evaluation metric 'epoch_loss'=-0.013302\n",
      "INFO:root:Epoch[238] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.49it/s, avg_epoch_loss=0.00126]\n",
      "INFO:root:Epoch[238] Elapsed time 0.915 seconds\n",
      "INFO:root:Epoch[238] Evaluation metric 'epoch_loss'=0.001262\n",
      "INFO:root:Epoch[239] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 101.54it/s, avg_epoch_loss=0.022]\n",
      "INFO:root:Epoch[239] Elapsed time 0.987 seconds\n",
      "INFO:root:Epoch[239] Evaluation metric 'epoch_loss'=0.022006\n",
      "INFO:root:Epoch[240] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 100.21it/s, avg_epoch_loss=-.0228]\n",
      "INFO:root:Epoch[240] Elapsed time 1.002 seconds\n",
      "INFO:root:Epoch[240] Evaluation metric 'epoch_loss'=-0.022778\n",
      "INFO:root:Epoch[241] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 88.78it/s, avg_epoch_loss=-.00919]\n",
      "INFO:root:Epoch[241] Elapsed time 1.129 seconds\n",
      "INFO:root:Epoch[241] Evaluation metric 'epoch_loss'=-0.009188\n",
      "INFO:root:Epoch[242] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 94.98it/s, avg_epoch_loss=-.0357]\n",
      "INFO:root:Epoch[242] Elapsed time 1.055 seconds\n",
      "INFO:root:Epoch[242] Evaluation metric 'epoch_loss'=-0.035692\n",
      "INFO:root:Epoch[243] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 115.64it/s, avg_epoch_loss=0.00788]\n",
      "INFO:root:Epoch[243] Elapsed time 0.866 seconds\n",
      "INFO:root:Epoch[243] Evaluation metric 'epoch_loss'=0.007880\n",
      "INFO:root:Epoch[244] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 130.32it/s, avg_epoch_loss=-.00879]\n",
      "INFO:root:Epoch[244] Elapsed time 0.770 seconds\n",
      "INFO:root:Epoch[244] Evaluation metric 'epoch_loss'=-0.008793\n",
      "INFO:root:Epoch[245] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.84it/s, avg_epoch_loss=-.00542]\n",
      "INFO:root:Epoch[245] Elapsed time 0.965 seconds\n",
      "INFO:root:Epoch[245] Evaluation metric 'epoch_loss'=-0.005415\n",
      "INFO:root:Epoch[246] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 105.22it/s, avg_epoch_loss=0.018]\n",
      "INFO:root:Epoch[246] Elapsed time 0.964 seconds\n",
      "INFO:root:Epoch[246] Evaluation metric 'epoch_loss'=0.018023\n",
      "INFO:root:Epoch[247] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 89.17it/s, avg_epoch_loss=0.00417]\n",
      "INFO:root:Epoch[247] Elapsed time 1.132 seconds\n",
      "INFO:root:Epoch[247] Evaluation metric 'epoch_loss'=0.004172\n",
      "INFO:root:Epoch[248] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 95.60it/s, avg_epoch_loss=0.0147]\n",
      "INFO:root:Epoch[248] Elapsed time 1.048 seconds\n",
      "INFO:root:Epoch[248] Evaluation metric 'epoch_loss'=0.014663\n",
      "INFO:root:Epoch[249] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 122.25it/s, avg_epoch_loss=-.0234]\n",
      "INFO:root:Epoch[249] Elapsed time 0.820 seconds\n",
      "INFO:root:Epoch[249] Evaluation metric 'epoch_loss'=-0.023360\n",
      "INFO:root:Epoch[250] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 139.39it/s, avg_epoch_loss=0.00999]\n",
      "INFO:root:Epoch[250] Elapsed time 0.731 seconds\n",
      "INFO:root:Epoch[250] Evaluation metric 'epoch_loss'=0.009991\n",
      "INFO:root:Epoch[251] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.52it/s, avg_epoch_loss=0.0266]\n",
      "INFO:root:Epoch[251] Elapsed time 1.027 seconds\n",
      "INFO:root:Epoch[251] Evaluation metric 'epoch_loss'=0.026592\n",
      "INFO:root:Epoch[252] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 73.83it/s, avg_epoch_loss=-.00738]\n",
      "INFO:root:Epoch[252] Elapsed time 1.357 seconds\n",
      "INFO:root:Epoch[252] Evaluation metric 'epoch_loss'=-0.007380\n",
      "INFO:root:Epoch[253] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.80it/s, avg_epoch_loss=0.00497]\n",
      "INFO:root:Epoch[253] Elapsed time 1.455 seconds\n",
      "INFO:root:Epoch[253] Evaluation metric 'epoch_loss'=0.004966\n",
      "INFO:root:Epoch[254] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.94it/s, avg_epoch_loss=0.00547]\n",
      "INFO:root:Epoch[254] Elapsed time 1.073 seconds\n",
      "INFO:root:Epoch[254] Evaluation metric 'epoch_loss'=0.005475\n",
      "INFO:root:Epoch[255] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 70.55it/s, avg_epoch_loss=0.0314]\n",
      "INFO:root:Epoch[255] Elapsed time 1.419 seconds\n",
      "INFO:root:Epoch[255] Evaluation metric 'epoch_loss'=0.031419\n",
      "INFO:root:Epoch[256] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 101.54it/s, avg_epoch_loss=-.00815]\n",
      "INFO:root:Epoch[256] Elapsed time 0.997 seconds\n",
      "INFO:root:Epoch[256] Evaluation metric 'epoch_loss'=-0.008150\n",
      "INFO:root:Epoch[257] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.22it/s, avg_epoch_loss=0.00024]\n",
      "INFO:root:Epoch[257] Elapsed time 0.876 seconds\n",
      "INFO:root:Epoch[257] Evaluation metric 'epoch_loss'=0.000240\n",
      "INFO:root:Epoch[258] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 87.28it/s, avg_epoch_loss=-.00234]\n",
      "INFO:root:Epoch[258] Elapsed time 1.148 seconds\n",
      "INFO:root:Epoch[258] Evaluation metric 'epoch_loss'=-0.002344\n",
      "INFO:root:Epoch[259] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 95.52it/s, avg_epoch_loss=-.0179]\n",
      "INFO:root:Epoch[259] Elapsed time 1.051 seconds\n",
      "INFO:root:Epoch[259] Evaluation metric 'epoch_loss'=-0.017903\n",
      "INFO:root:Epoch[260] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.58it/s, avg_epoch_loss=-.00191]\n",
      "INFO:root:Epoch[260] Elapsed time 0.852 seconds\n",
      "INFO:root:Epoch[260] Evaluation metric 'epoch_loss'=-0.001905\n",
      "INFO:root:Epoch[261] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 95.23it/s, avg_epoch_loss=0.00461]\n",
      "INFO:root:Epoch[261] Elapsed time 1.052 seconds\n",
      "INFO:root:Epoch[261] Evaluation metric 'epoch_loss'=0.004608\n",
      "INFO:root:Epoch[262] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 82.85it/s, avg_epoch_loss=0.000665]\n",
      "INFO:root:Epoch[262] Elapsed time 1.210 seconds\n",
      "INFO:root:Epoch[262] Evaluation metric 'epoch_loss'=0.000665\n",
      "INFO:root:Epoch[263] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 91.45it/s, avg_epoch_loss=0.00987]\n",
      "INFO:root:Epoch[263] Elapsed time 1.097 seconds\n",
      "INFO:root:Epoch[263] Evaluation metric 'epoch_loss'=0.009872\n",
      "INFO:root:Epoch[264] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.77it/s, avg_epoch_loss=0.00204]\n",
      "INFO:root:Epoch[264] Elapsed time 1.028 seconds\n",
      "INFO:root:Epoch[264] Evaluation metric 'epoch_loss'=0.002039\n",
      "INFO:root:Epoch[265] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 124.97it/s, avg_epoch_loss=-.0183]\n",
      "INFO:root:Epoch[265] Elapsed time 0.811 seconds\n",
      "INFO:root:Epoch[265] Evaluation metric 'epoch_loss'=-0.018253\n",
      "INFO:root:Epoch[266] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.49it/s, avg_epoch_loss=0.00118]\n",
      "INFO:root:Epoch[266] Elapsed time 0.959 seconds\n",
      "INFO:root:Epoch[266] Evaluation metric 'epoch_loss'=0.001176\n",
      "INFO:root:Epoch[267] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 88.13it/s, avg_epoch_loss=-.0145]\n",
      "INFO:root:Epoch[267] Elapsed time 1.148 seconds\n",
      "INFO:root:Epoch[267] Evaluation metric 'epoch_loss'=-0.014464\n",
      "INFO:root:Epoch[268] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 157.77it/s, avg_epoch_loss=0.0105]\n",
      "INFO:root:Epoch[268] Elapsed time 0.636 seconds\n",
      "INFO:root:Epoch[268] Evaluation metric 'epoch_loss'=0.010466\n",
      "INFO:root:Epoch[269] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 92.89it/s, avg_epoch_loss=0.00453]\n",
      "INFO:root:Epoch[269] Elapsed time 1.093 seconds\n",
      "INFO:root:Epoch[269] Evaluation metric 'epoch_loss'=0.004527\n",
      "INFO:root:Epoch[270] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 127.01it/s, avg_epoch_loss=-.0302]\n",
      "INFO:root:Epoch[270] Elapsed time 0.799 seconds\n",
      "INFO:root:Epoch[270] Evaluation metric 'epoch_loss'=-0.030196\n",
      "INFO:root:Epoch[271] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 101.62it/s, avg_epoch_loss=-.0163]\n",
      "INFO:root:Epoch[271] Elapsed time 0.985 seconds\n",
      "INFO:root:Epoch[271] Evaluation metric 'epoch_loss'=-0.016269\n",
      "INFO:root:Epoch[272] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.58it/s, avg_epoch_loss=0.0108]\n",
      "INFO:root:Epoch[272] Elapsed time 0.856 seconds\n",
      "INFO:root:Epoch[272] Evaluation metric 'epoch_loss'=0.010784\n",
      "INFO:root:Epoch[273] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 88.90it/s, avg_epoch_loss=0.00243]\n",
      "INFO:root:Epoch[273] Elapsed time 1.130 seconds\n",
      "INFO:root:Epoch[273] Evaluation metric 'epoch_loss'=0.002425\n",
      "INFO:root:Epoch[274] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 128.46it/s, avg_epoch_loss=-.0027]\n",
      "INFO:root:Epoch[274] Elapsed time 0.780 seconds\n",
      "INFO:root:Epoch[274] Evaluation metric 'epoch_loss'=-0.002698\n",
      "INFO:root:Epoch[275] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 133.40it/s, avg_epoch_loss=-.000762]\n",
      "INFO:root:Epoch[275] Elapsed time 0.751 seconds\n",
      "INFO:root:Epoch[275] Evaluation metric 'epoch_loss'=-0.000762\n",
      "INFO:root:Epoch[276] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.69it/s, avg_epoch_loss=0.0216]\n",
      "INFO:root:Epoch[276] Elapsed time 0.946 seconds\n",
      "INFO:root:Epoch[276] Evaluation metric 'epoch_loss'=0.021597\n",
      "INFO:root:Epoch[277] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.38it/s, avg_epoch_loss=-.00456]\n",
      "INFO:root:Epoch[277] Elapsed time 1.039 seconds\n",
      "INFO:root:Epoch[277] Evaluation metric 'epoch_loss'=-0.004564\n",
      "INFO:root:Epoch[278] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.68it/s, avg_epoch_loss=0.00602]\n",
      "INFO:root:Epoch[278] Elapsed time 1.274 seconds\n",
      "INFO:root:Epoch[278] Evaluation metric 'epoch_loss'=0.006019\n",
      "INFO:root:Epoch[279] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 124.94it/s, avg_epoch_loss=-.0124]\n",
      "INFO:root:Epoch[279] Elapsed time 0.808 seconds\n",
      "INFO:root:Epoch[279] Evaluation metric 'epoch_loss'=-0.012398\n",
      "INFO:root:Epoch[280] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 115.62it/s, avg_epoch_loss=0.0247]\n",
      "INFO:root:Epoch[280] Elapsed time 0.867 seconds\n",
      "INFO:root:Epoch[280] Evaluation metric 'epoch_loss'=0.024675\n",
      "INFO:root:Epoch[281] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.39it/s, avg_epoch_loss=-.00127]\n",
      "INFO:root:Epoch[281] Elapsed time 0.923 seconds\n",
      "INFO:root:Epoch[281] Evaluation metric 'epoch_loss'=-0.001274\n",
      "INFO:root:Epoch[282] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 123.58it/s, avg_epoch_loss=-.017]\n",
      "INFO:root:Epoch[282] Elapsed time 0.820 seconds\n",
      "INFO:root:Epoch[282] Evaluation metric 'epoch_loss'=-0.017004\n",
      "INFO:root:Epoch[283] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.78it/s, avg_epoch_loss=-.000466]\n",
      "INFO:root:Epoch[283] Elapsed time 0.881 seconds\n",
      "INFO:root:Epoch[283] Evaluation metric 'epoch_loss'=-0.000466\n",
      "INFO:root:Epoch[284] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.73it/s, avg_epoch_loss=-.00575]\n",
      "INFO:root:Epoch[284] Elapsed time 0.911 seconds\n",
      "INFO:root:Epoch[284] Evaluation metric 'epoch_loss'=-0.005745\n",
      "INFO:root:Epoch[285] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 115.87it/s, avg_epoch_loss=-.021]\n",
      "INFO:root:Epoch[285] Elapsed time 0.871 seconds\n",
      "INFO:root:Epoch[285] Evaluation metric 'epoch_loss'=-0.020971\n",
      "INFO:root:Epoch[286] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 62.68it/s, avg_epoch_loss=0.00221]\n",
      "INFO:root:Epoch[286] Elapsed time 1.605 seconds\n",
      "INFO:root:Epoch[286] Evaluation metric 'epoch_loss'=0.002215\n",
      "INFO:root:Epoch[287] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 144.38it/s, avg_epoch_loss=0.00748]\n",
      "INFO:root:Epoch[287] Elapsed time 0.694 seconds\n",
      "INFO:root:Epoch[287] Evaluation metric 'epoch_loss'=0.007481\n",
      "INFO:root:Epoch[288] Learning rate is 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 134.18it/s, avg_epoch_loss=-.0294]\n",
      "INFO:root:Epoch[288] Elapsed time 0.747 seconds\n",
      "INFO:root:Epoch[288] Evaluation metric 'epoch_loss'=-0.029351\n",
      "INFO:root:Epoch[289] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 139.25it/s, avg_epoch_loss=-.00219]\n",
      "INFO:root:Epoch[289] Elapsed time 0.720 seconds\n",
      "INFO:root:Epoch[289] Evaluation metric 'epoch_loss'=-0.002195\n",
      "INFO:root:Epoch[290] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.74it/s, avg_epoch_loss=-.0147]\n",
      "INFO:root:Epoch[290] Elapsed time 0.930 seconds\n",
      "INFO:root:Epoch[290] Evaluation metric 'epoch_loss'=-0.014669\n",
      "INFO:root:Epoch[291] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 125.85it/s, avg_epoch_loss=0.0123]\n",
      "INFO:root:Epoch[291] Elapsed time 0.797 seconds\n",
      "INFO:root:Epoch[291] Evaluation metric 'epoch_loss'=0.012257\n",
      "INFO:root:Epoch[292] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 139.64it/s, avg_epoch_loss=-.00383]\n",
      "INFO:root:Epoch[292] Elapsed time 0.718 seconds\n",
      "INFO:root:Epoch[292] Evaluation metric 'epoch_loss'=-0.003826\n",
      "INFO:root:Epoch[293] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.28it/s, avg_epoch_loss=-.0261]\n",
      "INFO:root:Epoch[293] Elapsed time 0.934 seconds\n",
      "INFO:root:Epoch[293] Evaluation metric 'epoch_loss'=-0.026129\n",
      "INFO:root:Epoch[294] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.43it/s, avg_epoch_loss=-.00296]\n",
      "INFO:root:Epoch[294] Elapsed time 0.914 seconds\n",
      "INFO:root:Epoch[294] Evaluation metric 'epoch_loss'=-0.002962\n",
      "INFO:root:Epoch[295] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 81.11it/s, avg_epoch_loss=-.0143]\n",
      "INFO:root:Epoch[295] Elapsed time 1.235 seconds\n",
      "INFO:root:Epoch[295] Evaluation metric 'epoch_loss'=-0.014304\n",
      "INFO:root:Epoch[296] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.79it/s, avg_epoch_loss=0.00355]\n",
      "INFO:root:Epoch[296] Elapsed time 0.904 seconds\n",
      "INFO:root:Epoch[296] Evaluation metric 'epoch_loss'=0.003552\n",
      "INFO:root:Epoch[297] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 90.44it/s, avg_epoch_loss=-.00253]\n",
      "INFO:root:Epoch[297] Elapsed time 1.108 seconds\n",
      "INFO:root:Epoch[297] Evaluation metric 'epoch_loss'=-0.002530\n",
      "INFO:root:Epoch[298] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 88.48it/s, avg_epoch_loss=-.0117]\n",
      "INFO:root:Epoch[298] Elapsed time 1.132 seconds\n",
      "INFO:root:Epoch[298] Evaluation metric 'epoch_loss'=-0.011671\n",
      "INFO:root:Epoch[299] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 100.43it/s, avg_epoch_loss=-.00444]\n",
      "INFO:root:Epoch[299] Elapsed time 0.998 seconds\n",
      "INFO:root:Epoch[299] Evaluation metric 'epoch_loss'=-0.004443\n",
      "INFO:root:Epoch[300] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.01it/s, avg_epoch_loss=-.0281]\n",
      "INFO:root:Epoch[300] Elapsed time 1.001 seconds\n",
      "INFO:root:Epoch[300] Evaluation metric 'epoch_loss'=-0.028148\n",
      "INFO:root:Epoch[301] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 124.65it/s, avg_epoch_loss=-.0115]\n",
      "INFO:root:Epoch[301] Elapsed time 0.805 seconds\n",
      "INFO:root:Epoch[301] Evaluation metric 'epoch_loss'=-0.011490\n",
      "INFO:root:Epoch[302] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 76.39it/s, avg_epoch_loss=-.00556]\n",
      "INFO:root:Epoch[302] Elapsed time 1.321 seconds\n",
      "INFO:root:Epoch[302] Evaluation metric 'epoch_loss'=-0.005560\n",
      "INFO:root:Epoch[303] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.73it/s, avg_epoch_loss=0.0187]\n",
      "INFO:root:Epoch[303] Elapsed time 0.966 seconds\n",
      "INFO:root:Epoch[303] Evaluation metric 'epoch_loss'=0.018718\n",
      "INFO:root:Epoch[304] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 124.29it/s, avg_epoch_loss=0.0116]\n",
      "INFO:root:Epoch[304] Elapsed time 0.806 seconds\n",
      "INFO:root:Epoch[304] Evaluation metric 'epoch_loss'=0.011596\n",
      "INFO:root:Epoch[305] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.67it/s, avg_epoch_loss=-.0166]\n",
      "INFO:root:Epoch[305] Elapsed time 0.794 seconds\n",
      "INFO:root:Epoch[305] Evaluation metric 'epoch_loss'=-0.016602\n",
      "INFO:root:Epoch[306] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.13it/s, avg_epoch_loss=0.00309]\n",
      "INFO:root:Epoch[306] Elapsed time 0.808 seconds\n",
      "INFO:root:Epoch[306] Evaluation metric 'epoch_loss'=0.003091\n",
      "INFO:root:Epoch[307] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 135.61it/s, avg_epoch_loss=-.00203]\n",
      "INFO:root:Epoch[307] Elapsed time 0.761 seconds\n",
      "INFO:root:Epoch[307] Evaluation metric 'epoch_loss'=-0.002030\n",
      "INFO:root:Epoch[308] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.30it/s, avg_epoch_loss=-.00361]\n",
      "INFO:root:Epoch[308] Elapsed time 0.931 seconds\n",
      "INFO:root:Epoch[308] Evaluation metric 'epoch_loss'=-0.003611\n",
      "INFO:root:Epoch[309] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 70.78it/s, avg_epoch_loss=0.0175]\n",
      "INFO:root:Epoch[309] Elapsed time 1.414 seconds\n",
      "INFO:root:Epoch[309] Evaluation metric 'epoch_loss'=0.017514\n",
      "INFO:root:Epoch[310] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 147.69it/s, avg_epoch_loss=-.00851]\n",
      "INFO:root:Epoch[310] Elapsed time 0.679 seconds\n",
      "INFO:root:Epoch[310] Evaluation metric 'epoch_loss'=-0.008508\n",
      "INFO:root:Epoch[311] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.32it/s, avg_epoch_loss=-.00418]\n",
      "INFO:root:Epoch[311] Elapsed time 0.641 seconds\n",
      "INFO:root:Epoch[311] Evaluation metric 'epoch_loss'=-0.004180\n",
      "INFO:root:Epoch[312] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 129.12it/s, avg_epoch_loss=-.0169]\n",
      "INFO:root:Epoch[312] Elapsed time 0.776 seconds\n",
      "INFO:root:Epoch[312] Evaluation metric 'epoch_loss'=-0.016913\n",
      "INFO:root:Epoch[313] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 129.74it/s, avg_epoch_loss=0.00477]\n",
      "INFO:root:Epoch[313] Elapsed time 0.772 seconds\n",
      "INFO:root:Epoch[313] Evaluation metric 'epoch_loss'=0.004772\n",
      "INFO:root:Epoch[314] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 79.85it/s, avg_epoch_loss=-.00856]\n",
      "INFO:root:Epoch[314] Elapsed time 1.254 seconds\n",
      "INFO:root:Epoch[314] Evaluation metric 'epoch_loss'=-0.008561\n",
      "INFO:root:Epoch[315] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.78it/s, avg_epoch_loss=-.00264]\n",
      "INFO:root:Epoch[315] Elapsed time 1.043 seconds\n",
      "INFO:root:Epoch[315] Evaluation metric 'epoch_loss'=-0.002640\n",
      "INFO:root:Epoch[316] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 136.24it/s, avg_epoch_loss=0.0081]\n",
      "INFO:root:Epoch[316] Elapsed time 0.736 seconds\n",
      "INFO:root:Epoch[316] Evaluation metric 'epoch_loss'=0.008104\n",
      "INFO:root:Epoch[317] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 131.29it/s, avg_epoch_loss=-.00721]\n",
      "INFO:root:Epoch[317] Elapsed time 0.764 seconds\n",
      "INFO:root:Epoch[317] Evaluation metric 'epoch_loss'=-0.007209\n",
      "INFO:root:Epoch[318] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 102.61it/s, avg_epoch_loss=-.0155]\n",
      "INFO:root:Epoch[318] Elapsed time 0.977 seconds\n",
      "INFO:root:Epoch[318] Evaluation metric 'epoch_loss'=-0.015477\n",
      "INFO:root:Epoch[319] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.16it/s, avg_epoch_loss=0.00293]\n",
      "INFO:root:Epoch[319] Elapsed time 0.931 seconds\n",
      "INFO:root:Epoch[319] Evaluation metric 'epoch_loss'=0.002928\n",
      "INFO:root:Epoch[320] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 119.54it/s, avg_epoch_loss=0.0127]\n",
      "INFO:root:Epoch[320] Elapsed time 0.838 seconds\n",
      "INFO:root:Epoch[320] Evaluation metric 'epoch_loss'=0.012680\n",
      "INFO:root:Epoch[321] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.74it/s, avg_epoch_loss=-.0164]\n",
      "INFO:root:Epoch[321] Elapsed time 1.035 seconds\n",
      "INFO:root:Epoch[321] Evaluation metric 'epoch_loss'=-0.016449\n",
      "INFO:root:Epoch[322] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.43it/s, avg_epoch_loss=-.0161]\n",
      "INFO:root:Epoch[322] Elapsed time 1.007 seconds\n",
      "INFO:root:Epoch[322] Evaluation metric 'epoch_loss'=-0.016088\n",
      "INFO:root:Epoch[323] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 75.13it/s, avg_epoch_loss=0.00233]\n",
      "INFO:root:Epoch[323] Elapsed time 1.333 seconds\n",
      "INFO:root:Epoch[323] Evaluation metric 'epoch_loss'=0.002332\n",
      "INFO:root:Epoch[324] Learning rate is 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 108.92it/s, avg_epoch_loss=0.0157]\n",
      "INFO:root:Epoch[324] Elapsed time 0.920 seconds\n",
      "INFO:root:Epoch[324] Evaluation metric 'epoch_loss'=0.015703\n",
      "INFO:root:Epoch[325] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 105.59it/s, avg_epoch_loss=-.00937]\n",
      "INFO:root:Epoch[325] Elapsed time 0.951 seconds\n",
      "INFO:root:Epoch[325] Evaluation metric 'epoch_loss'=-0.009367\n",
      "INFO:root:Epoch[326] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.41it/s, avg_epoch_loss=-.00654]\n",
      "INFO:root:Epoch[326] Elapsed time 0.960 seconds\n",
      "INFO:root:Epoch[326] Evaluation metric 'epoch_loss'=-0.006539\n",
      "INFO:root:Epoch[327] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.63it/s, avg_epoch_loss=0.00323]\n",
      "INFO:root:Epoch[327] Elapsed time 1.037 seconds\n",
      "INFO:root:Epoch[327] Evaluation metric 'epoch_loss'=0.003234\n",
      "INFO:root:Epoch[328] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 86.51it/s, avg_epoch_loss=-.0195]\n",
      "INFO:root:Epoch[328] Elapsed time 1.160 seconds\n",
      "INFO:root:Epoch[328] Evaluation metric 'epoch_loss'=-0.019464\n",
      "INFO:root:Epoch[329] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.46it/s, avg_epoch_loss=-.00562]\n",
      "INFO:root:Epoch[329] Elapsed time 0.794 seconds\n",
      "INFO:root:Epoch[329] Evaluation metric 'epoch_loss'=-0.005624\n",
      "INFO:root:Epoch[330] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 119.36it/s, avg_epoch_loss=-.00677]\n",
      "INFO:root:Epoch[330] Elapsed time 0.842 seconds\n",
      "INFO:root:Epoch[330] Evaluation metric 'epoch_loss'=-0.006774\n",
      "INFO:root:Epoch[331] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 89.53it/s, avg_epoch_loss=-.0161]\n",
      "INFO:root:Epoch[331] Elapsed time 1.121 seconds\n",
      "INFO:root:Epoch[331] Evaluation metric 'epoch_loss'=-0.016067\n",
      "INFO:root:Epoch[332] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 125.79it/s, avg_epoch_loss=0.00413]\n",
      "INFO:root:Epoch[332] Elapsed time 0.799 seconds\n",
      "INFO:root:Epoch[332] Evaluation metric 'epoch_loss'=0.004127\n",
      "INFO:root:Epoch[333] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 85.78it/s, avg_epoch_loss=-.0179]\n",
      "INFO:root:Epoch[333] Elapsed time 1.180 seconds\n",
      "INFO:root:Epoch[333] Evaluation metric 'epoch_loss'=-0.017882\n",
      "INFO:root:Epoch[334] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 127.75it/s, avg_epoch_loss=-.0208]\n",
      "INFO:root:Epoch[334] Elapsed time 0.785 seconds\n",
      "INFO:root:Epoch[334] Evaluation metric 'epoch_loss'=-0.020830\n",
      "INFO:root:Epoch[335] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.11it/s, avg_epoch_loss=-.0211]\n",
      "INFO:root:Epoch[335] Elapsed time 0.910 seconds\n",
      "INFO:root:Epoch[335] Evaluation metric 'epoch_loss'=-0.021078\n",
      "INFO:root:Epoch[336] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.26it/s, avg_epoch_loss=0.00123]\n",
      "INFO:root:Epoch[336] Elapsed time 1.030 seconds\n",
      "INFO:root:Epoch[336] Evaluation metric 'epoch_loss'=0.001233\n",
      "INFO:root:Epoch[337] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 106.80it/s, avg_epoch_loss=0.0153]\n",
      "INFO:root:Epoch[337] Elapsed time 0.939 seconds\n",
      "INFO:root:Epoch[337] Evaluation metric 'epoch_loss'=0.015314\n",
      "INFO:root:Epoch[338] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.45it/s, avg_epoch_loss=-.00301]\n",
      "INFO:root:Epoch[338] Elapsed time 1.072 seconds\n",
      "INFO:root:Epoch[338] Evaluation metric 'epoch_loss'=-0.003006\n",
      "INFO:root:Epoch[339] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.36it/s, avg_epoch_loss=0.00637]\n",
      "INFO:root:Epoch[339] Elapsed time 0.884 seconds\n",
      "INFO:root:Epoch[339] Evaluation metric 'epoch_loss'=0.006365\n",
      "INFO:root:Epoch[340] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 87.65it/s, avg_epoch_loss=0.0285]\n",
      "INFO:root:Epoch[340] Elapsed time 1.148 seconds\n",
      "INFO:root:Epoch[340] Evaluation metric 'epoch_loss'=0.028473\n",
      "INFO:root:Epoch[341] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 92.04it/s, avg_epoch_loss=-.0123]\n",
      "INFO:root:Epoch[341] Elapsed time 1.089 seconds\n",
      "INFO:root:Epoch[341] Evaluation metric 'epoch_loss'=-0.012260\n",
      "INFO:root:Epoch[342] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.59it/s, avg_epoch_loss=-.0181]\n",
      "INFO:root:Epoch[342] Elapsed time 0.868 seconds\n",
      "INFO:root:Epoch[342] Evaluation metric 'epoch_loss'=-0.018105\n",
      "INFO:root:Epoch[343] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.54it/s, avg_epoch_loss=-.00753]\n",
      "INFO:root:Epoch[343] Elapsed time 0.882 seconds\n",
      "INFO:root:Epoch[343] Evaluation metric 'epoch_loss'=-0.007530\n",
      "INFO:root:Epoch[344] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.53it/s, avg_epoch_loss=-.000523]\n",
      "INFO:root:Epoch[344] Elapsed time 0.958 seconds\n",
      "INFO:root:Epoch[344] Evaluation metric 'epoch_loss'=-0.000523\n",
      "INFO:root:Epoch[345] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.19it/s, avg_epoch_loss=0.0135]\n",
      "INFO:root:Epoch[345] Elapsed time 1.010 seconds\n",
      "INFO:root:Epoch[345] Evaluation metric 'epoch_loss'=0.013476\n",
      "INFO:root:Epoch[346] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 118.62it/s, avg_epoch_loss=-.0047]\n",
      "INFO:root:Epoch[346] Elapsed time 0.864 seconds\n",
      "INFO:root:Epoch[346] Evaluation metric 'epoch_loss'=-0.004700\n",
      "INFO:root:Epoch[347] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 133.48it/s, avg_epoch_loss=-.00202]\n",
      "INFO:root:Epoch[347] Elapsed time 0.760 seconds\n",
      "INFO:root:Epoch[347] Evaluation metric 'epoch_loss'=-0.002016\n",
      "INFO:root:Epoch[348] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 89.30it/s, avg_epoch_loss=0.00121]\n",
      "INFO:root:Epoch[348] Elapsed time 1.134 seconds\n",
      "INFO:root:Epoch[348] Evaluation metric 'epoch_loss'=0.001208\n",
      "INFO:root:Epoch[349] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 128.91it/s, avg_epoch_loss=0.0143]\n",
      "INFO:root:Epoch[349] Elapsed time 0.778 seconds\n",
      "INFO:root:Epoch[349] Evaluation metric 'epoch_loss'=0.014350\n",
      "INFO:root:Epoch[350] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.02it/s, avg_epoch_loss=0.0119]\n",
      "INFO:root:Epoch[350] Elapsed time 0.643 seconds\n",
      "INFO:root:Epoch[350] Evaluation metric 'epoch_loss'=0.011881\n",
      "INFO:root:Epoch[351] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.77it/s, avg_epoch_loss=-.028]\n",
      "INFO:root:Epoch[351] Elapsed time 0.639 seconds\n",
      "INFO:root:Epoch[351] Evaluation metric 'epoch_loss'=-0.027955\n",
      "INFO:root:Epoch[352] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 153.54it/s, avg_epoch_loss=0.00859]\n",
      "INFO:root:Epoch[352] Elapsed time 0.653 seconds\n",
      "INFO:root:Epoch[352] Evaluation metric 'epoch_loss'=0.008586\n",
      "INFO:root:Epoch[353] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.17it/s, avg_epoch_loss=-.0132]\n",
      "INFO:root:Epoch[353] Elapsed time 0.642 seconds\n",
      "INFO:root:Epoch[353] Evaluation metric 'epoch_loss'=-0.013173\n",
      "INFO:root:Epoch[354] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 133.50it/s, avg_epoch_loss=-.0109]\n",
      "INFO:root:Epoch[354] Elapsed time 0.752 seconds\n",
      "INFO:root:Epoch[354] Evaluation metric 'epoch_loss'=-0.010915\n",
      "INFO:root:Epoch[355] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 120.06it/s, avg_epoch_loss=0.00228]\n",
      "INFO:root:Epoch[355] Elapsed time 0.841 seconds\n",
      "INFO:root:Epoch[355] Evaluation metric 'epoch_loss'=0.002282\n",
      "INFO:root:Epoch[356] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 123.49it/s, avg_epoch_loss=-.0192]\n",
      "INFO:root:Epoch[356] Elapsed time 0.813 seconds\n",
      "INFO:root:Epoch[356] Evaluation metric 'epoch_loss'=-0.019166\n",
      "INFO:root:Epoch[357] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.08it/s, avg_epoch_loss=-.0101]\n",
      "INFO:root:Epoch[357] Elapsed time 0.903 seconds\n",
      "INFO:root:Epoch[357] Evaluation metric 'epoch_loss'=-0.010134\n",
      "INFO:root:Epoch[358] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 73.67it/s, avg_epoch_loss=-.0113]\n",
      "INFO:root:Epoch[358] Elapsed time 1.359 seconds\n",
      "INFO:root:Epoch[358] Evaluation metric 'epoch_loss'=-0.011323\n",
      "INFO:root:Epoch[359] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.15it/s, avg_epoch_loss=0.0278]\n",
      "INFO:root:Epoch[359] Elapsed time 0.642 seconds\n",
      "INFO:root:Epoch[359] Evaluation metric 'epoch_loss'=0.027793\n",
      "INFO:root:Epoch[360] Learning rate is 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 155.75it/s, avg_epoch_loss=0.0142]\n",
      "INFO:root:Epoch[360] Elapsed time 0.644 seconds\n",
      "INFO:root:Epoch[360] Evaluation metric 'epoch_loss'=0.014195\n",
      "INFO:root:Epoch[361] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 131.08it/s, avg_epoch_loss=0.00895]\n",
      "INFO:root:Epoch[361] Elapsed time 0.765 seconds\n",
      "INFO:root:Epoch[361] Evaluation metric 'epoch_loss'=0.008955\n",
      "INFO:root:Epoch[362] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.24it/s, avg_epoch_loss=-.017]\n",
      "INFO:root:Epoch[362] Elapsed time 1.074 seconds\n",
      "INFO:root:Epoch[362] Evaluation metric 'epoch_loss'=-0.017045\n",
      "INFO:root:Epoch[363] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.50it/s, avg_epoch_loss=-.00766]\n",
      "INFO:root:Epoch[363] Elapsed time 0.959 seconds\n",
      "INFO:root:Epoch[363] Evaluation metric 'epoch_loss'=-0.007659\n",
      "INFO:root:Epoch[364] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.98it/s, avg_epoch_loss=-.00753]\n",
      "INFO:root:Epoch[364] Elapsed time 1.284 seconds\n",
      "INFO:root:Epoch[364] Evaluation metric 'epoch_loss'=-0.007526\n",
      "INFO:root:Epoch[365] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.90it/s, avg_epoch_loss=-.0193]\n",
      "INFO:root:Epoch[365] Elapsed time 0.929 seconds\n",
      "INFO:root:Epoch[365] Evaluation metric 'epoch_loss'=-0.019320\n",
      "INFO:root:Epoch[366] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.00it/s, avg_epoch_loss=-.00465]\n",
      "INFO:root:Epoch[366] Elapsed time 0.857 seconds\n",
      "INFO:root:Epoch[366] Evaluation metric 'epoch_loss'=-0.004648\n",
      "INFO:root:Epoch[367] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 123.48it/s, avg_epoch_loss=0.0128]\n",
      "INFO:root:Epoch[367] Elapsed time 0.812 seconds\n",
      "INFO:root:Epoch[367] Evaluation metric 'epoch_loss'=0.012832\n",
      "INFO:root:Epoch[368] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 123.74it/s, avg_epoch_loss=-.00468]\n",
      "INFO:root:Epoch[368] Elapsed time 0.810 seconds\n",
      "INFO:root:Epoch[368] Evaluation metric 'epoch_loss'=-0.004680\n",
      "INFO:root:Epoch[369] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.84it/s, avg_epoch_loss=-.0132]\n",
      "INFO:root:Epoch[369] Elapsed time 0.640 seconds\n",
      "INFO:root:Epoch[369] Evaluation metric 'epoch_loss'=-0.013211\n",
      "INFO:root:Epoch[370] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 139.67it/s, avg_epoch_loss=-.000629]\n",
      "INFO:root:Epoch[370] Elapsed time 0.718 seconds\n",
      "INFO:root:Epoch[370] Evaluation metric 'epoch_loss'=-0.000629\n",
      "INFO:root:Epoch[371] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.09it/s, avg_epoch_loss=-.00983]\n",
      "INFO:root:Epoch[371] Elapsed time 0.863 seconds\n",
      "INFO:root:Epoch[371] Evaluation metric 'epoch_loss'=-0.009827\n",
      "INFO:root:Epoch[372] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.19it/s, avg_epoch_loss=-.0114]\n",
      "INFO:root:Epoch[372] Elapsed time 0.642 seconds\n",
      "INFO:root:Epoch[372] Evaluation metric 'epoch_loss'=-0.011383\n",
      "INFO:root:Epoch[373] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 152.81it/s, avg_epoch_loss=0.00209]\n",
      "INFO:root:Epoch[373] Elapsed time 0.656 seconds\n",
      "INFO:root:Epoch[373] Evaluation metric 'epoch_loss'=0.002088\n",
      "INFO:root:Epoch[374] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 149.24it/s, avg_epoch_loss=-.0159]\n",
      "INFO:root:Epoch[374] Elapsed time 0.672 seconds\n",
      "INFO:root:Epoch[374] Evaluation metric 'epoch_loss'=-0.015871\n",
      "INFO:root:Epoch[375] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 139.03it/s, avg_epoch_loss=0.00356]\n",
      "INFO:root:Epoch[375] Elapsed time 0.721 seconds\n",
      "INFO:root:Epoch[375] Evaluation metric 'epoch_loss'=0.003557\n",
      "INFO:root:Epoch[376] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 129.18it/s, avg_epoch_loss=0.00715]\n",
      "INFO:root:Epoch[376] Elapsed time 0.776 seconds\n",
      "INFO:root:Epoch[376] Evaluation metric 'epoch_loss'=0.007151\n",
      "INFO:root:Epoch[377] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 135.50it/s, avg_epoch_loss=-.0123]\n",
      "INFO:root:Epoch[377] Elapsed time 0.739 seconds\n",
      "INFO:root:Epoch[377] Evaluation metric 'epoch_loss'=-0.012272\n",
      "INFO:root:Epoch[378] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 133.41it/s, avg_epoch_loss=0.0206]\n",
      "INFO:root:Epoch[378] Elapsed time 0.751 seconds\n",
      "INFO:root:Epoch[378] Evaluation metric 'epoch_loss'=0.020554\n",
      "INFO:root:Epoch[379] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.41it/s, avg_epoch_loss=-.0127]\n",
      "INFO:root:Epoch[379] Elapsed time 0.861 seconds\n",
      "INFO:root:Epoch[379] Evaluation metric 'epoch_loss'=-0.012669\n",
      "INFO:root:Epoch[380] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 105.54it/s, avg_epoch_loss=0.000487]\n",
      "INFO:root:Epoch[380] Elapsed time 0.949 seconds\n",
      "INFO:root:Epoch[380] Evaluation metric 'epoch_loss'=0.000487\n",
      "INFO:root:Epoch[381] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 127.08it/s, avg_epoch_loss=-.0295]\n",
      "INFO:root:Epoch[381] Elapsed time 0.789 seconds\n",
      "INFO:root:Epoch[381] Evaluation metric 'epoch_loss'=-0.029471\n",
      "INFO:root:Epoch[382] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 95.25it/s, avg_epoch_loss=-.016]\n",
      "INFO:root:Epoch[382] Elapsed time 1.052 seconds\n",
      "INFO:root:Epoch[382] Evaluation metric 'epoch_loss'=-0.016029\n",
      "INFO:root:Epoch[383] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 136.43it/s, avg_epoch_loss=0.0201]\n",
      "INFO:root:Epoch[383] Elapsed time 0.734 seconds\n",
      "INFO:root:Epoch[383] Evaluation metric 'epoch_loss'=0.020096\n",
      "INFO:root:Epoch[384] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.52it/s, avg_epoch_loss=-.0178]\n",
      "INFO:root:Epoch[384] Elapsed time 1.006 seconds\n",
      "INFO:root:Epoch[384] Evaluation metric 'epoch_loss'=-0.017811\n",
      "INFO:root:Epoch[385] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.50it/s, avg_epoch_loss=-.0157]\n",
      "INFO:root:Epoch[385] Elapsed time 0.924 seconds\n",
      "INFO:root:Epoch[385] Evaluation metric 'epoch_loss'=-0.015743\n",
      "INFO:root:Epoch[386] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 129.86it/s, avg_epoch_loss=-.0178]\n",
      "INFO:root:Epoch[386] Elapsed time 0.772 seconds\n",
      "INFO:root:Epoch[386] Evaluation metric 'epoch_loss'=-0.017784\n",
      "INFO:root:Epoch[387] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 145.93it/s, avg_epoch_loss=-.0198]\n",
      "INFO:root:Epoch[387] Elapsed time 0.687 seconds\n",
      "INFO:root:Epoch[387] Evaluation metric 'epoch_loss'=-0.019823\n",
      "INFO:root:Epoch[388] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.86it/s, avg_epoch_loss=-.00279]\n",
      "INFO:root:Epoch[388] Elapsed time 0.792 seconds\n",
      "INFO:root:Epoch[388] Evaluation metric 'epoch_loss'=-0.002794\n",
      "INFO:root:Epoch[389] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 101.02it/s, avg_epoch_loss=-.0121]\n",
      "INFO:root:Epoch[389] Elapsed time 1.001 seconds\n",
      "INFO:root:Epoch[389] Evaluation metric 'epoch_loss'=-0.012094\n",
      "INFO:root:Epoch[390] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 122.89it/s, avg_epoch_loss=-.0118]\n",
      "INFO:root:Epoch[390] Elapsed time 0.837 seconds\n",
      "INFO:root:Epoch[390] Evaluation metric 'epoch_loss'=-0.011773\n",
      "INFO:root:Epoch[391] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.35it/s, avg_epoch_loss=-.00699]\n",
      "INFO:root:Epoch[391] Elapsed time 1.030 seconds\n",
      "INFO:root:Epoch[391] Evaluation metric 'epoch_loss'=-0.006989\n",
      "INFO:root:Epoch[392] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.62it/s, avg_epoch_loss=-.0254]\n",
      "INFO:root:Epoch[392] Elapsed time 1.292 seconds\n",
      "INFO:root:Epoch[392] Evaluation metric 'epoch_loss'=-0.025410\n",
      "INFO:root:Epoch[393] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.82it/s, avg_epoch_loss=0.016]\n",
      "INFO:root:Epoch[393] Elapsed time 1.309 seconds\n",
      "INFO:root:Epoch[393] Evaluation metric 'epoch_loss'=0.015953\n",
      "INFO:root:Epoch[394] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.66it/s, avg_epoch_loss=-.0195]\n",
      "INFO:root:Epoch[394] Elapsed time 1.025 seconds\n",
      "INFO:root:Epoch[394] Evaluation metric 'epoch_loss'=-0.019533\n",
      "INFO:root:Epoch[395] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 124.24it/s, avg_epoch_loss=-.0172]\n",
      "INFO:root:Epoch[395] Elapsed time 0.807 seconds\n",
      "INFO:root:Epoch[395] Evaluation metric 'epoch_loss'=-0.017164\n",
      "INFO:root:Epoch[396] Learning rate is 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 108.86it/s, avg_epoch_loss=0.0102]\n",
      "INFO:root:Epoch[396] Elapsed time 0.920 seconds\n",
      "INFO:root:Epoch[396] Evaluation metric 'epoch_loss'=0.010246\n",
      "INFO:root:Epoch[397] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.66it/s, avg_epoch_loss=-.00574]\n",
      "INFO:root:Epoch[397] Elapsed time 0.852 seconds\n",
      "INFO:root:Epoch[397] Evaluation metric 'epoch_loss'=-0.005737\n",
      "INFO:root:Epoch[398] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.90it/s, avg_epoch_loss=-.00627]\n",
      "INFO:root:Epoch[398] Elapsed time 1.013 seconds\n",
      "INFO:root:Epoch[398] Evaluation metric 'epoch_loss'=-0.006269\n",
      "INFO:root:Epoch[399] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 157.61it/s, avg_epoch_loss=-.0207]\n",
      "INFO:root:Epoch[399] Elapsed time 0.637 seconds\n",
      "INFO:root:Epoch[399] Evaluation metric 'epoch_loss'=-0.020651\n",
      "INFO:root:Epoch[400] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 157.28it/s, avg_epoch_loss=0.0232]\n",
      "INFO:root:Epoch[400] Elapsed time 0.638 seconds\n",
      "INFO:root:Epoch[400] Evaluation metric 'epoch_loss'=0.023232\n",
      "INFO:root:Epoch[401] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 128.53it/s, avg_epoch_loss=-.00874]\n",
      "INFO:root:Epoch[401] Elapsed time 0.780 seconds\n",
      "INFO:root:Epoch[401] Evaluation metric 'epoch_loss'=-0.008736\n",
      "INFO:root:Epoch[402] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.62it/s, avg_epoch_loss=0.00272]\n",
      "INFO:root:Epoch[402] Elapsed time 0.640 seconds\n",
      "INFO:root:Epoch[402] Evaluation metric 'epoch_loss'=0.002719\n",
      "INFO:root:Epoch[403] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 158.32it/s, avg_epoch_loss=0.0179]\n",
      "INFO:root:Epoch[403] Elapsed time 0.633 seconds\n",
      "INFO:root:Epoch[403] Evaluation metric 'epoch_loss'=0.017927\n",
      "INFO:root:Epoch[404] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 157.35it/s, avg_epoch_loss=0.000404]\n",
      "INFO:root:Epoch[404] Elapsed time 0.637 seconds\n",
      "INFO:root:Epoch[404] Evaluation metric 'epoch_loss'=0.000404\n",
      "INFO:root:Epoch[405] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 130.39it/s, avg_epoch_loss=-.00903]\n",
      "INFO:root:Epoch[405] Elapsed time 0.770 seconds\n",
      "INFO:root:Epoch[405] Evaluation metric 'epoch_loss'=-0.009028\n",
      "INFO:root:Epoch[406] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 84.21it/s, avg_epoch_loss=0.00978]\n",
      "INFO:root:Epoch[406] Elapsed time 1.189 seconds\n",
      "INFO:root:Epoch[406] Evaluation metric 'epoch_loss'=0.009777\n",
      "INFO:root:Epoch[407] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.63it/s, avg_epoch_loss=0.005]\n",
      "INFO:root:Epoch[407] Elapsed time 0.915 seconds\n",
      "INFO:root:Epoch[407] Evaluation metric 'epoch_loss'=0.004997\n",
      "INFO:root:Epoch[408] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 125.49it/s, avg_epoch_loss=-.00777]\n",
      "INFO:root:Epoch[408] Elapsed time 0.801 seconds\n",
      "INFO:root:Epoch[408] Evaluation metric 'epoch_loss'=-0.007769\n",
      "INFO:root:Epoch[409] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.14it/s, avg_epoch_loss=-.0097]\n",
      "INFO:root:Epoch[409] Elapsed time 1.041 seconds\n",
      "INFO:root:Epoch[409] Evaluation metric 'epoch_loss'=-0.009698\n",
      "INFO:root:Epoch[410] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 137.13it/s, avg_epoch_loss=-.0108]\n",
      "INFO:root:Epoch[410] Elapsed time 0.731 seconds\n",
      "INFO:root:Epoch[410] Evaluation metric 'epoch_loss'=-0.010770\n",
      "INFO:root:Epoch[411] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 94.56it/s, avg_epoch_loss=-.00761]\n",
      "INFO:root:Epoch[411] Elapsed time 1.059 seconds\n",
      "INFO:root:Epoch[411] Evaluation metric 'epoch_loss'=-0.007607\n",
      "INFO:root:Epoch[412] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 132.35it/s, avg_epoch_loss=-.0111]\n",
      "INFO:root:Epoch[412] Elapsed time 0.757 seconds\n",
      "INFO:root:Epoch[412] Evaluation metric 'epoch_loss'=-0.011133\n",
      "INFO:root:Epoch[413] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 134.02it/s, avg_epoch_loss=-.0168]\n",
      "INFO:root:Epoch[413] Elapsed time 0.748 seconds\n",
      "INFO:root:Epoch[413] Evaluation metric 'epoch_loss'=-0.016840\n",
      "INFO:root:Epoch[414] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 137.38it/s, avg_epoch_loss=0.0068]\n",
      "INFO:root:Epoch[414] Elapsed time 0.730 seconds\n",
      "INFO:root:Epoch[414] Evaluation metric 'epoch_loss'=0.006798\n",
      "INFO:root:Epoch[415] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 129.15it/s, avg_epoch_loss=-.00656]\n",
      "INFO:root:Epoch[415] Elapsed time 0.776 seconds\n",
      "INFO:root:Epoch[415] Evaluation metric 'epoch_loss'=-0.006563\n",
      "INFO:root:Epoch[416] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 69.70it/s, avg_epoch_loss=-.000433]\n",
      "INFO:root:Epoch[416] Elapsed time 1.436 seconds\n",
      "INFO:root:Epoch[416] Evaluation metric 'epoch_loss'=-0.000433\n",
      "INFO:root:Epoch[417] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 80.34it/s, avg_epoch_loss=0.00123]\n",
      "INFO:root:Epoch[417] Elapsed time 1.247 seconds\n",
      "INFO:root:Epoch[417] Evaluation metric 'epoch_loss'=0.001230\n",
      "INFO:root:Epoch[418] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 125.39it/s, avg_epoch_loss=-.00578]\n",
      "INFO:root:Epoch[418] Elapsed time 0.800 seconds\n",
      "INFO:root:Epoch[418] Evaluation metric 'epoch_loss'=-0.005782\n",
      "INFO:root:Epoch[419] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 128.33it/s, avg_epoch_loss=-.0217]\n",
      "INFO:root:Epoch[419] Elapsed time 0.781 seconds\n",
      "INFO:root:Epoch[419] Evaluation metric 'epoch_loss'=-0.021702\n",
      "INFO:root:Epoch[420] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 120.12it/s, avg_epoch_loss=0.0106]\n",
      "INFO:root:Epoch[420] Elapsed time 0.835 seconds\n",
      "INFO:root:Epoch[420] Evaluation metric 'epoch_loss'=0.010630\n",
      "INFO:root:Epoch[421] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 74.83it/s, avg_epoch_loss=0.0142]\n",
      "INFO:root:Epoch[421] Elapsed time 1.347 seconds\n",
      "INFO:root:Epoch[421] Evaluation metric 'epoch_loss'=0.014170\n",
      "INFO:root:Epoch[422] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 94.71it/s, avg_epoch_loss=-.0166]\n",
      "INFO:root:Epoch[422] Elapsed time 1.058 seconds\n",
      "INFO:root:Epoch[422] Evaluation metric 'epoch_loss'=-0.016637\n",
      "INFO:root:Epoch[423] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 106.55it/s, avg_epoch_loss=-.000345]\n",
      "INFO:root:Epoch[423] Elapsed time 0.942 seconds\n",
      "INFO:root:Epoch[423] Evaluation metric 'epoch_loss'=-0.000345\n",
      "INFO:root:Epoch[424] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 87.84it/s, avg_epoch_loss=-.0107]\n",
      "INFO:root:Epoch[424] Elapsed time 1.152 seconds\n",
      "INFO:root:Epoch[424] Evaluation metric 'epoch_loss'=-0.010678\n",
      "INFO:root:Epoch[425] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 142.73it/s, avg_epoch_loss=-.0245]\n",
      "INFO:root:Epoch[425] Elapsed time 0.702 seconds\n",
      "INFO:root:Epoch[425] Evaluation metric 'epoch_loss'=-0.024479\n",
      "INFO:root:Epoch[426] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 120.59it/s, avg_epoch_loss=0.0172]\n",
      "INFO:root:Epoch[426] Elapsed time 0.831 seconds\n",
      "INFO:root:Epoch[426] Evaluation metric 'epoch_loss'=0.017175\n",
      "INFO:root:Epoch[427] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 100.76it/s, avg_epoch_loss=-.00133]\n",
      "INFO:root:Epoch[427] Elapsed time 0.994 seconds\n",
      "INFO:root:Epoch[427] Evaluation metric 'epoch_loss'=-0.001333\n",
      "INFO:root:Epoch[428] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.01it/s, avg_epoch_loss=-.0126]\n",
      "INFO:root:Epoch[428] Elapsed time 0.904 seconds\n",
      "INFO:root:Epoch[428] Evaluation metric 'epoch_loss'=-0.012570\n",
      "INFO:root:Epoch[429] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.23it/s, avg_epoch_loss=-.0151]\n",
      "INFO:root:Epoch[429] Elapsed time 0.862 seconds\n",
      "INFO:root:Epoch[429] Evaluation metric 'epoch_loss'=-0.015110\n",
      "INFO:root:Epoch[430] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 138.22it/s, avg_epoch_loss=-.0335]\n",
      "INFO:root:Epoch[430] Elapsed time 0.736 seconds\n",
      "INFO:root:Epoch[430] Evaluation metric 'epoch_loss'=-0.033500\n",
      "INFO:root:Epoch[431] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 115.89it/s, avg_epoch_loss=0.0128]\n",
      "INFO:root:Epoch[431] Elapsed time 0.881 seconds\n",
      "INFO:root:Epoch[431] Evaluation metric 'epoch_loss'=0.012771\n",
      "INFO:root:Epoch[432] Learning rate is 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 116.37it/s, avg_epoch_loss=-.0204]\n",
      "INFO:root:Epoch[432] Elapsed time 0.866 seconds\n",
      "INFO:root:Epoch[432] Evaluation metric 'epoch_loss'=-0.020417\n",
      "INFO:root:Epoch[433] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 101.16it/s, avg_epoch_loss=-.00994]\n",
      "INFO:root:Epoch[433] Elapsed time 0.990 seconds\n",
      "INFO:root:Epoch[433] Evaluation metric 'epoch_loss'=-0.009939\n",
      "INFO:root:Epoch[434] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 86.91it/s, avg_epoch_loss=-.00901]\n",
      "INFO:root:Epoch[434] Elapsed time 1.152 seconds\n",
      "INFO:root:Epoch[434] Evaluation metric 'epoch_loss'=-0.009009\n",
      "INFO:root:Epoch[435] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 101.20it/s, avg_epoch_loss=-.0275]\n",
      "INFO:root:Epoch[435] Elapsed time 1.012 seconds\n",
      "INFO:root:Epoch[435] Evaluation metric 'epoch_loss'=-0.027465\n",
      "INFO:root:Epoch[436] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 90.54it/s, avg_epoch_loss=0.00341]\n",
      "INFO:root:Epoch[436] Elapsed time 1.143 seconds\n",
      "INFO:root:Epoch[436] Evaluation metric 'epoch_loss'=0.003414\n",
      "INFO:root:Epoch[437] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.02it/s, avg_epoch_loss=-.0116]\n",
      "INFO:root:Epoch[437] Elapsed time 0.888 seconds\n",
      "INFO:root:Epoch[437] Evaluation metric 'epoch_loss'=-0.011595\n",
      "INFO:root:Epoch[438] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 133.77it/s, avg_epoch_loss=0.00628]\n",
      "INFO:root:Epoch[438] Elapsed time 0.749 seconds\n",
      "INFO:root:Epoch[438] Evaluation metric 'epoch_loss'=0.006277\n",
      "INFO:root:Epoch[439] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.22it/s, avg_epoch_loss=-.015]\n",
      "INFO:root:Epoch[439] Elapsed time 0.874 seconds\n",
      "INFO:root:Epoch[439] Evaluation metric 'epoch_loss'=-0.014967\n",
      "INFO:root:Epoch[440] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 105.88it/s, avg_epoch_loss=1.59e-5]\n",
      "INFO:root:Epoch[440] Elapsed time 0.970 seconds\n",
      "INFO:root:Epoch[440] Evaluation metric 'epoch_loss'=0.000016\n",
      "INFO:root:Epoch[441] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 122.85it/s, avg_epoch_loss=-.0134]\n",
      "INFO:root:Epoch[441] Elapsed time 0.817 seconds\n",
      "INFO:root:Epoch[441] Evaluation metric 'epoch_loss'=-0.013365\n",
      "INFO:root:Epoch[442] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 134.89it/s, avg_epoch_loss=-.0046]\n",
      "INFO:root:Epoch[442] Elapsed time 0.753 seconds\n",
      "INFO:root:Epoch[442] Evaluation metric 'epoch_loss'=-0.004599\n",
      "INFO:root:Epoch[443] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 121.68it/s, avg_epoch_loss=-.0127]\n",
      "INFO:root:Epoch[443] Elapsed time 0.844 seconds\n",
      "INFO:root:Epoch[443] Evaluation metric 'epoch_loss'=-0.012670\n",
      "INFO:root:Epoch[444] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 105.81it/s, avg_epoch_loss=-.0118]\n",
      "INFO:root:Epoch[444] Elapsed time 0.947 seconds\n",
      "INFO:root:Epoch[444] Evaluation metric 'epoch_loss'=-0.011791\n",
      "INFO:root:Epoch[445] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 136.07it/s, avg_epoch_loss=-.015]\n",
      "INFO:root:Epoch[445] Elapsed time 0.737 seconds\n",
      "INFO:root:Epoch[445] Evaluation metric 'epoch_loss'=-0.014991\n",
      "INFO:root:Epoch[446] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 128.83it/s, avg_epoch_loss=-.0114]\n",
      "INFO:root:Epoch[446] Elapsed time 0.791 seconds\n",
      "INFO:root:Epoch[446] Evaluation metric 'epoch_loss'=-0.011367\n",
      "INFO:root:Epoch[447] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 74.36it/s, avg_epoch_loss=-.00281]\n",
      "INFO:root:Epoch[447] Elapsed time 1.348 seconds\n",
      "INFO:root:Epoch[447] Evaluation metric 'epoch_loss'=-0.002810\n",
      "INFO:root:Epoch[448] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 139.10it/s, avg_epoch_loss=-.0173]\n",
      "INFO:root:Epoch[448] Elapsed time 0.721 seconds\n",
      "INFO:root:Epoch[448] Evaluation metric 'epoch_loss'=-0.017278\n",
      "INFO:root:Epoch[449] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 105.77it/s, avg_epoch_loss=-.0088]\n",
      "INFO:root:Epoch[449] Elapsed time 0.947 seconds\n",
      "INFO:root:Epoch[449] Evaluation metric 'epoch_loss'=-0.008799\n",
      "INFO:root:Epoch[450] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.35it/s, avg_epoch_loss=-.0245]\n",
      "INFO:root:Epoch[450] Elapsed time 0.970 seconds\n",
      "INFO:root:Epoch[450] Evaluation metric 'epoch_loss'=-0.024538\n",
      "INFO:root:Epoch[451] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.40it/s, avg_epoch_loss=-.0066]\n",
      "INFO:root:Epoch[451] Elapsed time 0.971 seconds\n",
      "INFO:root:Epoch[451] Evaluation metric 'epoch_loss'=-0.006605\n",
      "INFO:root:Epoch[452] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.41it/s, avg_epoch_loss=0.00378]\n",
      "INFO:root:Epoch[452] Elapsed time 0.875 seconds\n",
      "INFO:root:Epoch[452] Evaluation metric 'epoch_loss'=0.003781\n",
      "INFO:root:Epoch[453] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.20it/s, avg_epoch_loss=-.0223]\n",
      "INFO:root:Epoch[453] Elapsed time 0.971 seconds\n",
      "INFO:root:Epoch[453] Evaluation metric 'epoch_loss'=-0.022305\n",
      "INFO:root:Epoch[454] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.94it/s, avg_epoch_loss=0.0126]\n",
      "INFO:root:Epoch[454] Elapsed time 0.875 seconds\n",
      "INFO:root:Epoch[454] Evaluation metric 'epoch_loss'=0.012553\n",
      "INFO:root:Epoch[455] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 129.73it/s, avg_epoch_loss=-9.54e-5]\n",
      "INFO:root:Epoch[455] Elapsed time 0.783 seconds\n",
      "INFO:root:Epoch[455] Evaluation metric 'epoch_loss'=-0.000095\n",
      "INFO:root:Epoch[456] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 75.46it/s, avg_epoch_loss=-.0244]\n",
      "INFO:root:Epoch[456] Elapsed time 1.327 seconds\n",
      "INFO:root:Epoch[456] Evaluation metric 'epoch_loss'=-0.024397\n",
      "INFO:root:Epoch[457] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.58it/s, avg_epoch_loss=-.0246]\n",
      "INFO:root:Epoch[457] Elapsed time 1.006 seconds\n",
      "INFO:root:Epoch[457] Evaluation metric 'epoch_loss'=-0.024647\n",
      "INFO:root:Epoch[458] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 81.41it/s, avg_epoch_loss=-.000923]\n",
      "INFO:root:Epoch[458] Elapsed time 1.231 seconds\n",
      "INFO:root:Epoch[458] Evaluation metric 'epoch_loss'=-0.000923\n",
      "INFO:root:Epoch[459] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 85.88it/s, avg_epoch_loss=-.0149]\n",
      "INFO:root:Epoch[459] Elapsed time 1.178 seconds\n",
      "INFO:root:Epoch[459] Evaluation metric 'epoch_loss'=-0.014943\n",
      "INFO:root:Epoch[460] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 85.07it/s, avg_epoch_loss=-.0257]\n",
      "INFO:root:Epoch[460] Elapsed time 1.177 seconds\n",
      "INFO:root:Epoch[460] Evaluation metric 'epoch_loss'=-0.025705\n",
      "INFO:root:Epoch[461] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 124.45it/s, avg_epoch_loss=-.00109]\n",
      "INFO:root:Epoch[461] Elapsed time 0.816 seconds\n",
      "INFO:root:Epoch[461] Evaluation metric 'epoch_loss'=-0.001089\n",
      "INFO:root:Epoch[462] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 128.81it/s, avg_epoch_loss=0.0136]\n",
      "INFO:root:Epoch[462] Elapsed time 0.779 seconds\n",
      "INFO:root:Epoch[462] Evaluation metric 'epoch_loss'=0.013634\n",
      "INFO:root:Epoch[463] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 145.55it/s, avg_epoch_loss=-.0168]\n",
      "INFO:root:Epoch[463] Elapsed time 0.689 seconds\n",
      "INFO:root:Epoch[463] Evaluation metric 'epoch_loss'=-0.016780\n",
      "INFO:root:Epoch[464] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.60it/s, avg_epoch_loss=-.01]\n",
      "INFO:root:Epoch[464] Elapsed time 0.891 seconds\n",
      "INFO:root:Epoch[464] Evaluation metric 'epoch_loss'=-0.010011\n",
      "INFO:root:Epoch[465] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 138.70it/s, avg_epoch_loss=0.000633]\n",
      "INFO:root:Epoch[465] Elapsed time 0.730 seconds\n",
      "INFO:root:Epoch[465] Evaluation metric 'epoch_loss'=0.000633\n",
      "INFO:root:Epoch[466] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 131.31it/s, avg_epoch_loss=-.0134]\n",
      "INFO:root:Epoch[466] Elapsed time 0.763 seconds\n",
      "INFO:root:Epoch[466] Evaluation metric 'epoch_loss'=-0.013448\n",
      "INFO:root:Epoch[467] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.48it/s, avg_epoch_loss=-.00536]\n",
      "INFO:root:Epoch[467] Elapsed time 0.853 seconds\n",
      "INFO:root:Epoch[467] Evaluation metric 'epoch_loss'=-0.005365\n",
      "INFO:root:Epoch[468] Learning rate is 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 147.10it/s, avg_epoch_loss=-.00117]\n",
      "INFO:root:Epoch[468] Elapsed time 0.681 seconds\n",
      "INFO:root:Epoch[468] Evaluation metric 'epoch_loss'=-0.001173\n",
      "INFO:root:Epoch[469] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.68it/s, avg_epoch_loss=-.0272]\n",
      "INFO:root:Epoch[469] Elapsed time 0.792 seconds\n",
      "INFO:root:Epoch[469] Evaluation metric 'epoch_loss'=-0.027230\n",
      "INFO:root:Epoch[470] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 130.43it/s, avg_epoch_loss=0.00383]\n",
      "INFO:root:Epoch[470] Elapsed time 0.768 seconds\n",
      "INFO:root:Epoch[470] Evaluation metric 'epoch_loss'=0.003829\n",
      "INFO:root:Epoch[471] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.83it/s, avg_epoch_loss=-.00371]\n",
      "INFO:root:Epoch[471] Elapsed time 1.013 seconds\n",
      "INFO:root:Epoch[471] Evaluation metric 'epoch_loss'=-0.003709\n",
      "INFO:root:Epoch[472] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.90it/s, avg_epoch_loss=-.0052]\n",
      "INFO:root:Epoch[472] Elapsed time 1.034 seconds\n",
      "INFO:root:Epoch[472] Evaluation metric 'epoch_loss'=-0.005201\n",
      "INFO:root:Epoch[473] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 122.50it/s, avg_epoch_loss=-.00268]\n",
      "INFO:root:Epoch[473] Elapsed time 0.818 seconds\n",
      "INFO:root:Epoch[473] Evaluation metric 'epoch_loss'=-0.002680\n",
      "INFO:root:Epoch[474] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 133.55it/s, avg_epoch_loss=0.00951]\n",
      "INFO:root:Epoch[474] Elapsed time 0.750 seconds\n",
      "INFO:root:Epoch[474] Evaluation metric 'epoch_loss'=0.009510\n",
      "INFO:root:Epoch[475] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 127.45it/s, avg_epoch_loss=-.00887]\n",
      "INFO:root:Epoch[475] Elapsed time 0.787 seconds\n",
      "INFO:root:Epoch[475] Evaluation metric 'epoch_loss'=-0.008870\n",
      "INFO:root:Epoch[476] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 138.64it/s, avg_epoch_loss=-.01]\n",
      "INFO:root:Epoch[476] Elapsed time 0.724 seconds\n",
      "INFO:root:Epoch[476] Evaluation metric 'epoch_loss'=-0.010009\n",
      "INFO:root:Epoch[477] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 127.99it/s, avg_epoch_loss=0.0126]\n",
      "INFO:root:Epoch[477] Elapsed time 0.785 seconds\n",
      "INFO:root:Epoch[477] Evaluation metric 'epoch_loss'=0.012614\n",
      "INFO:root:Epoch[478] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.95it/s, avg_epoch_loss=-.0157]\n",
      "INFO:root:Epoch[478] Elapsed time 0.789 seconds\n",
      "INFO:root:Epoch[478] Evaluation metric 'epoch_loss'=-0.015706\n",
      "INFO:root:Epoch[479] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 135.11it/s, avg_epoch_loss=-.00964]\n",
      "INFO:root:Epoch[479] Elapsed time 0.745 seconds\n",
      "INFO:root:Epoch[479] Evaluation metric 'epoch_loss'=-0.009641\n",
      "INFO:root:Epoch[480] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.98it/s, avg_epoch_loss=-.000194]\n",
      "INFO:root:Epoch[480] Elapsed time 0.955 seconds\n",
      "INFO:root:Epoch[480] Evaluation metric 'epoch_loss'=-0.000194\n",
      "INFO:root:Epoch[481] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 120.75it/s, avg_epoch_loss=-.00225]\n",
      "INFO:root:Epoch[481] Elapsed time 0.830 seconds\n",
      "INFO:root:Epoch[481] Evaluation metric 'epoch_loss'=-0.002253\n",
      "INFO:root:Epoch[482] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.69it/s, avg_epoch_loss=-.00106]\n",
      "INFO:root:Epoch[482] Elapsed time 0.966 seconds\n",
      "INFO:root:Epoch[482] Evaluation metric 'epoch_loss'=-0.001064\n",
      "INFO:root:Epoch[483] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 140.06it/s, avg_epoch_loss=-.0118]\n",
      "INFO:root:Epoch[483] Elapsed time 0.716 seconds\n",
      "INFO:root:Epoch[483] Evaluation metric 'epoch_loss'=-0.011753\n",
      "INFO:root:Epoch[484] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 131.00it/s, avg_epoch_loss=-.00467]\n",
      "INFO:root:Epoch[484] Elapsed time 0.765 seconds\n",
      "INFO:root:Epoch[484] Evaluation metric 'epoch_loss'=-0.004674\n",
      "INFO:root:Epoch[485] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 156.36it/s, avg_epoch_loss=-.00552]\n",
      "INFO:root:Epoch[485] Elapsed time 0.643 seconds\n",
      "INFO:root:Epoch[485] Evaluation metric 'epoch_loss'=-0.005519\n",
      "INFO:root:Epoch[486] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.56it/s, avg_epoch_loss=-.00705]\n",
      "INFO:root:Epoch[486] Elapsed time 1.037 seconds\n",
      "INFO:root:Epoch[486] Evaluation metric 'epoch_loss'=-0.007046\n",
      "INFO:root:Epoch[487] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 134.31it/s, avg_epoch_loss=-.0351]\n",
      "INFO:root:Epoch[487] Elapsed time 0.747 seconds\n",
      "INFO:root:Epoch[487] Evaluation metric 'epoch_loss'=-0.035146\n",
      "INFO:root:Epoch[488] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.93it/s, avg_epoch_loss=-.0121]\n",
      "INFO:root:Epoch[488] Elapsed time 0.789 seconds\n",
      "INFO:root:Epoch[488] Evaluation metric 'epoch_loss'=-0.012060\n",
      "INFO:root:Epoch[489] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 126.26it/s, avg_epoch_loss=0.00403]\n",
      "INFO:root:Epoch[489] Elapsed time 0.794 seconds\n",
      "INFO:root:Epoch[489] Evaluation metric 'epoch_loss'=0.004029\n",
      "INFO:root:Epoch[490] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 155.94it/s, avg_epoch_loss=-.0179]\n",
      "INFO:root:Epoch[490] Elapsed time 0.651 seconds\n",
      "INFO:root:Epoch[490] Evaluation metric 'epoch_loss'=-0.017874\n",
      "INFO:root:Epoch[491] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.22it/s, avg_epoch_loss=-.0033]\n",
      "INFO:root:Epoch[491] Elapsed time 0.928 seconds\n",
      "INFO:root:Epoch[491] Evaluation metric 'epoch_loss'=-0.003304\n",
      "INFO:root:Epoch[492] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 130.34it/s, avg_epoch_loss=-.028]\n",
      "INFO:root:Epoch[492] Elapsed time 0.769 seconds\n",
      "INFO:root:Epoch[492] Evaluation metric 'epoch_loss'=-0.027969\n",
      "INFO:root:Epoch[493] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.42it/s, avg_epoch_loss=0.00977]\n",
      "INFO:root:Epoch[493] Elapsed time 0.893 seconds\n",
      "INFO:root:Epoch[493] Evaluation metric 'epoch_loss'=0.009771\n",
      "INFO:root:Epoch[494] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 137.60it/s, avg_epoch_loss=-.0159]\n",
      "INFO:root:Epoch[494] Elapsed time 0.731 seconds\n",
      "INFO:root:Epoch[494] Evaluation metric 'epoch_loss'=-0.015907\n",
      "INFO:root:Epoch[495] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 91.98it/s, avg_epoch_loss=-.00081]\n",
      "INFO:root:Epoch[495] Elapsed time 1.089 seconds\n",
      "INFO:root:Epoch[495] Evaluation metric 'epoch_loss'=-0.000810\n",
      "INFO:root:Epoch[496] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.13it/s, avg_epoch_loss=-.00156]\n",
      "INFO:root:Epoch[496] Elapsed time 0.893 seconds\n",
      "INFO:root:Epoch[496] Evaluation metric 'epoch_loss'=-0.001564\n",
      "INFO:root:Epoch[497] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.56it/s, avg_epoch_loss=-.023]\n",
      "INFO:root:Epoch[497] Elapsed time 0.899 seconds\n",
      "INFO:root:Epoch[497] Evaluation metric 'epoch_loss'=-0.023013\n",
      "INFO:root:Epoch[498] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:01<00:00, 84.63it/s, avg_epoch_loss=-.00418]\n",
      "INFO:root:Epoch[498] Elapsed time 1.194 seconds\n",
      "INFO:root:Epoch[498] Evaluation metric 'epoch_loss'=-0.004177\n",
      "INFO:root:Epoch[499] Learning rate is 5e-05\n",
      "100%|██████████| 100/100 [00:00<00:00, 101.48it/s, avg_epoch_loss=-.0264]\n",
      "INFO:root:Epoch[499] Elapsed time 0.987 seconds\n",
      "INFO:root:Epoch[499] Evaluation metric 'epoch_loss'=-0.026360\n",
      "INFO:root:Loading parameters from best epoch (242)\n",
      "INFO:root:Final loss: -0.03569216398987919 (occurred at epoch 242)\n",
      "INFO:root:End model training\n",
      "Running evaluation: 100%|██████████| 2042/2042 [00:12<00:00, 164.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"MSE\": 0.09335215464032448,\n",
      "    \"abs_error\": 513.5942371384267,\n",
      "    \"abs_target_sum\": 1757.3268753519892,\n",
      "    \"abs_target_mean\": 0.8605910261273209,\n",
      "    \"seasonal_error\": NaN,\n",
      "    \"MASE\": NaN,\n",
      "    \"sMAPE\": 0.5382073546279266,\n",
      "    \"MSIS\": NaN,\n",
      "    \"QuantileLoss[0.1]\": 215.49960600413934,\n",
      "    \"Coverage[0.1]\": 0.07394711067580803,\n",
      "    \"QuantileLoss[0.5]\": 513.5942371384267,\n",
      "    \"Coverage[0.5]\": 0.3050930460333007,\n",
      "    \"QuantileLoss[0.9]\": 252.3655072586292,\n",
      "    \"Coverage[0.9]\": 0.6973555337904016,\n",
      "    \"RMSE\": 0.3055358483718801,\n",
      "    \"NRMSE\": 0.35503025141547007,\n",
      "    \"ND\": 0.2922587962103264,\n",
      "    \"wQuantileLoss[0.1]\": 0.12262920975414729,\n",
      "    \"wQuantileLoss[0.5]\": 0.2922587962103264,\n",
      "    \"wQuantileLoss[0.9]\": 0.14360760698437555,\n",
      "    \"mean_wQuantileLoss\": 0.1861652043162831,\n",
      "    \"MAE_Coverage\": 0.14120143650016323\n",
      "}\n",
      "mae =  2.5264446620959844\n",
      "make full testdb: 5050 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|██████████| 5050/5050 [00:31<00:00, 158.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"MSE\": 3.1388387876495174,\n",
      "    \"abs_error\": 7175.945288561277,\n",
      "    \"abs_target_sum\": 8846.521035476744,\n",
      "    \"abs_target_mean\": 1.7517863436587613,\n",
      "    \"seasonal_error\": NaN,\n",
      "    \"MASE\": NaN,\n",
      "    \"sMAPE\": 0.6411656156998071,\n",
      "    \"MSIS\": NaN,\n",
      "    \"QuantileLoss[0.1]\": 3209.236312967886,\n",
      "    \"Coverage[0.1]\": 0.2633663366336634,\n",
      "    \"QuantileLoss[0.5]\": 7175.945288561277,\n",
      "    \"Coverage[0.5]\": 0.29306930693069305,\n",
      "    \"QuantileLoss[0.9]\": 10352.914670106926,\n",
      "    \"Coverage[0.9]\": 0.3178217821782178,\n",
      "    \"RMSE\": 1.7716768293482639,\n",
      "    \"NRMSE\": 1.0113544016149592,\n",
      "    \"ND\": 0.8111601453027644,\n",
      "    \"wQuantileLoss[0.1]\": 0.3627681774675098,\n",
      "    \"wQuantileLoss[0.5]\": 0.8111601453027644,\n",
      "    \"wQuantileLoss[0.9]\": 1.1702809080076981,\n",
      "    \"mean_wQuantileLoss\": 0.7814030769259906,\n",
      "    \"MAE_Coverage\": 0.3174917491749175\n",
      "}\n",
      "save model data//pitmodel-m100-mlp-Pocono-dsel-f2-e500-l10-10-5-student-d0.1-1k-nocurcautionlaps.pickle with 5050 keys.\n"
     ]
    }
   ],
   "source": [
    "p, t, s, e = {}, {} ,{}, {}\n",
    "\n",
    "testevent=f'{trainrace}-2018'\n",
    "feature_cnt=2\n",
    "\n",
    "key = f'{testevent}-{feature_cnt}'\n",
    "df_train, df_test, _data = dataset[key]\n",
    "trainset, testset, train_ds, test_ds, scaler = _data['sel']\n",
    "pm, mid = train_model(500,dropout = 0.1,id='sel', feature_cnt=feature_cnt)\n",
    "t[mid],s[mid], e[mid] = eval_model(pm, test_ds)\n",
    "p[mid] = pm\n",
    "\n",
    "mae = raw_eval(t[mid],s[mid])\n",
    "\n",
    "pitmodel = save_full_pitmodel(mid, scaler, maxgap=100,feature_cnt=feature_cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate all trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, t, s, e = {}, {} ,{}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sync_test_ds = _data['all'][3]\n",
    "cols = ['Year','Model','MAE','50-Risk','90-Risk']\n",
    "\n",
    "### run train on all data\n",
    "allruns = ['sel','all','noshort','normal','caution','plen2']\n",
    "testevent='Indy500-2018'\n",
    "\n",
    "retdata = []\n",
    "for feature_cnt in [2,3]:\n",
    "    for tid in allruns:\n",
    "        #train\n",
    "        key = f'{testevent}-{feature_cnt}'\n",
    "        df_train, df_test, _data = dataset[key]\n",
    "        \n",
    "        trainset, testset, train_ds, test_ds, scaler = _data[tid]\n",
    "        pm, mid = train_model(500,dropout = 0.1, id=tid, feature_cnt=feature_cnt)\n",
    "\n",
    "        #test\n",
    "        sync_testset = _data['normal'][1]\n",
    "        sync_test_ds, _, _ = makedb(sync_testset, scaler, perm=False, feature_cnt=feature_cnt)\n",
    "        t[mid],s[mid], e[mid] = eval_model(pm, sync_test_ds)\n",
    "        p[mid] = pm\n",
    "\n",
    "        mae = raw_eval(t[mid],s[mid])\n",
    "        retdata.append([testevent,tid, mae, e[mid][\"wQuantileLoss[0.5]\"],e[mid][\"wQuantileLoss[0.9]\"]])\n",
    "\n",
    "        #run_test(t[mid], s[mid], [31,816,846,856])\n",
    "        pitmodel = save_full_pitmodel(mid, scaler, maxgap=65,feature_cnt=feature_cnt)\n",
    "    \n",
    "pitmodel_result = pd.DataFrame(data=retdata, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#savedata('mlp-train-savedata.pickle',[p,t,s,e])\n",
    "p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitmodel_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testid = 'sel'\n",
    "retdata = []\n",
    "truth, pred, samples = {}, {}, {}     \n",
    "#cols = ['Year','Model','MAE','50-Risk','90-Risk','50-Risk','90-Risk']\n",
    "cols = ['Year','Model','MAE','50-Risk','90-Risk']\n",
    "\n",
    "trainruns = ['sel','all','normal']\n",
    "testruns = ['sel','all','normal','caution','plen2']\n",
    "\n",
    "for feature_cnt in [2,3]:\n",
    "    for tid in trainruns:\n",
    "        mid = f\"mlp-d{tid}-f{feature_cnt}-e500-l10-10-5-student-d0.1\"\n",
    "\n",
    "        for testevent in ['Indy500-2018','Indy500-2019']:\n",
    "            key = f'{testevent}-{feature_cnt}'\n",
    "            df_train, df_test, _data = dataset[key]\n",
    "            scaler = _data[tid][-1]\n",
    "\n",
    "            for testid in testruns:\n",
    "                #trainset, testset, train_ds, test_ds, scaler\n",
    "                sync_testset = _data[testid][1]\n",
    "                test_ds, _, _ = makedb(sync_testset, scaler, perm=False,feature_cnt=feature_cnt)\n",
    "\n",
    "                tx,sx, ex = eval_model(p[mid], test_ds)\n",
    "                mae = raw_eval(tx,sx)\n",
    "                print(mid, 'mae=', mae,ex[\"wQuantileLoss[0.5]\"],ex[\"wQuantileLoss[0.9]\"] )\n",
    "\n",
    "                # prisk direct\n",
    "                truth[mid], pred[mid], samples[mid] = decode(tx,sx)\n",
    "                idx = np.where(samples[mid] < 0)\n",
    "                samples[mid][idx] = 0\n",
    "\n",
    "                _, prisk_vals = prisk_direct_bysamples(samples[mid],truth[mid])\n",
    "                print(prisk_vals[1], prisk_vals[2])        \n",
    "\n",
    "                retdata.append([testevent,tid + '-' + testid, mae, \n",
    "                               #ex[\"wQuantileLoss[0.5]\"],ex[\"wQuantileLoss[0.9]\"],\n",
    "                               prisk_vals[1], prisk_vals[2]])\n",
    "        \n",
    "test_result = pd.DataFrame(data=retdata, columns=cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.to_csv('pitmodel_mlp_evaluation_result_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testid = 'sel'\n",
    "retdata = []\n",
    "truth, pred, samples = {}, {}, {}     \n",
    "#cols = ['Year','Model','MAE','50-Risk','90-Risk','50-Risk','90-Risk']\n",
    "cols = ['Year','Model','FeatureCnt','MAE','50-Risk','90-Risk']\n",
    "\n",
    "trainruns = ['sel','all']\n",
    "for feature_cnt in [2,3]:\n",
    "    for tid in trainruns:\n",
    "        mid = f\"mlp-d{tid}-f{feature_cnt}-e500-l10-10-5-student-d0.1\"\n",
    "\n",
    "        for testevent in ['Indy500-2018','Indy500-2019']:\n",
    "            key = f'{testevent}-{feature_cnt}'\n",
    "            df_train, df_test, _data = dataset[key]\n",
    "            scaler = _data[tid][-1]\n",
    "\n",
    "            for testid in ['all','sel', 'caution','shortnormal']:\n",
    "                #trainset, testset, train_ds, test_ds, scaler\n",
    "                if testid == 'shortnormal':\n",
    "                    test_sel = df_test[(df_test['pit_oncaution']==0) & (df_test['stint_len']<=23)]\n",
    "                    sync_testset = test_sel[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "                else:\n",
    "                    sync_testset = _data[testid][1]\n",
    "                           \n",
    "                test_ds, _, _ = makedb(sync_testset, scaler, perm=False,feature_cnt=feature_cnt)\n",
    "\n",
    "                tx,sx, ex = eval_model(p[mid], test_ds)\n",
    "                mae = raw_eval(tx,sx)\n",
    "                print(mid, 'mae=', mae,ex[\"wQuantileLoss[0.5]\"],ex[\"wQuantileLoss[0.9]\"] )\n",
    "\n",
    "                # prisk direct\n",
    "                truth[mid], pred[mid], samples[mid] = decode(tx,sx)\n",
    "                idx = np.where(samples[mid] < 0)\n",
    "                samples[mid][idx] = 0\n",
    "\n",
    "                _, prisk_vals = prisk_direct_bysamples(samples[mid],truth[mid])\n",
    "                print(prisk_vals[1], prisk_vals[2])        \n",
    "\n",
    "                retdata.append([testevent,tid + '-' + testid , feature_cnt, mae, \n",
    "                               #ex[\"wQuantileLoss[0.5]\"],ex[\"wQuantileLoss[0.9]\"],\n",
    "                               prisk_vals[1], prisk_vals[2]])\n",
    "        \n",
    "test_result = pd.DataFrame(data=retdata, columns=cols) \n",
    "test_result.to_csv('pitmodel_mlp_evaluation_result_paper.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#straight implementation of prisk\n",
    "def quantile_loss(target, quantile_forecast, q):\n",
    "    return 2.0 * np.nansum(\n",
    "        np.abs(\n",
    "            (quantile_forecast - target)\n",
    "            * ((target <= quantile_forecast) - q)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def abs_target_sum(target): \n",
    "    return np.nansum(np.abs(target)) \n",
    "\n",
    "def prisk_direct_bysamples(forecast, target, quantiles=[0.1,0.5,0.9], startid = 0, verbose=False):\n",
    "    \"\"\"\n",
    "    calculate prisk by <samples, tss> directly (equal to gluonts implementation)\n",
    "    \n",
    "    target: endrank\n",
    "    forecast: pred_endrank\n",
    "    item_id: <carno, startlap>\n",
    "    \"\"\"\n",
    "    \n",
    "    prisk = np.zeros((len(quantiles)))\n",
    "    target_sum = 0\n",
    "    aggrisk = np.zeros((len(quantiles)))\n",
    "    \n",
    "    #calc quantiles\n",
    "    # len(quantiles) x 1\n",
    "    quantile_forecasts = np.quantile(forecast, quantiles, axis=0)\n",
    "\n",
    "    for idx, q in enumerate(quantiles):\n",
    "        q_forecast = quantile_forecasts[idx]\n",
    "        prisk[idx] = quantile_loss(target[startid:], q_forecast[startid:], q)\n",
    "        target_sum = abs_target_sum(target[startid:])\n",
    "\n",
    "    if verbose==True and carno==3:\n",
    "        print('target:', target[startid:])\n",
    "        print('forecast:', q_forecast[startid:])\n",
    "        print('target_sum:', target_sum)\n",
    "\n",
    "        print('quantile_forecasts:', quantile_forecasts[:,startid:])\n",
    "        \n",
    "    #agg\n",
    "    #aggrisk = np.mean(prisk, axis=0)\n",
    "    #prisk_sum = np.nansum(prisk, axis=0)\n",
    "    prisk_sum = prisk\n",
    "    \n",
    "    if verbose==True:\n",
    "        print('prisk:',prisk)\n",
    "        print('prisk_sum:',prisk_sum)\n",
    "        print('target_sum:',target_sum)\n",
    "    for idx, q in enumerate(quantiles):\n",
    "        aggrisk[idx] = np.divide(prisk_sum[idx], target_sum)\n",
    "    \n",
    "    agg_metrics = {}\n",
    "    for idx, q in enumerate(quantiles):\n",
    "        agg_metrics[f'wQuantileLoss[{q}]'] = aggrisk[idx]\n",
    "        \n",
    "    print(agg_metrics.values())\n",
    "    \n",
    "    return agg_metrics, aggrisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset, testset, train_ds, test_ds, scaler = _data['all']\n",
    "trainset, testset, train_ds, test_ds, scaler = _data['sel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(500,dropout = 0.1,id='sel')\n",
    "t[mid],s[mid], e[mid] = eval_model(pm, test_ds)\n",
    "p[mid] = pm\n",
    "\n",
    "mae = raw_eval(t[mid],s[mid])\n",
    "\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitmodel = save_full_pitmodel(mid, 'sel', maxgap=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run train on all data\n",
    "trainset, testset, train_ds, test_ds, scaler = _data['all']\n",
    "\n",
    "pm, mid = train_model(500,dropout = 0.1,id='all')\n",
    "t[mid],s[mid], e[mid] = eval_model(pm, test_ds)\n",
    "p[mid] = pm\n",
    "\n",
    "mae = raw_eval(t[mid],s[mid])\n",
    "\n",
    "run_test(t[mid], s[mid], [31,816,846,856])\n",
    "pitmodel = save_full_pitmodel(mid, 'all', maxgap=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run train on all data\n",
    "tid = 'noshort'\n",
    "trainset, testset, train_ds, test_ds, scaler = _data[tid]\n",
    "\n",
    "pm, mid = train_model(500,dropout = 0.1,id=tid)\n",
    "t[mid],s[mid], e[mid] = eval_model(pm, test_ds)\n",
    "p[mid] = pm\n",
    "\n",
    "mae = raw_eval(t[mid],s[mid])\n",
    "\n",
    "run_test(t[mid], s[mid], [31,816,846,856])\n",
    "pitmodel = save_full_pitmodel(mid, tid, maxgap=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(500,dropout = 0.1)\n",
    "t[mid],s[mid], e[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(2000,dropout = 0.1)\n",
    "t[mid],s[mid], e[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "save_model(p[mid], mid)\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(200,dropout = 0.1, layers=[8,4])\n",
    "t[mid],s[mid], e[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[mid],s[mid], e[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(500, layers=[10,5])\n",
    "t[mid],s[mid] = eval_model(pm)\n",
    "p[mid] = pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(500, layers=[32,16,8,4])\n",
    "t[mid],s[mid] = eval_model(pm)\n",
    "p[mid] = pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(2000, layers=[32,16,8,4])\n",
    "t[mid],s[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec = next(iter(train_ds))\n",
    "trec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(tss, forecasts, [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sel.iloc[816]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sel.iloc[836]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[mid],s[mid] = eval_model(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred(t[mid],s[mid], 816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(2,dropout = 0.1)\n",
    "#t[mid],s[mid], e[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "#run_test(t[mid], s[mid], [31,816,846,856])\n",
    "\n",
    "#mid = 'mlp-e2000-l10-10-5-student-d0.1'\n",
    "save_model(p[mid], mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test pitmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_scaler = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 'mlp-e2000-l10-10-5-student-d0.1'\n",
    "t[id],s[id], e[id] = eval_model(p[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = s[id]\n",
    "tss = t[id]\n",
    "\n",
    "scaler = _scaler\n",
    "testset = test_sel[['lap2nextpit','caution_laps','pitage']].values\n",
    "\n",
    "pitmodel = PitModel()\n",
    "\n",
    "pitmodel.save_model('pitmodel_test', testset, forecasts, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcasts = pitmodel.forecast_ds(testset, forecasts)\n",
    "scaler = _scaler\n",
    "run_test(tss, newcasts, [31,816,846,856],raw_forecast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pitmodel.model['0-0'][0,:], pitmodel.model['0-0'][1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pitmodel.model['10-13'][0,:], pitmodel.model['10-13'][1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitmodel.model['0-0'][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = _scaler\n",
    "test_all = df_test[['lap2nextpit','caution_laps','pitage']].values\n",
    "test_ds, _, test_set = makedb(test_all, scaler, perm=False)\n",
    "\n",
    "id = 'mlp-e2000-l10-10-5-student-d0.1'\n",
    "t[id],s[id], e[id] = eval_model(p[id])\n",
    "forecasts = s[id]\n",
    "tss = t[id]\n",
    "\n",
    "pitmodel = PitModel()\n",
    "\n",
    "pitmodel.save_model(f'mlp-{id}.pickle', test_all, forecasts, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testall_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = _scaler\n",
    "maxgap = 60\n",
    "test_ds, _, test_set, test_all = make_fulltestdb(scaler, maxgap = maxgap)\n",
    "\n",
    "id = 'mlp-e2000-l10-10-5-student-d0.1'\n",
    "\n",
    "t[id],s[id], e[id] = eval_model(p[id])\n",
    "forecasts = s[id]\n",
    "tss = t[id]\n",
    "\n",
    "pitmodel = PitModel()\n",
    "\n",
    "pitmodel.save_model(f'pitmodel-m{maxgap}-{id}.pickle', test_all, forecasts, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitmodel.model['0-0'][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pitmodel.model['0-0'][0,:], pitmodel.model['0-0'][1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['mlp-dsel-e500-l10-10-5-student-d0.1'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shortterm predictions using pitmodel(plen=2)\n",
    "\n",
    "convert forecast samples of pitmodel to forecast samples of pit@plen laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_car12 = df_test[df_test['carno']==12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds, _, test_set = makedb(test_car12[['lap2nextpit','caution_laps','pitage']].values, scaler, perm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_car12[test_car12['lap']==31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_car12[test_car12['lap']==30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = df_test[(df_test['eid']==5) & (df_test['carno']==12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12[(df12['lap']>=45) & (df12['lap']<55)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12.cur_cautionlaps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.zeros((1000))\n",
    "for i in range(1000):\n",
    "    samples[i] = pitmodel.predict(1,16,1)\n",
    "    \n",
    "samples[samples<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(samples<5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on normal set\n",
    "tid = 'sel'\n",
    "testid = 'normal'\n",
    "feature_cnt = 2\n",
    "testevent = 'Indy500-2018'\n",
    "mid = f\"mlp-d{tid}-f{feature_cnt}-e500-l10-10-5-student-d0.1\"\n",
    "\n",
    "key = f'{testevent}-{feature_cnt}'\n",
    "df_train, df_test, _data = dataset[key]\n",
    "scaler = _data[tid][-1]\n",
    "\n",
    "#trainset, testset, train_ds, test_ds, scaler\n",
    "sync_testset = _data[testid][1]\n",
    "print('testset len=', len(sync_testset))\n",
    "test_ds, _, _ = makedb(sync_testset, scaler, perm=False,feature_cnt=feature_cnt)\n",
    "\n",
    "tx,sx, ex = eval_model(p[mid], test_ds)\n",
    "mae = raw_eval(tx,sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = 'sel'\n",
    "testid = 'sel'\n",
    "feature_cnt = 2\n",
    "testevent = 'Indy500-2018'\n",
    "mid = f\"mlp-d{tid}-f{feature_cnt}-e500-l10-10-5-student-d0.1\"\n",
    "\n",
    "key = f'{testevent}-{feature_cnt}'\n",
    "df_train, df_test, _data = dataset[key]\n",
    "scaler = _data[tid][-1]\n",
    "\n",
    "#trainset, testset, train_ds, test_ds, scaler\n",
    "sync_testset = _data[testid][1]\n",
    "print('testset len=', len(sync_testset))\n",
    "test_ds, _, _ = makedb(sync_testset, scaler, perm=False,feature_cnt=feature_cnt)\n",
    "\n",
    "tx,sx, ex = eval_model(p[mid], test_ds)\n",
    "mae = raw_eval(tx,sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = 'sel'\n",
    "testid = 'sel'\n",
    "feature_cnt = 2\n",
    "testevent = 'Indy500-2018'\n",
    "mid = f\"mlp-d{tid}-f{feature_cnt}-e500-l10-10-5-student-d0.1\"\n",
    "\n",
    "key = f'{testevent}-{feature_cnt}'\n",
    "df_train, df_test, _data = dataset[key]\n",
    "scaler = _data[tid][-1]\n",
    "\n",
    "#trainset, testset, train_ds, test_ds, scaler\n",
    "test_sel = df_test[(df_test['pit_oncaution']==0) & (df_test['stint_len']<23)]\n",
    "sync_testset = test_sel[['lap2nextpit','caution_laps','pitage','cur_cautionlaps']].values\n",
    "print('testset len=', len(sync_testset))\n",
    "test_ds, _, _ = makedb(sync_testset, scaler, perm=False,feature_cnt=feature_cnt)\n",
    "\n",
    "tx,sx, ex = eval_model(p[mid], test_ds)\n",
    "mae = raw_eval(tx,sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitmodel.model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitmodel.model['0-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'kdk-TRA-xxx'\n",
    "a.replace('TRA', 'BBB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pitstop_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b6757f61c712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtracerace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pocono-2018'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpitstop_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpitstop_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raceid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtrainrace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pitstop_df' is not defined"
     ]
    }
   ],
   "source": [
    "tracerace='Pocono-2018'\n",
    "dfall = pitstop_df[pitstop_df['raceid']==trainrace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>raceid</th>\n",
       "      <th>eventid</th>\n",
       "      <th>carno</th>\n",
       "      <th>pit_id</th>\n",
       "      <th>lap_number</th>\n",
       "      <th>lap_time</th>\n",
       "      <th>lap_cnt</th>\n",
       "      <th>cautionlap_cnt</th>\n",
       "      <th>pit_oncaution_len</th>\n",
       "      <th>pit_oncaution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>3202</td>\n",
       "      <td>Pocono</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>47.7285</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>3203</td>\n",
       "      <td>Pocono</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>280.1038</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>3204</td>\n",
       "      <td>Pocono</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>48.1099</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>3205</td>\n",
       "      <td>Pocono</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>78.4307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>3206</td>\n",
       "      <td>Pocono</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>47.3519</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>4082</td>\n",
       "      <td>Pocono</td>\n",
       "      <td>27</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>50.1933</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>4083</td>\n",
       "      <td>Pocono</td>\n",
       "      <td>27</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>51.8781</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>4084</td>\n",
       "      <td>Pocono</td>\n",
       "      <td>27</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>84.7716</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>4085</td>\n",
       "      <td>Pocono</td>\n",
       "      <td>27</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>112</td>\n",
       "      <td>49.4751</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>4086</td>\n",
       "      <td>Pocono</td>\n",
       "      <td>27</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>95.4744</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>885 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  raceid  eventid  carno  pit_id  lap_number  lap_time  \\\n",
       "3202        3202  Pocono       21      1       0          32   47.7285   \n",
       "3203        3203  Pocono       21      1       1          61  280.1038   \n",
       "3204        3204  Pocono       21      1       2          81   48.1099   \n",
       "3205        3205  Pocono       21      1       3          82   78.4307   \n",
       "3206        3206  Pocono       21      1       4         109   47.3519   \n",
       "...          ...     ...      ...    ...     ...         ...       ...   \n",
       "4082        4082  Pocono       27     98       2          33   50.1933   \n",
       "4083        4083  Pocono       27     98       3          70   51.8781   \n",
       "4084        4084  Pocono       27     98       4          79   84.7716   \n",
       "4085        4085  Pocono       27     98       5         112   49.4751   \n",
       "4086        4086  Pocono       27     98       6         126   95.4744   \n",
       "\n",
       "      lap_cnt  cautionlap_cnt  pit_oncaution_len  pit_oncaution  \n",
       "3202       32               4                  0              0  \n",
       "3203       28               0                  0              1  \n",
       "3204       19               0                  0              0  \n",
       "3205        0               0                  0              0  \n",
       "3206       26               0                  0              0  \n",
       "...       ...             ...                ...            ...  \n",
       "4082       28               2                  0              0  \n",
       "4083       36               6                  0              0  \n",
       "4084        8               7                  7              1  \n",
       "4085       32               1                  0              0  \n",
       "4086       13               1                  1              1  \n",
       "\n",
       "[885 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
