{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nextpit model with simplemlp\n",
    "\n",
    "+ input pitstop dataset, remove pitstops with pit_oncaution = 1, refer to lapstatus_dataset-fastrun\n",
    "+ context_length = 1, prediction_length = 1\n",
    "+ target : gap to nextpit\n",
    "+ covariates are: cautions_laps, pitage, (carid, eid)\n",
    "+ modeling the distribution of nextpit-gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import inspect\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pathlib import Path\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.distribution.multivariate_gaussian import MultivariateGaussianOutput\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.model.prophet import ProphetPredictor\n",
    "from gluonts.model.r_forecast import RForecastPredictor\n",
    "from indycar.model.NaivePredictor import NaivePredictor\n",
    "from indycar.model.ZeroPredictor import ZeroPredictor\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch_hdd/hpda/indycar/notebook/15.AblationEval'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "random.seed()\n",
    "os.getcwd()\n",
    "#GPUID = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# remove NaN at the tail\n",
    "# there should be no nans in the middle of the ts\n",
    "COL_LAPTIME=0\n",
    "COL_RANK=1\n",
    "COL_TRACKSTATUS=2\n",
    "COL_LAPSTATUS=3\n",
    "COL_TIMEDIFF=4\n",
    "COL_CAUTION_LAPS_INSTINT=5\n",
    "COL_LAPS_INSTINT= 6\n",
    "\n",
    "# oracle mode\n",
    "MODE_ORACLE = 1024  # oracle = track + lap\n",
    "MODE_ORACLE_TRACKONLY = 1\n",
    "MODE_ORACLE_LAPONLY = 2   \n",
    "   \n",
    "\n",
    "# oracle mode for training\n",
    "MODE_NOLAP = 1   \n",
    "MODE_NOTRACK = 2\n",
    "\n",
    "# predicting mode\n",
    "MODE_TESTZERO = 4\n",
    "MODE_TESTCURTRACK = 8\n",
    "\n",
    "MODE_PREDTRACK = 16\n",
    "MODE_PREDPIT = 32\n",
    "\n",
    "# disturbe analysis\n",
    "MODE_DISTURB_CLEARTRACK = 64\n",
    "MODE_DISTURB_ADJUSTTRACK = 128\n",
    "MODE_DISTURB_ADJUSTPIT = 256\n",
    "\n",
    "\n",
    "_mode_map = {MODE_ORACLE:'MODE_ORACLE',MODE_ORACLE_TRACKONLY:'MODE_ORACLE_TRACKONLY',\n",
    "            MODE_ORACLE_LAPONLY:'MODE_ORACLE_LAPONLY',\n",
    "             MODE_TESTZERO:'MODE_TESTZERO',MODE_TESTCURTRACK:'MODE_TESTCURTRACK',\n",
    "             MODE_PREDTRACK:'MODE_PREDTRACK',MODE_PREDPIT:'MODE_PREDPIT',\n",
    "            MODE_DISTURB_CLEARTRACK:'MODE_DISTURB_CLEARTRACK',MODE_DISTURB_ADJUSTTRACK:'MODE_DISTURB_ADJUSTTRACK',\n",
    "            MODE_DISTURB_ADJUSTPIT:'MODE_DISTURB_ADJUSTPIT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(event, year=0):\n",
    "    #inputfile = '../data/final/C_'+ event +'-' + year + '-final.csv'\n",
    "    if year>0:\n",
    "        inputfile = '../data/final/C_'+ event +'-' + year + '.csv'\n",
    "    else:\n",
    "        inputfile = '../data/final/C_'+ event +'.csv'\n",
    "    #outputprefix = year +'-' + event + '-'\n",
    "    dataset = pd.read_csv(inputfile)\n",
    "    #dataset.info(verbose=True)    \n",
    "    \n",
    "    final_lap = max(dataset.completed_laps)\n",
    "    total_laps = final_lap + 1\n",
    "\n",
    "    # get records for the cars that finish the race\n",
    "    completed_car_numbers= dataset[dataset.completed_laps == final_lap].car_number.values\n",
    "    completed_car_count = len(completed_car_numbers)\n",
    "\n",
    "    #print('count of completed cars:', completed_car_count)\n",
    "    #print('completed cars:', completed_car_numbers)\n",
    "\n",
    "    #make a copy\n",
    "    alldata = dataset.copy()\n",
    "    dataset = dataset[dataset['car_number'].isin(completed_car_numbers)]\n",
    "    rankdata = alldata.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "    \n",
    "    cldata = make_cl_data(dataset)\n",
    "    acldata = make_cl_data(alldata)\n",
    "\n",
    "    return alldata, rankdata, acldata\n",
    "\n",
    "# make indy car completed_laps dataset\n",
    "# car_number, completed_laps, rank, elapsed_time, rank_diff, elapsed_time_diff \n",
    "def make_cl_data(dataset):\n",
    "\n",
    "    # pick up data with valid rank\n",
    "    rankdata = dataset.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "\n",
    "    # resort by car_number, lap\n",
    "    uni_ds = rankdata.sort_values(by=['car_number', 'completed_laps', 'elapsed_time'], ascending=True)    \n",
    "    #uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \"current_status\", \"track_status\", \"lap_status\",\n",
    "    #                  \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "    #                  \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "    \n",
    "    uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \n",
    "                      \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "                      \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "        \n",
    "    carnumber = set(uni_ds['car_number'])\n",
    "    #print('cars:', carnumber)\n",
    "    #print('#cars=', len(carnumber))\n",
    "   \n",
    "    # faster solution , uni_ds already sorted by car_number and lap\n",
    "    uni_ds['rank_diff'] = uni_ds['rank'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['rank_diff'][mask] = 0\n",
    "    \n",
    "    uni_ds['time_diff'] = uni_ds['elapsed_time'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['time_diff'][mask] = 0\n",
    "    \n",
    "    #df = uni_ds[['car_number','completed_laps','rank','elapsed_time','rank_diff','time_diff']]\n",
    "    df = uni_ds[['car_number','completed_laps','rank','elapsed_time',\n",
    "                 'rank_diff','time_diff',\"current_status\", \"track_status\", \"lap_status\"]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def test_flag(a, bitflag):\n",
    "    return (a & bitflag) ==  bitflag\n",
    "\n",
    "def get_modestr(a):\n",
    "    modestr = ''\n",
    "    for key in _mode_map:\n",
    "        if test_flag(a, key):\n",
    "            modestr += '%s,'%(_mode_map[key])\n",
    "            \n",
    "    return modestr\n",
    "\n",
    "# endpos -> vector of prediction_length\n",
    "_track_pred  = {}\n",
    "_track_true  = {}\n",
    "def init_track_model():\n",
    "    global _track_pred,_track_true\n",
    "    _track_pred = {}\n",
    "    _track_true  = {}\n",
    "    \n",
    "def get_track_model(track_rec, endpos, prediction_length, context_len=10):\n",
    "    \"\"\"\n",
    "    return the predicted track status\n",
    "    \"\"\"\n",
    "    global _track_pred,_track_true\n",
    "    # this is the perfect track model for Indy500 2018\n",
    "    track_model = [6,4,4,5,6,6,4]\n",
    "    if endpos in _track_pred:\n",
    "        return _track_pred[endpos]\n",
    "    else:\n",
    "        #get yflag lap count from the start pred point\n",
    "        yflaplen = 0\n",
    "        for i in range(1, context_len):\n",
    "            if track_rec[- prediction_length - i] == 1:\n",
    "                yflaplen += 1\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        #laps remain, fill into the future\n",
    "        trackpred = np.array([0 for x in range(prediction_length)])\n",
    "        \n",
    "        yflap_pred = random.choice(track_model)\n",
    "        if yflaplen > 0 and yflap_pred > yflaplen:\n",
    "            trackpred[:(yflap_pred - yflaplen)] = 1\n",
    "        _track_pred[endpos] = trackpred\n",
    "        \n",
    "        _track_true[endpos]  = track_rec[- prediction_length:].copy()\n",
    "        \n",
    "        return trackpred\n",
    "\n",
    "    \n",
    "# endpos -> vector of prediction_length\n",
    "_track_adjust  = {}\n",
    "def init_adjust_track_model():\n",
    "    global _track_adjust\n",
    "    _track_adjust = {}\n",
    "    \n",
    "def adjust_track_model(track_rec, endpos, prediction_length, tailpos):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        tailpos ; <0 end pos of 1\n",
    "    return the predicted track status\n",
    "    \"\"\"\n",
    "    global _track_adjust\n",
    "    # this is the perfect track model for Indy500 2018\n",
    "    track_model = [-1,0,1]\n",
    "    if endpos in _track_adjust:\n",
    "        return _track_adjust[endpos]\n",
    "    else:\n",
    "        yflap_adjust = random.choice(track_model)\n",
    "        \n",
    "        #laps remain, fill into the future\n",
    "        trackadjust = track_rec[-prediction_length:].copy()\n",
    "        if yflap_adjust == -1:\n",
    "            trackadjust[tailpos] = 0\n",
    "        elif yflap_adjust == 1:\n",
    "            trackadjust[tailpos] = 0\n",
    "            if (tailpos + 1) <= -1:\n",
    "                trackadjust[tailpos+1] = 1\n",
    "        \n",
    "        _track_adjust[endpos] = trackadjust\n",
    "        \n",
    "        return trackadjust\n",
    "\n",
    "# carno -> lap_status\n",
    "_lap_adjust = {}    \n",
    "_empirical_model = {}\n",
    "def init_adjust_pitmodel():\n",
    "    global _lap_adjust\n",
    "    _lap_adjust = {}    \n",
    "    _empirical_model = {}\n",
    "\n",
    "def get_adjust_lapstatus(carno, lapstatus, force = True):\n",
    "    \"\"\"\n",
    "    init the lapstatus for each car, save it for future reference\n",
    "    \n",
    "    input:\n",
    "        carno;\n",
    "        lapstatus  ; the trueth\n",
    "    \n",
    "    \"\"\"\n",
    "    if carno not in _lap_adjust:\n",
    "        #adjust it\n",
    "        lapadjust = lapstatus.copy()\n",
    "        for pos in range(0, len(lapstatus)):\n",
    "            if lapadjust[pos] == 1:\n",
    "\n",
    "                success = False\n",
    "\n",
    "                while(not success):\n",
    "                    # adjust this pit lap position\n",
    "                    pos_adjust = get_random_choice(_adjust_model)\n",
    "\n",
    "                    new_pos = pos + pos_adjust\n",
    "\n",
    "                    if new_pos >= 0 and new_pos < len(lapstatus):\n",
    "                        #valid\n",
    "                        lapadjust[pos] = 0\n",
    "                        lapadjust[new_pos] = 1\n",
    "                        success = True\n",
    "                        \n",
    "                        #add statistics\n",
    "                        if pos_adjust not in _empirical_model:\n",
    "                            _empirical_model[pos_adjust] = 1\n",
    "                        else:\n",
    "                            _empirical_model[pos_adjust] += 1\n",
    "\n",
    "                    if force==False:\n",
    "                        break\n",
    "\n",
    "        _lap_adjust[carno] = lapadjust\n",
    "\n",
    "    return _lap_adjust[carno]\n",
    "        \n",
    "        \n",
    "def build_random_model(modeldict):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        modeldict ; {val: probability}\n",
    "    return:\n",
    "        model  ;  [val, cdf]\n",
    "    \"\"\"\n",
    "    # val, cdf\n",
    "    cdf = 0\n",
    "    model = np.zeros((len(modeldict), 2))\n",
    "    for idx, val in enumerate(sorted(modeldict.keys())):\n",
    "        model[idx, 0] = val\n",
    "        model[idx, 1] = cdf + modeldict[val]\n",
    "        cdf = model[idx, 1]\n",
    "        \n",
    "    #normalize\n",
    "    model[:, 1] = model[:, 1]/cdf\n",
    "    return model\n",
    "    \n",
    "def print_model(model, iscdf=True):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        model  ;  [val, cdf]\n",
    "    \"\"\"\n",
    "    sorted_model = model[np.argsort(model[:, 0])]\n",
    "    cdf = 0\n",
    "    \n",
    "    sumval = 1.\n",
    "    if not iscdf:\n",
    "        sumval = np.sum(sorted_model[:,1])\n",
    "    \n",
    "    ret = []\n",
    "    for row in sorted_model:\n",
    "        ret.append((row[0], (row[1]-cdf)/sumval))\n",
    "        if iscdf:\n",
    "            cdf = row[1]\n",
    "    #output\n",
    "    print(['%d:%.3f'%(x[0],x[1]) for x in ret])\n",
    "    \n",
    "    \n",
    "def get_random_choice(model):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        model  ;  [val, cdf]\n",
    "    return:\n",
    "        val according to its probability\n",
    "    \"\"\"\n",
    "    \n",
    "    target = np.random.rand()\n",
    "    idx = np.sum(model[:,1] < target)\n",
    "    return int(model[idx,0])\n",
    "    \n",
    "#_modeldict={-2:0.1,-1:0.2,0:0.4, 1:0.2, 2:0.1 }\n",
    "_modeldict={-2:0.1,-1:0.2,0:0.05, 1:0.2, 2:0.1 }\n",
    "_adjust_model = build_random_model(_modeldict)\n",
    "\n",
    "def adjust_pit_model(lap_rec, prediction_length, force=True):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        tailpos ; <0 end pos of 1\n",
    "    return the predicted lap status\n",
    "    \"\"\"\n",
    "    #laps remain, fill into the future\n",
    "    lapadjust = lap_rec[-prediction_length:].copy()\n",
    "    for pos in range(0, prediction_length):\n",
    "        if lapadjust[pos] == 1:\n",
    "            \n",
    "            success = False\n",
    "            \n",
    "            while(not success):\n",
    "                # adjust this pit lap position\n",
    "                pos_adjust = get_random_choice(_adjust_model)\n",
    "\n",
    "                new_pos = pos + pos_adjust\n",
    "\n",
    "                if new_pos >= 0 and new_pos < prediction_length:\n",
    "                    #valid\n",
    "                    lapadjust[pos] = 0\n",
    "                    lapadjust[new_pos] = 1\n",
    "                    success = True\n",
    "                    \n",
    "                if force==False:\n",
    "                    break\n",
    "                    \n",
    "    return lapadjust\n",
    "\n",
    "def adjust_pit_model_fix(lap_rec, endpos, prediction_length):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        tailpos ; <0 end pos of 1\n",
    "    return the predicted lap status\n",
    "    \"\"\"\n",
    "    adjust_model = [-1,0,1]\n",
    "    lap_adjust = random.choice(adjust_model)\n",
    "        \n",
    "    #laps remain, fill into the future\n",
    "    lapadjust = lap_rec[-prediction_length:].copy()\n",
    "    for pos in range(0, prediction_length):\n",
    "        if lapadjust[pos] == 1:\n",
    "            # adjust this pit lap position\n",
    "            pos_adjust = random.choice(adjust_model)\n",
    "\n",
    "            if pos_adjust == -1:\n",
    "                if (pos - 1 >= 0):\n",
    "                    lapadjust[pos] = 0\n",
    "                    lapadjust[pos - 1] = 1\n",
    "            elif pos_adjust == 1:\n",
    "                if (pos + 1 < prediction_length):\n",
    "                    lapadjust[pos] = 0\n",
    "                    lapadjust[pos + 1] = 1\n",
    "\n",
    "    return lapadjust\n",
    "    \n",
    "# pit model is separate for each car\n",
    "def get_pit_model(cuation_laps_instint, laps_instint, prediction_length):\n",
    "    \"\"\"\n",
    "    return the predicted pit status\n",
    "    \"\"\"\n",
    "    # this is the perfect empirical pit model for Indy500 2018\n",
    "    pit_model_all = [[33, 32, 35, 32, 35, 34, 35, 34, 37, 32, 37, 30, 33, 36, 35, 33, 36, 30, 31, 33, 36, 37, 35, 34, 34, 33, 37, 35, 39, 32, 36, 35, 34, 32, 36, 32, 31, 36, 33, 33, 35, 37, 40, 32, 32, 34, 35, 36, 33, 37, 35, 37, 34, 35, 39, 32, 31, 37, 32, 35, 36, 39, 35, 36, 34, 35, 33, 33, 34, 32, 33, 34],\n",
    "                [45, 44, 46, 44, 43, 46, 45, 43, 41, 48, 46, 43, 47, 45, 49, 44, 48, 42, 44, 46, 45, 45, 43, 44, 44, 43, 46]]\n",
    "    pit_model_top8 = [[33, 32, 35, 33, 36, 33, 36, 33, 37, 35, 36, 33, 37, 34],\n",
    "                 [46, 45, 43, 48, 46, 45, 45, 43]]\n",
    "    \n",
    "    pit_model = pit_model_all\n",
    "    \n",
    "    if cuation_laps_instint>10:\n",
    "        #use low model\n",
    "        pred_pit_laps = random.choice(pit_model[0])\n",
    "    else:\n",
    "        pred_pit_laps = random.choice(pit_model[1])\n",
    "                \n",
    "    #laps remain, fill into the future\n",
    "    pitpred = np.array([0 for x in range(prediction_length)])\n",
    "    \n",
    "    if (pred_pit_laps > laps_instint) and (pred_pit_laps <= laps_instint + prediction_length):\n",
    "        pitpred[pred_pit_laps - laps_instint - 1] = 1\n",
    "         \n",
    "    return pitpred    \n",
    "    \n",
    "#dynamical/static feature configure\n",
    "#FEATURE_CARID = 1\n",
    "FEATURE_STATUS = 2\n",
    "FEATURE_PITAGE = 4\n",
    "\n",
    "def make_dataset_byevent(runs, prediction_length, freq, \n",
    "                       useeid = False,\n",
    "                       run_ts= COL_LAPTIME, \n",
    "                       test_event = 'Indy500-2018',\n",
    "                       test_cars = [],  \n",
    "                       use_global_dict = True,\n",
    "                       oracle_mode = MODE_ORACLE,\n",
    "                       feature_mode = FEATURE_STATUS,\n",
    "                       half_moving_win = 0,\n",
    "                       train_ratio=0.8,\n",
    "                       context_ratio = 0.,\n",
    "                       verbose = False\n",
    "                ):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    input:\n",
    "        oracle_mode: false to simulate prediction in real by \n",
    "                set the covariates of track and lap status as nan in the testset\n",
    "        half_moving_win  ; extend to 0:-1 ,1:-1/2plen, 2:-plen\n",
    "    \n",
    "    \"\"\"    \n",
    "    #force \n",
    "    #run_ts = _run_ts\n",
    "    #test_event = _test_event\n",
    "    \n",
    "    \n",
    "    init_track_model()\n",
    "    init_adjust_track_model()\n",
    "    \n",
    "    start = pd.Timestamp(\"01-01-2019\", freq=freq)  # can be different for each time series\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #select run\n",
    "    if runs>=0:\n",
    "        _laptime_data = [laptime_data[runs].copy()]\n",
    "    else:\n",
    "        _laptime_data = laptime_data.copy()\n",
    "    \n",
    "   \n",
    "    #add statistics for adjust test\n",
    "    # trackstatus, lapstatus\n",
    "    mae = [0,0]\n",
    "    \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        if events[_data[0]] == test_event:\n",
    "            test_mode = True\n",
    "        \n",
    "        else:\n",
    "            test_mode = False\n",
    "            #jump out\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        max_len = int(np.max(ts_len))\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        \n",
    "        if context_ratio != 0.:\n",
    "            # add this part to train set\n",
    "            context_len = int(np.max(ts_len) * context_ratio)\n",
    "        else:    \n",
    "            context_len = prediction_length*2\n",
    "        if context_len < 10:\n",
    "            context_len = 10\n",
    "            \n",
    "        if verbose:\n",
    "            #print(f'====event:{events[_data[0]]}, train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)}')\n",
    "            print(f'====event:{events[_data[0]]}, prediction_len={prediction_length},train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)},context_len={context_len}')\n",
    "                \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            rec_raw = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                if verbose:\n",
    "                    print(f'a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                continue                \n",
    "            \n",
    "            if use_global_dict:\n",
    "                carno = _data[1][rowid]\n",
    "                carid = global_carids[_data[1][rowid]]\n",
    "            else:\n",
    "                #simulation dataset, todo, fix the carids as decoder\n",
    "                carno = rowid\n",
    "                carid = rowid\n",
    "                \n",
    "            \n",
    "            if useeid:\n",
    "                static_cat = [carid, _data[0]]    \n",
    "            else:\n",
    "                static_cat = [carid]    \n",
    "                \n",
    "            \n",
    "            # adjust for disturbance analysis\n",
    "            if test_mode and test_flag(oracle_mode, MODE_DISTURB_ADJUSTPIT):\n",
    "                lap_status = rec[COL_LAPSTATUS, :].copy()\n",
    "                rec[COL_LAPSTATUS, :] = get_adjust_lapstatus(carno, lap_status)\n",
    "                \n",
    "            # selection of features\n",
    "            if test_flag(oracle_mode, MODE_NOTRACK) or test_flag(oracle_mode, MODE_ORACLE_LAPONLY):                \n",
    "                rec[COL_TRACKSTATUS, :] = 0\n",
    "            if test_flag(oracle_mode, MODE_NOLAP) or test_flag(oracle_mode, MODE_ORACLE_TRACKONLY):                \n",
    "                rec[COL_LAPSTATUS, :] = 0\n",
    "\n",
    "            test_rec_cnt = 0\n",
    "            if not test_mode:\n",
    "                \n",
    "                # all go to train set\n",
    "                _train.append({'target': rec[run_ts,:].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [rec[COL_TRACKSTATUS,:],\n",
    "                                       rec[COL_LAPSTATUS,:]]\n",
    "                              }\n",
    "                              )\n",
    "            else:\n",
    "                # reset train_len\n",
    "                #context_len = prediction_length*2\n",
    "                #if context_len < 10:\n",
    "                #    context_len = 10\n",
    "                #context_len = train_len\n",
    "                \n",
    "                # multiple test ts(rolling window as half of the prediction_length)\n",
    "\n",
    "                #step = -int(prediction_length/2) if half_moving_win else -prediction_length\n",
    "                if half_moving_win == 1:\n",
    "                    step = -int(prediction_length/2)\n",
    "                elif half_moving_win == 2:\n",
    "                    step = -prediction_length\n",
    "                else:\n",
    "                    step = -1\n",
    "                \n",
    "                #bug fix, fixed the split point for all cars/ts\n",
    "                for endpos in range(max_len, context_len+prediction_length, \n",
    "                                    step):\n",
    "\n",
    "                    #check if enough for this ts\n",
    "                    if endpos > totallen:\n",
    "                        continue\n",
    "                    \n",
    "                    track_rec = rec[COL_TRACKSTATUS, :endpos].copy()\n",
    "                    lap_rec = rec[COL_LAPSTATUS, :endpos].copy()\n",
    "                    pitage_rec = rec[COL_LAPS_INSTINT, :endpos].copy()\n",
    "                    \n",
    "                    caution_laps_instint = int(rec[COL_CAUTION_LAPS_INSTINT, endpos -prediction_length - 1])\n",
    "                    laps_instint = int(rec[COL_LAPS_INSTINT, endpos -prediction_length - 1])\n",
    "                    \n",
    "\n",
    "                    # test mode\n",
    "                    if test_flag(oracle_mode, MODE_TESTCURTRACK):\n",
    "                        # since nan does not work, use cur-val instead\n",
    "                        track_rec[-prediction_length:] = track_rec[-prediction_length - 1]\n",
    "                        #track_rec[-prediction_length:] = random.randint(0,1)\n",
    "                        #lap_rec[-prediction_length:] = lap_rec[-prediction_length - 1]\n",
    "                        lap_rec[-prediction_length:] = 0\n",
    "                        \n",
    "                        #for pitage, just assume there is no pit\n",
    "                        start_pitage = pitage_rec[-prediction_length - 1]\n",
    "                        pitage_rec[-prediction_length:] = np.array([x+start_pitage+1 for x in range(prediction_length)])\n",
    "                        \n",
    "                        \n",
    "                    elif test_flag(oracle_mode, MODE_TESTZERO):\n",
    "                        #set prediction part as nan\n",
    "                        #track_rec[-prediction_length:] = np.nan\n",
    "                        #lap_rec[-prediction_length:] = np.nan\n",
    "                        track_rec[-prediction_length:] = 0\n",
    "                        lap_rec[-prediction_length:] = 0        \n",
    "\n",
    "                        #for pitage, just assume there is no pit\n",
    "                        start_pitage = pitage_rec[-prediction_length - 1]\n",
    "                        pitage_rec[-prediction_length:] = np.array([x+start_pitage+1 for x in range(prediction_length)])\n",
    "                        \n",
    "                    # predicting with status model\n",
    "                    if test_flag(oracle_mode, MODE_PREDTRACK):\n",
    "                        predrec = get_track_model(track_rec, endpos, prediction_length)\n",
    "                        track_rec[-prediction_length:] = predrec\n",
    "                        #lap_rec[-prediction_length:] = 0\n",
    "                        \n",
    "                    if test_flag(oracle_mode, MODE_PREDPIT):\n",
    "                        #predrec = get_track_model(track_rec, endpos, prediction_length)\n",
    "                        #track_rec[-prediction_length:] = predrec\n",
    "                        lap_rec[-prediction_length:] = get_pit_model(caution_laps_instint,\n",
    "                                                                    laps_instint,prediction_length)\n",
    "                        \n",
    "                        \n",
    "                        #for pitage, use the predicted lap info to update pitage\n",
    "                        start_pitage = pitage_rec[-prediction_length - 1]\n",
    "                        for pos in range(prediction_length):\n",
    "                            if lap_rec[-prediction_length + pos]==0:\n",
    "                                pitage_rec[-prediction_length + pos] = start_pitage+1\n",
    "                            else:\n",
    "                                #new pit\n",
    "                                start_pitage = 0\n",
    "                                pitage_rec[-prediction_length + pos] = start_pitage\n",
    "                        \n",
    "                    # disturbe analysis\n",
    "                    if test_flag(oracle_mode, MODE_DISTURB_CLEARTRACK):\n",
    "                        # clear the oracle track status\n",
    "                        # future 1s in trackstatus\n",
    "                        # pattern like 0 1 xx\n",
    "                        for _pos in range(-prediction_length + 1, -1):\n",
    "                            if track_rec[_pos - 1] == 0:\n",
    "                                track_rec[_pos] = 0\n",
    "                                \n",
    "                    if test_flag(oracle_mode, MODE_DISTURB_ADJUSTTRACK):\n",
    "                        # adjust the end position of track, or caution lap length\n",
    "                        # find the end of caution laps\n",
    "                        _tail = 0\n",
    "                        for _pos in range(-1,-prediction_length + 1,-1):\n",
    "                            if track_rec[_pos] == 1:\n",
    "                                #find the tail\n",
    "                                _tail = _pos\n",
    "                                break\n",
    "                        if _tail != 0:\n",
    "                            #found\n",
    "                            adjustrec = adjust_track_model(track_rec, endpos, prediction_length, _tail)\n",
    "                            track_rec[-prediction_length:] = adjustrec\n",
    "                        \n",
    "                    #if test_flag(oracle_mode, MODE_DISTURB_ADJUSTPIT):\n",
    "                    #    # adjust the position of pit\n",
    "                    #    if np.sum(lap_rec[-prediction_length:]) > 0:\n",
    "                    #        adjustrec = adjust_pit_model(lap_rec, endpos, prediction_length)\n",
    "                    #        lap_rec[-prediction_length:] = adjustrec\n",
    "                        \n",
    "                    #okay, end of adjustments, test difference here\n",
    "                    # rec_raw .vs. track_rec, lap_rec\n",
    "                    track_rec_raw = rec_raw[COL_TRACKSTATUS, :endpos]\n",
    "                    lap_rec_raw = rec_raw[COL_LAPSTATUS, :endpos]\n",
    "                    \n",
    "                    mae[0] = mae[0] + np.nansum(np.abs(track_rec[-prediction_length:] - track_rec_raw[-prediction_length:]))\n",
    "                    mae[1] = mae[1] + np.nansum(np.abs(lap_rec[-prediction_length:] - lap_rec_raw[-prediction_length:]))\n",
    "\n",
    "                    if feature_mode == FEATURE_STATUS:\n",
    "                        _test.append({'target': rec[run_ts,:endpos].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [track_rec,lap_rec]\n",
    "                                 }\n",
    "                              )   \n",
    "                    elif feature_mode == FEATURE_PITAGE:\n",
    "                        _test.append({'target': rec[run_ts,:endpos].astype(np.float32), \n",
    "                                    'start': start, \n",
    "                                    'feat_static_cat': static_cat,\n",
    "                                    'feat_dynamic_real': [track_rec,lap_rec,pitage_rec]\n",
    "                                     }\n",
    "                                  )   \n",
    "                    \n",
    "                    test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            if verbose:\n",
    "                print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'train len:{len(train_set)}, test len:{len(test_set)}, mae_track:{mae[0]},mae_lap:{mae[1]},')\n",
    "    \n",
    "    train_ds = ListDataset(train_set, freq=freq)\n",
    "    test_ds = ListDataset(test_set, freq=freq)    \n",
    "    \n",
    "    return train_ds, test_ds, train_set, test_set\n",
    "\n",
    "def save_dataset(datafile,freq, prediction_length, cardinality, train_ds, test_ds):\n",
    "    with open(datafile, 'wb') as f:\n",
    "        #pack [global_carids, laptime_data]\n",
    "        savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "        #savedata = [freq, train_set, test_set]\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for Indy500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_ds,predictor):\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor=predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    return tss, forecasts\n",
    "\n",
    "   \n",
    "def run_prediction_ex(test_ds, prediction_length, model_name,trainid):\n",
    "    with mx.Context(mx.gpu(7)):    \n",
    "        pred_ret = []\n",
    "\n",
    "        rootdir = f'../models/remote/{_dataset_id}/{_task_id}-{trainid}/'\n",
    "        # deepAR-Oracle\n",
    "        if model_name == 'curtrack':\n",
    "            model=f'deepAR-Oracle-{_task_id}-curtrack-indy-f1min-t{prediction_length}-e1000-r1_curtrack_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        elif model_name == 'zerotrack':\n",
    "            model=f'deepAR-Oracle-{_task_id}-nolap-zerotrack-indy-f1min-t{prediction_length}-e1000-r1_zerotrack_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "            \n",
    "        # deepAR-Oracle\n",
    "        elif model_name == 'oracle':\n",
    "            model=f'deepAR-Oracle-{_task_id}-all-indy-f1min-t{prediction_length}-e1000-r1_oracle_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "        # deepAR-Oracle\n",
    "        elif model_name == 'oracle-laponly':\n",
    "            model=f'deepAR-Oracle-{_task_id}-all-indy-f1min-t{prediction_length}-e1000-r1_oracle-laponly_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "        # deepAR-Oracle\n",
    "        elif model_name == 'oracle-trackonly':\n",
    "            model=f'deepAR-Oracle-{_task_id}-all-indy-f1min-t{prediction_length}-e1000-r1_oracle-trackonly_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "        # deepAR\n",
    "        elif model_name == 'deepAR':\n",
    "            model=f'deepAR-{_task_id}-all-indy-f1min-t{prediction_length}-e1000-r1_deepar_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        # naive\n",
    "        elif model_name == 'naive':\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  NaivePredictor(freq= freq, prediction_length = prediction_length)\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "        # zero, zero keeps the rank unchange\n",
    "        elif model_name == 'zero':\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  ZeroPredictor(freq= freq, prediction_length = prediction_length)\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        # arima\n",
    "        elif model_name == 'arima':\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  RForecastPredictor(method_name='arima',freq= freq, \n",
    "                                            prediction_length = prediction_length,trunc_length=60)\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "        else:\n",
    "            print(f'error: model {model_name} not support yet!')\n",
    "\n",
    "        return pred_ret     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc rank\n",
    "def eval_rank_bytimediff(test_ds,tss,forecasts,prediction_length):\n",
    "    \"\"\"\n",
    "    timediff models\n",
    "    \n",
    "    works for one event only\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        #forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        \n",
    "        timediff_array = tss[idx].values.copy()\n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        forecasts_et[completed_laps][carno] = [timediff_array[-prediction_len:].copy(),\n",
    "                                                   forecast_laptime_mean.copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        time_diff = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            time_diff[0, carid, :] = forecasts_et[lap][carno][0].reshape((prediction_len))\n",
    "            time_diff[1, carid, :] = forecasts_et[lap][carno][1].reshape((prediction_len))\n",
    "\n",
    "        #calculate rank    \n",
    "        idx = np.argsort(time_diff[0], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        idx = np.argsort(time_diff[1], axis=0)\n",
    "        pred_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        rank_ret.append([lap, time_diff, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et\n",
    "    \n",
    "#calc rank\n",
    "def eval_rank_bylaptime(test_ds,tss,forecasts,prediction_length, start_offset):\n",
    "    \"\"\"\n",
    "    evaluate rank by laptime forecasting\n",
    "    \n",
    "    input:\n",
    "        test_ds       ; must be test set for a single event, because test_ds itself does not \n",
    "                        contain features to identify the eventid\n",
    "        start_offset[]; elapsed time for lap0, for one specific event\n",
    "        tss,forecasts ; forecast result\n",
    "        prediction_length ; \n",
    "    return:\n",
    "        rank_ret      ;  [lap, elapsed_time, true_rank, pred_rank] \n",
    "        forecasts_et  ;  {[completed_laps][carno]} ->(elapsed_time, elapsed_time_pred)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        #start_offset is global var\n",
    "        offset = start_offset[(start_offset['car_number']==carno)].elapsed_time.values[0] \n",
    "        #print('start_offset:', offset)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        #forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "\n",
    "        laptime_array = tss[idx].values.copy()\n",
    "        elapsed_time = np.cumsum(laptime_array) + offset\n",
    "\n",
    "        laptime_array = tss[idx].values.copy()\n",
    "        laptime_array[-prediction_len:] = forecast_laptime_mean \n",
    "        elapsed_time_hat = np.cumsum(laptime_array) + offset\n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        #forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len-1:].copy(),\n",
    "        #                                           elapsed_time_hat[-prediction_len-1:].copy()]\n",
    "        forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len:].copy(),\n",
    "                                                   elapsed_time_hat[-prediction_len:].copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        #elapsed_time = np.zeros((2, len(carlist), prediction_len+1))\n",
    "        elapsed_time = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            elapsed_time[0, carid, :] = forecasts_et[lap][carno][0]\n",
    "            elapsed_time[1, carid, :] = forecasts_et[lap][carno][1]\n",
    "\n",
    "        #calculate rank    \n",
    "        idx = np.argsort(elapsed_time[0], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        idx = np.argsort(elapsed_time[1], axis=0)\n",
    "        pred_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        rank_ret.append([lap, elapsed_time, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et\n",
    "   \n",
    "def eval_laptime(test_ds,tss,forecasts,prediction_length, start_offset):\n",
    "    \"\"\"\n",
    "    evaluate rank by laptime forecasting\n",
    "    \n",
    "    input:\n",
    "        test_ds       ; must be test set for a single event, because test_ds itself does not \n",
    "                        contain features to identify the eventid\n",
    "        start_offset[]; elapsed time for lap0, for one specific event\n",
    "        tss,forecasts ; forecast result\n",
    "        prediction_length ; \n",
    "    return:\n",
    "        rank_ret      ;  [lap, elapsed_time, true_rank, pred_rank] \n",
    "        forecasts_et  ;  {[completed_laps][carno]} ->(elapsed_time, elapsed_time_pred)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        #start_offset is global var\n",
    "        #offset = start_offset[(start_offset['car_number']==carno)].elapsed_time.values[0] \n",
    "        #print('start_offset:', offset)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        #forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "\n",
    "        laptime_array = tss[idx].values.copy()\n",
    "        #elapsed_time = np.cumsum(laptime_array) + offset\n",
    "\n",
    "        laptime_array_hat = tss[idx].values.copy()\n",
    "        laptime_array_hat[-prediction_len:] = forecast_laptime_mean \n",
    "        #elapsed_time_hat = np.cumsum(laptime_array) + offset\n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        #forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len-1:].copy(),\n",
    "        #                                           elapsed_time_hat[-prediction_len-1:].copy()]\n",
    "        forecasts_et[completed_laps][carno] = [laptime_array[-prediction_len:].copy(),\n",
    "                                                   laptime_array_hat[-prediction_len:].copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        #elapsed_time = np.zeros((2, len(carlist), prediction_len+1))\n",
    "        lap_time = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            lap_time[0, carid, :] = forecasts_et[lap][carno][0].reshape((prediction_len))\n",
    "            lap_time[1, carid, :] = forecasts_et[lap][carno][1].reshape((prediction_len))\n",
    "\n",
    "        #calculate rank    \n",
    "        #idx = np.argsort(elapsed_time[0], axis=0)\n",
    "        #true_rank = np.argsort(idx, axis=0)\n",
    "        true_laptime = lap_time[0]\n",
    "\n",
    "        #idx = np.argsort(elapsed_time[1], axis=0)\n",
    "        #pred_rank = np.argsort(idx, axis=0)\n",
    "        pred_laptime = lap_time[1]\n",
    "\n",
    "        rank_ret.append([lap, lap_time, true_laptime, pred_laptime])\n",
    "        \n",
    "    return rank_ret,forecasts_et    \n",
    "\n",
    "#calc rank\n",
    "def eval_rank(test_ds,tss,forecasts,prediction_length, start_offset):\n",
    "    \"\"\"\n",
    "    evaluate rank by laptime forecasting\n",
    "    \n",
    "    input:\n",
    "        test_ds       ; must be test set for a single event, because test_ds itself does not \n",
    "                        contain features to identify the eventid\n",
    "        start_offset[]; elapsed time for lap0, for one specific event\n",
    "        tss,forecasts ; forecast result\n",
    "        prediction_length ; \n",
    "    return:\n",
    "        rank_ret      ;  [lap, elapsed_time, true_rank, pred_rank] \n",
    "        forecasts_et  ;  {[completed_laps][carno]} ->(elapsed_time, elapsed_time_pred)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        #start_offset is global var\n",
    "        if isinstance(start_offset, pd.core.frame.DataFrame):\n",
    "            offset = start_offset[(start_offset['car_number']==carno)].elapsed_time.values[0] \n",
    "        \n",
    "            \n",
    "        #print('start_offset:', offset)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        #forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "\n",
    "        if isinstance(start_offset, pd.core.frame.DataFrame):\n",
    "            #print('eval_rank:laptime2rank')\n",
    "            laptime_array = tss[idx].values.copy()\n",
    "            elapsed_time = np.cumsum(laptime_array) + offset\n",
    "\n",
    "            laptime_array = tss[idx].values.copy()\n",
    "            laptime_array[-prediction_len:] = forecast_laptime_mean \n",
    "            elapsed_time_hat = np.cumsum(laptime_array) + offset\n",
    "        else:\n",
    "            #print('eval_rank:rank-direct')\n",
    "            # rank directly\n",
    "            elapsed_time  = tss[idx].values.copy()\n",
    "\n",
    "            elapsed_time_hat = tss[idx].values.copy()\n",
    "            elapsed_time_hat[-prediction_len:] = forecast_laptime_mean             \n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        #forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len-1:].copy(),\n",
    "        #                                           elapsed_time_hat[-prediction_len-1:].copy()]\n",
    "        forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len:].copy(),\n",
    "                                                   elapsed_time_hat[-prediction_len:].copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        #elapsed_time = np.zeros((2, len(carlist), prediction_len+1))\n",
    "        elapsed_time = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            elapsed_time[0, carid, :] = forecasts_et[lap][carno][0].reshape((prediction_len))\n",
    "            elapsed_time[1, carid, :] = forecasts_et[lap][carno][1].reshape((prediction_len))\n",
    "\n",
    "        #calculate rank    \n",
    "        idx = np.argsort(elapsed_time[0], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        idx = np.argsort(elapsed_time[1], axis=0)\n",
    "        pred_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        rank_ret.append([lap, elapsed_time, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et    \n",
    "    \n",
    "def get_acc(rank_ret,prediction_length, verbose = False):   \n",
    "    \"\"\"\n",
    "    input:\n",
    "        rank_ret: [lap, elapsed_time, true_rank, pred_rank], use [2][3] columns\n",
    "    return:\n",
    "        ((metrics...)\n",
    "         (record count...))\n",
    "         \n",
    "    the result can be used to calculate micro/macro metrics\n",
    "    \"\"\"\n",
    "    # evaluate\n",
    "    #top1 accuracy\n",
    "    top1acc = 0\n",
    "    top1acc_farmost = 0\n",
    "    top5acc = 0\n",
    "    top5acc_farmost = 0\n",
    "    tau = 0\n",
    "    rmse = 0.\n",
    "    \n",
    "    for rec in rank_ret:\n",
    "        trueRank = rec[2]\n",
    "        predRank = rec[3]\n",
    "\n",
    "        #top1 , rank = 0, first col is not prediction\n",
    "        top1acc += np.sum((trueRank==0) & (predRank==0)) \n",
    "        \n",
    "        top1acc_farmost += np.sum((trueRank[:,-1]==0) & (predRank[:,-1]==0))\n",
    "        \n",
    "        #top5\n",
    "        top5acc += np.sum((trueRank<5) & (predRank<5)) \n",
    "        \n",
    "        top5acc_farmost += np.sum((trueRank[:,-1]<5) & (predRank[:,-1]<5))\n",
    "        \n",
    "        # tau\n",
    "        tao, _ = stats.kendalltau(trueRank, predRank)\n",
    "        tau += tao\n",
    "        \n",
    "        #rmse\n",
    "        rmse += mean_squared_error(predRank,trueRank)\n",
    "        \n",
    "    recnt = len(rank_ret)\n",
    "    if recnt > 0:\n",
    "        top1acc = top1acc *1.0/ (recnt*prediction_length)\n",
    "        top1acc_farmost = top1acc_farmost *1.0/ recnt\n",
    "        top5acc = top5acc *1.0/ (5*recnt*prediction_length)\n",
    "        top5acc_farmost = top5acc_farmost *1.0/ (5*recnt)\n",
    "        tau = tau/recnt\n",
    "        rmse = rmse/recnt\n",
    "\n",
    "        if verbose:\n",
    "            print(f'total:{len(rank_ret)}, prediction_length:{prediction_length}') \n",
    "            print('top1acc=', top1acc,\n",
    "                  'top1acc_farmost=', top1acc_farmost,\n",
    "                  'top5acc=', top5acc,\n",
    "                  'top5acc_farmost=', top5acc_farmost,\n",
    "                 )\n",
    "            print('tau = ', tau,\n",
    "                 'rmse = ', rmse)\n",
    "    \n",
    "    return ((top1acc,top1acc_farmost,top5acc,top5acc_farmost,tau,rmse),\n",
    "            (recnt*prediction_length,recnt,5*recnt*prediction_length,5*recnt,recnt,recnt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_cars = [], \n",
    "                   datamode = MODE_ORACLE,models = ['oracle']):\n",
    "    \"\"\"\n",
    "    dependency: test_event, test on one event only\n",
    "    \n",
    "    \"\"\"\n",
    "    retdf = []\n",
    "    pred_ret = {}\n",
    "    ds_ret = {}\n",
    "    rank_result = {}\n",
    "    \n",
    "    ### create test dataset\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[_test_event], prediction_length,freq, \n",
    "                                         oracle_mode=datamode,\n",
    "                                         run_ts = _run_ts,\n",
    "                                         test_event = _test_event,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    for model in models:\n",
    "        print('exp:',inspect.stack()[0][3],'model:', model, \n",
    "              'datamode:', get_modestr(datamode),'eval:', _exp_id )\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,\n",
    "                                           trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "\n",
    "        \n",
    "        if _exp_id=='rank': \n",
    "            #rank prediction\n",
    "            rank_ret, forecast_ret = eval_rank(test_ds,tss,forecasts,prediction_length,\n",
    "                                               0)\n",
    "        elif _exp_id=='laptime2rank':\n",
    "            rank_ret, forecast_ret = eval_rank(test_ds,tss,forecasts,prediction_length,\n",
    "                                               global_start_offset[_test_event])\n",
    "        elif _exp_id=='laptime':\n",
    "            #laptime instead\n",
    "            rank_ret, forecast_ret = eval_laptime(test_ds,tss,forecasts,prediction_length,\n",
    "                                                  global_start_offset[_test_event])\n",
    "        else:\n",
    "            print(f'Error, {_exp_id} evaluation not support yet')\n",
    "            break\n",
    "        \n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,get_modestr(datamode),trainid]\n",
    "        ret.extend(metrics[0])\n",
    "        retdf.append(ret)\n",
    "        \n",
    "        rank_result[model] = (rank_ret,forecast_ret)\n",
    "    \n",
    "    return pred_ret, ds_ret, rank_result, retdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(runs, plens, half, trainids, train_ratio, testfunc, datamode='', models=[]):\n",
    "    \"\"\"\n",
    "    \n",
    "    input:\n",
    "        plens=[2,5,10]\n",
    "        half=[False]\n",
    "        #trainids = [\"indy500-r0.2\",\"indy500-r0.4\",\"indy500\"]\n",
    "        trainids = [\"r0.5\"]\n",
    "        #half=[True,False]\n",
    "        #plens=[2]\n",
    "        runs = 5\n",
    "        train_ratio=0.5 \n",
    "        exp_id='mean-splitbystage-predpit'\n",
    "        \n",
    "        testfunc ; run_exp_predpit, run_exp_predtrack, run_exp ...\n",
    "\n",
    "    return:\n",
    "    \n",
    "        dfret  ; average result of multiple runs\n",
    "                 dataframe['model' , 'prediction_length', 'halfmode','datamode','trainid',\n",
    "                         'top1acc','top1acc_farmost','top5acc','top5acc_farmost','tau','rmse',\n",
    "                         'top1acc_std','top1acc_farmost_std','top5acc_std','top5acc_farmost_std','tau_std','rmse_std']\n",
    "                          \n",
    "        alldata_ret  ; for debug\n",
    "            [runid][halfmode,plen,trainid] -> (pred_ret, test_ds, rank_ret)\n",
    "                pred_ret[model] ->　[tss, forecasts]\n",
    "                test_ds[model] ->　test_ds\n",
    "                rank_ret[model] -> ([lap, elapsed_time, true_rank, pred_rank],forecast_ret)\n",
    "                    forecast_ret[completed_laps][carno] -> (elapsed_time, elapsed_time_hat)\n",
    "    \n",
    "    \"\"\"\n",
    "    if plens == [] or half == [] or trainids == []:\n",
    "        print(\"error with empty settings\")\n",
    "        return\n",
    "    \n",
    "    #testfunc or (datamode & models)\n",
    "    if isinstance(testfunc,str) and (datamode == '' or models == []):\n",
    "        print(\"error with testfunc\")\n",
    "        return\n",
    "\n",
    "    allret = []\n",
    "    alldata_ret = []\n",
    "    for runid in range(runs):\n",
    "        exp_data = []\n",
    "        exp_result = []\n",
    "\n",
    "        for halfmode in half:\n",
    "            for plen in plens:\n",
    "                for trainid in trainids:\n",
    "                    print('='*10)\n",
    "                    if not isinstance(testfunc,str):\n",
    "                        pred_ret, test_ds, rank_ret, metric_ret = testfunc(plen, halfmode, \n",
    "                                                            train_ratio=train_ratio,\n",
    "                                                            trainid=trainid)\n",
    "                    else:\n",
    "                        pred_ret, test_ds, rank_ret, metric_ret = run_exp(plen, halfmode, \n",
    "                                                            train_ratio=train_ratio,\n",
    "                                                            trainid=trainid, \n",
    "                                                            datamode=datamode,\n",
    "                                                            models=models)\n",
    "                        \n",
    "\n",
    "                    #save \n",
    "                    exp_data.append((pred_ret, test_ds, rank_ret))\n",
    "                    exp_result.extend(metric_ret)\n",
    "\n",
    "        #save result\n",
    "        result = pd.DataFrame(exp_result, columns = ['model' , 'prediction_length', 'halfmode',\n",
    "                                           'datamode','trainid',\n",
    "                                           'top1acc','top1acc_farmost','top5acc',\n",
    "                                           'top5acc_farmost','tau','rmse'])\n",
    "\n",
    "        #result['runid'] = [runid for x in range(len(result))]\n",
    "        allret.append(result)\n",
    "        alldata_ret.append(exp_data)\n",
    "\n",
    "    #final\n",
    "    rowcnt = len(allret[0])\n",
    "    metrics = np.empty((runs, rowcnt, 6))\n",
    "    for runid, ret in enumerate(allret):\n",
    "        metrics[runid, :,:] = ret[['top1acc','top1acc_farmost','top5acc',\n",
    "                                           'top5acc_farmost','tau','rmse']].values\n",
    "\n",
    "\n",
    "    #average\n",
    "    averagemat = np.mean(metrics[:,:,:], axis=0)\n",
    "    stdmat = np.std(metrics[:,:,:], axis=0)\n",
    "    dfhead = allret[0][['model' , 'prediction_length', 'halfmode', 'datamode','trainid']]\n",
    "    \n",
    "    \n",
    "    dfaverage = pd.DataFrame(averagemat, columns = ['top1acc','top1acc_farmost','top5acc',\n",
    "                                       'top5acc_farmost','tau','rmse'])\n",
    "    dfstd = pd.DataFrame(stdmat, columns = ['top1acc_std','top1acc_farmost_std','top5acc_std',\n",
    "                                       'top5acc_farmost_std','tau_std','rmse_std'])\n",
    "    dfret = pd.concat([dfhead, dfaverage, dfstd], axis=1)\n",
    "\n",
    "    #if exp_id != '':\n",
    "    #    dfret.to_csv(f'laptime2rank-evaluate-indy500-{exp_id}-result.csv', float_format='%.3f')\n",
    "\n",
    "    return dfret, alldata_ret\n",
    "\n",
    "\n",
    "def checkret_status(dataret, runid = 0, idx = 0,model='oracle'):\n",
    "    \"\"\"\n",
    "    check the test_ds track and lap status\n",
    "    \n",
    "        alldata_ret  ; for debug\n",
    "            [runid][halfmode,plen,trainid] -> (pred_ret, test_ds, rank_ret)\n",
    "                pred_ret[model] ->　[tss, forecasts]\n",
    "                test_ds[model] ->　test_ds\n",
    "                rank_ret[model] -> ([lap, elapsed_time, true_rank, pred_rank],forecast_ret)\n",
    "                    forecast_ret[completed_laps][carno] -> (elapsed_time, elapsed_time_hat)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    _, plen = dataret[runid][idx][0][model][1][0].samples.shape\n",
    "    test_ds = dataret[runid][idx][1][model]\n",
    "   \n",
    "    \n",
    "    ds_iter =  iter(test_ds)\n",
    "    yfcnt = 0\n",
    "    pitcnt = 0\n",
    "    for recid in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        \n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        \n",
    "        track_rec,lap_rec = test_rec['feat_dynamic_real']\n",
    "        yfcnt += np.sum(track_rec[-plen:])\n",
    "        pitcnt += np.sum(lap_rec[-plen:])\n",
    "        \n",
    "    print('yfcnt:', yfcnt, 'pitcnt:',pitcnt)\n",
    "\n",
    "\n",
    "def get_ref_oracle_testds(plens, halfs, train_ratio=0.8, \n",
    "                   test_cars = []):           \n",
    "    \n",
    "    testset = {}\n",
    "    for prediction_length in plens:\n",
    "        for half_moving_win in halfs:\n",
    "            train_ds, test_ds,_,_ = make_dataset_byevent(events_id[_test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_ORACLE,\n",
    "                                         run_ts = _run_ts,\n",
    "                                         test_event = _test_event,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)    \n",
    "            \n",
    "            # get key\n",
    "            key = '%d-%d'%(prediction_length,half_moving_win)\n",
    "            testset[key] = test_ds\n",
    "            \n",
    "    return testset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def checkret_confusionmat(dataret, ref_testset, runid= 0, testid = '', model='oracle'):\n",
    "    \"\"\"\n",
    "    output the 4x4 confusion matrix split by track and lap status\n",
    "    \n",
    "    input:\n",
    "        ref_oracle_testds  ; oracle test ds\n",
    "    \n",
    "    \"\"\"\n",
    "    plen_length = len(dataret[runid])\n",
    "    \n",
    "    dflist = []\n",
    "    for idx in range(plen_length):\n",
    "        _, plen = dataret[runid][idx][0][model][1][0].samples.shape\n",
    "        test_ds = dataret[runid][idx][1][model]\n",
    "        rank_ret = dataret[runid][idx][2][model][0]\n",
    "\n",
    "        key = '%d-%d'%(plen,0)\n",
    "        if key not in ref_testset:\n",
    "            print(f'error, {key} not found in ref_testset')\n",
    "            continue\n",
    "        \n",
    "        ref_oracle_testds = ref_testset[key]\n",
    "        if len(ref_oracle_testds) != len(test_ds):\n",
    "            print('error, size of testds mismatch', len(ref_oracle_testds), len(test_ds))\n",
    "            continue\n",
    "\n",
    "        # confusion matrix for <trackstatus, lapstatus> type: 00,01,10,11\n",
    "        # lap(start lap of prediction)  -> type\n",
    "        lapmap = {}\n",
    "        ds_iter =  iter(ref_oracle_testds)\n",
    "        for recid in range(len(ref_oracle_testds)):\n",
    "            test_rec = next(ds_iter) \n",
    "\n",
    "            carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "\n",
    "            track_rec,lap_rec = test_rec['feat_dynamic_real']\n",
    "            yfcnt = np.sum(track_rec[-plen:])\n",
    "            pitcnt = np.sum(lap_rec[-plen:])    \n",
    "\n",
    "            #laptype = ('0' if yfcnt==0 else '1') + ('0' if pitcnt==0 else '1')\n",
    "\n",
    "            lap = len(track_rec) - plen + 1\n",
    "            if lap not in lapmap:\n",
    "                #lapmap[lap] = laptype\n",
    "                lapmap[lap] = (yfcnt, pitcnt)\n",
    "            else:\n",
    "                oldtype = lapmap[lap]\n",
    "                lapmap[lap] = (yfcnt + oldtype[0], pitcnt + oldtype[1])\n",
    "\n",
    "\n",
    "        #split the rank_ret by laptype\n",
    "        types=['00','10','01','11']\n",
    "        acc_ret = []\n",
    "        for laptype in types:\n",
    "            check_ret = []\n",
    "            for item in rank_ret:\n",
    "                typecnt = lapmap[item[0]]\n",
    "\n",
    "                thetype = ('0' if typecnt[0]==0 else '1') + ('0' if typecnt[1]==0 else '1')\n",
    "\n",
    "                if thetype == laptype:\n",
    "                    check_ret.append(item)\n",
    "            # get acc\n",
    "            metrics = get_acc(check_ret,plen)\n",
    "            recret = [testid, plen, laptype, len(check_ret)]\n",
    "            recret.extend(metrics[0])\n",
    "            acc_ret.append(recret)\n",
    "\n",
    "        #add all test\n",
    "        metrics = get_acc(rank_ret,plen)\n",
    "        recret = [testid, plen, 'aa', len(rank_ret)]\n",
    "        recret.extend(metrics[0])\n",
    "        acc_ret.append(recret)\n",
    "        \n",
    "        _dfacc = pd.DataFrame(acc_ret, columns = ['testid','plen',\n",
    "                                'type','reccnt','top1acc','top1acc_farmost','top5acc',\n",
    "                                'top5acc_farmost','tau','rmse'])\n",
    "        \n",
    "        dflist.append(_dfacc)\n",
    "    \n",
    "    dfacc = pd.concat(dflist, axis=0)\n",
    "    \n",
    "    return dfacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_testds(datamode, test_cars=[]):\n",
    "    \"\"\"\n",
    "    report mae, etc\n",
    "    \"\"\"\n",
    "    for prediction_length in plens:\n",
    "        for half_moving_win in half:\n",
    "            train_ds, test_ds,_,_ = make_dataset_byevent(events_id[_test_event], prediction_length,freq, \n",
    "                                         oracle_mode=datamode,\n",
    "                                         run_ts = _run_ts,\n",
    "                                         test_event = _test_event,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "            \n",
    "def dotest(config):\n",
    "    acclist = []\n",
    "    dflist = []\n",
    "    for model in config.keys():\n",
    "        conf = config[model]\n",
    "        for teststr in conf.keys():\n",
    "            testfunc = teststr\n",
    "            datamode = conf[teststr]\n",
    "\n",
    "\n",
    "            df, dataret = run_test(runs, plens, half, trainids, \n",
    "                                   train_ratio, testfunc, datamode=datamode,models=[model])\n",
    "\n",
    "            #concat\n",
    "            acc = checkret_confusionmat(dataret, ref_testset, \n",
    "                                        testid = teststr, model=model)\n",
    "            dflist.append(df)\n",
    "            acclist.append(acc)\n",
    "\n",
    "    dfret = pd.concat(dflist, axis=0)\n",
    "    dfacc = pd.concat(acclist, axis=0)\n",
    "    return dfret, dfacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# configurataion\n",
    "#\n",
    "# model path:  <_dataset_id>/<_task_id>-<trainid>/\n",
    "_dataset_id = 'indy2013-2018-nocarid'\n",
    "#_dataset_id = 'indy2013-2018'\n",
    "_test_event = 'Indy500-2019'\n",
    "\n",
    "#_task_id = 'rank'  # rank,laptime, the trained model's task\n",
    "#_run_ts = COL_RANK   #COL_LAPTIME,COL_RANK\n",
    "#_exp_id='rank'  #rank, laptime, laptim2rank, timediff2rank... \n",
    "\n",
    "_task_id = 'laptime'  # rank,laptime, the trained model's task\n",
    "_run_ts = COL_LAPTIME   #COL_LAPTIME,COL_RANK\n",
    "_exp_id='laptime2rank'  #rank, laptime, laptim2rank, timediff2rank... \n",
    "\n",
    "#_task_id = 'laptime'  # rank,laptime, the trained model's task\n",
    "#_run_ts = COL_LAPTIME   #COL_LAPTIME,COL_RANK\n",
    "#_exp_id='laptime'  #rank, laptime, laptim2rank, timediff2rank... \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# parameters\n",
    "#\n",
    "stagedata = {}\n",
    "global_carids = {}\n",
    "traindata = None\n",
    "cur_carid = 0\n",
    "#years = ['2011','2012','2013', '2014', '2015', '2016', '2017']\n",
    "\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "#events = ['Indy500']\n",
    "events = [f'Indy500-{x}' for x in years]\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "dbid = f'Indy500_{years[0]}_{years[-1]}'\n",
    "\n",
    "global_start_offset = {}\n",
    "\n",
    "for event in events:\n",
    "    #dataid = f'{event}-{year}'\n",
    "    #alldata, rankdata, acldata, flagdata\n",
    "    stagedata[event] = load_data(event)\n",
    "\n",
    "    alldata, rankdata, acldata = stagedata[event]\n",
    "    \n",
    "    #offset\n",
    "    global_start_offset[event] = rankdata[rankdata['completed_laps']==0][['car_number','elapsed_time']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from here\n",
    "import pickle\n",
    "#with open('laptime_rank_timediff_fulltest-oracle-%s.pickle'%year, 'rb') as f:\n",
    "with open(f'laptime_rank_timediff_pit-oracle-{dbid}.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    global_carids, laptime_data = pickle.load(f, encoding='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"1min\"\n",
    "#decode global_carids\n",
    "decode_carids={carid:carno for carno, carid in global_carids.items()}\n",
    "    \n",
    "#useeid = False\n",
    "#interpolate = False\n",
    "#ipstr = '-ip' if interpolate else '-noip'\n",
    "#ipstr = '%s-%s'%('ip' if interpolate else 'noip', 'eid' if useeid else 'noeid')\n",
    "#if useeid:\n",
    "#    cardinality = [len(global_carids), len(laptime_data)]\n",
    "#else:\n",
    "#    cardinality = [len(global_carids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oracle test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5526, mae_track:0.0,mae_lap:0.0,\n",
      "train len:0, test len:5436, mae_track:0.0,mae_lap:0.0,\n",
      "train len:0, test len:4986, mae_track:0.0,mae_lap:0.0,\n",
      "==========\n",
      "train len:0, test len:5526, mae_track:0.0,mae_lap:0.0,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp: run_exp model: oracle datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5526, forecasts len=5526\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5436, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5436, forecasts len=5436\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:4986, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=4986, forecasts len=4986\n",
      "==========\n",
      "train len:0, test len:5526, mae_track:1502.0,mae_lap:418.0,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY,MODE_ORACLE_LAPONLY, eval: laptime2rank\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5526, forecasts len=5526\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5436, mae_track:3755.0,mae_lap:1045.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY,MODE_ORACLE_LAPONLY, eval: laptime2rank\n",
      "predicting model=oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5436, forecasts len=5436\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:4986, mae_track:7510.0,mae_lap:2078.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY,MODE_ORACLE_LAPONLY, eval: laptime2rank\n",
      "predicting model=oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=4986, forecasts len=4986\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5526, mae_track:1502.0,mae_lap:0.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_LAPONLY, eval: laptime2rank\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5526, forecasts len=5526\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5436, mae_track:3755.0,mae_lap:0.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_LAPONLY, eval: laptime2rank\n",
      "predicting model=oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5436, forecasts len=5436\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:4986, mae_track:7510.0,mae_lap:0.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_LAPONLY, eval: laptime2rank\n",
      "predicting model=oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=4986, forecasts len=4986\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5526, mae_track:0.0,mae_lap:418.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY, eval: laptime2rank\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5526, forecasts len=5526\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5436, mae_track:0.0,mae_lap:1045.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY, eval: laptime2rank\n",
      "predicting model=oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5436, forecasts len=5436\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:4986, mae_track:0.0,mae_lap:2078.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY, eval: laptime2rank\n",
      "predicting model=oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=4986, forecasts len=4986\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5526, mae_track:998.0,mae_lap:429.0,\n",
      "exp: run_exp model: oracle datamode: MODE_PREDTRACK,MODE_PREDPIT, eval: laptime2rank\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5526, forecasts len=5526\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5436, mae_track:2981.0,mae_lap:1085.0,\n",
      "exp: run_exp model: oracle datamode: MODE_PREDTRACK,MODE_PREDPIT, eval: laptime2rank\n",
      "predicting model=oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5436, forecasts len=5436\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:4986, mae_track:6646.0,mae_lap:2268.0,\n",
      "exp: run_exp model: oracle datamode: MODE_PREDTRACK,MODE_PREDPIT, eval: laptime2rank\n",
      "predicting model=oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=4986, forecasts len=4986\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5526, mae_track:908.0,mae_lap:418.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY,MODE_PREDTRACK, eval: laptime2rank\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5526, forecasts len=5526\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5436, mae_track:2987.0,mae_lap:1045.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY,MODE_PREDTRACK, eval: laptime2rank\n",
      "predicting model=oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5436, forecasts len=5436\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:4986, mae_track:6658.0,mae_lap:2078.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY,MODE_PREDTRACK, eval: laptime2rank\n",
      "predicting model=oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=4986, forecasts len=4986\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5526, mae_track:1502.0,mae_lap:441.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_LAPONLY,MODE_PREDPIT, eval: laptime2rank\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5526, forecasts len=5526\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5436, mae_track:3755.0,mae_lap:1090.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_LAPONLY,MODE_PREDPIT, eval: laptime2rank\n",
      "predicting model=oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5436, forecasts len=5436\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:4986, mae_track:7510.0,mae_lap:2276.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_LAPONLY,MODE_PREDPIT, eval: laptime2rank\n",
      "predicting model=oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=4986, forecasts len=4986\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5526, mae_track:516.0,mae_lap:418.0,\n",
      "exp: run_exp model: oracle datamode: MODE_TESTCURTRACK, eval: laptime2rank\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5526, forecasts len=5526\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5436, mae_track:2580.0,mae_lap:1045.0,\n",
      "exp: run_exp model: oracle datamode: MODE_TESTCURTRACK, eval: laptime2rank\n",
      "predicting model=oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5436, forecasts len=5436\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:4986, mae_track:8828.0,mae_lap:2078.0,\n",
      "exp: run_exp model: oracle datamode: MODE_TESTCURTRACK, eval: laptime2rank\n",
      "predicting model=oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=4986, forecasts len=4986\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5526, mae_track:1502.0,mae_lap:418.0,\n",
      "exp: run_exp model: oracle datamode: MODE_TESTZERO, eval: laptime2rank\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5526, forecasts len=5526\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5436, mae_track:3755.0,mae_lap:1045.0,\n",
      "exp: run_exp model: oracle datamode: MODE_TESTZERO, eval: laptime2rank\n",
      "predicting model=oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5436, forecasts len=5436\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:4986, mae_track:7510.0,mae_lap:2078.0,\n",
      "exp: run_exp model: oracle datamode: MODE_TESTZERO, eval: laptime2rank\n",
      "predicting model=oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=4986, forecasts len=4986\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5526, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: deepAR datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=deepAR, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5526, forecasts len=5526\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:5436, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: deepAR datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=deepAR, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=5436, forecasts len=5436\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len:0, test len:4986, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: deepAR datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=deepAR, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=4986, forecasts len=4986\n",
      "==========\n",
      "train len:0, test len:5526, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: naive datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=naive, plen=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=5526, forecasts len=5526\n",
      "==========\n",
      "train len:0, test len:5436, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: naive datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=naive, plen=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=5436, forecasts len=5436\n",
      "==========\n",
      "train len:0, test len:4986, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: naive datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=naive, plen=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=4986, forecasts len=4986\n",
      "==========\n",
      "train len:0, test len:5526, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: zero datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=zero, plen=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/ZeroPredictor.py:62: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=5526, forecasts len=5526\n",
      "==========\n",
      "train len:0, test len:5436, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: zero datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=zero, plen=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/ZeroPredictor.py:62: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=5436, forecasts len=5436\n",
      "==========\n",
      "train len:0, test len:4986, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: zero datamode: MODE_ORACLE, eval: laptime2rank\n",
      "predicting model=zero, plen=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/ZeroPredictor.py:62: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=4986, forecasts len=4986\n"
     ]
    }
   ],
   "source": [
    "### test\n",
    " \n",
    "\n",
    "#half=[True, False]\n",
    "#plens=[2,5,10,20,30]\n",
    "plens=[2,5,10]\n",
    "half=[0]\n",
    "trainids = [\"2018\"]\n",
    "#trainids = [\"r0.5\",\"r0.6\"]\n",
    "runs = 1\n",
    "train_ratio=0.4\n",
    "\n",
    "acc_output = f'{_exp_id}-evaluate-mean-splitbyevent-fulltest-contigency-d{_dataset_id}-t{_test_event}-r{runs}-tr{train_ratio}-result.csv'\n",
    "ret_output = f'{_exp_id}-evaluate-mean-splitbyevent-fulltest-all-d{_dataset_id}-t{_test_event}-r{runs}-tr{train_ratio}-result.csv'\n",
    "\n",
    "#trainids = [\"indy500\"]\n",
    "#runs = 1\n",
    "#plens=[2]\n",
    "\n",
    "\n",
    "config = {'oracle':\n",
    "            {'fulloracle':MODE_ORACLE,'notracklap':MODE_NOTRACK + MODE_NOLAP,\n",
    "             'laponly':MODE_ORACLE_LAPONLY, 'trackonly':MODE_ORACLE_TRACKONLY,\n",
    "              'fullpred':MODE_PREDTRACK + MODE_PREDPIT,\n",
    "              'predtrack':MODE_PREDTRACK + MODE_ORACLE_TRACKONLY,\n",
    "              'predpit':MODE_PREDPIT + MODE_ORACLE_LAPONLY,\n",
    "              'curtrack':MODE_TESTCURTRACK,\n",
    "              'zerotrack':MODE_TESTZERO\n",
    "             },\n",
    "          'deepAR':{'deepAR':MODE_ORACLE},\n",
    "          'naive':{'naive':MODE_ORACLE},\n",
    "          'zero':{'zero':MODE_ORACLE}\n",
    "         }\n",
    "\n",
    "ref_testset = get_ref_oracle_testds(plens, half, train_ratio=train_ratio)\n",
    "\n",
    "dfret, dfacc = dotest(config)\n",
    "\n",
    "dfret.to_csv(ret_output, float_format='%.3f')\n",
    "dfacc.to_csv(acc_output, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/IPython/core/compilerop.py\u001b[0m(101)\u001b[0;36mast_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     99 \u001b[0;31m        \u001b[0mArguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mexactly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    100 \u001b[0;31m        and are passed to the built-in compile function.\"\"\"\n",
      "\u001b[0m\u001b[0;32m--> 101 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    103 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mreset_compiler_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> up\n",
      "*** Oldest frame\n",
      "ipdb> up\n",
      "*** Oldest frame\n",
      "ipdb> up\n",
      "*** Oldest frame\n",
      "ipdb> quit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testid</th>\n",
       "      <th>plen</th>\n",
       "      <th>type</th>\n",
       "      <th>reccnt</th>\n",
       "      <th>top1acc</th>\n",
       "      <th>top1acc_farmost</th>\n",
       "      <th>top5acc</th>\n",
       "      <th>top5acc_farmost</th>\n",
       "      <th>tau</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fulloracle</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.937234</td>\n",
       "      <td>0.919149</td>\n",
       "      <td>0.953946</td>\n",
       "      <td>2.337005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fulloracle</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.782703</td>\n",
       "      <td>0.686486</td>\n",
       "      <td>0.899027</td>\n",
       "      <td>0.856216</td>\n",
       "      <td>0.920812</td>\n",
       "      <td>4.643340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fulloracle</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.682941</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.850706</td>\n",
       "      <td>0.777647</td>\n",
       "      <td>0.874577</td>\n",
       "      <td>8.178037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notracklap</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.875532</td>\n",
       "      <td>0.837234</td>\n",
       "      <td>0.909656</td>\n",
       "      <td>7.416958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notracklap</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.609730</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.796324</td>\n",
       "      <td>0.699459</td>\n",
       "      <td>0.843629</td>\n",
       "      <td>14.382751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notracklap</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.442353</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.699059</td>\n",
       "      <td>0.587059</td>\n",
       "      <td>0.762783</td>\n",
       "      <td>21.983188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laponly</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.864362</td>\n",
       "      <td>0.845745</td>\n",
       "      <td>0.941489</td>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.952893</td>\n",
       "      <td>2.618737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laponly</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.816216</td>\n",
       "      <td>0.735135</td>\n",
       "      <td>0.912432</td>\n",
       "      <td>0.888649</td>\n",
       "      <td>0.926792</td>\n",
       "      <td>4.313287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laponly</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.724118</td>\n",
       "      <td>0.629412</td>\n",
       "      <td>0.893294</td>\n",
       "      <td>0.844706</td>\n",
       "      <td>0.895467</td>\n",
       "      <td>5.834462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trackonly</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.747340</td>\n",
       "      <td>0.675532</td>\n",
       "      <td>0.880851</td>\n",
       "      <td>0.842553</td>\n",
       "      <td>0.913370</td>\n",
       "      <td>6.904673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trackonly</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.596757</td>\n",
       "      <td>0.427027</td>\n",
       "      <td>0.805622</td>\n",
       "      <td>0.714595</td>\n",
       "      <td>0.848356</td>\n",
       "      <td>13.385462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trackonly</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.424706</td>\n",
       "      <td>0.217647</td>\n",
       "      <td>0.711529</td>\n",
       "      <td>0.604706</td>\n",
       "      <td>0.767631</td>\n",
       "      <td>21.144961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fullpred</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.771277</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.895213</td>\n",
       "      <td>0.860638</td>\n",
       "      <td>0.924150</td>\n",
       "      <td>5.959597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fullpred</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.604324</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.814270</td>\n",
       "      <td>0.717838</td>\n",
       "      <td>0.857719</td>\n",
       "      <td>12.654210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fullpred</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.416471</td>\n",
       "      <td>0.229412</td>\n",
       "      <td>0.697176</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.772056</td>\n",
       "      <td>21.019272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predtrack</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.664894</td>\n",
       "      <td>0.896277</td>\n",
       "      <td>0.863830</td>\n",
       "      <td>0.916419</td>\n",
       "      <td>6.634985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predtrack</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.628108</td>\n",
       "      <td>0.454054</td>\n",
       "      <td>0.809297</td>\n",
       "      <td>0.709189</td>\n",
       "      <td>0.850856</td>\n",
       "      <td>13.429536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predtrack</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.434706</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.711294</td>\n",
       "      <td>0.608235</td>\n",
       "      <td>0.770430</td>\n",
       "      <td>21.186288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predpit</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.752660</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.834043</td>\n",
       "      <td>0.912358</td>\n",
       "      <td>7.255143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predpit</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.619459</td>\n",
       "      <td>0.470270</td>\n",
       "      <td>0.779027</td>\n",
       "      <td>0.669189</td>\n",
       "      <td>0.843436</td>\n",
       "      <td>14.385447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predpit</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.252941</td>\n",
       "      <td>0.692588</td>\n",
       "      <td>0.585882</td>\n",
       "      <td>0.762253</td>\n",
       "      <td>22.102251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>curtrack</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>0.831915</td>\n",
       "      <td>0.915298</td>\n",
       "      <td>6.969062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>curtrack</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.571892</td>\n",
       "      <td>0.410811</td>\n",
       "      <td>0.779459</td>\n",
       "      <td>0.669189</td>\n",
       "      <td>0.834057</td>\n",
       "      <td>15.820064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>curtrack</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.405294</td>\n",
       "      <td>0.170588</td>\n",
       "      <td>0.668353</td>\n",
       "      <td>0.550588</td>\n",
       "      <td>0.741941</td>\n",
       "      <td>25.741962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zerotrack</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.899468</td>\n",
       "      <td>0.869149</td>\n",
       "      <td>0.927242</td>\n",
       "      <td>5.692075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zerotrack</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.605405</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.820757</td>\n",
       "      <td>0.725405</td>\n",
       "      <td>0.865177</td>\n",
       "      <td>11.972517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zerotrack</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.427647</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.712471</td>\n",
       "      <td>0.603529</td>\n",
       "      <td>0.783255</td>\n",
       "      <td>19.745764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepAR</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.303191</td>\n",
       "      <td>0.759574</td>\n",
       "      <td>0.693617</td>\n",
       "      <td>0.814273</td>\n",
       "      <td>15.554030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepAR</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.309189</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.624865</td>\n",
       "      <td>0.454054</td>\n",
       "      <td>0.712802</td>\n",
       "      <td>27.388526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepAR</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.307647</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.590235</td>\n",
       "      <td>0.455294</td>\n",
       "      <td>0.647049</td>\n",
       "      <td>33.655123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naive</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.726064</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.845745</td>\n",
       "      <td>0.802128</td>\n",
       "      <td>0.873237</td>\n",
       "      <td>11.185519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naive</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.558919</td>\n",
       "      <td>0.356757</td>\n",
       "      <td>0.733838</td>\n",
       "      <td>0.601081</td>\n",
       "      <td>0.767816</td>\n",
       "      <td>22.914437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naive</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.368235</td>\n",
       "      <td>0.135294</td>\n",
       "      <td>0.610824</td>\n",
       "      <td>0.475294</td>\n",
       "      <td>0.645435</td>\n",
       "      <td>36.248289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zero</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>188</td>\n",
       "      <td>0.789894</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.895745</td>\n",
       "      <td>0.864894</td>\n",
       "      <td>0.927564</td>\n",
       "      <td>6.465938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zero</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>185</td>\n",
       "      <td>0.665946</td>\n",
       "      <td>0.518919</td>\n",
       "      <td>0.816432</td>\n",
       "      <td>0.723243</td>\n",
       "      <td>0.868785</td>\n",
       "      <td>12.423479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zero</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>170</td>\n",
       "      <td>0.497647</td>\n",
       "      <td>0.288235</td>\n",
       "      <td>0.724941</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.793813</td>\n",
       "      <td>19.434474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       testid  plen type  reccnt   top1acc  top1acc_farmost   top5acc  \\\n",
       "4  fulloracle     2   aa     188  0.856383         0.829787  0.937234   \n",
       "4  fulloracle     5   aa     185  0.782703         0.686486  0.899027   \n",
       "4  fulloracle    10   aa     170  0.682941         0.576471  0.850706   \n",
       "4  notracklap     2   aa     188  0.765957         0.702128  0.875532   \n",
       "4  notracklap     5   aa     185  0.609730         0.459459  0.796324   \n",
       "4  notracklap    10   aa     170  0.442353         0.247059  0.699059   \n",
       "4     laponly     2   aa     188  0.864362         0.845745  0.941489   \n",
       "4     laponly     5   aa     185  0.816216         0.735135  0.912432   \n",
       "4     laponly    10   aa     170  0.724118         0.629412  0.893294   \n",
       "4   trackonly     2   aa     188  0.747340         0.675532  0.880851   \n",
       "4   trackonly     5   aa     185  0.596757         0.427027  0.805622   \n",
       "4   trackonly    10   aa     170  0.424706         0.217647  0.711529   \n",
       "4    fullpred     2   aa     188  0.771277         0.702128  0.895213   \n",
       "4    fullpred     5   aa     185  0.604324         0.459459  0.814270   \n",
       "4    fullpred    10   aa     170  0.416471         0.229412  0.697176   \n",
       "4   predtrack     2   aa     188  0.744681         0.664894  0.896277   \n",
       "4   predtrack     5   aa     185  0.628108         0.454054  0.809297   \n",
       "4   predtrack    10   aa     170  0.434706         0.258824  0.711294   \n",
       "4     predpit     2   aa     188  0.752660         0.680851  0.872340   \n",
       "4     predpit     5   aa     185  0.619459         0.470270  0.779027   \n",
       "4     predpit    10   aa     170  0.450000         0.252941  0.692588   \n",
       "4    curtrack     2   aa     188  0.734043         0.659574  0.877660   \n",
       "4    curtrack     5   aa     185  0.571892         0.410811  0.779459   \n",
       "4    curtrack    10   aa     170  0.405294         0.170588  0.668353   \n",
       "4   zerotrack     2   aa     188  0.755319         0.680851  0.899468   \n",
       "4   zerotrack     5   aa     185  0.605405         0.432432  0.820757   \n",
       "4   zerotrack    10   aa     170  0.427647         0.235294  0.712471   \n",
       "4      deepAR     2   aa     188  0.446809         0.303191  0.759574   \n",
       "4      deepAR     5   aa     185  0.309189         0.070270  0.624865   \n",
       "4      deepAR    10   aa     170  0.307647         0.152941  0.590235   \n",
       "4       naive     2   aa     188  0.726064         0.648936  0.845745   \n",
       "4       naive     5   aa     185  0.558919         0.356757  0.733838   \n",
       "4       naive    10   aa     170  0.368235         0.135294  0.610824   \n",
       "4        zero     2   aa     188  0.789894         0.734043  0.895745   \n",
       "4        zero     5   aa     185  0.665946         0.518919  0.816432   \n",
       "4        zero    10   aa     170  0.497647         0.288235  0.724941   \n",
       "\n",
       "   top5acc_farmost       tau       rmse  \n",
       "4         0.919149  0.953946   2.337005  \n",
       "4         0.856216  0.920812   4.643340  \n",
       "4         0.777647  0.874577   8.178037  \n",
       "4         0.837234  0.909656   7.416958  \n",
       "4         0.699459  0.843629  14.382751  \n",
       "4         0.587059  0.762783  21.983188  \n",
       "4         0.930851  0.952893   2.618737  \n",
       "4         0.888649  0.926792   4.313287  \n",
       "4         0.844706  0.895467   5.834462  \n",
       "4         0.842553  0.913370   6.904673  \n",
       "4         0.714595  0.848356  13.385462  \n",
       "4         0.604706  0.767631  21.144961  \n",
       "4         0.860638  0.924150   5.959597  \n",
       "4         0.717838  0.857719  12.654210  \n",
       "4         0.588235  0.772056  21.019272  \n",
       "4         0.863830  0.916419   6.634985  \n",
       "4         0.709189  0.850856  13.429536  \n",
       "4         0.608235  0.770430  21.186288  \n",
       "4         0.834043  0.912358   7.255143  \n",
       "4         0.669189  0.843436  14.385447  \n",
       "4         0.585882  0.762253  22.102251  \n",
       "4         0.831915  0.915298   6.969062  \n",
       "4         0.669189  0.834057  15.820064  \n",
       "4         0.550588  0.741941  25.741962  \n",
       "4         0.869149  0.927242   5.692075  \n",
       "4         0.725405  0.865177  11.972517  \n",
       "4         0.603529  0.783255  19.745764  \n",
       "4         0.693617  0.814273  15.554030  \n",
       "4         0.454054  0.712802  27.388526  \n",
       "4         0.455294  0.647049  33.655123  \n",
       "4         0.802128  0.873237  11.185519  \n",
       "4         0.601081  0.767816  22.914437  \n",
       "4         0.475294  0.645435  36.248289  \n",
       "4         0.864894  0.927564   6.465938  \n",
       "4         0.723243  0.868785  12.423479  \n",
       "4         0.623529  0.793813  19.434474  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfacc[dfacc['type']=='aa']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjust pit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODE_DISTURB_CLEARTRACK = 64\n",
    "#MODE_DISTURB_ADJUSTTRACK = 128\n",
    "#MODE_DISTURB_ADJUSTPIT = 256\n",
    "config_adjust = {'cleartrack':MODE_DISTURB_CLEARTRACK,'adjusttrack':MODE_DISTURB_CLEARTRACK + MODE_DISTURB_ADJUSTTRACK,\n",
    "         'adjustpit':MODE_DISTURB_ADJUSTPIT, 'adjustall':MODE_DISTURB_CLEARTRACK+ MODE_DISTURB_ADJUSTTRACK+MODE_DISTURB_ADJUSTPIT,\n",
    "         }\n",
    "adjust_dfret, adjust_dfacc = dotest(config_adjust)\n",
    "config_t = {'adjust_laponly':MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "         }\n",
    "\n",
    "t_dfret, t_dfacc = dotest(config_t)\n",
    "config_t = {'predpit':MODE_PREDPIT + MODE_ORACLE_LAPONLY\n",
    "         }\n",
    "\n",
    "t2_dfret, t2_dfacc = dotest(config_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_modeldict={-3:0.1, -2:0.15,-1:0.2,0:0.05, 1:0.2, 2:0.15,3:0.1 }\n",
    "_adjust_model = build_random_model(_modeldict)\n",
    "datamode = MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "check_testds(datamode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_t = {'newadjust_laponly':MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "         }\n",
    "\n",
    "t3_dfret, t3_dfacc = dotest(config_t)\n",
    "test_dfacc = pd.concat([t_dfacc,t2_dfacc,t3_dfacc], axis=0)\n",
    "test_dfacc[test_dfacc['type']=='aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_modeldict={-3:0.0, -2:0.15,-1:0.2,0:0.2, 1:0.2, 2:0.15,3:0.0 }\n",
    "_adjust_model = build_random_model(_modeldict)\n",
    "init_adjust_pitmodel()\n",
    "datamode = MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "check_testds(datamode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_t = {'newadjust_laponly':MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "         }\n",
    "\n",
    "t3_dfret, t3_dfacc = dotest(config_t)\n",
    "test_dfacc = pd.concat([t_dfacc,t2_dfacc,t3_dfacc], axis=0)\n",
    "test_dfacc[test_dfacc['type']=='aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_modeldict={-4:0.05, -3:0.1, -2:0.2,-1:0.3, 0:0.2, 1:0.1, 2:0.1 }\n",
    "_adjust_model = build_random_model(_modeldict)\n",
    "init_adjust_pitmodel()\n",
    "datamode = MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "check_testds(datamode)\n",
    "\n",
    "real_model = build_random_model(_empirical_model)\n",
    "print('adjust model:')\n",
    "print_model(_adjust_model, iscdf=True)\n",
    "print('real adjust model:')\n",
    "print_model(real_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_t = {'newadjust_laponly':MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "         }\n",
    "\n",
    "t3_dfret, t3_dfacc = dotest(config_t)\n",
    "test_dfacc = pd.concat([t_dfacc,t2_dfacc,t3_dfacc], axis=0)\n",
    "test_dfacc[test_dfacc['type']=='aa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, dataret = run_test(1, [2],[0], trainids, 0.4, 'zero', datamode=MODE_ORACLE,models=['zero'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkret_status(dataret,model='zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ret = dataret[0][0][2]['zero'][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ret[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(global_start_offset[_test_event], pd.core.frame.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(global_start_offset[_test_event])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check the carid decoder\n",
    "dbid1 = 'Indy500_2013_2018'\n",
    "dbid2 = 'Indy500_2013_2019'\n",
    "#with open('laptime_rank_timediff_fulltest-oracle-%s.pickle'%year, 'rb') as f:\n",
    "with open(f'laptime_rank_timediff_pit-oracle-{dbid1}.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    global_carids1, laptime_data1 = pickle.load(f, encoding='latin1') \n",
    "    \n",
    "with open(f'laptime_rank_timediff_pit-oracle-{dbid2}.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    global_carids2, laptime_data2 = pickle.load(f, encoding='latin1') \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 2: 1,\n",
       " 3: 2,\n",
       " 4: 3,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 6,\n",
       " 8: 7,\n",
       " 9: 8,\n",
       " 10: 9,\n",
       " 11: 10,\n",
       " 12: 11,\n",
       " 14: 12,\n",
       " 15: 13,\n",
       " 16: 14,\n",
       " 18: 15,\n",
       " 19: 16,\n",
       " 20: 17,\n",
       " 21: 18,\n",
       " 22: 19,\n",
       " 25: 20,\n",
       " 26: 21,\n",
       " 27: 22,\n",
       " 41: 23,\n",
       " 55: 24,\n",
       " 60: 25,\n",
       " 63: 26,\n",
       " 77: 27,\n",
       " 78: 28,\n",
       " 81: 29,\n",
       " 83: 30,\n",
       " 91: 31,\n",
       " 98: 32,\n",
       " 17: 33,\n",
       " 28: 34,\n",
       " 33: 35,\n",
       " 34: 36,\n",
       " 67: 37,\n",
       " 68: 38,\n",
       " 24: 39,\n",
       " 29: 40,\n",
       " 32: 41,\n",
       " 43: 42,\n",
       " 48: 43,\n",
       " 88: 44,\n",
       " 35: 45,\n",
       " 42: 46,\n",
       " 61: 47,\n",
       " 40: 48,\n",
       " 44: 49,\n",
       " 50: 50,\n",
       " 13: 51,\n",
       " 23: 52,\n",
       " 30: 53,\n",
       " 59: 54,\n",
       " 64: 55,\n",
       " 66: 56}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_carids1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 2: 1,\n",
       " 3: 2,\n",
       " 4: 3,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 6,\n",
       " 8: 7,\n",
       " 9: 8,\n",
       " 10: 9,\n",
       " 11: 10,\n",
       " 12: 11,\n",
       " 14: 12,\n",
       " 15: 13,\n",
       " 16: 14,\n",
       " 18: 15,\n",
       " 19: 16,\n",
       " 20: 17,\n",
       " 21: 18,\n",
       " 22: 19,\n",
       " 25: 20,\n",
       " 26: 21,\n",
       " 27: 22,\n",
       " 41: 23,\n",
       " 55: 24,\n",
       " 60: 25,\n",
       " 63: 26,\n",
       " 77: 27,\n",
       " 78: 28,\n",
       " 81: 29,\n",
       " 83: 30,\n",
       " 91: 31,\n",
       " 98: 32,\n",
       " 17: 33,\n",
       " 28: 34,\n",
       " 33: 35,\n",
       " 34: 36,\n",
       " 67: 37,\n",
       " 68: 38,\n",
       " 24: 39,\n",
       " 29: 40,\n",
       " 32: 41,\n",
       " 43: 42,\n",
       " 48: 43,\n",
       " 88: 44,\n",
       " 35: 45,\n",
       " 42: 46,\n",
       " 61: 47,\n",
       " 40: 48,\n",
       " 44: 49,\n",
       " 50: 50,\n",
       " 13: 51,\n",
       " 23: 52,\n",
       " 30: 53,\n",
       " 59: 54,\n",
       " 64: 55,\n",
       " 66: 56,\n",
       " 39: 57}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_carids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_carids2={carid:carno for carno, carid in global_carids2.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 2,\n",
       " 2: 3,\n",
       " 3: 4,\n",
       " 4: 5,\n",
       " 5: 6,\n",
       " 6: 7,\n",
       " 7: 8,\n",
       " 8: 9,\n",
       " 9: 10,\n",
       " 10: 11,\n",
       " 11: 12,\n",
       " 12: 14,\n",
       " 13: 15,\n",
       " 14: 16,\n",
       " 15: 18,\n",
       " 16: 19,\n",
       " 17: 20,\n",
       " 18: 21,\n",
       " 19: 22,\n",
       " 20: 25,\n",
       " 21: 26,\n",
       " 22: 27,\n",
       " 23: 41,\n",
       " 24: 55,\n",
       " 25: 60,\n",
       " 26: 63,\n",
       " 27: 77,\n",
       " 28: 78,\n",
       " 29: 81,\n",
       " 30: 83,\n",
       " 31: 91,\n",
       " 32: 98,\n",
       " 33: 17,\n",
       " 34: 28,\n",
       " 35: 33,\n",
       " 36: 34,\n",
       " 37: 67,\n",
       " 38: 68,\n",
       " 39: 24,\n",
       " 40: 29,\n",
       " 41: 32,\n",
       " 42: 43,\n",
       " 43: 48,\n",
       " 44: 88,\n",
       " 45: 35,\n",
       " 46: 42,\n",
       " 47: 61,\n",
       " 48: 40,\n",
       " 49: 44,\n",
       " 50: 50,\n",
       " 51: 13,\n",
       " 52: 23,\n",
       " 53: 30,\n",
       " 54: 59,\n",
       " 55: 64,\n",
       " 56: 66}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_carids1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 2,\n",
       " 2: 3,\n",
       " 3: 4,\n",
       " 4: 5,\n",
       " 5: 6,\n",
       " 6: 7,\n",
       " 7: 8,\n",
       " 8: 9,\n",
       " 9: 10,\n",
       " 10: 11,\n",
       " 11: 12,\n",
       " 12: 14,\n",
       " 13: 15,\n",
       " 14: 16,\n",
       " 15: 18,\n",
       " 16: 19,\n",
       " 17: 20,\n",
       " 18: 21,\n",
       " 19: 22,\n",
       " 20: 25,\n",
       " 21: 26,\n",
       " 22: 27,\n",
       " 23: 41,\n",
       " 24: 55,\n",
       " 25: 60,\n",
       " 26: 63,\n",
       " 27: 77,\n",
       " 28: 78,\n",
       " 29: 81,\n",
       " 30: 83,\n",
       " 31: 91,\n",
       " 32: 98,\n",
       " 33: 17,\n",
       " 34: 28,\n",
       " 35: 33,\n",
       " 36: 34,\n",
       " 37: 67,\n",
       " 38: 68,\n",
       " 39: 24,\n",
       " 40: 29,\n",
       " 41: 32,\n",
       " 42: 43,\n",
       " 43: 48,\n",
       " 44: 88,\n",
       " 45: 35,\n",
       " 46: 42,\n",
       " 47: 61,\n",
       " 48: 40,\n",
       " 49: 44,\n",
       " 50: 50,\n",
       " 51: 13,\n",
       " 52: 23,\n",
       " 53: 30,\n",
       " 54: 59,\n",
       " 55: 64,\n",
       " 56: 66,\n",
       " 57: 39}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_carids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run():\n",
    "    return 1,2\n",
    "\n",
    "a = run()\n",
    "a[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
