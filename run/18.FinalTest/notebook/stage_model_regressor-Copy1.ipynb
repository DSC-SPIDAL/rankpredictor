{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stage_model_regressor\n",
    "\n",
    "predicting target = change of rank\n",
    "\n",
    "base: 14./stage_model_regressor_withneighbor-newfeatures\n",
    "\n",
    "prediction models of chg_of_rank_in_stage on stage dataset\n",
    "\n",
    "data format:\n",
    "    target , eventid ,    car_number,    stageid,     features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.ridge module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.stochastic_gradient module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.svm.classes module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.svm. Anything that cannot be imported from sklearn.svm is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn.linear_model.ridge import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model.stochastic_gradient import SGDRegressor\n",
    "from sklearn.svm.classes import SVR\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulid regression model\n",
    "regressors = ['currank','avgrank','dice','lasso','ridge','rf','svr','xgb']\n",
    "def get_regressor(regressor = 'lr'):\n",
    "    if regressor == \"lasso\":\n",
    "        clf = LassoCV(cv=5, random_state=0)\n",
    "    elif regressor == \"ridge\":\n",
    "        clf = RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
    "    elif regressor == \"rf\":\n",
    "        clf = RandomForestRegressor(n_estimators=100)\n",
    "    elif regressor == 'svr':\n",
    "        clf = SVR(kernel='rbf')\n",
    "    elif regressor == 'xgb':\n",
    "        clf = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42, max_depth=3)\n",
    "    elif regressor == 'dice':\n",
    "        clf = RandomDice('1234')\n",
    "    elif regressor == 'currank':\n",
    "        clf = CurRank()\n",
    "    elif regressor == 'avgrank':\n",
    "        clf = AverageRank()        \n",
    "    else:\n",
    "        clf = None\n",
    "        \n",
    "    return clf\n",
    "\n",
    "\n",
    "class CurRank():\n",
    "    \"\"\"\n",
    "    predict with current rank\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    def predict(self, test_x):\n",
    "        pred_y = [0 for x in range(test_x.shape[0])]\n",
    "        return np.array(pred_y)\n",
    "    \n",
    "class AverageRank():\n",
    "    \"\"\"\n",
    "    print('[*] predict with average rankchg (change_in_rank_all):idx = 15')\n",
    "    change_in_rank_all = test[:,15]\n",
    "    pred_y_avg = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in change_in_rank_all])\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    def predict(self, test_x):\n",
    "        pred_y = []\n",
    "        for x in test_x:\n",
    "            #13, change_in_rank_all\n",
    "            pred_y.append(x[13])\n",
    "        #pred_y_avg = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in pred_y])\n",
    "        pred_y_avg = pred_y\n",
    "        return np.array(pred_y_avg)   \n",
    "\n",
    "class RandomDice():\n",
    "    \"\"\"\n",
    "    a random dice model\n",
    "    \"\"\"\n",
    "    def __init__(self, seed='1234'):\n",
    "        self.dist = []\n",
    "        self.val = []\n",
    "        random.seed(seed)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        total = y.shape[0]\n",
    "        yval = set(y)\n",
    "        \n",
    "        ratio = 0.\n",
    "        for val in yval:\n",
    "            self.val.append(val)\n",
    "            ratio += np.sum(y==val)*1.0 / total\n",
    "            self.dist.append(ratio)\n",
    "            \n",
    "    def predict(self, test_x):\n",
    "        pred_y = []\n",
    "        for x in test_x:\n",
    "            dice = random.random()\n",
    "            #search in self.dist\n",
    "            find_idx = -1\n",
    "            for idx, ratio in enumerate(self.dist):\n",
    "                if dice <= ratio:\n",
    "                    find_idx = idx\n",
    "                    break\n",
    "            \n",
    "            #or the last one match\n",
    "            pred_y.append(self.val[find_idx])\n",
    "            \n",
    "        return np.array(pred_y)\n",
    "\n",
    "def evaluate(test_y, pred_y):\n",
    "    mae = metrics.mean_absolute_error(test_y, pred_y) \n",
    "    rmse = math.sqrt(metrics.mean_squared_error(test_y, pred_y))\n",
    "    r2 = metrics.r2_score(test_y, pred_y)\n",
    "    print('rmse=%.2f, mae=%.2f, r2=%.2f'%(rmse, mae, r2))\n",
    "    return mae,rmse, r2\n",
    "    \n",
    "#\n",
    "#features\n",
    "#    cols=[Myidx, 'target','eventid','car_number','stageid',\n",
    "#             'firststage','pit_in_caution','start_position',\n",
    "#             'start_rank','start_rank_ratio','top_pack','bottom_pack',\n",
    "#             'average_rank','average_rank_all',\n",
    "#             'change_in_rank','change_in_rank_all','rate_of_change','rate_of_change_all']    \n",
    "def split_by_eventid(stagedata, eventid):\n",
    "    \"\"\"\n",
    "    split by eventid\n",
    "    \"\"\"\n",
    "    #if not eventid in stagedata:\n",
    "    #    print('error, %d not found in stagedata'%eventid)\n",
    "    #    return\n",
    "    \n",
    "    train = stagedata[stagedata['eventid'] != eventid].to_numpy()\n",
    "    test  = stagedata[stagedata['eventid'] == eventid].to_numpy()\n",
    "\n",
    "    #2:car_number\n",
    "    train_x = train[:,2:]\n",
    "    #train_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in train[:,1]])\n",
    "    train_y = train[:,1]\n",
    "    test_x = test[:,2:]\n",
    "    #test_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in test[:,1]])\n",
    "    test_y = test[:,1]\n",
    "    \n",
    "    return train, test, train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def split_by_stageid(stagedata, stageid):\n",
    "    \"\"\"\n",
    "    split by stageid\n",
    "    \"\"\"\n",
    "    #if not eventid in stagedata:\n",
    "    #    print('error, %d not found in stagedata'%eventid)\n",
    "    #    return\n",
    "    \n",
    "    train = stagedata[stagedata['stageid'] <= stageid].to_numpy()\n",
    "    test  = stagedata[stagedata['stageid'] > stageid].to_numpy()\n",
    "\n",
    "    train_x = train[:,2:]\n",
    "    #train_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in train[:,1]])\n",
    "    train_y = train[:,1]\n",
    "    test_x = test[:,2:]\n",
    "    #test_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in test[:,1]])\n",
    "    test_y = test[:,1]\n",
    "    \n",
    "    return train, test, train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def regressor_model(name='svr'):\n",
    "    ### test learning models\n",
    "    print('[*] predict with %s model'%name)\n",
    "    clf = get_regressor(name)\n",
    "    clf.fit(train_x, train_y)\n",
    "\n",
    "    pred_y = clf.predict(test_x)\n",
    "    score = evaluate(test_y, pred_y)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 35 columns):\n",
      "Unnamed: 0                   1313 non-null int64\n",
      "target                       1313 non-null int64\n",
      "eventid                      1313 non-null int64\n",
      "car_number                   1313 non-null int64\n",
      "stageid                      1313 non-null int64\n",
      "firststage                   1313 non-null int64\n",
      "pit_in_caution               1313 non-null int64\n",
      "start_position               1313 non-null int64\n",
      "start_rank                   1313 non-null int64\n",
      "start_rank_ratio             1313 non-null float64\n",
      "top_pack                     1313 non-null int64\n",
      "bottom_pack                  1313 non-null int64\n",
      "average_rank                 1313 non-null float64\n",
      "average_rank_all             1313 non-null float64\n",
      "change_in_rank               1313 non-null int64\n",
      "change_in_rank_all           1313 non-null float64\n",
      "rate_of_change               1313 non-null int64\n",
      "rate_of_change_all           1313 non-null float64\n",
      "laptime_green_mean_prev      1313 non-null float64\n",
      "laptime_green_std_prev       1313 non-null float64\n",
      "laptime_green_mean_all       1313 non-null float64\n",
      "laptime_green_std_all        1313 non-null float64\n",
      "laptime_mean_prev            1313 non-null float64\n",
      "laptime_std_prev             1313 non-null float64\n",
      "laptime_mean_all             1313 non-null float64\n",
      "laptime_std_all              1313 non-null float64\n",
      "laps_prev                    1313 non-null int64\n",
      "laps_after_last_pitstop      1313 non-null int64\n",
      "pittime_prev                 1313 non-null float64\n",
      "prev_nb0_change_in_rank      1313 non-null int64\n",
      "prev_nb1_change_in_rank      1313 non-null int64\n",
      "prev_nb2_change_in_rank      1313 non-null int64\n",
      "follow_nb0_change_in_rank    1313 non-null int64\n",
      "follow_nb1_change_in_rank    1313 non-null int64\n",
      "follow_nb2_change_in_rank    1313 non-null int64\n",
      "dtypes: float64(14), int64(21)\n",
      "memory usage: 359.1 KB\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "_trim = 0\n",
    "_include_final = False\n",
    "include_str = '1' if _include_final else '0'\n",
    "suffix = f'indy500-2013-2019-end{include_str}-t{_trim}'\n",
    "output_file = f'stage-indy500-2013-2019-end{include_str}-t{_trim}.csv'\n",
    "stagedata = pd.read_csv(output_file)\n",
    "stagedata.fillna(0, inplace=True)\n",
    "stagedata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model on data split by event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['runid', 'trainsize', 'testsize', 'testdistribution', 'currank', 'avgrank', 'dice', 'lasso', 'ridge', 'rf', 'svr', 'xgb']\n",
      "Testset = Indy500-2013\n",
      "[*] predict with currank model\n",
      "rmse=7.83, mae=5.60, r2=-0.01\n",
      "[*] predict with avgrank model\n",
      "rmse=10.88, mae=7.43, r2=-0.94\n",
      "[*] predict with dice model\n",
      "rmse=10.41, mae=7.63, r2=-0.77\n",
      "[*] predict with lasso model\n",
      "rmse=6.46, mae=5.08, r2=0.32\n",
      "[*] predict with ridge model\n",
      "rmse=6.52, mae=5.16, r2=0.30\n",
      "[*] predict with rf model\n",
      "rmse=6.45, mae=5.05, r2=0.32\n",
      "[*] predict with svr model\n",
      "rmse=7.35, mae=5.32, r2=0.12\n",
      "[*] predict with xgb model\n",
      "[10:32:48] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "rmse=6.94, mae=5.48, r2=0.21\n",
      "Testset = Indy500-2014\n",
      "[*] predict with currank model\n",
      "rmse=5.43, mae=3.55, r2=-0.01\n",
      "[*] predict with avgrank model\n",
      "rmse=7.82, mae=5.20, r2=-1.09\n",
      "[*] predict with dice model\n",
      "rmse=8.91, mae=6.12, r2=-1.71\n",
      "[*] predict with lasso model\n",
      "rmse=5.00, mae=3.73, r2=0.15\n",
      "[*] predict with ridge model\n",
      "rmse=5.01, mae=3.78, r2=0.14\n",
      "[*] predict with rf model\n",
      "rmse=5.29, mae=4.03, r2=0.05\n",
      "[*] predict with svr model\n",
      "rmse=5.20, mae=3.33, r2=0.08\n",
      "[*] predict with xgb model\n",
      "[10:32:51] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "rmse=5.52, mae=4.13, r2=-0.04\n",
      "Testset = Indy500-2015\n",
      "[*] predict with currank model\n",
      "rmse=7.15, mae=5.15, r2=-0.00\n",
      "[*] predict with avgrank model\n",
      "rmse=8.97, mae=6.62, r2=-0.58\n",
      "[*] predict with dice model\n",
      "rmse=9.25, mae=7.04, r2=-0.68\n",
      "[*] predict with lasso model\n",
      "rmse=6.05, mae=4.60, r2=0.28\n",
      "[*] predict with ridge model\n",
      "rmse=6.10, mae=4.64, r2=0.27\n",
      "[*] predict with rf model\n",
      "rmse=6.01, mae=4.60, r2=0.29\n",
      "[*] predict with svr model\n",
      "rmse=6.69, mae=4.88, r2=0.12\n",
      "[*] predict with xgb model\n",
      "[10:32:54] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "rmse=6.38, mae=4.88, r2=0.20\n",
      "Testset = Indy500-2016\n",
      "[*] predict with currank model\n",
      "rmse=6.13, mae=4.07, r2=-0.00\n",
      "[*] predict with avgrank model\n",
      "rmse=8.25, mae=5.45, r2=-0.81\n",
      "[*] predict with dice model\n",
      "rmse=8.72, mae=6.36, r2=-1.02\n",
      "[*] predict with lasso model\n",
      "rmse=5.73, mae=4.03, r2=0.13\n",
      "[*] predict with ridge model\n",
      "rmse=5.73, mae=4.02, r2=0.13\n",
      "[*] predict with rf model\n",
      "rmse=5.56, mae=3.92, r2=0.18\n",
      "[*] predict with svr model\n",
      "rmse=5.89, mae=3.94, r2=0.08\n",
      "[*] predict with xgb model\n",
      "[10:32:56] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "rmse=5.81, mae=4.07, r2=0.10\n",
      "Testset = Indy500-2017\n",
      "[*] predict with currank model\n",
      "rmse=5.76, mae=3.85, r2=-0.01\n",
      "[*] predict with avgrank model\n",
      "rmse=7.75, mae=5.10, r2=-0.82\n",
      "[*] predict with dice model\n",
      "rmse=8.19, mae=6.24, r2=-1.03\n",
      "[*] predict with lasso model\n",
      "rmse=4.71, mae=3.44, r2=0.33\n",
      "[*] predict with ridge model\n",
      "rmse=5.21, mae=3.84, r2=0.18\n",
      "[*] predict with rf model\n",
      "rmse=5.15, mae=3.76, r2=0.20\n",
      "[*] predict with svr model\n",
      "rmse=5.34, mae=3.65, r2=0.14\n",
      "[*] predict with xgb model\n",
      "[10:32:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "rmse=5.47, mae=4.19, r2=0.09\n",
      "Testset = Indy500-2018\n",
      "[*] predict with currank model\n",
      "rmse=5.60, mae=4.16, r2=-0.00\n",
      "[*] predict with avgrank model\n",
      "rmse=7.73, mae=5.85, r2=-0.90\n",
      "[*] predict with dice model\n",
      "rmse=7.98, mae=6.06, r2=-1.03\n",
      "[*] predict with lasso model\n",
      "rmse=4.83, mae=3.63, r2=0.25\n",
      "[*] predict with ridge model\n",
      "rmse=4.69, mae=3.45, r2=0.30\n",
      "[*] predict with rf model\n",
      "rmse=4.88, mae=3.66, r2=0.24\n",
      "[*] predict with svr model\n",
      "rmse=5.33, mae=3.93, r2=0.09\n",
      "[*] predict with xgb model\n",
      "[10:33:02] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "rmse=5.17, mae=3.88, r2=0.15\n",
      "Testset = Indy500-2019\n",
      "[*] predict with currank model\n",
      "rmse=6.88, mae=4.64, r2=-0.01\n",
      "[*] predict with avgrank model\n",
      "rmse=9.67, mae=6.99, r2=-0.99\n",
      "[*] predict with dice model\n",
      "rmse=9.42, mae=7.01, r2=-0.89\n",
      "[*] predict with lasso model\n",
      "rmse=6.05, mae=4.50, r2=0.22\n",
      "[*] predict with ridge model\n",
      "rmse=6.08, mae=4.57, r2=0.22\n",
      "[*] predict with rf model\n",
      "rmse=6.28, mae=4.74, r2=0.16\n",
      "[*] predict with svr model\n",
      "rmse=6.50, mae=4.43, r2=0.10\n",
      "[*] predict with xgb model\n",
      "[10:33:04] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "rmse=6.50, mae=4.91, r2=0.10\n"
     ]
    }
   ],
   "source": [
    "cols = ['runid','trainsize','testsize','testdistribution']\n",
    "cols.extend(regressors)\n",
    "print('cols:%s'%cols)\n",
    "retdf0 = pd.DataFrame([],columns=cols)\n",
    "retdf1 = pd.DataFrame([],columns=cols)\n",
    "\n",
    "events = set(stagedata['eventid'])\n",
    "\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "#events = ['Indy500']\n",
    "eventsname = [f'Indy500-{x}' for x in years]\n",
    "events_id={key:idx for idx, key in enumerate(eventsname)}\n",
    "for eventid in events:\n",
    "    print('Testset = %s'%eventsname[eventid])\n",
    "    \n",
    "    train, test, train_x, train_y, test_x, test_y = split_by_eventid(stagedata, eventid)\n",
    "    test_distribution = '+:%d,0:%d,-:%d'%(np.sum(test_y>0),np.sum(test_y==0),np.sum(test_y<0))\n",
    "    #print('Testset by stageid= %s, trainsize=%d, testsize=%d, dist=%s'%\n",
    "    #      (stageid, train_x.shape[0], test_x.shape[0], test_distribution))\n",
    "    \n",
    "    #record\n",
    "    rec0 = [eventsname[eventid],train_x.shape[0],test_x.shape[0],test_distribution]\n",
    "    rec1 = [eventsname[eventid],train_x.shape[0],test_x.shape[0],test_distribution]\n",
    "    \n",
    "    acc0 = [0 for x in range(len(regressors))]\n",
    "    acc1 = [0 for x in range(len(regressors))]\n",
    "    for idx, clf in enumerate(regressors):\n",
    "        acc = regressor_model(clf)\n",
    "        acc0[idx] = acc[0]\n",
    "        acc1[idx] = acc[2]\n",
    "\n",
    "    rec0.extend(acc0)\n",
    "    rec1.extend(acc1)\n",
    "    #print('rec:%s'%rec)\n",
    "    \n",
    "    #new df\n",
    "    df = pd.DataFrame([rec0],columns=cols)\n",
    "    retdf0 = pd.concat([retdf0, df])        \n",
    "    \n",
    "    df = pd.DataFrame([rec1],columns=cols)\n",
    "    retdf1 = pd.concat([retdf1, df])        \n",
    "\n",
    "    \n",
    "retdf0.to_csv('regressors_stagedata_splitbyevent%s_rmse.csv'%suffix)\n",
    "retdf1.to_csv('regressors_stagedata_splitbyevent%s_r2.csv'%suffix)\n",
    "\n",
    "df_event_rmse = retdf0\n",
    "df_event_r2 = retdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runid</th>\n",
       "      <th>trainsize</th>\n",
       "      <th>testsize</th>\n",
       "      <th>testdistribution</th>\n",
       "      <th>currank</th>\n",
       "      <th>avgrank</th>\n",
       "      <th>dice</th>\n",
       "      <th>lasso</th>\n",
       "      <th>ridge</th>\n",
       "      <th>rf</th>\n",
       "      <th>svr</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500-2013</td>\n",
       "      <td>1147</td>\n",
       "      <td>166</td>\n",
       "      <td>+:59,0:27,-:80</td>\n",
       "      <td>5.596386</td>\n",
       "      <td>7.429410</td>\n",
       "      <td>7.626506</td>\n",
       "      <td>5.078278</td>\n",
       "      <td>5.162019</td>\n",
       "      <td>5.054880</td>\n",
       "      <td>5.323669</td>\n",
       "      <td>5.475791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500-2014</td>\n",
       "      <td>1118</td>\n",
       "      <td>195</td>\n",
       "      <td>+:57,0:33,-:105</td>\n",
       "      <td>3.553846</td>\n",
       "      <td>5.198114</td>\n",
       "      <td>6.117949</td>\n",
       "      <td>3.727094</td>\n",
       "      <td>3.775338</td>\n",
       "      <td>4.028103</td>\n",
       "      <td>3.327721</td>\n",
       "      <td>4.126001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500-2015</td>\n",
       "      <td>1146</td>\n",
       "      <td>167</td>\n",
       "      <td>+:67,0:21,-:79</td>\n",
       "      <td>5.149701</td>\n",
       "      <td>6.615129</td>\n",
       "      <td>7.035928</td>\n",
       "      <td>4.597048</td>\n",
       "      <td>4.641885</td>\n",
       "      <td>4.596407</td>\n",
       "      <td>4.877424</td>\n",
       "      <td>4.884574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500-2016</td>\n",
       "      <td>1087</td>\n",
       "      <td>226</td>\n",
       "      <td>+:87,0:27,-:112</td>\n",
       "      <td>4.070796</td>\n",
       "      <td>5.449612</td>\n",
       "      <td>6.358407</td>\n",
       "      <td>4.025054</td>\n",
       "      <td>4.023724</td>\n",
       "      <td>3.919735</td>\n",
       "      <td>3.944889</td>\n",
       "      <td>4.066634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500-2017</td>\n",
       "      <td>1098</td>\n",
       "      <td>215</td>\n",
       "      <td>+:66,0:44,-:105</td>\n",
       "      <td>3.846512</td>\n",
       "      <td>5.103788</td>\n",
       "      <td>6.237209</td>\n",
       "      <td>3.439982</td>\n",
       "      <td>3.840743</td>\n",
       "      <td>3.755256</td>\n",
       "      <td>3.648004</td>\n",
       "      <td>4.194707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500-2018</td>\n",
       "      <td>1154</td>\n",
       "      <td>159</td>\n",
       "      <td>+:64,0:16,-:79</td>\n",
       "      <td>4.163522</td>\n",
       "      <td>5.849166</td>\n",
       "      <td>6.056604</td>\n",
       "      <td>3.625050</td>\n",
       "      <td>3.452740</td>\n",
       "      <td>3.655094</td>\n",
       "      <td>3.925686</td>\n",
       "      <td>3.877281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500-2019</td>\n",
       "      <td>1128</td>\n",
       "      <td>185</td>\n",
       "      <td>+:58,0:28,-:99</td>\n",
       "      <td>4.643243</td>\n",
       "      <td>6.994731</td>\n",
       "      <td>7.005405</td>\n",
       "      <td>4.502440</td>\n",
       "      <td>4.566593</td>\n",
       "      <td>4.736000</td>\n",
       "      <td>4.427722</td>\n",
       "      <td>4.913280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          runid trainsize testsize testdistribution   currank   avgrank  \\\n",
       "0  Indy500-2013      1147      166   +:59,0:27,-:80  5.596386  7.429410   \n",
       "0  Indy500-2014      1118      195  +:57,0:33,-:105  3.553846  5.198114   \n",
       "0  Indy500-2015      1146      167   +:67,0:21,-:79  5.149701  6.615129   \n",
       "0  Indy500-2016      1087      226  +:87,0:27,-:112  4.070796  5.449612   \n",
       "0  Indy500-2017      1098      215  +:66,0:44,-:105  3.846512  5.103788   \n",
       "0  Indy500-2018      1154      159   +:64,0:16,-:79  4.163522  5.849166   \n",
       "0  Indy500-2019      1128      185   +:58,0:28,-:99  4.643243  6.994731   \n",
       "\n",
       "       dice     lasso     ridge        rf       svr       xgb  \n",
       "0  7.626506  5.078278  5.162019  5.054880  5.323669  5.475791  \n",
       "0  6.117949  3.727094  3.775338  4.028103  3.327721  4.126001  \n",
       "0  7.035928  4.597048  4.641885  4.596407  4.877424  4.884574  \n",
       "0  6.358407  4.025054  4.023724  3.919735  3.944889  4.066634  \n",
       "0  6.237209  3.439982  3.840743  3.755256  3.648004  4.194707  \n",
       "0  6.056604  3.625050  3.452740  3.655094  3.925686  3.877281  \n",
       "0  7.005405  4.502440  4.566593  4.736000  4.427722  4.913280  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_event_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['runid', 'trainsize', 'testsize', 'testdistribution', 'currank', 'avgrank', 'dice', 'lasso', 'ridge', 'rf', 'svr', 'xgb']\n",
      "Testset = Indy500-2018\n",
      "[*] predict with currank model\n",
      "rmse=5.60, mae=4.16, r2=-0.00\n",
      "[*] predict with avgrank model\n",
      "rmse=7.73, mae=5.85, r2=-0.90\n",
      "[*] predict with dice model\n",
      "rmse=8.18, mae=6.14, r2=-1.13\n",
      "[*] predict with lasso model\n",
      "rmse=4.84, mae=3.59, r2=0.25\n",
      "[*] predict with ridge model\n",
      "rmse=4.68, mae=3.43, r2=0.30\n",
      "[*] predict with rf model\n",
      "rmse=5.07, mae=3.80, r2=0.18\n",
      "[*] predict with svr model\n",
      "rmse=5.34, mae=3.94, r2=0.09\n",
      "[*] predict with xgb model\n",
      "[10:33:07] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "rmse=5.10, mae=3.87, r2=0.17\n",
      "Testset = Indy500-2019\n",
      "[*] predict with currank model\n",
      "rmse=6.88, mae=4.64, r2=-0.01\n",
      "[*] predict with avgrank model\n",
      "rmse=9.67, mae=6.99, r2=-0.99\n",
      "[*] predict with dice model\n",
      "rmse=9.52, mae=7.07, r2=-0.93\n",
      "[*] predict with lasso model\n",
      "rmse=6.05, mae=4.49, r2=0.22\n",
      "[*] predict with ridge model\n",
      "rmse=6.10, mae=4.60, r2=0.21\n",
      "[*] predict with rf model\n",
      "rmse=6.49, mae=4.83, r2=0.10\n",
      "[*] predict with svr model\n",
      "rmse=6.55, mae=4.45, r2=0.09\n",
      "[*] predict with xgb model\n",
      "[10:33:09] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "rmse=6.87, mae=4.93, r2=-0.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runid</th>\n",
       "      <th>trainsize</th>\n",
       "      <th>testsize</th>\n",
       "      <th>testdistribution</th>\n",
       "      <th>currank</th>\n",
       "      <th>avgrank</th>\n",
       "      <th>dice</th>\n",
       "      <th>lasso</th>\n",
       "      <th>ridge</th>\n",
       "      <th>rf</th>\n",
       "      <th>svr</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500-2018</td>\n",
       "      <td>969</td>\n",
       "      <td>159</td>\n",
       "      <td>+:64,0:16,-:79</td>\n",
       "      <td>4.163522</td>\n",
       "      <td>5.849166</td>\n",
       "      <td>6.144654</td>\n",
       "      <td>3.587794</td>\n",
       "      <td>3.433554</td>\n",
       "      <td>3.800377</td>\n",
       "      <td>3.940862</td>\n",
       "      <td>3.865105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500-2019</td>\n",
       "      <td>969</td>\n",
       "      <td>185</td>\n",
       "      <td>+:58,0:28,-:99</td>\n",
       "      <td>4.643243</td>\n",
       "      <td>6.994731</td>\n",
       "      <td>7.070270</td>\n",
       "      <td>4.492015</td>\n",
       "      <td>4.600140</td>\n",
       "      <td>4.834811</td>\n",
       "      <td>4.445445</td>\n",
       "      <td>4.925282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          runid trainsize testsize testdistribution   currank   avgrank  \\\n",
       "0  Indy500-2018       969      159   +:64,0:16,-:79  4.163522  5.849166   \n",
       "0  Indy500-2019       969      185   +:58,0:28,-:99  4.643243  6.994731   \n",
       "\n",
       "       dice     lasso     ridge        rf       svr       xgb  \n",
       "0  6.144654  3.587794  3.433554  3.800377  3.940862  3.865105  \n",
       "0  7.070270  4.492015  4.600140  4.834811  4.445445  4.925282  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### train 2013-2017\n",
    "#load data\n",
    "_trim = 0\n",
    "_include_final = False\n",
    "include_str = '1' if _include_final else '0'\n",
    "suffix = f'indy500-2013-2019-end{include_str}-t{_trim}'\n",
    "output_file = f'stage-indy500-2013-2019-end{include_str}-t{_trim}.csv'\n",
    "stagedata = pd.read_csv(output_file)\n",
    "\n",
    "stagedata.fillna(0, inplace=True)\n",
    "\n",
    "cols = ['runid','trainsize','testsize','testdistribution']\n",
    "cols.extend(regressors)\n",
    "print('cols:%s'%cols)\n",
    "retdf0 = pd.DataFrame([],columns=cols)\n",
    "retdf1 = pd.DataFrame([],columns=cols)\n",
    "\n",
    "events = set(stagedata['eventid'])\n",
    "\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "#events = ['Indy500']\n",
    "eventsname = [f'Indy500-{x}' for x in years]\n",
    "events_id={key:idx for idx, key in enumerate(eventsname)}\n",
    "\n",
    "#first \n",
    "eventid = events_id['Indy500-2018']\n",
    "ignore_eventid = events_id['Indy500-2019']\n",
    "stdata_2018 = stagedata[stagedata['eventid']!=ignore_eventid]\n",
    "\n",
    "print('Testset = %s'%eventsname[eventid])\n",
    "\n",
    "train, test, train_x, train_y, test_x, test_y = split_by_eventid(stdata_2018, eventid)\n",
    "test_distribution = '+:%d,0:%d,-:%d'%(np.sum(test_y>0),np.sum(test_y==0),np.sum(test_y<0))\n",
    "#print('Testset by stageid= %s, trainsize=%d, testsize=%d, dist=%s'%\n",
    "#      (stageid, train_x.shape[0], test_x.shape[0], test_distribution))\n",
    "\n",
    "#record\n",
    "rec0 = [eventsname[eventid],train_x.shape[0],test_x.shape[0],test_distribution]\n",
    "rec1 = [eventsname[eventid],train_x.shape[0],test_x.shape[0],test_distribution]\n",
    "\n",
    "acc0 = [0 for x in range(len(regressors))]\n",
    "acc1 = [0 for x in range(len(regressors))]\n",
    "for idx, clf in enumerate(regressors):\n",
    "    acc = regressor_model(clf)\n",
    "    acc0[idx] = acc[0]\n",
    "    acc1[idx] = acc[2]\n",
    "\n",
    "rec0.extend(acc0)\n",
    "rec1.extend(acc1)\n",
    "#print('rec:%s'%rec)\n",
    "\n",
    "#new df\n",
    "df = pd.DataFrame([rec0],columns=cols)\n",
    "retdf0 = pd.concat([retdf0, df])        \n",
    "\n",
    "\n",
    "#second \n",
    "eventid = events_id['Indy500-2019']\n",
    "ignore_eventid = events_id['Indy500-2018']\n",
    "stdata_2019 = stagedata[stagedata['eventid']!=ignore_eventid]\n",
    "\n",
    "print('Testset = %s'%eventsname[eventid])\n",
    "\n",
    "train, test, train_x, train_y, test_x, test_y = split_by_eventid(stdata_2019, eventid)\n",
    "test_distribution = '+:%d,0:%d,-:%d'%(np.sum(test_y>0),np.sum(test_y==0),np.sum(test_y<0))\n",
    "#print('Testset by stageid= %s, trainsize=%d, testsize=%d, dist=%s'%\n",
    "#      (stageid, train_x.shape[0], test_x.shape[0], test_distribution))\n",
    "\n",
    "#record\n",
    "rec0 = [eventsname[eventid],train_x.shape[0],test_x.shape[0],test_distribution]\n",
    "rec1 = [eventsname[eventid],train_x.shape[0],test_x.shape[0],test_distribution]\n",
    "\n",
    "acc0 = [0 for x in range(len(regressors))]\n",
    "acc1 = [0 for x in range(len(regressors))]\n",
    "for idx, clf in enumerate(regressors):\n",
    "    acc = regressor_model(clf)\n",
    "    acc0[idx] = acc[0]\n",
    "    acc1[idx] = acc[2]\n",
    "\n",
    "rec0.extend(acc0)\n",
    "rec1.extend(acc1)\n",
    "#print('rec:%s'%rec)\n",
    "\n",
    "#new df\n",
    "df = pd.DataFrame([rec0],columns=cols)\n",
    "retdf0 = pd.concat([retdf0, df])    \n",
    "\n",
    "retdf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retdf0.to_csv(f'stint_regressor_result_t2013-2017_t{_trim}.csv', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
