{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP-pitmodel\n",
    "\n",
    "base: 18./ make_pitstop_dataset-nextpit\n",
    "\n",
    "build a pitstop dataset with <cautions_laps, pitage, gap2nextpit>\n",
    "gluonts interface of Dataset = Iterable[DataEntry], DataEntry = Dict(str, any)\n",
    "\n",
    "+ input pitstop dataset, remove pitstops with pit_oncaution = 1, refer to lapstatus_dataset-fastrun\n",
    "+ context_length = 1, prediction_length = 1\n",
    "+ target : gap to nextpit\n",
    "+ covariates are: cautions_laps, pitage, (carid, eid)\n",
    "+ modeling the distribution of nextpit-gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import random\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import inspect\n",
    "from scipy import stats\n",
    "from pathlib import Path \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pathlib import Path\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.distribution.neg_binomial import NegativeBinomialOutput\n",
    "from gluonts.distribution.student_t import StudentTOutput\n",
    "from gluonts.model.forecast import SampleForecast\n",
    "\n",
    "from indycar.model.mlp import MLPEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch_hdd/hpda/indycar/notebook/19.RankNet'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def test_flag(a, bitflag):\n",
    "    return (a & bitflag) ==  bitflag\n",
    "\n",
    "#\n",
    "# remove NaN at the tail\n",
    "# there should be no nans in the middle of the ts\n",
    "COL_LAPTIME=0\n",
    "COL_RANK=1\n",
    "COL_TRACKSTATUS=2\n",
    "COL_LAPSTATUS=3\n",
    "COL_TIMEDIFF=4\n",
    "COL_CAUTION_LAPS_INSTINT=5\n",
    "COL_LAPS_INSTINT= 6\n",
    "COL_ELAPSED_TIME= 7\n",
    "COL_LAP2NEXTPIT = 8\n",
    "\n",
    "\n",
    "MODE_ORACLE = 0\n",
    "MODE_NOLAP = 1\n",
    "MODE_NOTRACK = 2\n",
    "MODE_TESTZERO = 4\n",
    "MODE_TESTCURTRACK = 8\n",
    "#MODE_STR={MODE_ORACLE:'oracle', MODE_NOLAP:'nolap',MODE_NOTRACK:'notrack',MODE_TEST:'test'}\n",
    "\n",
    "def split_ts(rec, carno, eid):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        ts\n",
    "    output:\n",
    "        nextpit records\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    pitstops = np.where(rec[COL_LAPSTATUS,:] == 1)[0]\n",
    "    \n",
    "    if len(pitstops)==0:\n",
    "        print('no pit ts')\n",
    "        return output\n",
    "    \n",
    "    #pit_oncaution = np.zeros_like((pitstops))\n",
    "    #for pit in pitstops:\n",
    "    #    if rec[COL_TRACKSTATUS,:] == 1:\n",
    "    #        pit_oncaution = 1\n",
    "    pit_oncaution = np.zeros_like((rec[COL_LAP2NEXTPIT,:]))\n",
    "    stint_len = np.zeros_like((rec[COL_LAP2NEXTPIT,:]))\n",
    "    pos = 0\n",
    "    for pit in pitstops:\n",
    "        if rec[COL_TRACKSTATUS,pit] == 1:\n",
    "            #next pit is oncaution\n",
    "            # set pos -> pit as oncaution\n",
    "            pit_oncaution[pos:pit] = 1\n",
    "        else:\n",
    "            pit_oncaution[pos:pit] = 0\n",
    "            \n",
    "        stint_len[pos:pit] = pit - pos\n",
    "        pos = pit\n",
    "        \n",
    "            \n",
    "    #prepare output : lap2nextpit, CAUTION_LAPS_INSTINT,LAPS_INSTINT, pit_oncaution, carno, eid, lap, stintlen\n",
    "    totallen = pitstops[-1]\n",
    "    #output = np.zeros((totallen, 6 ))\n",
    "    #for idx in range(totallen):\n",
    "    #    output[idx, 0] = rec[COL_LAP2NEXTPIT ,idx]\n",
    "    #    output[idx, 1] = rec[COL_CAUTION_LAPS_INSTINT ,idx]\n",
    "    #    output[idx, 2] = rec[COL_LAPS_INSTINT ,idx]\n",
    "    #    output[idx, 3] = pit_oncaution[idx]\n",
    "    #    output[idx, 4] = carno\n",
    "    #    output[idx, 5] = eid\n",
    "        \n",
    "    for idx in range(totallen):\n",
    "        output.append([ rec[COL_LAP2NEXTPIT ,idx]\n",
    "                        ,rec[COL_CAUTION_LAPS_INSTINT ,idx]\n",
    "                        ,rec[COL_LAPS_INSTINT ,idx]\n",
    "                        ,pit_oncaution[idx]\n",
    "                        ,carno\n",
    "                        ,eid\n",
    "                        ,idx\n",
    "                        ,stint_len[idx]\n",
    "                      ])\n",
    "        \n",
    "    return output\n",
    "\n",
    "def make_dataset_byevent(test_event = 'Indy500-2018'):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    oracle_mode: false to simulate prediction in real by \n",
    "        set the covariates of track and lap status as nan in the testset\n",
    "            \n",
    "    \n",
    "    \"\"\"    \n",
    "    useeid = False\n",
    "    run_ts = COL_LAP2NEXTPIT\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        if events[_data[0]] == test_event:\n",
    "            test_mode = True\n",
    "        else:\n",
    "            test_mode = False\n",
    "            \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            \n",
    "            carno = _data[1][rowid]\n",
    "            carid = global_carids[_data[1][rowid]]\n",
    "            \n",
    "            eid = _data[0]\n",
    "            \n",
    "            # all go to train set\n",
    "            output = split_ts(rec, carno, eid)\n",
    "            #if len(output) == 0:\n",
    "            #    continue\n",
    "            \n",
    "            test_rec_cnt = 0\n",
    "            if not test_mode:\n",
    "                _train.extend(output)\n",
    "                \n",
    "            else:\n",
    "                _test.extend(output)\n",
    "                test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'train len:{len(train_set)}, test len:{len(test_set)}')\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "def save_dataset(datafile,freq, prediction_length, cardinality, train_ds, test_ds):\n",
    "    with open(datafile, 'wb') as f:\n",
    "        #pack [global_carids, laptime_data]\n",
    "        savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "        #savedata = [freq, train_set, test_set]\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_inlap_status = 0\n",
    "#years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "#events = ['Indy500']\n",
    "events = [f'Indy500-{x}' for x in years]\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "dbid = f'Indy500_{years[0]}_{years[-1]}_v9_p{_inlap_status}'\n",
    "testevent = 'Indy500-2018'\n",
    "# start from here\n",
    "import pickle\n",
    "#with open('laptime_rank_timediff_fulltest-oracle-%s.pickle'%year, 'rb') as f:\n",
    "with open(f'laptime_rank_timediff_pit-oracle-{dbid}.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    global_carids, laptime_data = pickle.load(f, encoding='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carno:1, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:4, totallen:0, nancount:200, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:6, totallen:30, nancount:170, test_reccnt:0\n",
      "carno:7, totallen:177, nancount:23, test_reccnt:0\n",
      "carno:8, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:187, nancount:13, test_reccnt:0\n",
      "carno:11, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:170, nancount:30, test_reccnt:0\n",
      "carno:16, totallen:179, nancount:21, test_reccnt:0\n",
      "carno:18, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:19, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:21, totallen:170, nancount:30, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:191, nancount:9, test_reccnt:0\n",
      "carno:41, totallen:178, nancount:22, test_reccnt:0\n",
      "carno:55, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:60, totallen:168, nancount:32, test_reccnt:0\n",
      "carno:63, totallen:45, nancount:155, test_reccnt:0\n",
      "carno:77, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:78, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:81, totallen:182, nancount:18, test_reccnt:0\n",
      "carno:83, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:91, totallen:43, nancount:157, test_reccnt:0\n",
      "carno:98, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:6, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:7, totallen:189, nancount:11, test_reccnt:0\n",
      "carno:8, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:9, totallen:152, nancount:48, test_reccnt:0\n",
      "carno:10, totallen:175, nancount:25, test_reccnt:0\n",
      "carno:11, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:43, nancount:157, test_reccnt:0\n",
      "carno:16, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:17, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:18, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:19, totallen:193, nancount:7, test_reccnt:0\n",
      "carno:20, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:33, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:34, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:41, totallen:187, nancount:13, test_reccnt:0\n",
      "carno:63, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:67, totallen:122, nancount:78, test_reccnt:0\n",
      "carno:68, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:77, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:83, totallen:148, nancount:52, test_reccnt:0\n",
      "carno:91, totallen:86, nancount:114, test_reccnt:0\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:7, totallen:200, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:8, totallen:0, nancount:200, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:149, nancount:51, test_reccnt:0\n",
      "carno:11, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:17, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:18, totallen:115, nancount:85, test_reccnt:0\n",
      "carno:19, totallen:115, nancount:85, test_reccnt:0\n",
      "carno:20, totallen:100, nancount:100, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:24, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:25, totallen:197, nancount:3, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:32, totallen:99, nancount:101, test_reccnt:0\n",
      "carno:41, totallen:169, nancount:31, test_reccnt:0\n",
      "no pit ts\n",
      "carno:43, totallen:0, nancount:200, test_reccnt:0\n",
      "carno:48, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:63, totallen:178, nancount:22, test_reccnt:0\n",
      "carno:83, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:88, totallen:61, nancount:139, test_reccnt:0\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:47, nancount:153, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:99, nancount:101, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:7, totallen:125, nancount:75, test_reccnt:0\n",
      "carno:8, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:11, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:162, nancount:38, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:16, totallen:192, nancount:8, test_reccnt:0\n",
      "carno:18, totallen:114, nancount:86, test_reccnt:0\n",
      "carno:19, totallen:193, nancount:7, test_reccnt:0\n",
      "carno:20, totallen:97, nancount:103, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:193, nancount:7, test_reccnt:0\n",
      "carno:24, totallen:65, nancount:135, test_reccnt:0\n",
      "carno:25, totallen:108, nancount:92, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:29, totallen:179, nancount:21, test_reccnt:0\n",
      "carno:35, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:41, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:42, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:61, totallen:190, nancount:10, test_reccnt:0\n",
      "carno:63, totallen:195, nancount:5, test_reccnt:0\n",
      "carno:77, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:88, totallen:194, nancount:6, test_reccnt:0\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:56, nancount:144, test_reccnt:0\n",
      "carno:5, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:7, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:8, totallen:200, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:9, totallen:28, nancount:172, test_reccnt:0\n",
      "carno:10, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:11, totallen:174, nancount:26, test_reccnt:0\n",
      "carno:12, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:16, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:17, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:18, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:19, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:24, totallen:113, nancount:87, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:112, nancount:88, test_reccnt:0\n",
      "carno:29, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:40, totallen:133, nancount:67, test_reccnt:0\n",
      "carno:44, totallen:97, nancount:103, test_reccnt:0\n",
      "carno:50, totallen:56, nancount:144, test_reccnt:0\n",
      "carno:63, totallen:186, nancount:14, test_reccnt:0\n",
      "carno:77, totallen:33, nancount:167, test_reccnt:0\n",
      "carno:83, totallen:123, nancount:77, test_reccnt:0\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:3, totallen:145, nancount:55, test_reccnt:1\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:7, totallen:184, nancount:16, test_reccnt:1\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:10, totallen:52, nancount:148, test_reccnt:1\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:13, totallen:49, nancount:151, test_reccnt:1\n",
      "carno:14, totallen:171, nancount:29, test_reccnt:1\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:17, totallen:190, nancount:10, test_reccnt:1\n",
      "carno:18, totallen:132, nancount:68, test_reccnt:1\n",
      "carno:19, totallen:196, nancount:4, test_reccnt:1\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:21, totallen:190, nancount:10, test_reccnt:1\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:24, totallen:124, nancount:76, test_reccnt:1\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:26, totallen:189, nancount:11, test_reccnt:1\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:1\n",
      "no pit ts\n",
      "carno:30, totallen:32, nancount:168, test_reccnt:1\n",
      "carno:32, totallen:109, nancount:91, test_reccnt:1\n",
      "carno:33, totallen:45, nancount:155, test_reccnt:1\n",
      "carno:59, totallen:195, nancount:5, test_reccnt:1\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:7, totallen:183, nancount:17, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:18, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:19, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:23, totallen:181, nancount:19, test_reccnt:0\n",
      "carno:24, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:26, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:30, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:32, totallen:66, nancount:134, test_reccnt:0\n",
      "carno:33, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:39, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:42, totallen:183, nancount:17, test_reccnt:0\n",
      "carno:48, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:60, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:63, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:77, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:81, totallen:54, nancount:146, test_reccnt:0\n",
      "no pit ts\n",
      "carno:88, totallen:0, nancount:200, test_reccnt:0\n",
      "carno:98, totallen:180, nancount:20, test_reccnt:0\n",
      "train len:30284, test len:4920\n"
     ]
    }
   ],
   "source": [
    "train, test =  make_dataset_byevent(test_event = 'Indy500-2018')\n",
    "#prepare output : lap2nextpit, CAUTION_LAPS_INSTINT,LAPS_INSTINT, pit_oncaution, carno, eid, lap\n",
    "df_train = pd.DataFrame(train,columns=['lap2nextpit', 'caution_laps','pitage', 'pit_oncaution', \n",
    "                 'carno','eid','lap','stint_len'])\n",
    "df_test = pd.DataFrame(test,columns=['lap2nextpit', 'caution_laps','pitage', 'pit_oncaution', \n",
    "                 'carno','eid','lap','stint_len'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = f'pitstop_nextpit_dataset-{dbid}-t{testevent}.pickle'\n",
    "with open(datafile, 'wb') as f:\n",
    "    savedata = [df_train, df_test, events, testevent]\n",
    "    pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lap2nextpit</th>\n",
       "      <th>caution_laps</th>\n",
       "      <th>pitage</th>\n",
       "      <th>pit_oncaution</th>\n",
       "      <th>carno</th>\n",
       "      <th>eid</th>\n",
       "      <th>lap</th>\n",
       "      <th>stint_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30279</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30280</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30281</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>176</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30282</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>177</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30283</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>178</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30284 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lap2nextpit  caution_laps  pitage  pit_oncaution  carno  eid  lap  \\\n",
       "0             30.0           0.0     1.0            0.0      1    0    0   \n",
       "1             29.0           0.0     2.0            0.0      1    0    1   \n",
       "2             28.0           0.0     3.0            0.0      1    0    2   \n",
       "3             27.0           1.0     4.0            0.0      1    0    3   \n",
       "4             26.0           2.0     5.0            0.0      1    0    4   \n",
       "...            ...           ...     ...            ...    ...  ...  ...   \n",
       "30279          2.0           0.0     0.0            1.0     98    6  174   \n",
       "30280          1.0           1.0     1.0            1.0     98    6  175   \n",
       "30281          2.0           0.0     0.0            1.0     98    6  176   \n",
       "30282          1.0           1.0     1.0            1.0     98    6  177   \n",
       "30283          1.0           0.0     0.0            1.0     98    6  178   \n",
       "\n",
       "       stint_len  \n",
       "0           30.0  \n",
       "1           30.0  \n",
       "2           30.0  \n",
       "3           30.0  \n",
       "4           30.0  \n",
       "...          ...  \n",
       "30279        2.0  \n",
       "30280        2.0  \n",
       "30281        2.0  \n",
       "30282        2.0  \n",
       "30283        1.0  \n",
       "\n",
       "[30284 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make gluonts\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "def makedb(data, scaler='standard', perm = True):\n",
    "    db = []\n",
    "    start = pd.Timestamp(\"01-01-2019\", freq='1min')  # can be different for each time series\n",
    "    \n",
    "    scalers = {'minmax':MinMaxScaler(), 'standard':StandardScaler()}\n",
    "    \n",
    "    if isinstance(scaler, str):\n",
    "        if scaler in scalers:\n",
    "            scaler = scalers[scaler]\n",
    "            scaler.fit(data)\n",
    "            df = scaler.transform(data)\n",
    "        else:\n",
    "            # no scaler\n",
    "            df = data\n",
    "    else:\n",
    "        #use input scaler\n",
    "        #scaler.fit(data)\n",
    "        df = scaler.transform(data)\n",
    "        \n",
    "    \n",
    "    #permute\n",
    "    if perm:\n",
    "        perm = np.random.permutation(len(df))\n",
    "        df = df[perm]\n",
    "    \n",
    "    for x in df:\n",
    "        \n",
    "        #db.append({'target':np.array(x[0]), 'feat':[np.array(x[1]),np.array(x[2])]})\n",
    "        db.append({'target':np.array([x[0]]), 'feat':np.array([x[1],x[2]]),\n",
    "                  \"start\":start, 'forecast_start':start})\n",
    "        #db.append({'target':np.array(x[0]).reshape((1,-1)), 'feat':[np.array(x[1]).reshape((1,-1)),np.array(x[2]).reshape((1,-1))]})\n",
    "        \n",
    "    return db, scaler, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fulltestdb(scaler, maxgap=60):\n",
    "    db = []\n",
    "    start = pd.Timestamp(\"01-01-2019\", freq='1min')  # can be different for each time series\n",
    "\n",
    "    data = []\n",
    "    for caution_lap in range(maxgap):\n",
    "        for pitage in range(caution_lap, maxgap):\n",
    "            data.append([0.,caution_lap, pitage ])\n",
    "    data = np.array(data)\n",
    "    \n",
    "    if not isinstance(scaler, str):\n",
    "        df = scaler.transform(data)\n",
    "    else:\n",
    "        df = data\n",
    "    \n",
    "    #data\n",
    "    print(f'make full testdb: {len(df)} records')\n",
    "    for x in df:\n",
    "        db.append({'target':np.array([x[0]]), 'feat':np.array([x[1],x[2]]),\n",
    "                  \"start\":start, 'forecast_start':start})\n",
    "            \n",
    "    return db, scaler, df, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24973 13976\n"
     ]
    }
   ],
   "source": [
    "train_sel = df_train[(df_train['pit_oncaution']==0) &(df_train['stint_len']>23)]\n",
    "train_sel_2013_2017 = train_sel[train_sel['eid']<5]\n",
    "train_all_2013_2017 = df_train[df_train['eid']<5]\n",
    "\n",
    "print(len(train_all_2013_2017), len(train_sel_2013_2017))    \n",
    "\n",
    "test_sel = df_test[(df_test['pit_oncaution']==0) &(df_test['stint_len']>23)]\n",
    "test_all = df_test\n",
    "\n",
    "#test_all = df_test[(df_test['stint_len']>23)]\n",
    "#datafile = f'pitstop_nextpit_dataset-{dbid}-t{testevent}-sel.pickle'\n",
    "#with open(datafile, 'wb') as f:\n",
    "#    savedata = [train_sel, test_sel, events, testevent]\n",
    "#    pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)\n",
    "#    \n",
    "#print(len(train_sel), len(test_sel))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = {}\n",
    "#model store\n",
    "p, t, s, e = {}, {} ,{}, {}\n",
    "\n",
    "# negbin, use no sclaer\n",
    "#train_ds, scaler = makedb(train_sel[['lap2nextpit','caution_laps','pitage']].values, scaler='')\n",
    "#train_ds, scaler = makedb(train_sel[['lap2nextpit','caution_laps','pitage']].values, scaler='minmax')\n",
    "train_ds, scaler, train_set = makedb(train_sel[['lap2nextpit','caution_laps','pitage']].values, scaler='standard')\n",
    "test_ds, _, test_set = makedb(test_sel[['lap2nextpit','caution_laps','pitage']].values, scaler, perm=False)\n",
    "\n",
    "# selected db\n",
    "trainset = train_sel_2013_2017[['lap2nextpit','caution_laps','pitage']].values\n",
    "testset = test_sel[['lap2nextpit','caution_laps','pitage']].values\n",
    "train_ds, scaler, _ = makedb(trainset, scaler='standard')\n",
    "test_ds, _, _ = makedb(testset, scaler, perm=False)\n",
    "\n",
    "_data['sel'] = [trainset, testset, train_ds, test_ds, scaler]\n",
    "\n",
    "\n",
    "# selected db\n",
    "trainset = train_all_2013_2017[['lap2nextpit','caution_laps','pitage']].values\n",
    "testset = test_all[['lap2nextpit','caution_laps','pitage']].values\n",
    "train_ds, scaler, _ = makedb(trainset, scaler='standard')\n",
    "test_ds, _, _ = makedb(testset, scaler, perm=False)\n",
    "\n",
    "_data['all'] = [trainset, testset, train_ds, test_ds, scaler]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, layers=[10,10,5], output = 'student', dropout = .5, id='all'):\n",
    "    distr_outputs ={'student':StudentTOutput(),  \n",
    "                    'negbin':NegativeBinomialOutput() \n",
    "                   }\n",
    "    if not output in distr_outputs:\n",
    "        print(f'distr_output: {output} not found error.')\n",
    "        return\n",
    "    \n",
    "    distr_output = distr_outputs[output]\n",
    "    \n",
    "    modelid = 'mlp-d%s-e%s-l%s-%s-d%s'%(id, epochs, '-'.join([str(x) for x in layers]), output, dropout)\n",
    "    \n",
    "    estimator = MLPEstimator(\n",
    "        num_hidden_dimensions=layers,\n",
    "        prediction_length=1,\n",
    "        context_length=1,\n",
    "        freq='1min',\n",
    "        dropout = dropout,\n",
    "        distr_output = distr_output,\n",
    "        trainer=Trainer(ctx=\"gpu(0)\", \n",
    "                        batch_size = 32,\n",
    "                        epochs= epochs,\n",
    "                        learning_rate=1e-3,\n",
    "                        hybridize=False,\n",
    "                        num_batches_per_epoch=100\n",
    "                       )\n",
    "    )    \n",
    "\n",
    "    predictor = estimator.train(train_ds)\n",
    "\n",
    "    return predictor, modelid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(predictor, test_ds):\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset    \n",
    "        predictor=predictor,  # predictor                                  \n",
    "        num_samples=100,  # number of sample paths we want for evaluation \n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)     \n",
    "    evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9]) \n",
    "    agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n",
    "    print(json.dumps(agg_metrics, indent=4)) \n",
    "    return tss, forecasts, agg_metrics\n",
    "\n",
    "\n",
    "def raw_eval(tss, forecasts):\n",
    "    \"\"\"\n",
    "    scaler\n",
    "    \"\"\"\n",
    "    rec = np.zeros((3))\n",
    "\n",
    "    truth, pred = [],[]\n",
    "    #go through the dataset\n",
    "    for idx in range(len(tss)):\n",
    "        rec[0] = list(tss[idx].values)[0]\n",
    "    \n",
    "        if isinstance(scaler, str):\n",
    "            truth.append(int(rec[0]))\n",
    "        else:\n",
    "            truth.append(int(scaler.inverse_transform(rec)[0]))\n",
    "    \n",
    "        rec[0] = np.mean(forecasts[idx].samples)\n",
    "        \n",
    "        if isinstance(scaler, str):\n",
    "            pred.append(int(rec[0]))    \n",
    "        else:\n",
    "            pred.append(int(scaler.inverse_transform(rec)[0]))        \n",
    "\n",
    "    #get mae\n",
    "    mae = mean_absolute_error(truth, pred)\n",
    "    print('mae = ', mae)\n",
    "    return mae\n",
    "    \n",
    "\n",
    "def save_model(predictor, outdir):\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    \n",
    "    predictor.serialize(Path(outdir)) \n",
    "\n",
    "def get_pred(tss, forecasts, idx,raw_forecast = False):\n",
    "    rec = np.zeros((3))\n",
    "    rec[0] = list(tss[idx].values)[0]\n",
    "    \n",
    "    if isinstance(scaler, str):\n",
    "        truth = int(rec[0])\n",
    "    else:\n",
    "        truth = int(scaler.inverse_transform(rec)[0])\n",
    "    \n",
    "    ret = []\n",
    "    for sample in forecasts[idx].samples:\n",
    "        rec[0] = sample\n",
    "        if isinstance(scaler, str) or raw_forecast:\n",
    "            ret.append(int(rec[0]))    \n",
    "        else:\n",
    "            ret.append(int(scaler.inverse_transform(rec)[0]))    \n",
    "        \n",
    "    print('idx:', idx, 't:', truth, 'p:', int(np.mean(ret)))\n",
    "    plt.hist(ret, bins=range(min(ret),max(ret)+1), alpha=0.7, label='%s'%idx)\n",
    "    return truth, ret\n",
    "\n",
    "def run_test(tss, forecasts, testlist, raw_forecast = False):\n",
    "    for idx in testlist:\n",
    "        get_pred(tss, forecasts, idx, raw_forecast)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pitmodel\n",
    "class PitModel():\n",
    "    \"\"\"\n",
    "     <caution_lap, pitage> -> [distribution]    \n",
    "     distribution := sorted cdf [val:probability, val2:p2, ...]\n",
    "         [0,:] -> val\n",
    "         [1,:] -> cdf p\n",
    "         \n",
    "     no scaler, raw feat and target\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, modelfile=''):\n",
    "        self.model = {}\n",
    "        self.name = ''\n",
    "        \n",
    "        if modelfile:\n",
    "            self.load_model(modelfile)\n",
    "                \n",
    "    def load_model(self, modelfile):\n",
    "        with open(modelfile, 'rb') as f:\n",
    "            self.name, self.model = pickle.load(f, encoding='latin1')\n",
    "            print(f'init model:{self.name}')\n",
    "        \n",
    "    def save_model(self, modelname, test_ds, forecasts, scaler):\n",
    "        \n",
    "        model = {}\n",
    "        \n",
    "        #get the sclaer for the first column(lap2nextpit)\n",
    "        sc, scf = '', ''\n",
    "        if isinstance(scaler, StandardScaler):\n",
    "            sc = StandardScaler()\n",
    "            sc.scale_ = scaler.scale_[0]\n",
    "            sc.mean_ = scaler.mean_[0]\n",
    "            sc.var_ = scaler.var_[0]\n",
    "\n",
    "            scf = StandardScaler()\n",
    "            scf.scale_ = scaler.scale_[1:]\n",
    "            scf.mean_ = scaler.mean_[1:]\n",
    "            scf.var_ = scaler.var_[1:]\n",
    "\n",
    "        \n",
    "        for idx, rec in enumerate(test_ds):\n",
    "            feat = rec[1:]\n",
    "                \n",
    "            key = '-'.join([str(int(x)) for x in feat])\n",
    "            \n",
    "            if not key in model:\n",
    "            \n",
    "                samples = forecasts[idx].samples.reshape(-1)\n",
    "                \n",
    "                if not isinstance(sc, str):\n",
    "                    samples = sc.inverse_transform(samples)\n",
    "                \n",
    "                #force to prediction to be valid lap2nextpit\n",
    "                samples = samples.astype(int)\n",
    "                samples = samples[samples > 0]\n",
    "\n",
    "                #\n",
    "                valset = set(list(samples))\n",
    "                plen = len(valset)\n",
    "                distr = np.zeros((2, plen))\n",
    "                distr[0, :] = sorted(valset)\n",
    "                smap = {val:id for id, val in enumerate(distr[0, :])}\n",
    "                for s in samples:\n",
    "                    distr[1,smap[s]] += 1\n",
    "                tsum = np.sum(distr[1,:])\n",
    "                distr[1, :] /= tsum\n",
    "                distr[1, :] = np.cumsum(distr[1, :])\n",
    "\n",
    "                model[key] = distr\n",
    "                \n",
    "        #save model\n",
    "        self.model = model\n",
    "        self.name = modelname\n",
    "        with open(modelname, 'wb') as f:\n",
    "            savedata = [self.name, self.model]\n",
    "            pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)        \n",
    "        print(f'save model {modelname} with {len(self.model)} keys.')\n",
    "                \n",
    "    def predict(self, *args):\n",
    "        key = '-'.join([str(int(x)) for x in args])\n",
    "        #if key in self.model:\n",
    "        try:\n",
    "            distr = self.model[key]\n",
    "            \n",
    "            #[0, 1.)\n",
    "            p = np.random.random()  \n",
    "            i = np.sum(distr[1,:] < p)\n",
    "            \n",
    "            return distr[0,i]\n",
    "        except:\n",
    "            #exception\n",
    "            #todo, backto special model\n",
    "            print(f'ERROR: key {key} not found in model')\n",
    "                       \n",
    "    def forecast_ds(self, test_ds, forecasts):\n",
    "        \"\"\"\n",
    "        test_ds as testset, the unsclaed input\n",
    "        forecasts ; the template\n",
    "        \"\"\"\n",
    "        \n",
    "        plen = len(test_ds)\n",
    "        sample_cnt = forecasts[0].samples.shape[0]\n",
    "        assert(plen == len(forecasts))\n",
    "        \n",
    "\n",
    "        #build a new forecasts object\n",
    "        nf = []\n",
    "        for fc in forecasts:\n",
    "            nfc = SampleForecast(samples = np.zeros_like(fc.samples), \n",
    "                                 freq=fc.freq, start_date=fc.start_date)\n",
    "            nf.append(nfc)\n",
    "        \n",
    "        for idx, rec in enumerate(test_ds):\n",
    "            feat = rec[1:]\n",
    "                    \n",
    "            onecast = np.zeros((sample_cnt))\n",
    "            for i in range(sample_cnt):\n",
    "                onecast[i] = self.predict(feat[0], feat[[1]])\n",
    "        \n",
    "            nf[idx].samples = onecast\n",
    "\n",
    "        return nf\n",
    "    \n",
    "\n",
    "def save_full_pitmodel(mid, runid, maxgap=60):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        p[mid]; predictor\n",
    "        runid ; 'all' or 'sel' of the trainning set\n",
    "    \"\"\"\n",
    "    \n",
    "    #get scaler\n",
    "    scaler = _data[runid][4]\n",
    "\n",
    "    # make full test set\n",
    "    test_ds, _, _, test_all = make_fulltestdb(scaler, maxgap = maxgap)\n",
    "\n",
    "    tss,forecasts, _ = eval_model(p[mid], test_ds)\n",
    "\n",
    "    pitmodel = PitModel()\n",
    "\n",
    "    pitmodel.save_model(f'pitmodel-m{maxgap}-{mid}.pickle', test_all, forecasts, scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset, train_ds, test_ds, scaler = _data['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae =  7.2231707317073175\n",
      "idx: 31 t: 18 p: 24\n",
      "idx: 816 t: 20 p: 11\n",
      "idx: 846 t: 21 p: 17\n",
      "idx: 856 t: 11 p: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pm, mid = train_model(500,dropout = 0.1)\n",
    "t[mid],s[mid], e[mid] = eval_model(pm, test_ds)\n",
    "p[mid] = pm\n",
    "\n",
    "mae = raw_eval(t[mid],s[mid])\n",
    "\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 31 t: 18 p: 24\n",
      "idx: 816 t: 20 p: 11\n",
      "idx: 846 t: 21 p: 17\n",
      "idx: 856 t: 11 p: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make full testdb: 1830 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|██████████| 1830/1830 [00:10<00:00, 170.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"MSE\": 0.7731969228788884,\n",
      "    \"abs_error\": 1333.656721007439,\n",
      "    \"abs_target_sum\": 2966.1651649956075,\n",
      "    \"abs_target_mean\": 1.6208552814183648,\n",
      "    \"seasonal_error\": NaN,\n",
      "    \"MASE\": NaN,\n",
      "    \"sMAPE\": 0.6198420666028964,\n",
      "    \"MSIS\": NaN,\n",
      "    \"QuantileLoss[0.1]\": 546.8604449627725,\n",
      "    \"Coverage[0.1]\": 0.44808743169398907,\n",
      "    \"QuantileLoss[0.5]\": 1333.656721007439,\n",
      "    \"Coverage[0.5]\": 0.7524590163934426,\n",
      "    \"QuantileLoss[0.9]\": 760.8667135679584,\n",
      "    \"Coverage[0.9]\": 0.7912568306010929,\n",
      "    \"RMSE\": 0.8793161677570182,\n",
      "    \"NRMSE\": 0.5425013434805563,\n",
      "    \"ND\": 0.44962321611292133,\n",
      "    \"wQuantileLoss[0.1]\": 0.1843661477170582,\n",
      "    \"wQuantileLoss[0.5]\": 0.44962321611292133,\n",
      "    \"wQuantileLoss[0.9]\": 0.256515288678837,\n",
      "    \"mean_wQuantileLoss\": 0.2968348841696055,\n",
      "    \"MAE_Coverage\": 0.23642987249544625\n",
      "}\n",
      "save model pitmodel-m60-mlp-dall-e500-l10-10-5-student-d0.1.pickle with 1830 keys.\n"
     ]
    }
   ],
   "source": [
    "save_full_pitmodel(mid, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|██████████| 3638/3638 [00:19<00:00, 182.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"MSE\": 0.40147687182793795,\n",
      "    \"abs_error\": 1727.264953942361,\n",
      "    \"abs_target_sum\": 3779.0495181689503,\n",
      "    \"abs_target_mean\": 1.03877117046975,\n",
      "    \"seasonal_error\": NaN,\n",
      "    \"MASE\": NaN,\n",
      "    \"sMAPE\": 0.7341374790495121,\n",
      "    \"MSIS\": NaN,\n",
      "    \"QuantileLoss[0.1]\": 613.4820881473909,\n",
      "    \"Coverage[0.1]\": 0.07174271577789995,\n",
      "    \"QuantileLoss[0.5]\": 1727.264953942361,\n",
      "    \"Coverage[0.5]\": 0.19461242440901594,\n",
      "    \"QuantileLoss[0.9]\": 1598.6573588345072,\n",
      "    \"Coverage[0.9]\": 0.44310060472787244,\n",
      "    \"RMSE\": 0.6336220259965226,\n",
      "    \"NRMSE\": 0.6099726715653727,\n",
      "    \"ND\": 0.45706332918846393,\n",
      "    \"wQuantileLoss[0.1]\": 0.1623376685586907,\n",
      "    \"wQuantileLoss[0.5]\": 0.45706332918846393,\n",
      "    \"wQuantileLoss[0.9]\": 0.42303159859336775,\n",
      "    \"mean_wQuantileLoss\": 0.34747753211350746,\n",
      "    \"MAE_Coverage\": 0.2635147516950706\n",
      "}\n",
      "mae =  4.658878504672897\n",
      "idx: 31 t: 31 p: 27\n",
      "idx: 816 t: 44 p: 28\n",
      "idx: 846 t: 14 p: 9\n",
      "idx: 856 t: 4 p: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAWCUlEQVR4nO3df5BV5Z3n8fdX7IhRR4zdWij2QsZkxDLYxh51CosiugZ0LHEsQiaZzTIpLcYo/ogxM06SWnXcKUfdiY7FlC6CAcsQND9NxVmMQTFr3KAQcUTJgCambAVBhEoUZWj87h/3YAj2pW/3vX2b0/1+Vd3qe55z7j1fjt0fn3rOOc+JzESSVD77DXYBkqT+McAlqaQMcEkqKQNckkrKAJekktq/mTtrbW3NsWPHNnOXklR6K1eufD0z2/Zsb2qAjx07lhUrVjRzl5JUehHxm57aax5CiYgREfF0RPyoWB4XEcsj4oWIuC8iPtCoYiVJvevLGPgVwJrdlm8Cbs3MY4EtwIWNLEyStHc1BXhEjAH+HJhXLAdwBvCdYpOFwPkDUaAkqWe1joHfBvwtcEixfDiwNTO7i+Uu4OiePhgRs4BZAO3t7f2vVJIKO3bsoKuri3feeWewS2mokSNHMmbMGFpaWmravtcAj4hzgY2ZuTIiJve1oMycC8wF6OzsdOIVSXXr6urikEMOYezYsVQGBMovM9m8eTNdXV2MGzeups/U0gOfCJwXEecAI4E/Av4FGBUR+xe98DHAK/2sW5L65J133hlS4Q0QERx++OFs2rSp5s/0OgaemX+fmWMycyzwl8AjmflXwKPA9GKzmcADfS9ZkvpnKIX3Ln39N9VzJ+bfAVdFxAtUxsTn1/FdkqQ+6tONPJm5DFhWvP8VcErjS5KkvrlwwVMN/b75f/2ne13/zjvvMGnSJLZv3053dzfTp0/n+uuvZ86cOdx22228+OKLbNq0idbW1obWtaem3om5L3n54i9UXXfMnXc0sRJJZXPAAQfwyCOPcPDBB7Njxw5OP/10zj77bCZOnMi5557L5MmTm1LHsA1wSeqviODggw8GKpc07tixg4jgpJNOamodzkYoSf2wc+dOOjo6OOKIIzjrrLM49dRTm16DAS5J/TBixAhWrVpFV1cXTz75JKtXr256DQa4JNVh1KhRfOITn2DJkiVN37cBLkl9tGnTJrZu3QrA22+/zcMPP8xxxx3X9Do8iSmp9Hq77K/R1q9fz8yZM9m5cyfvvvsuM2bM4Nxzz+X222/n5ptvZsOGDUyYMIFzzjmHefPmDVgdBrgk9dGECRN4+umn39d++eWXc/nllzetDodQJKmkDHBJKikDXJJKygCXpJIywCWppAxwSSopLyOUVH6LPt3Y7/vsfb1ucuuttzJv3jwigo997GN84xvfYN68eVWnk122bBlXXnklO3bsoLW1lccee6zuMg1wSeqjV155hdtvv53nn3+eAw88kBkzZrB48eKq08lu3bqVSy65hCVLltDe3s7GjRsbUocBLkn90N3dzdtvv01LSwvbtm3jqKOOqjqd7KJFi7jgggtob28H4IgjjmhIDY6BS1IfHX300Vx99dW0t7czevRoDj30UD75yU9W3X7t2rVs2bKFyZMnc/LJJ3PPPfc0pI5eAzwiRkbEkxHxTEQ8FxHXF+0LIuLXEbGqeHU0pCJJ2sdt2bKFBx54gF//+te8+uqrvPXWW9x7771Vt+/u7mblypU8+OCDPPTQQ9xwww2sXbu27jpq6YFvB87IzBOBDmBqRJxWrPtyZnYUr1V1VyNJJfCTn/yEcePG0dbWRktLCxdccAFPPPFE1e3HjBnDlClTOOigg2htbWXSpEk888wzddfRa4BnxZvFYkvxyrr3LEkl1d7ezs9//nO2bdtGZrJ06VLGjx9fdftp06bx+OOP093dzbZt21i+fPlet69VTScxI2IEsBI4FvjXzFweEV8A/jEi/gewFLgmM7f38NlZwCzgvQF8SWqoGi77a6RTTz2V6dOn8/GPf5z999+fk046iVmzZlWdTnb8+PFMnTqVCRMmsN9++3HRRRdxwgkn1F1HZNbemY6IUcD3gcuAzcAG4APAXODFzPyHvX2+s7MzV6xY0f9qG8in0kvltWbNmob0YPdFPf3bImJlZnbuuW2frkLJzK3Ao8DUzFxfDK9sB74BnFJHzZKkPqrlKpS2oudNRBwInAX8MiJGF20BnA80/4mekjSM1TIGPhpYWIyD7wfcn5k/iohHIqINCGAVcPEA1ilJ2kOvAZ6Z/w687/aizDxjQCqSJNXEOzElqaQMcEkqKSezklR6s5fObuj3zTlzTq/b9DSd7MiRI4HK0+nvvvtu3nzzzfe2v//++7nuuuuICE488UQWLVpUd532wCWpj3ZNJ7tixQpWr17Nzp07Wbx4MQArVqxgy5Ytf7D9unXruPHGG/nZz37Gc889x2233daQOgxwSeqHXdPJ7ro9/qijjmLnzp18+ctf5uabb/6Dbe+66y4uvfRSDjvsMMDpZCVp0FSbTnbOnDmcd955jB49+g+2X7t2LWvXrmXixImcdtppLFmypCF1OAYuSX20+3Syo0aN4lOf+hT33HMP3/72t1m2bNn7tu/u7mbdunUsW7aMrq4uJk2axLPPPsuoUaPqqsMeuCT1UU/TyV577bW88MILHHvssYwdO5Zt27Zx7LHHApXpZM877zxaWloYN24cH/3oR1m3bl3ddRjgktRHPU0ne9VVV7FhwwZeeuklXnrpJT74wQ/ywgsvAHD++ee/1zN//fXXWbt2LR/+8IfrrsMhFEmlV8tlf41UbTrZaqZMmcKPf/xjjj/+eEaMGMEtt9zC4YcfXncdfZpOtl5OJyupEZxOtsIhFEkqKQNckkrKAJekkjLAJamkDHBJKikDXJJKqtfrwCNiJPBT4IBi++9k5rURMQ5YDBwOrAQ+l5n/OZDFSlJP9nZZcH/UcilxT9PJXnzxxTz22GMceuihACxYsICOjg4Ali1bxpVXXsmOHTtobW3lscceq7vOWm7k2Q6ckZlvRkQL8HhE/B/gKuDWzFwcEXcCFwJeQC1pyNs1nezzzz/PgQceyIwZM96bTvaWW25h+vTpf7D91q1bueSSS1iyZAnt7e1s3LixIXX0OoSSFbtmJW8pXgmcAXynaF9I5cn0kjQs9DSdbDWLFi3iggsuoL29HWjydLIRMSIiVgEbgYeBF4GtmdldbNIFHN2QiiRpH1dtOlmAr371q0yYMIEvfvGLbN++HahMJ7tlyxYmT57MySefzD333NOQOmoK8MzcmZkdwBjgFOC4WncQEbMiYkVErNi0aVM/y5Skfcfu08m++uqrvPXWW9x7773ceOON/PKXv+Spp57ijTfe4KabbgIqvfWVK1fy4IMP8tBDD3HDDTewdu3auuvo01UombkVeBT4M2BUROwaQx8DvFLlM3MzszMzO9va2uoqVpL2BT1NJ/vEE08wevRoIoIDDjiAz3/+8zz55JNAZTrZKVOmcNBBB9Ha2sqkSZN45pln6q6j1wCPiLaIGFW8PxA4C1hDJch3jdTPBB6ouxpJKoGeppMdP34869evByAz+cEPfsAJJ5wAwLRp03j88cffGy9fvnx5QybjquUqlNHAwogYQSXw78/MH0XE88DiiPifwNPA/LqrkaR+aPYMotWmkz377LPZtGkTmUlHRwd33nknAOPHj2fq1KlMmDCB/fbbj4suuui9cK+H08n2wOlkpX2b08lWeCemJJWUAS5JJWWASyqlZg7/Nktf/00GuKTSGTlyJJs3bx5SIZ6ZbN68mZEjR9b8GR9qLKl0xowZQ1dXF0Pt5sCRI0cyZsyYmrc3wEtm9tLZVdc1+8nc0mBpaWlh3Lhxg13GoHMIRZJKygCXpJIywCWppAxwSSqpIX0Ss9GPWZKkfYk9cEkqKQNckkrKAJekkjLAJamkDHBJKikDXJJKygCXpJKq5aHGx0TEoxHxfEQ8FxFXFO3XRcQrEbGqeJ0z8OVKknap5UaebuBLmfmLiDgEWBkRDxfrbs3M/zVw5UmSquk1wDNzPbC+eP+7iFgDHD3QhUmS9q5PY+ARMRY4CVheNM2OiH+PiLsj4rAqn5kVESsiYsVQm3xdkgZTzQEeEQcD3wWuzMzfAncAfwx0UOmh/3NPn8vMuZnZmZmdbW1tDShZkgQ1BnhEtFAJ729m5vcAMvO1zNyZme8CdwGnDFyZkqQ91XIVSgDzgTWZ+fXd2kfvttlfAKsbX54kqZparkKZCHwOeDYiVhVtXwE+ExEdQAIvAX8zIBVKknpUy1UojwPRw6p/a3w5kqRaeSemJJWUAS5JJWWAS1JJGeCSVFIGuCSV1JB+Kv1wM3vp7Krr5pw5p4mVSGoGe+CSVFIGuCSVlAEuSSVlgEtSSXkSUyq7RZ/uuf2z9zW3DjWdPXBJKikDXJJKygCXpJIywCWppDyJKZXAhQueqrpu/geaWIj2KfbAJamkankm5jER8WhEPB8Rz0XEFUX7hyLi4YhYV/w8bODLlSTtUksPvBv4UmYeD5wGXBoRxwPXAEsz8yPA0mJZktQkvQZ4Zq7PzF8U738HrAGOBqYBC4vNFgLnD1SRkqT369MYeESMBU4ClgNHZub6YtUG4MiGViZJ2quar0KJiIOB7wJXZuZvI37/oPrMzIjIKp+bBcwCaG9vr6/aJnn54i/02H7MnXc0uRJJqq6mHnhEtFAJ729m5veK5tciYnSxfjSwsafPZubczOzMzM62trZG1CxJorarUAKYD6zJzK/vtuqHwMzi/UzggcaXJ0mqppYhlInA54BnI2JV0fYV4J+A+yPiQuA3wIyBKVGS1JNeAzwzHweiyuozG1uOJKlW3okpSSVlgEtSSRngklRSBrgklZQBLkkl5Xzg0r6i2sOJAbi6aWWoPOyBS1JJGeCSVFIGuCSVlAEuSSVlgEtSSRngklRSBrgklZQBLkklZYBLUkkZ4JJUUt5KLzXZhQue6rF9/geaXIhKzx64JJVULQ81vjsiNkbE6t3arouIVyJiVfE6Z2DLlCTtqZYe+AJgag/tt2ZmR/H6t8aWJUnqTa8Bnpk/Bd5oQi2SpD6o5yTm7Ij478AK4EuZuaWnjSJiFjALoL29vY7dSUPbqpe3Vl95ZN8/11FnPdr39fck5h3AH1P5HVkP/HO1DTNzbmZ2ZmZnW1tbP3cnSdpTvwI8M1/LzJ2Z+S5wF3BKY8uSJPWmXwEeEaN3W/wLYHW1bSVJA6PXMfCI+BYwGWiNiC7gWmByRHQACbwE/M0A1ihJ6kGvAZ6Zn+mhef4A1CKpiste+9pgl6B9kHdiSlJJGeCSVFIGuCSVlAEuSSVlgEtSSTkf+D5q9tLZTfm+OWfOaeh+JDWPPXBJKikDXJJKygCXpJIywCWppAxwSSopA1ySSsoAl6SSMsAlqaQMcEkqKe/ElIaqRZ+uvu6z9zWvDg0Ye+CSVFIGuCSVVK8BHhF3R8TGiFi9W9uHIuLhiFhX/DxsYMuUJO2plh74AmDqHm3XAEsz8yPA0mJZktREvQZ4Zv4UeGOP5mnAwuL9QuD8BtclSepFf8fAj8zM9cX7DcCR1TaMiFkRsSIiVmzatKmfu5Mk7anuk5iZmUDuZf3czOzMzM62trZ6dydJKvQ3wF+LiNEAxc+NjStJklSL/gb4D4GZxfuZwAONKUeSVKtaLiP8FvD/gD+JiK6IuBD4J+CsiFgH/NdiWZLURL3eSp+Zn6my6swG1yKpgVa9vLXquo4m1qGB452YklRSBrgklZQBLkklZYBLUkk5H3gfvHzxF6quO+bOO5pYicrsste+NtglOFf4EGEPXJJKygCXpJIywCWppAxwSSopA1ySSsqrUAbR7KWzB7sESSVmD1ySSsoAl6SSMsAlqaQMcEkqKU9iSgNg1U1TBruEvXKu8KHBHrgklVRdPfCIeAn4HbAT6M7MzkYUJUnqXSOGUD6Rma834HskSX3gEIoklVS9PfAEfhwRCfzvzJy75wYRMQuYBdDe3l7n7nq2t3m6B9u+frdlf+qbc+acAahEUl/V2wM/PTM/DpwNXBoRk/bcIDPnZmZnZna2tbXVuTtJ0i51BXhmvlL83Ah8HzilEUVJknrX7wCPiIMi4pBd74FPAqsbVZgkae/qGQM/Evh+ROz6nkWZuaQhVUmSetXvAM/MXwEnNrAWSVIfeCu9VIcLFzzVY/tlTa5Dw5PXgUtSSRngklRSBrgklZQBLkkl5UlMqQ6Xvfa1wS5Bw5g9cEkqKQNckkrKAJekkjLAJamkPImp4WXRp3tu/+x9VT9S7W5LGJp3XFb7987/6z9tciXqjT1wSSopA1ySSsoAl6SSMsAlqaRKcxKzmQ8ufvb1nh8s9LHWE5pWw1DU8JNj/TghWc2qm6ZUXTcUT1TuTbW7S1fdVP0zHceM6nnFXv5b7O2Yd/zdQ9V3ti+r9jsJ/fq97I09cEkqKQNckkqqrgCPiKkR8R8R8UJEXNOooiRJvavnqfQjgH8FzgaOBz4TEcc3qjBJ0t7V0wM/BXghM3+Vmf8JLAamNaYsSVJvIjP798GI6cDUzLyoWP4ccGpmzt5ju1nArGLxT4D/6H+5VbUCrw/A95aNx6HC41DhcagYCsfhv2Rm256NA34ZYWbOBeYO5D4iYkVmdg7kPsrA41DhcajwOFQM5eNQzxDKK8Axuy2PKdokSU1QT4A/BXwkIsZFxAeAvwR+2JiyJEm96fcQSmZ2R8Rs4CFgBHB3Zj7XsMr6ZkCHaErE41DhcajwOFQM2ePQ75OYkqTB5Z2YklRSBrgklVSpA3w438ofEXdHxMaIWL1b24ci4uGIWFf8PGwwa2yGiDgmIh6NiOcj4rmIuKJoH1bHIiJGRsSTEfFMcRyuL9rHRcTy4m/kvuKCgyEvIkZExNMR8aNieUgeh9IGuLfyswCYukfbNcDSzPwIsLRYHuq6gS9l5vHAacClxe/BcDsW24EzMvNEoAOYGhGnATcBt2bmscAW4MJBrLGZrgDW7LY8JI9DaQOcYX4rf2b+FHhjj+ZpwMLi/ULg/KYWNQgyc31m/qJ4/zsqf7RHM8yORVa8WSy2FK8EzgC+U7QP+eMAEBFjgD8H5hXLwRA9DmUO8KOBl3db7irahrMjM3N98X4DcORgFtNsETEWOAlYzjA8FsWwwSpgI/Aw8CKwNTO7i02Gy9/IbcDfAu8Wy4czRI9DmQNce5GV60OHzTWiEXEw8F3gysz87e7rhsuxyMydmdlB5a7oU4DjBrmkpouIc4GNmblysGtphtI8Uq0H3sr/fq9FxOjMXB8Ro6n0xIa8iGihEt7fzMzvFc3D8lgAZObWiHgU+DNgVETsX/Q+h8PfyETgvIg4BxgJ/BHwLwzR41DmHri38r/fD4GZxfuZwAODWEtTFOOb84E1mfn13VYNq2MREW0RMap4fyBwFpXzAY8C04vNhvxxyMy/z8wxmTmWSiY8kpl/xRA9DqW+E7P4v+xt/P5W/n8c5JKaJiK+BUymMlXma8C1wA+A+4F24DfAjMzc80TnkBIRpwP/F3iW3495foXKOPiwORYRMYHKybkRVDpm92fmP0TEh6mc4P8Q8DTw3zJz++BV2jwRMRm4OjPPHarHodQBLknDWZmHUCRpWDPAJamkDHBJKikDXJJKygCXpJIywCWppAxwSSqp/w/8rOcka65I3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runid = 'sel'\n",
    "#trainset, testset, train_ds, test_ds, scaler = _data[runid]\n",
    "#pm, mid = train_model(500,dropout = 0.1, id = runid)\n",
    "t[mid],s[mid], e[mid] = eval_model(pm,test_ds)\n",
    "p[mid] = pm\n",
    "mae = raw_eval(t[mid],s[mid])\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 31 t: 31 p: 27\n",
      "idx: 816 t: 44 p: 28\n",
      "idx: 846 t: 14 p: 9\n",
      "idx: 856 t: 4 p: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4920"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make full testdb: 2145 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|██████████| 2145/2145 [00:12<00:00, 174.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"MSE\": 1.4126874378783432,\n",
      "    \"abs_error\": 2116.3819956522934,\n",
      "    \"abs_target_sum\": 3779.5638833230714,\n",
      "    \"abs_target_mean\": 1.7620344444396603,\n",
      "    \"seasonal_error\": NaN,\n",
      "    \"MASE\": NaN,\n",
      "    \"sMAPE\": 0.7475020353194095,\n",
      "    \"MSIS\": NaN,\n",
      "    \"QuantileLoss[0.1]\": 2419.7226531269066,\n",
      "    \"Coverage[0.1]\": 0.627972027972028,\n",
      "    \"QuantileLoss[0.5]\": 2116.3819956522934,\n",
      "    \"Coverage[0.5]\": 0.661072261072261,\n",
      "    \"QuantileLoss[0.9]\": 1264.6830327334515,\n",
      "    \"Coverage[0.9]\": 0.6881118881118881,\n",
      "    \"RMSE\": 1.1885652854926998,\n",
      "    \"NRMSE\": 0.67454145930199,\n",
      "    \"ND\": 0.559954021412525,\n",
      "    \"wQuantileLoss[0.1]\": 0.6402121323583598,\n",
      "    \"wQuantileLoss[0.5]\": 0.559954021412525,\n",
      "    \"wQuantileLoss[0.9]\": 0.3346108365342712,\n",
      "    \"mean_wQuantileLoss\": 0.5115923301017187,\n",
      "    \"MAE_Coverage\": 0.3003108003108003\n",
      "}\n",
      "save model pitmodel-m65-mlp-dsel-e500-l10-10-5-student-d0.1.pickle with 2145 keys.\n"
     ]
    }
   ],
   "source": [
    "#mid =  'mlp-dsel-e500-l10-10-5-student-d0.1'\n",
    "save_full_pitmodel(mid, 'sel', maxgap=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(500,dropout = 0.1)\n",
    "t[mid],s[mid], e[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(2000,dropout = 0.1)\n",
    "t[mid],s[mid], e[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "save_model(p[mid], mid)\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(200,dropout = 0.1, layers=[8,4])\n",
    "t[mid],s[mid], e[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[mid],s[mid], e[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(500, layers=[10,5])\n",
    "t[mid],s[mid] = eval_model(pm)\n",
    "p[mid] = pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(500, layers=[32,16,8,4])\n",
    "t[mid],s[mid] = eval_model(pm)\n",
    "p[mid] = pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(2000, layers=[32,16,8,4])\n",
    "t[mid],s[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "run_test(t[mid], s[mid], [31,816,846,856])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec = next(iter(train_ds))\n",
    "trec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(tss, forecasts, [31,816,846,856])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sel.iloc[816]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sel.iloc[836]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[mid],s[mid] = eval_model(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred(t[mid],s[mid], 816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm, mid = train_model(2,dropout = 0.1)\n",
    "#t[mid],s[mid], e[mid] = eval_model(pm)\n",
    "p[mid] = pm\n",
    "#run_test(t[mid], s[mid], [31,816,846,856])\n",
    "\n",
    "#mid = 'mlp-e2000-l10-10-5-student-d0.1'\n",
    "save_model(p[mid], mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test pitmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_scaler = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 'mlp-e2000-l10-10-5-student-d0.1'\n",
    "t[id],s[id], e[id] = eval_model(p[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = s[id]\n",
    "tss = t[id]\n",
    "\n",
    "scaler = _scaler\n",
    "testset = test_sel[['lap2nextpit','caution_laps','pitage']].values\n",
    "\n",
    "pitmodel = PitModel()\n",
    "\n",
    "pitmodel.save_model('pitmodel_test', testset, forecasts, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcasts = pitmodel.forecast_ds(testset, forecasts)\n",
    "scaler = _scaler\n",
    "run_test(tss, newcasts, [31,816,846,856],raw_forecast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pitmodel.model['0-0'][0,:], pitmodel.model['0-0'][1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pitmodel.model['10-13'][0,:], pitmodel.model['10-13'][1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitmodel.model['0-0'][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = _scaler\n",
    "test_all = df_test[['lap2nextpit','caution_laps','pitage']].values\n",
    "test_ds, _, test_set = makedb(test_all, scaler, perm=False)\n",
    "\n",
    "id = 'mlp-e2000-l10-10-5-student-d0.1'\n",
    "t[id],s[id], e[id] = eval_model(p[id])\n",
    "forecasts = s[id]\n",
    "tss = t[id]\n",
    "\n",
    "pitmodel = PitModel()\n",
    "\n",
    "pitmodel.save_model(f'mlp-{id}.pickle', test_all, forecasts, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testall_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = _scaler\n",
    "maxgap = 60\n",
    "test_ds, _, test_set, test_all = make_fulltestdb(scaler, maxgap = maxgap)\n",
    "\n",
    "id = 'mlp-e2000-l10-10-5-student-d0.1'\n",
    "\n",
    "t[id],s[id], e[id] = eval_model(p[id])\n",
    "forecasts = s[id]\n",
    "tss = t[id]\n",
    "\n",
    "pitmodel = PitModel()\n",
    "\n",
    "pitmodel.save_model(f'pitmodel-m{maxgap}-{id}.pickle', test_all, forecasts, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitmodel.model['0-0'][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pitmodel.model['0-0'][0,:], pitmodel.model['0-0'][1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['mlp-dsel-e500-l10-10-5-student-d0.1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
