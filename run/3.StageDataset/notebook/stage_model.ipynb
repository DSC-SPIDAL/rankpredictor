{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stage_model\n",
    "\n",
    "prediction models on stage dataset\n",
    "\n",
    "data format:\n",
    "    target , eventid ,    car_number,    stageid,     features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# to use only one GPU.\n",
    "# use this on r-001\n",
    "# otherwise comment\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "#import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulid regression model\n",
    "def get_classifier(classifier = 'lr'):\n",
    "    \n",
    "    class_weight = None\n",
    "    \n",
    "    if classifier == \"lsvc\":\n",
    "        clf = LinearSVC(penalty='l1',dual=False, tol=1e-3, class_weight=class_weight )\n",
    "    elif classifier == \"lsvcl2\":\n",
    "        clf = LinearSVC(penalty='l2', tol=1e-4, class_weight=class_weight)\n",
    "    elif classifier == 'rf':\n",
    "        #clf = RandomForestClassifier(n_estimators=100, n_jobs=4,criterion='entropy', min_samples_split=1,class_weight = class_weight)\n",
    "        clf = RandomForestClassifier(n_estimators=100, n_jobs=-1,criterion='entropy', class_weight = class_weight)\n",
    "    elif classifier == 'lr':\n",
    "        clf = LogisticRegression(class_weight = class_weight, n_jobs=-1, fit_intercept = False, verbose = 0)\n",
    "    elif classifier == 'lrbias':\n",
    "        clf = LogisticRegression(class_weight = class_weight, n_jobs=-1, fit_intercept = True, verbose = 1)\n",
    "    elif classifier == 'lrl1':\n",
    "        clf = LogisticRegression(class_weight = class_weight, penalty='l1',n_jobs=-1)\n",
    "    elif classifier == 'xgb':\n",
    "        clf = xgb.XGBClassifier(booster = 'gbtree', nthread = -1, subsample = 1, n_estimators = 600, colsample_bytree = 1, max_depth = 3, min_child_weight = 1)\n",
    "    else:\n",
    "        clf = None\n",
    "        \n",
    "    return clf\n",
    "\n",
    "def evaluate(test_y, pred_y):\n",
    "    precision = metrics.precision_score(test_y, pred_y, average=None) \n",
    "    recall = metrics.recall_score(test_y, pred_y, average=None)\n",
    "    score = metrics.accuracy_score(test_y, pred_y)\n",
    "    print('precision=%s, recall=%s, accuracy=%.2f'%(precision,recall, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 805 entries, 0 to 804\n",
      "Data columns (total 18 columns):\n",
      "Unnamed: 0            805 non-null int64\n",
      "target                805 non-null int64\n",
      "eventid               805 non-null int64\n",
      "car_number            805 non-null int64\n",
      "stageid               805 non-null int64\n",
      "firststage            805 non-null int64\n",
      "pit_in_caution        805 non-null int64\n",
      "start_position        805 non-null int64\n",
      "start_rank            805 non-null int64\n",
      "start_rank_ratio      805 non-null float64\n",
      "top_pack              805 non-null int64\n",
      "bottom_pack           805 non-null int64\n",
      "average_rank          805 non-null float64\n",
      "average_rank_all      805 non-null float64\n",
      "change_in_rank        805 non-null int64\n",
      "change_in_rank_all    805 non-null float64\n",
      "rate_of_change        805 non-null int64\n",
      "rate_of_change_all    805 non-null float64\n",
      "dtypes: float64(5), int64(13)\n",
      "memory usage: 113.3 KB\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "stagedata = pd.read_csv('stage-2018.csv')\n",
    "stagedata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#events = ['Phoenix','Indy500','Texas','Iowa','Pocono','Gateway']\n",
    "events = list(stagedata['eventid'])\n",
    "train = stagedata[stagedata['eventid']!=1].to_numpy()\n",
    "test  = stagedata[stagedata['eventid']==1].to_numpy()\n",
    "\n",
    "train_x = train[:,2:]\n",
    "train_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in train[:,1]])\n",
    "test_x = test[:,2:]\n",
    "test_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in test[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. predict with current rank, rankchg = 0\n",
      "precision=[0.         0.20888889 0.        ], recall=[0. 1. 0.], accuracy=0.21\n",
      "2. predict with average rankchg (change_in_rank_all):idx = 15\n",
      "precision=[0.4017094  0.24528302 0.23636364], recall=[0.48958333 0.27659574 0.15853659], accuracy=0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "### baseline\n",
    "\n",
    "#1. predict with current rank, rankchg = 0\n",
    "print('1. predict with current rank, rankchg = 0')\n",
    "pred_y_simple = np.zeros_like(test_y)\n",
    "evaluate(test_y, pred_y_simple)\n",
    "\n",
    "#2. predict with average rankchg (change_in_rank_all):idx = 15\n",
    "print('2. predict with average rankchg (change_in_rank_all):idx = 15')\n",
    "change_in_rank_all = test[:,15]\n",
    "pred_y_avg = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in change_in_rank_all])\n",
    "evaluate(test_y, pred_y_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.56834532 0.33333333 0.58441558], recall=[0.82291667 0.06382979 0.54878049], accuracy=0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    }
   ],
   "source": [
    "### test learning models\n",
    "clf = get_classifier()\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "pred_y = clf.predict(test_x)\n",
    "precision = metrics.precision_score(test_y, pred_y, average=None) \n",
    "recall = metrics.recall_score(test_y, pred_y, average=None)\n",
    "score = metrics.accuracy_score(test_y, pred_y)\n",
    "print('precision=%s, recall=%s, accuracy=%.2f'%(precision,recall, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
