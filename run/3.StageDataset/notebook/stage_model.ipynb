{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stage_model\n",
    "\n",
    "prediction models on stage dataset\n",
    "\n",
    "data format:\n",
    "    target , eventid ,    car_number,    stageid,     features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# to use only one GPU.\n",
    "# use this on r-001\n",
    "# otherwise comment\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulid regression model\n",
    "classifiers = ['currank','avgrank','dice','lr','lrl1','lsvc','lsvcl2','rf','lrbias','xgb']\n",
    "def get_classifier(classifier = 'lr'):\n",
    "    \n",
    "    class_weight = None\n",
    "    \n",
    "    if classifier == \"lsvc\":\n",
    "        clf = LinearSVC(penalty='l1',dual=False, tol=1e-3, class_weight=class_weight )\n",
    "    elif classifier == \"lsvcl2\":\n",
    "        clf = LinearSVC(penalty='l2', tol=1e-4, class_weight=class_weight)\n",
    "    elif classifier == 'rf':\n",
    "        #clf = RandomForestClassifier(n_estimators=100, n_jobs=4,criterion='entropy', min_samples_split=1,class_weight = class_weight)\n",
    "        clf = RandomForestClassifier(n_estimators=100, n_jobs=-1,criterion='entropy', class_weight = class_weight)\n",
    "    elif classifier == 'lr':\n",
    "        clf = LogisticRegression(class_weight = class_weight, n_jobs=-1, fit_intercept = False, verbose = 0)\n",
    "    elif classifier == 'lrbias':\n",
    "        clf = LogisticRegression(class_weight = class_weight, n_jobs=-1, fit_intercept = True, verbose = 1)\n",
    "    elif classifier == 'lrl1':\n",
    "        clf = LogisticRegression(class_weight = class_weight, penalty='l1',n_jobs=-1)\n",
    "    elif classifier == 'xgb':\n",
    "        clf = xgb.XGBClassifier(booster = 'gbtree', nthread = -1, subsample = 1, n_estimators = 600, colsample_bytree = 1, max_depth = 3, min_child_weight = 1)\n",
    "    elif classifier == 'dice':\n",
    "        clf = RandomDice('1234')\n",
    "    elif classifier == 'currank':\n",
    "        clf = CurRank()\n",
    "    elif classifier == 'avgrank':\n",
    "        clf = AverageRank()        \n",
    "    else:\n",
    "        clf = None\n",
    "        \n",
    "    return clf\n",
    "\n",
    "\n",
    "class CurRank():\n",
    "    \"\"\"\n",
    "    predict with current rank\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    def predict(self, test_x):\n",
    "        pred_y = [0 for x in range(test_x.shape[0])]\n",
    "        return np.array(pred_y)\n",
    "    \n",
    "class AverageRank():\n",
    "    \"\"\"\n",
    "    print('[*] predict with average rankchg (change_in_rank_all):idx = 15')\n",
    "    change_in_rank_all = test[:,15]\n",
    "    pred_y_avg = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in change_in_rank_all])\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    def predict(self, test_x):\n",
    "        pred_y = []\n",
    "        for x in test_x:\n",
    "            #13, change_in_rank_all\n",
    "            pred_y.append(x[13])\n",
    "        pred_y_avg = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in pred_y])\n",
    "        return np.array(pred_y_avg)   \n",
    "\n",
    "class RandomDice():\n",
    "    \"\"\"\n",
    "    a random dice model\n",
    "    \"\"\"\n",
    "    def __init__(self, seed='1234'):\n",
    "        self.dist = []\n",
    "        self.val = []\n",
    "        random.seed(seed)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        total = y.shape[0]\n",
    "        yval = set(y)\n",
    "        \n",
    "        ratio = 0.\n",
    "        for val in yval:\n",
    "            self.val.append(val)\n",
    "            ratio += np.sum(y==val)*1.0 / total\n",
    "            self.dist.append(ratio)\n",
    "            \n",
    "    def predict(self, test_x):\n",
    "        pred_y = []\n",
    "        for x in test_x:\n",
    "            dice = random.random()\n",
    "            #search in self.dist\n",
    "            find_idx = -1\n",
    "            for idx, ratio in enumerate(self.dist):\n",
    "                if dice <= ratio:\n",
    "                    find_idx = idx\n",
    "                    break\n",
    "            \n",
    "            #or the last one match\n",
    "            pred_y.append(self.val[find_idx])\n",
    "            \n",
    "        return np.array(pred_y)\n",
    "\n",
    "def evaluate(test_y, pred_y):\n",
    "    precision = metrics.precision_score(test_y, pred_y, average=None) \n",
    "    recall = metrics.recall_score(test_y, pred_y, average=None)\n",
    "    f1 = metrics.f1_score(test_y, pred_y, average=None)\n",
    "    accuracy = metrics.accuracy_score(test_y, pred_y)\n",
    "    print('precision=%s, recall=%s, f1=%s, accuracy=%.2f'%(precision,recall, f1, accuracy))\n",
    "    return accuracy\n",
    "    \n",
    "#\n",
    "#features\n",
    "#    cols=[Myidx, 'target','eventid','car_number','stageid',\n",
    "#             'firststage','pit_in_caution','start_position',\n",
    "#             'start_rank','start_rank_ratio','top_pack','bottom_pack',\n",
    "#             'average_rank','average_rank_all',\n",
    "#             'change_in_rank','change_in_rank_all','rate_of_change','rate_of_change_all']    \n",
    "def split_by_eventid(stagedata, eventid):\n",
    "    \"\"\"\n",
    "    split by eventid\n",
    "    \"\"\"\n",
    "    #if not eventid in stagedata:\n",
    "    #    print('error, %d not found in stagedata'%eventid)\n",
    "    #    return\n",
    "    \n",
    "    train = stagedata[stagedata['eventid'] != eventid].to_numpy()\n",
    "    test  = stagedata[stagedata['eventid'] == eventid].to_numpy()\n",
    "\n",
    "    #2:car_number\n",
    "    train_x = train[:,2:]\n",
    "    train_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in train[:,1]])\n",
    "    test_x = test[:,2:]\n",
    "    test_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in test[:,1]])\n",
    "    \n",
    "    return train, test, train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def split_by_stageid(stagedata, stageid):\n",
    "    \"\"\"\n",
    "    split by stageid\n",
    "    \"\"\"\n",
    "    #if not eventid in stagedata:\n",
    "    #    print('error, %d not found in stagedata'%eventid)\n",
    "    #    return\n",
    "    \n",
    "    train = stagedata[stagedata['stageid'] <= stageid].to_numpy()\n",
    "    test  = stagedata[stagedata['stageid'] > stageid].to_numpy()\n",
    "\n",
    "    train_x = train[:,2:]\n",
    "    train_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in train[:,1]])\n",
    "    test_x = test[:,2:]\n",
    "    test_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in test[:,1]])\n",
    "    \n",
    "    return train, test, train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "### baseline\n",
    "def baseline_model():\n",
    "    #1. predict with current rank, rankchg = 0\n",
    "    print('[*] predict with current rank, rankchg = 0')\n",
    "    pred_y_simple = np.zeros_like(test_y)\n",
    "    score1 = evaluate(test_y, pred_y_simple)\n",
    "\n",
    "    #2. predict with average rankchg (change_in_rank_all):idx = 15\n",
    "    print('[*] predict with average rankchg (change_in_rank_all):idx = 15')\n",
    "    change_in_rank_all = test[:,15]\n",
    "    pred_y_avg = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in change_in_rank_all])\n",
    "    score2 = evaluate(test_y, pred_y_avg)\n",
    "    return score1, score2\n",
    "\n",
    "def classifier_model(name='lr'):\n",
    "    ### test learning models\n",
    "    print('[*] predict with %s model'%name)\n",
    "    clf = get_classifier(name)\n",
    "    clf.fit(train_x, train_y)\n",
    "\n",
    "    pred_y = clf.predict(test_x)\n",
    "    score = evaluate(test_y, pred_y)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 805 entries, 0 to 804\n",
      "Data columns (total 18 columns):\n",
      "Unnamed: 0            805 non-null int64\n",
      "target                805 non-null int64\n",
      "eventid               805 non-null int64\n",
      "car_number            805 non-null int64\n",
      "stageid               805 non-null int64\n",
      "firststage            805 non-null int64\n",
      "pit_in_caution        805 non-null int64\n",
      "start_position        805 non-null int64\n",
      "start_rank            805 non-null int64\n",
      "start_rank_ratio      805 non-null float64\n",
      "top_pack              805 non-null int64\n",
      "bottom_pack           805 non-null int64\n",
      "average_rank          805 non-null float64\n",
      "average_rank_all      805 non-null float64\n",
      "change_in_rank        805 non-null int64\n",
      "change_in_rank_all    805 non-null float64\n",
      "rate_of_change        805 non-null int64\n",
      "rate_of_change_all    805 non-null float64\n",
      "dtypes: float64(5), int64(13)\n",
      "memory usage: 113.3 KB\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "stagedata = pd.read_csv('stage-2018.csv')\n",
    "stagedata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>eventid</th>\n",
       "      <th>car_number</th>\n",
       "      <th>stageid</th>\n",
       "      <th>firststage</th>\n",
       "      <th>pit_in_caution</th>\n",
       "      <th>start_position</th>\n",
       "      <th>start_rank</th>\n",
       "      <th>start_rank_ratio</th>\n",
       "      <th>top_pack</th>\n",
       "      <th>bottom_pack</th>\n",
       "      <th>average_rank</th>\n",
       "      <th>average_rank_all</th>\n",
       "      <th>change_in_rank</th>\n",
       "      <th>change_in_rank_all</th>\n",
       "      <th>rate_of_change</th>\n",
       "      <th>rate_of_change_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.025641</td>\n",
       "      <td>7.025641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.328947</td>\n",
       "      <td>3.921739</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.736842</td>\n",
       "      <td>4.523256</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>8</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-7</td>\n",
       "      <td>-1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.025641</td>\n",
       "      <td>15.025641</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>14.976744</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.887324</td>\n",
       "      <td>16.166667</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>15.932773</td>\n",
       "      <td>7</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.660377</td>\n",
       "      <td>17.697674</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.041667</td>\n",
       "      <td>18.209091</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.897436</td>\n",
       "      <td>7.897436</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.112676</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>4.988439</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.025641</td>\n",
       "      <td>5.025641</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.138889</td>\n",
       "      <td>3.801802</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.825397</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.974359</td>\n",
       "      <td>17.974359</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.301370</td>\n",
       "      <td>13.625000</td>\n",
       "      <td>-8</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.622951</td>\n",
       "      <td>11.861272</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.563636</td>\n",
       "      <td>10.583333</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.051282</td>\n",
       "      <td>10.051282</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.162162</td>\n",
       "      <td>7.504425</td>\n",
       "      <td>-5</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.758621</td>\n",
       "      <td>6.573099</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>74</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.701754</td>\n",
       "      <td>3.701754</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.064516</td>\n",
       "      <td>3.369748</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>76</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.981481</td>\n",
       "      <td>3.248555</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.254545</td>\n",
       "      <td>5.254545</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>79</td>\n",
       "      <td>-3</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.298246</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.017857</td>\n",
       "      <td>5.529762</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>81</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.514793</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>82</td>\n",
       "      <td>-8</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>83</td>\n",
       "      <td>-3</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>-8</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.080645</td>\n",
       "      <td>12.672131</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.163636</td>\n",
       "      <td>12.203390</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>10</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>87</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>88</td>\n",
       "      <td>-2</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.890909</td>\n",
       "      <td>19.890909</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>89</td>\n",
       "      <td>-2</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.685185</td>\n",
       "      <td>19.788991</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.090909</td>\n",
       "      <td>19.219512</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.954545</td>\n",
       "      <td>18.569565</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>92</td>\n",
       "      <td>-6</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>93</td>\n",
       "      <td>-2</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.547170</td>\n",
       "      <td>13.547170</td>\n",
       "      <td>-6</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.807692</td>\n",
       "      <td>12.685714</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>95</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.654206</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>96</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.603774</td>\n",
       "      <td>14.956250</td>\n",
       "      <td>9</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>9</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>97</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.019231</td>\n",
       "      <td>15.892857</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>99</td>\n",
       "      <td>-2</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.773585</td>\n",
       "      <td>7.773585</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.660714</td>\n",
       "      <td>8.229358</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>102</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.472727</td>\n",
       "      <td>8.646341</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.021739</td>\n",
       "      <td>9.823810</td>\n",
       "      <td>5</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>805 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  target  eventid  car_number  stageid  firststage  \\\n",
       "0             0       0        0           1        0           0   \n",
       "1             1      -5        0           1        1           1   \n",
       "2             2       3        0           1        2           1   \n",
       "3             3      -4        0           1        3           1   \n",
       "4             4       0        0           1        4           1   \n",
       "5             5      -1        0           4        0           0   \n",
       "6             6      -3        0           4        1           1   \n",
       "7             7       3        0           4        2           1   \n",
       "8             8       7        0           4        3           1   \n",
       "9             9      -1        0           4        4           1   \n",
       "10           10      -1        0           4        5           1   \n",
       "11           11      -1        0           4        6           1   \n",
       "12           12       3        0           5        0           0   \n",
       "13           13      -3        0           5        1           1   \n",
       "14           14      -3        0           5        2           1   \n",
       "15           15       4        0           5        3           1   \n",
       "16           16      -1        0           6        0           0   \n",
       "17           17      -2        0           6        1           1   \n",
       "18           18      -2        0           6        2           1   \n",
       "19           19       1        0           6        3           1   \n",
       "20           20       1        0           9        0           0   \n",
       "21           21      -8        0           9        1           1   \n",
       "22           22      -3        0           9        2           1   \n",
       "23           23      -2        0           9        3           1   \n",
       "24           24      -1        0           9        4           1   \n",
       "25           25      -1        0          10        0           0   \n",
       "26           26      -5        0          10        1           1   \n",
       "27           27      -1        0          10        2           1   \n",
       "28           28      15        0          10        3           1   \n",
       "29           29       1        0          12        0           0   \n",
       "..          ...     ...      ...         ...      ...         ...   \n",
       "775          74      -1        5          27        1           1   \n",
       "776          75       1        5          27        2           1   \n",
       "777          76      -1        5          27        3           1   \n",
       "778          77       0        5          28        0           0   \n",
       "779          78       1        5          28        1           1   \n",
       "780          79      -3        5          28        2           1   \n",
       "781          80       0        5          28        3           1   \n",
       "782          81      16        5          28        4           1   \n",
       "783          82      -8        5          30        0           0   \n",
       "784          83      -3        5          30        1           1   \n",
       "785          84       7        5          30        2           1   \n",
       "786          85       0        5          30        3           1   \n",
       "787          86       0        5          59        0           0   \n",
       "788          87      -1        5          59        1           1   \n",
       "789          88      -2        5          59        2           1   \n",
       "790          89      -2        5          59        3           1   \n",
       "791          90       2        5          59        4           1   \n",
       "792          91       0        5          59        5           1   \n",
       "793          92      -6        5          88        0           0   \n",
       "794          93      -2        5          88        1           1   \n",
       "795          94       0        5          88        2           1   \n",
       "796          95       9        5          88        3           1   \n",
       "797          96      -1        5          88        4           1   \n",
       "798          97      -1        5          88        5           1   \n",
       "799          98       0        5          88        6           1   \n",
       "800          99      -2        5          98        0           0   \n",
       "801         100       0        5          98        1           1   \n",
       "802         101       0        5          98        2           1   \n",
       "803         102       5        5          98        3           1   \n",
       "804         103       1        5          98        4           1   \n",
       "\n",
       "     pit_in_caution  start_position  start_rank  start_rank_ratio  top_pack  \\\n",
       "0                 0               7           7          0.304348         0   \n",
       "1                 1               7           7          0.304348         0   \n",
       "2                 0               7           2          0.086957         1   \n",
       "3                 0               7           5          0.217391         1   \n",
       "4                 1               7           1          0.043478         1   \n",
       "5                 0              16          16          0.695652         0   \n",
       "6                 1              16          15          0.652174         0   \n",
       "7                 1              16          12          0.521739         0   \n",
       "8                 0              16          15          0.652174         0   \n",
       "9                 0              16          22          0.956522         0   \n",
       "10                0              16          21          0.913043         0   \n",
       "11                1              16          20          0.869565         0   \n",
       "12                0               5           5          0.217391         1   \n",
       "13                1               5           8          0.347826         0   \n",
       "14                0               5           5          0.217391         1   \n",
       "15                0               5           2          0.086957         1   \n",
       "16                0               6           6          0.260870         0   \n",
       "17                1               6           5          0.217391         1   \n",
       "18                0               6           3          0.130435         1   \n",
       "19                0               6           1          0.043478         1   \n",
       "20                0              17          17          0.739130         0   \n",
       "21                1              17          18          0.782609         0   \n",
       "22                0              17          10          0.434783         0   \n",
       "23                0              17           7          0.304348         0   \n",
       "24                1              17           5          0.217391         1   \n",
       "25                0              11          11          0.478261         0   \n",
       "26                1              11          10          0.434783         0   \n",
       "27                0              11           5          0.217391         1   \n",
       "28                0              11           4          0.173913         1   \n",
       "29                0               3           3          0.130435         1   \n",
       "..              ...             ...         ...               ...       ...   \n",
       "775               0               2           3          0.142857         1   \n",
       "776               0               2           2          0.095238         1   \n",
       "777               1               2           3          0.142857         1   \n",
       "778               0               5           5          0.238095         1   \n",
       "779               0               5           5          0.238095         1   \n",
       "780               0               5           6          0.285714         0   \n",
       "781               1               5           3          0.142857         1   \n",
       "782               1               5           3          0.142857         1   \n",
       "783               0              13          13          0.619048         0   \n",
       "784               0              13           5          0.238095         1   \n",
       "785               0              13           2          0.095238         1   \n",
       "786               1              13           9          0.428571         0   \n",
       "787               0              20          20          0.952381         0   \n",
       "788               1              20          20          0.952381         0   \n",
       "789               0              20          19          0.904762         0   \n",
       "790               0              20          17          0.809524         0   \n",
       "791               0              20          15          0.714286         0   \n",
       "792               0              20          17          0.809524         0   \n",
       "793               0              19          19          0.904762         0   \n",
       "794               0              19          13          0.619048         0   \n",
       "795               0              19          11          0.523810         0   \n",
       "796               0              19          11          0.523810         0   \n",
       "797               0              19          20          0.952381         0   \n",
       "798               1              19          19          0.904762         0   \n",
       "799               0              19          18          0.857143         0   \n",
       "800               0              10          10          0.476190         0   \n",
       "801               0              10           8          0.380952         0   \n",
       "802               0              10           8          0.380952         0   \n",
       "803               0              10           8          0.380952         0   \n",
       "804               0              10          13          0.619048         0   \n",
       "\n",
       "     bottom_pack  average_rank  average_rank_all  change_in_rank  \\\n",
       "0              0      7.000000          7.000000               0   \n",
       "1              0      7.025641          7.025641               0   \n",
       "2              0      2.328947          3.921739              -5   \n",
       "3              0      5.736842          4.523256               3   \n",
       "4              0      3.071429          4.166667              -4   \n",
       "5              0     16.000000         16.000000               0   \n",
       "6              0     15.025641         15.025641              -1   \n",
       "7              0     14.500000         14.976744              -3   \n",
       "8              0     16.887324         16.166667               3   \n",
       "9              1     10.600000         15.932773               7   \n",
       "10             1     21.660377         17.697674              -1   \n",
       "11             1     20.041667         18.209091              -1   \n",
       "12             0      5.000000          5.000000               0   \n",
       "13             0      7.897436          7.897436               3   \n",
       "14             0      5.112676          6.100000              -3   \n",
       "15             0      3.047619          4.988439              -3   \n",
       "16             0      6.000000          6.000000               0   \n",
       "17             0      5.025641          5.025641              -1   \n",
       "18             0      3.138889          3.801802              -2   \n",
       "19             0      2.825397          3.448276              -2   \n",
       "20             0     17.000000         17.000000               0   \n",
       "21             1     17.974359         17.974359               1   \n",
       "22             0     11.301370         13.625000              -8   \n",
       "23             0      8.622951         11.861272              -3   \n",
       "24             0      6.563636         10.583333              -2   \n",
       "25             0     11.000000         11.000000               0   \n",
       "26             0     10.051282         10.051282              -1   \n",
       "27             0      6.162162          7.504425              -5   \n",
       "28             0      4.758621          6.573099              -1   \n",
       "29             0      3.000000          3.000000               0   \n",
       "..           ...           ...               ...             ...   \n",
       "775            0      3.701754          3.701754               1   \n",
       "776            0      3.064516          3.369748              -1   \n",
       "777            0      2.981481          3.248555               1   \n",
       "778            0      5.000000          5.000000               0   \n",
       "779            0      5.254545          5.254545               0   \n",
       "780            0      6.298246          5.785714               1   \n",
       "781            0      5.017857          5.529762              -3   \n",
       "782            0      3.000000          5.514793               0   \n",
       "783            0     13.000000         13.000000               0   \n",
       "784            0     12.250000         12.250000              -8   \n",
       "785            0     13.080645         12.672131              -3   \n",
       "786            0     11.163636         12.203390               7   \n",
       "787            1     20.000000         20.000000               0   \n",
       "788            1     20.000000         20.000000               0   \n",
       "789            1     19.890909         19.890909              -1   \n",
       "790            1     19.685185         19.788991              -2   \n",
       "791            0     18.090909         19.219512              -2   \n",
       "792            1     16.954545         18.569565               2   \n",
       "793            1     19.000000         19.000000               0   \n",
       "794            0     13.547170         13.547170              -6   \n",
       "795            0     11.807692         12.685714              -2   \n",
       "796            0     11.000000         12.654206               0   \n",
       "797            1     19.603774         14.956250               9   \n",
       "798            1     19.166667         15.250000              -1   \n",
       "799            1     18.019231         15.892857              -1   \n",
       "800            0     10.000000         10.000000               0   \n",
       "801            0      7.773585          7.773585              -2   \n",
       "802            0      8.660714          8.229358               0   \n",
       "803            0      9.472727          8.646341               0   \n",
       "804            0     14.021739          9.823810               5   \n",
       "\n",
       "     change_in_rank_all  rate_of_change  rate_of_change_all  \n",
       "0              0.000000               0            0.000000  \n",
       "1              0.000000               0            0.000000  \n",
       "2             -2.500000               0            0.000000  \n",
       "3             -0.666667               8            1.500000  \n",
       "4             -1.500000              -7           -1.333333  \n",
       "5              0.000000               0            0.000000  \n",
       "6             -1.000000               0            0.000000  \n",
       "7             -2.000000               0            0.000000  \n",
       "8             -0.333333               6            2.000000  \n",
       "9              1.500000               4            2.666667  \n",
       "10             1.000000              -8            0.000000  \n",
       "11             0.666667               0            0.000000  \n",
       "12             0.000000               0            0.000000  \n",
       "13             3.000000               0            0.000000  \n",
       "14             0.000000               0            0.000000  \n",
       "15            -1.000000               0           -3.000000  \n",
       "16             0.000000               0            0.000000  \n",
       "17            -1.000000               0            0.000000  \n",
       "18            -1.500000               0            0.000000  \n",
       "19            -1.666667               0           -0.500000  \n",
       "20             0.000000               0            0.000000  \n",
       "21             1.000000               0            0.000000  \n",
       "22            -3.500000               0            0.000000  \n",
       "23            -3.333333               5           -2.000000  \n",
       "24            -3.000000               1           -1.000000  \n",
       "25             0.000000               0            0.000000  \n",
       "26            -1.000000               0            0.000000  \n",
       "27            -3.000000               0            0.000000  \n",
       "28            -2.333333               4            0.000000  \n",
       "29             0.000000               0            0.000000  \n",
       "..                  ...             ...                 ...  \n",
       "775            1.000000               0            0.000000  \n",
       "776            0.000000               0            0.000000  \n",
       "777            0.333333               2            0.000000  \n",
       "778            0.000000               0            0.000000  \n",
       "779            0.000000               0            0.000000  \n",
       "780            0.500000               0            0.000000  \n",
       "781           -0.666667              -4           -1.500000  \n",
       "782           -0.500000               3            0.000000  \n",
       "783            0.000000               0            0.000000  \n",
       "784           -8.000000               0            0.000000  \n",
       "785           -5.500000               0            0.000000  \n",
       "786           -1.333333              10            7.500000  \n",
       "787            0.000000               0            0.000000  \n",
       "788            0.000000               0            0.000000  \n",
       "789           -1.000000               0            0.000000  \n",
       "790           -1.500000               0            0.000000  \n",
       "791           -1.666667               0           -0.500000  \n",
       "792           -0.750000               4            1.000000  \n",
       "793            0.000000               0            0.000000  \n",
       "794           -6.000000               0            0.000000  \n",
       "795           -4.000000               0            0.000000  \n",
       "796           -2.666667               2            3.000000  \n",
       "797            0.250000               9            5.000000  \n",
       "798            0.000000             -10            1.250000  \n",
       "799           -0.166667               0            1.000000  \n",
       "800            0.000000               0            0.000000  \n",
       "801           -2.000000               0            0.000000  \n",
       "802           -1.000000               0            0.000000  \n",
       "803           -0.666667               0            1.000000  \n",
       "804            0.750000               5            2.333333  \n",
       "\n",
       "[805 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stagedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['runid', 'trainsize', 'testsize', 'testdistribution', 'currank', 'avgrank', 'dice', 'lr', 'lrl1', 'lsvc', 'lsvcl2', 'rf', 'lrbias', 'xgb']\n",
      "Testset = Phoenix\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.14035088 0.        ], recall=[0. 1. 0.], f1=[0.         0.24615385 0.        ], accuracy=0.14\n",
      "[*] predict with avgrank model\n",
      "precision=[0.48275862 0.16129032 0.16      ], recall=[0.46666667 0.3125     0.10526316], f1=[0.47457627 0.21276596 0.12698413], accuracy=0.32\n",
      "[*] predict with dice model\n",
      "precision=[0.52173913 0.2        0.31578947], recall=[0.4        0.375      0.31578947], f1=[0.45283019 0.26086957 0.31578947], accuracy=0.37\n",
      "[*] predict with lr model\n",
      "precision=[0.625      0.27272727 0.4516129 ], recall=[0.75       0.1875     0.36842105], f1=[0.68181818 0.22222222 0.4057971 ], accuracy=0.54\n",
      "[*] predict with lrl1 model\n",
      "precision=[0.62666667 0.27272727 0.46428571], recall=[0.78333333 0.1875     0.34210526], f1=[0.6962963  0.22222222 0.39393939], accuracy=0.55\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.62121212 0.25       0.41666667], recall=[0.68333333 0.1875     0.39473684], f1=[0.65079365 0.21428571 0.40540541], accuracy=0.52\n",
      "[*] predict with lsvcl2 model\n",
      "precision=[0.625      0.375      0.66666667], recall=[0.91666667 0.1875     0.31578947], f1=[0.74324324 0.25       0.42857143], accuracy=0.61\n",
      "[*] predict with rf model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.63076923 0.26315789 0.6       ], recall=[0.68333333 0.3125     0.47368421], f1=[0.656      0.28571429 0.52941176], accuracy=0.56\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.63768116 0.25       0.45454545], recall=[0.73333333 0.1875     0.39473684], f1=[0.68217054 0.21428571 0.42253521], accuracy=0.54\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.58333333 0.21875    0.54545455], recall=[0.58333333 0.4375     0.31578947], f1=[0.58333333 0.29166667 0.4       ], accuracy=0.47\n",
      "rec:['Phoenix', 691, 114, '+:38,0:16,-:60', 0.14035087719298245, 0.32456140350877194, 0.3684210526315789, 0.543859649122807, 0.5526315789473685, 0.5175438596491229, 0.6140350877192983, 0.5614035087719298, 0.543859649122807, 0.47368421052631576]\n",
      "Testset = Indy500\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.20888889 0.        ], recall=[0. 1. 0.], f1=[0.         0.34558824 0.        ], accuracy=0.21\n",
      "[*] predict with avgrank model\n",
      "precision=[0.4017094  0.24528302 0.23636364], recall=[0.48958333 0.27659574 0.15853659], f1=[0.44131455 0.26       0.18978102], accuracy=0.32\n",
      "[*] predict with dice model\n",
      "precision=[0.47619048 0.26315789 0.38095238], recall=[0.52083333 0.31914894 0.29268293], f1=[0.49751244 0.28846154 0.33103448], accuracy=0.40\n",
      "[*] predict with lr model\n",
      "precision=[0.56834532 0.33333333 0.58441558], recall=[0.82291667 0.06382979 0.54878049], f1=[0.67234043 0.10714286 0.56603774], accuracy=0.56\n",
      "[*] predict with lrl1 model\n",
      "precision=[0.5620438  0.27272727 0.58441558], recall=[0.80208333 0.06382979 0.54878049], f1=[0.66094421 0.10344828 0.56603774], accuracy=0.56\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.55555556 0.3        0.57746479], recall=[0.83333333 0.06382979 0.5       ], f1=[0.66666667 0.10526316 0.53594771], accuracy=0.55\n",
      "[*] predict with lsvcl2 model\n",
      "precision=[0.59813084 0.32142857 0.56451613], recall=[0.66666667 0.38297872 0.42682927], f1=[0.63054187 0.34951456 0.48611111], accuracy=0.52\n",
      "[*] predict with rf model\n",
      "precision=[0.54054054 0.7        0.59701493], recall=[0.83333333 0.14893617 0.48780488], f1=[0.6557377  0.24561404 0.53691275], accuracy=0.56\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.5620438  0.27272727 0.58441558], recall=[0.80208333 0.06382979 0.54878049], f1=[0.66094421 0.10344828 0.56603774], accuracy=0.56\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.57024793 0.31707317 0.55555556], recall=[0.71875    0.27659574 0.42682927], f1=[0.6359447  0.29545455 0.48275862], accuracy=0.52\n",
      "rec:['Indy500', 580, 225, '+:82,0:47,-:96', 0.2088888888888889, 0.3244444444444444, 0.39555555555555555, 0.5644444444444444, 0.5555555555555556, 0.5511111111111111, 0.52, 0.5644444444444444, 0.5555555555555556, 0.52]\n",
      "Testset = Texas\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.26771654 0.        ], recall=[0. 1. 0.], f1=[0.         0.42236025 0.        ], accuracy=0.27\n",
      "[*] predict with avgrank model\n",
      "precision=[0.37037037 0.3255814  0.2       ], recall=[0.37037037 0.41176471 0.15384615], f1=[0.37037037 0.36363636 0.17391304], accuracy=0.31\n",
      "[*] predict with dice model\n",
      "precision=[0.30357143 0.23333333 0.31707317], recall=[0.31481481 0.20588235 0.33333333], f1=[0.30909091 0.21875    0.325     ], accuracy=0.29\n",
      "[*] predict with lr model\n",
      "precision=[0.6440678  0.57894737 0.55102041], recall=[0.7037037  0.32352941 0.69230769], f1=[0.67256637 0.41509434 0.61363636], accuracy=0.60\n",
      "[*] predict with lrl1 model\n",
      "precision=[0.63076923 0.625      0.56521739], recall=[0.75925926 0.29411765 0.66666667], f1=[0.68907563 0.4        0.61176471], accuracy=0.61\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.63636364 0.61111111 0.60465116], recall=[0.77777778 0.32352941 0.66666667], f1=[0.7        0.42307692 0.63414634], accuracy=0.62\n",
      "[*] predict with lsvcl2 model\n",
      "precision=[0.66666667 0.55555556 0.34042553], recall=[0.18518519 0.29411765 0.82051282], f1=[0.28985507 0.38461538 0.48120301], accuracy=0.41\n",
      "[*] predict with rf model\n",
      "precision=[0.69565217 0.31818182 0.37288136], recall=[0.59259259 0.20588235 0.56410256], f1=[0.64       0.25       0.44897959], accuracy=0.48\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.63492063 0.57894737 0.57777778], recall=[0.74074074 0.32352941 0.66666667], f1=[0.68376068 0.41509434 0.61904762], accuracy=0.61\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.55263158 0.35294118 0.38888889], recall=[0.38888889 0.17647059 0.71794872], f1=[0.45652174 0.23529412 0.5045045 ], accuracy=0.43\n",
      "rec:['Texas', 678, 127, '+:39,0:34,-:54', 0.2677165354330709, 0.31496062992125984, 0.29133858267716534, 0.5984251968503937, 0.6062992125984252, 0.6220472440944882, 0.4094488188976378, 0.48031496062992124, 0.6062992125984252, 0.4330708661417323]\n",
      "Testset = Iowa\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.25688073 0.        ], recall=[0. 1. 0.], f1=[0.         0.40875912 0.        ], accuracy=0.26\n",
      "[*] predict with avgrank model\n",
      "precision=[0.30232558 0.20689655 0.35135135], recall=[0.33333333 0.21428571 0.30952381], f1=[0.31707317 0.21052632 0.32911392], accuracy=0.29\n",
      "[*] predict with dice model\n",
      "precision=[0.25531915 0.18518519 0.31428571], recall=[0.30769231 0.17857143 0.26190476], f1=[0.27906977 0.18181818 0.28571429], accuracy=0.26\n",
      "[*] predict with lr model\n",
      "precision=[0.39393939 0.15625    0.72727273], recall=[0.66666667 0.17857143 0.19047619], f1=[0.4952381  0.16666667 0.30188679], accuracy=0.36\n",
      "[*] predict with lrl1 model\n",
      "precision=[0.39130435 0.1        0.8       ], recall=[0.69230769 0.10714286 0.19047619], f1=[0.5        0.10344828 0.30769231], accuracy=0.35\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.36842105 0.08695652 0.8       ], recall=[0.71794872 0.07142857 0.19047619], f1=[0.48695652 0.07843137 0.30769231], accuracy=0.35\n",
      "[*] predict with lsvcl2 model\n",
      "precision=[0.41176471 0.09090909 0.40740741], recall=[0.17948718 0.03571429 0.78571429], f1=[0.25       0.05128205 0.53658537], accuracy=0.38\n",
      "[*] predict with rf model\n",
      "precision=[0.35616438 0.10526316 0.52941176], recall=[0.66666667 0.07142857 0.21428571], f1=[0.46428571 0.08510638 0.30508475], accuracy=0.34\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.3880597  0.12903226 0.72727273], recall=[0.66666667 0.14285714 0.19047619], f1=[0.49056604 0.13559322 0.30188679], accuracy=0.35\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.33333333 0.13513514 0.5       ], recall=[0.46153846 0.17857143 0.21428571], f1=[0.38709677 0.15384615 0.3       ], accuracy=0.29\n",
      "rec:['Iowa', 696, 109, '+:42,0:28,-:39', 0.25688073394495414, 0.29357798165137616, 0.25688073394495414, 0.3577981651376147, 0.3486238532110092, 0.3486238532110092, 0.3761467889908257, 0.3394495412844037, 0.3486238532110092, 0.29357798165137616]\n",
      "Testset = Pocono\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.48412698 0.        ], recall=[0. 1. 0.], f1=[0.         0.65240642 0.        ], accuracy=0.48\n",
      "[*] predict with avgrank model\n",
      "precision=[0.265625   0.44117647 0.10714286], recall=[0.47222222 0.24590164 0.10344828], f1=[0.34       0.31578947 0.10526316], accuracy=0.28\n",
      "[*] predict with dice model\n",
      "precision=[0.23214286 0.34615385 0.18181818], recall=[0.36111111 0.14754098 0.27586207], f1=[0.2826087  0.20689655 0.21917808], accuracy=0.24\n",
      "[*] predict with lr model\n",
      "precision=[0.40384615 0.66666667 0.26470588], recall=[0.58333333 0.06557377 0.62068966], f1=[0.47727273 0.11940299 0.37113402], accuracy=0.34\n",
      "[*] predict with lrl1 model\n",
      "precision=[0.4        0.6        0.25352113], recall=[0.55555556 0.04918033 0.62068966], f1=[0.46511628 0.09090909 0.36      ], accuracy=0.33\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.41176471 0.5        0.26027397], recall=[0.58333333 0.01639344 0.65517241], f1=[0.48275862 0.03174603 0.37254902], accuracy=0.33\n",
      "[*] predict with lsvcl2 model\n",
      "precision=[0.36363636 0.         0.19444444], recall=[0.88888889 0.         0.24137931], f1=[0.51612903 0.         0.21538462], accuracy=0.31\n",
      "[*] predict with rf model\n",
      "precision=[0.41304348 0.66666667 0.24324324], recall=[0.52777778 0.06557377 0.62068966], f1=[0.46341463 0.11940299 0.34951456], accuracy=0.33\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.41176471 0.6        0.25714286], recall=[0.58333333 0.04918033 0.62068966], f1=[0.48275862 0.09090909 0.36363636], accuracy=0.33\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.41304348 0.63157895 0.27868852], recall=[0.52777778 0.19672131 0.5862069 ], f1=[0.46341463 0.3        0.37777778], accuracy=0.38\n",
      "rec:['Pocono', 679, 126, '+:29,0:61,-:36', 0.48412698412698413, 0.2777777777777778, 0.23809523809523808, 0.3412698412698413, 0.3253968253968254, 0.3253968253968254, 0.30952380952380953, 0.3253968253968254, 0.3333333333333333, 0.38095238095238093]\n",
      "Testset = Gateway\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.26923077 0.        ], recall=[0. 1. 0.], f1=[0.         0.42424242 0.        ], accuracy=0.27\n",
      "[*] predict with avgrank model\n",
      "precision=[0.36956522 0.29411765 0.29166667], recall=[0.4047619  0.35714286 0.20588235], f1=[0.38636364 0.32258065 0.24137931], accuracy=0.33\n",
      "[*] predict with dice model\n",
      "precision=[0.34782609 0.13043478 0.2       ], recall=[0.38095238 0.10714286 0.20588235], f1=[0.36363636 0.11764706 0.20289855], accuracy=0.25\n",
      "[*] predict with lr model\n",
      "precision=[0.8125     0.34722222 0.5625    ], recall=[0.30952381 0.89285714 0.26470588], f1=[0.44827586 0.5        0.36      ], accuracy=0.45\n",
      "[*] predict with lrl1 model\n",
      "precision=[0.90909091 0.33333333 0.5       ], recall=[0.23809524 0.96428571 0.17647059], f1=[0.37735849 0.49541284 0.26086957], accuracy=0.41\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.90909091 0.33333333 0.5       ], recall=[0.23809524 0.96428571 0.17647059], f1=[0.37735849 0.49541284 0.26086957], accuracy=0.41\n",
      "[*] predict with lsvcl2 model\n",
      "precision=[0.5        0.26666667 0.30120482], recall=[0.07142857 0.14285714 0.73529412], f1=[0.125      0.18604651 0.42735043], accuracy=0.31\n",
      "[*] predict with rf model\n",
      "precision=[0.54054054 0.30555556 0.35483871], recall=[0.47619048 0.39285714 0.32352941], f1=[0.50632911 0.34375    0.33846154], accuracy=0.40\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.83333333 0.325      0.5       ], recall=[0.23809524 0.92857143 0.17647059], f1=[0.37037037 0.48148148 0.26086957], accuracy=0.40\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.55263158 0.29268293 0.36      ], recall=[0.5        0.42857143 0.26470588], f1=[0.525      0.34782609 0.30508475], accuracy=0.40\n",
      "rec:['Gateway', 701, 104, '+:34,0:28,-:42', 0.2692307692307692, 0.3269230769230769, 0.25, 0.4519230769230769, 0.41346153846153844, 0.41346153846153844, 0.3076923076923077, 0.40384615384615385, 0.40384615384615385, 0.40384615384615385]\n"
     ]
    }
   ],
   "source": [
    "cols = ['runid','trainsize','testsize','testdistribution']\n",
    "cols.extend(classifiers)\n",
    "print('cols:%s'%cols)\n",
    "retdf = pd.DataFrame([],columns=cols)\n",
    "\n",
    "eventsname = ['Phoenix','Indy500','Texas','Iowa','Pocono','Gateway']\n",
    "events = set(stagedata['eventid'])\n",
    "for eventid in events:\n",
    "    print('Testset = %s'%eventsname[eventid])\n",
    "    \n",
    "    train, test, train_x, train_y, test_x, test_y = split_by_eventid(stagedata, eventid)\n",
    "    test_distribution = '+:%d,0:%d,-:%d'%(np.sum(test_y>0),np.sum(test_y==0),np.sum(test_y<0))\n",
    "    #print('Testset by stageid= %s, trainsize=%d, testsize=%d, dist=%s'%\n",
    "    #      (stageid, train_x.shape[0], test_x.shape[0], test_distribution))\n",
    "    \n",
    "    #record\n",
    "    rec = [eventsname[eventid],train_x.shape[0],test_x.shape[0],test_distribution]\n",
    "    \n",
    "    acc = [0 for x in range(len(classifiers))]\n",
    "    for idx, clf in enumerate(classifiers):\n",
    "        acc[idx] = classifier_model(clf)\n",
    "\n",
    "    rec.extend(acc)\n",
    "    print('rec:%s'%rec)\n",
    "    \n",
    "    #new df\n",
    "    df = pd.DataFrame([rec],columns=cols)\n",
    "    retdf = pd.concat([retdf, df])        \n",
    "    \n",
    "retdf.to_csv('crossvalid_stagedata_splitbyevent.csv')\n",
    "df_event = retdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runid</th>\n",
       "      <th>trainsize</th>\n",
       "      <th>testsize</th>\n",
       "      <th>testdistribution</th>\n",
       "      <th>currank</th>\n",
       "      <th>avgrank</th>\n",
       "      <th>dice</th>\n",
       "      <th>lr</th>\n",
       "      <th>lrl1</th>\n",
       "      <th>lsvc</th>\n",
       "      <th>lsvcl2</th>\n",
       "      <th>rf</th>\n",
       "      <th>lrbias</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>691</td>\n",
       "      <td>114</td>\n",
       "      <td>+:38,0:16,-:60</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.324561</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.517544</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500</td>\n",
       "      <td>580</td>\n",
       "      <td>225</td>\n",
       "      <td>+:82,0:47,-:96</td>\n",
       "      <td>0.208889</td>\n",
       "      <td>0.324444</td>\n",
       "      <td>0.395556</td>\n",
       "      <td>0.564444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.564444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas</td>\n",
       "      <td>678</td>\n",
       "      <td>127</td>\n",
       "      <td>+:39,0:34,-:54</td>\n",
       "      <td>0.267717</td>\n",
       "      <td>0.314961</td>\n",
       "      <td>0.291339</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.622047</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.480315</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.433071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>696</td>\n",
       "      <td>109</td>\n",
       "      <td>+:42,0:28,-:39</td>\n",
       "      <td>0.256881</td>\n",
       "      <td>0.293578</td>\n",
       "      <td>0.256881</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.339450</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.293578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pocono</td>\n",
       "      <td>679</td>\n",
       "      <td>126</td>\n",
       "      <td>+:29,0:61,-:36</td>\n",
       "      <td>0.484127</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.341270</td>\n",
       "      <td>0.325397</td>\n",
       "      <td>0.325397</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.325397</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gateway</td>\n",
       "      <td>701</td>\n",
       "      <td>104</td>\n",
       "      <td>+:34,0:28,-:42</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.403846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     runid trainsize testsize testdistribution   currank   avgrank      dice  \\\n",
       "0  Phoenix       691      114   +:38,0:16,-:60  0.140351  0.324561  0.368421   \n",
       "0  Indy500       580      225   +:82,0:47,-:96  0.208889  0.324444  0.395556   \n",
       "0    Texas       678      127   +:39,0:34,-:54  0.267717  0.314961  0.291339   \n",
       "0     Iowa       696      109   +:42,0:28,-:39  0.256881  0.293578  0.256881   \n",
       "0   Pocono       679      126   +:29,0:61,-:36  0.484127  0.277778  0.238095   \n",
       "0  Gateway       701      104   +:34,0:28,-:42  0.269231  0.326923  0.250000   \n",
       "\n",
       "         lr      lrl1      lsvc    lsvcl2        rf    lrbias       xgb  \n",
       "0  0.543860  0.552632  0.517544  0.614035  0.561404  0.543860  0.473684  \n",
       "0  0.564444  0.555556  0.551111  0.520000  0.564444  0.555556  0.520000  \n",
       "0  0.598425  0.606299  0.622047  0.409449  0.480315  0.606299  0.433071  \n",
       "0  0.357798  0.348624  0.348624  0.376147  0.339450  0.348624  0.293578  \n",
       "0  0.341270  0.325397  0.325397  0.309524  0.325397  0.333333  0.380952  \n",
       "0  0.451923  0.413462  0.413462  0.307692  0.403846  0.403846  0.403846  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] predict with currank model\n",
      "precision=[0.         0.25613497 0.        ], recall=[0. 1. 0.], f1=[0.         0.40781441 0.        ], accuracy=0.26\n",
      "[*] predict with avgrank model\n",
      "precision=[0.37172775 0.22535211 0.23115578], recall=[0.53787879 0.09580838 0.2081448 ], f1=[0.43962848 0.13445378 0.21904762], accuracy=0.31\n",
      "[*] predict with dice model\n",
      "precision=[0.41197183 0.25806452 0.3956044 ], recall=[0.44318182 0.28742515 0.32579186], f1=[0.4270073  0.27195467 0.3573201 ], accuracy=0.36\n",
      "[*] predict with lr model\n",
      "precision=[0.49633252 0.36842105 0.56603774], recall=[0.76893939 0.41916168 0.13574661], f1=[0.60326895 0.39215686 0.2189781 ], accuracy=0.46\n",
      "[*] predict with lrl1 model\n",
      "precision=[0.49608355 0.36097561 0.46875   ], recall=[0.71969697 0.44311377 0.13574661], f1=[0.58732612 0.39784946 0.21052632], accuracy=0.45\n",
      "[*] predict with lsvc model\n",
      "precision=[0.47074468 0.3438914  0.27272727], recall=[0.67045455 0.45508982 0.0678733 ], f1=[0.553125   0.39175258 0.10869565], accuracy=0.41\n",
      "[*] predict with lsvcl2 model\n",
      "precision=[0.46966292 0.35121951 1.        ], recall=[0.79166667 0.43113772 0.00904977], f1=[0.58956276 0.38709677 0.01793722], accuracy=0.43\n",
      "[*] predict with rf model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.44444444 0.32850242 0.33108108], recall=[0.5        0.40718563 0.22171946], f1=[0.47058824 0.36363636 0.26558266], accuracy=0.38\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.49234694 0.35576923 0.48076923], recall=[0.73106061 0.44311377 0.11312217], f1=[0.58841463 0.39466667 0.18315018], accuracy=0.45\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.4497992  0.29338843 0.34782609], recall=[0.42424242 0.4251497  0.25339367], f1=[0.43664717 0.34718826 0.29319372], accuracy=0.37\n",
      "rec:['stage0', 153, 652, '+:221,0:167,-:264', 0.2561349693251534, 0.3128834355828221, 0.36349693251533743, 0.4647239263803681, 0.450920245398773, 0.4110429447852761, 0.4340490797546012, 0.38190184049079756, 0.44785276073619634, 0.3665644171779141]\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.26305609 0.        ], recall=[0. 1. 0.], f1=[0.         0.41653905 0.        ], accuracy=0.26\n",
      "[*] predict with avgrank model\n",
      "precision=[0.34674923 0.24242424 0.24223602], recall=[0.57435897 0.05882353 0.20967742], f1=[0.43243243 0.09467456 0.22478386], accuracy=0.31\n",
      "[*] predict with dice model\n",
      "precision=[0.39312977 0.22881356 0.37956204], recall=[0.52820513 0.19852941 0.27956989], f1=[0.45076586 0.21259843 0.32198142], accuracy=0.35\n",
      "[*] predict with lr model\n",
      "precision=[0.42746114 0.44642857 0.58666667], recall=[0.84615385 0.18382353 0.23655914], f1=[0.56798623 0.26041667 0.33716475], accuracy=0.45\n",
      "[*] predict with lrl1 model\n",
      "precision=[0.44722222 0.45614035 0.62      ], recall=[0.82564103 0.19117647 0.33333333], f1=[0.58018018 0.26943005 0.43356643], accuracy=0.48\n",
      "[*] predict with lsvc model\n",
      "precision=[0.46449704 0.41489362 0.58823529], recall=[0.80512821 0.28676471 0.2688172 ], f1=[0.5891182  0.33913043 0.36900369], accuracy=0.48\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.51648352 0.29927007 0.52631579], recall=[0.24102564 0.60294118 0.43010753], f1=[0.32867133 0.4        0.47337278], accuracy=0.40\n",
      "[*] predict with rf model\n",
      "precision=[0.43801653 0.33333333 0.5106383 ], recall=[0.81538462 0.14705882 0.25806452], f1=[0.56989247 0.20408163 0.34285714], accuracy=0.44\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.4296875  0.44827586 0.58666667], recall=[0.84615385 0.19117647 0.23655914], f1=[0.56994819 0.26804124 0.33716475], accuracy=0.45\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.4787234  0.34482759 0.53781513], recall=[0.69230769 0.29411765 0.34408602], f1=[0.56603774 0.31746032 0.41967213], accuracy=0.46\n",
      "rec:['stage1', 288, 517, '+:186,0:136,-:195', 0.26305609284332687, 0.30754352030947774, 0.3520309477756286, 0.4526112185686654, 0.4816247582205029, 0.4758220502901354, 0.40425531914893614, 0.43907156673114117, 0.45454545454545453, 0.4622823984526112]\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.29166667 0.        ], recall=[0. 1. 0.], f1=[0.        0.4516129 0.       ], accuracy=0.29\n",
      "[*] predict with avgrank model\n",
      "precision=[0.28630705 0.28571429 0.21311475], recall=[0.52272727 0.05357143 0.18571429], f1=[0.36997319 0.09022556 0.19847328], accuracy=0.26\n",
      "[*] predict with dice model\n",
      "precision=[0.3627451  0.17567568 0.33018868], recall=[0.56060606 0.11607143 0.25      ], f1=[0.44047619 0.13978495 0.28455285], accuracy=0.32\n",
      "[*] predict with lr model\n",
      "precision=[0.49142857 0.         0.48543689], recall=[0.65151515 0.         0.71428571], f1=[0.56026059 0.         0.57803468], accuracy=0.48\n",
      "[*] predict with lrl1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.44298246 0.16666667 0.53333333], recall=[0.76515152 0.00892857 0.57142857], f1=[0.56111111 0.01694915 0.55172414], accuracy=0.47\n",
      "[*] predict with lsvc model\n",
      "precision=[0.49238579 0.         0.51086957], recall=[0.73484848 0.         0.67142857], f1=[0.58966565 0.         0.58024691], accuracy=0.50\n",
      "[*] predict with lsvcl2 model\n",
      "precision=[0.51136364 0.28057554 0.54140127], recall=[0.34090909 0.34821429 0.60714286], f1=[0.40909091 0.31075697 0.57239057], accuracy=0.44\n",
      "[*] predict with rf model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.432      0.40625    0.56862745], recall=[0.81818182 0.11607143 0.41428571], f1=[0.56544503 0.18055556 0.47933884], accuracy=0.47\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.47953216 0.         0.48076923], recall=[0.62121212 0.         0.71428571], f1=[0.54125413 0.         0.57471264], accuracy=0.47\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.425      0.36923077 0.46218487], recall=[0.64393939 0.21428571 0.39285714], f1=[0.51204819 0.27118644 0.42471042], accuracy=0.43\n",
      "rec:['stage2', 421, 384, '+:140,0:112,-:132', 0.2916666666666667, 0.2630208333333333, 0.3177083333333333, 0.484375, 0.4739583333333333, 0.4973958333333333, 0.4401041666666667, 0.4661458333333333, 0.4739583333333333, 0.4270833333333333]\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.34496124 0.        ], recall=[0. 1. 0.], f1=[0.        0.5129683 0.       ], accuracy=0.34\n",
      "[*] predict with avgrank model\n",
      "precision=[0.22929936 0.29411765 0.21428571], recall=[0.46153846 0.05617978 0.1978022 ], f1=[0.30638298 0.09433962 0.20571429], accuracy=0.23\n",
      "[*] predict with dice model\n",
      "precision=[0.28985507 0.4375     0.34722222], recall=[0.51282051 0.23595506 0.27472527], f1=[0.37037037 0.30656934 0.30674847], accuracy=0.33\n",
      "[*] predict with lr model\n",
      "precision=[0.46875    0.18181818 0.52941176], recall=[0.76923077 0.02247191 0.69230769], f1=[0.58252427 0.04       0.6       ], accuracy=0.48\n",
      "[*] predict with lrl1 model\n",
      "precision=[0.4295302  0.09090909 0.59183673], recall=[0.82051282 0.01123596 0.63736264], f1=[0.56387665 0.02       0.61375661], accuracy=0.48\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.4609375  0.125      0.52459016], recall=[0.75641026 0.01123596 0.7032967 ], f1=[0.57281553 0.02061856 0.60093897], accuracy=0.48\n",
      "[*] predict with lsvcl2 model\n",
      "precision=[0.33802817 0.4        0.6       ], recall=[0.92307692 0.06741573 0.1978022 ], f1=[0.49484536 0.11538462 0.29752066], accuracy=0.37\n",
      "[*] predict with rf model\n",
      "precision=[0.40625    0.5        0.53846154], recall=[0.83333333 0.11235955 0.46153846], f1=[0.54621849 0.18348624 0.49704142], accuracy=0.45\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.464      0.16666667 0.51239669], recall=[0.74358974 0.02247191 0.68131868], f1=[0.57142857 0.03960396 0.58490566], accuracy=0.47\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.3880597  0.51724138 0.48421053], recall=[0.66666667 0.16853933 0.50549451], f1=[0.49056604 0.25423729 0.49462366], accuracy=0.44\n",
      "rec:['stage3', 547, 258, '+:91,0:89,-:78', 0.3449612403100775, 0.22868217054263565, 0.3333333333333333, 0.4844961240310077, 0.47674418604651164, 0.4806201550387597, 0.37209302325581395, 0.45348837209302323, 0.4728682170542636, 0.437984496124031]\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.35810811 0.        ], recall=[0. 1. 0.], f1=[0.         0.52736318 0.        ], accuracy=0.36\n",
      "[*] predict with avgrank model\n",
      "precision=[0.21348315 0.22222222 0.2       ], recall=[0.40425532 0.03773585 0.20833333], f1=[0.27941176 0.06451613 0.20408163], accuracy=0.21\n",
      "[*] predict with dice model\n",
      "precision=[0.33802817 0.4375     0.28888889], recall=[0.5106383  0.26415094 0.27083333], f1=[0.40677966 0.32941176 0.27956989], accuracy=0.34\n",
      "[*] predict with lr model\n",
      "precision=[0.61904762 0.51515152 0.53424658], recall=[0.55319149 0.32075472 0.8125    ], f1=[0.58426966 0.39534884 0.6446281 ], accuracy=0.55\n",
      "[*] predict with lrl1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.62222222 0.53333333 0.53424658], recall=[0.59574468 0.30188679 0.8125    ], f1=[0.60869565 0.38554217 0.6446281 ], accuracy=0.56\n",
      "[*] predict with lsvc model\n",
      "precision=[0.63636364 0.53333333 0.52702703], recall=[0.59574468 0.30188679 0.8125    ], f1=[0.61538462 0.38554217 0.63934426], accuracy=0.56\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.46296296 0.47435897 0.75      ], recall=[0.53191489 0.69811321 0.25      ], f1=[0.4950495 0.5648855 0.375    ], accuracy=0.50\n",
      "[*] predict with rf model\n",
      "precision=[0.42465753 0.53333333 0.62222222], recall=[0.65957447 0.30188679 0.58333333], f1=[0.51666667 0.38554217 0.60215054], accuracy=0.51\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.65116279 0.5625     0.53424658], recall=[0.59574468 0.33962264 0.8125    ], f1=[0.62222222 0.42352941 0.6446281 ], accuracy=0.57\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.43636364 0.39534884 0.54      ], recall=[0.5106383  0.32075472 0.5625    ], f1=[0.47058824 0.35416667 0.55102041], accuracy=0.46\n",
      "rec:['stage4', 657, 148, '+:48,0:53,-:47', 0.3581081081081081, 0.20945945945945946, 0.34459459459459457, 0.5540540540540541, 0.5608108108108109, 0.5608108108108109, 0.5, 0.5067567567567568, 0.5743243243243243, 0.4594594594594595]\n",
      "[*] predict with currank model\n",
      "precision=[0.     0.3625 0.    ], recall=[0. 1. 0.], f1=[0.         0.53211009 0.        ], accuracy=0.36\n",
      "[*] predict with avgrank model\n",
      "precision=[0.19565217 0.28571429 0.18518519], recall=[0.36       0.06896552 0.19230769], f1=[0.25352113 0.11111111 0.18867925], accuracy=0.20\n",
      "[*] predict with dice model\n",
      "precision=[0.32352941 0.26666667 0.35483871], recall=[0.44       0.13793103 0.42307692], f1=[0.37288136 0.18181818 0.38596491], accuracy=0.33\n",
      "[*] predict with lr model\n",
      "precision=[0.625      0.5        0.72222222], recall=[0.4        0.79310345 0.5       ], f1=[0.48780488 0.61333333 0.59090909], accuracy=0.57\n",
      "[*] predict with lrl1 model\n",
      "precision=[0.625      0.52083333 0.75      ], recall=[0.4        0.86206897 0.46153846], f1=[0.48780488 0.64935065 0.57142857], accuracy=0.59\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.61111111 0.52272727 0.66666667], recall=[0.44       0.79310345 0.46153846], f1=[0.51162791 0.63013699 0.54545455], accuracy=0.57\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.25      0.3943662 1.       ], recall=[0.08       0.96551724 0.03846154], f1=[0.12121212 0.56       0.07407407], accuracy=0.39\n",
      "[*] predict with rf model\n",
      "precision=[0.55263158 0.58823529 0.68      ], recall=[0.84       0.34482759 0.65384615], f1=[0.66666667 0.43478261 0.66666667], accuracy=0.60\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.625      0.5106383  0.70588235], recall=[0.4        0.82758621 0.46153846], f1=[0.48780488 0.63157895 0.55813953], accuracy=0.57\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.44444444 0.51851852 0.5       ], recall=[0.48       0.48275862 0.5       ], f1=[0.46153846 0.5        0.5       ], accuracy=0.49\n",
      "rec:['stage5', 725, 80, '+:26,0:29,-:25', 0.3625, 0.2, 0.325, 0.575, 0.5875, 0.575, 0.3875, 0.6, 0.575, 0.4875]\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.34210526 0.        ], recall=[0. 1. 0.], f1=[0.         0.50980392 0.        ], accuracy=0.34\n",
      "[*] predict with avgrank model\n",
      "precision=[0.27272727 0.33333333 0.1       ], recall=[0.42857143 0.15384615 0.09090909], f1=[0.33333333 0.21052632 0.0952381 ], accuracy=0.24\n",
      "[*] predict with dice model\n",
      "precision=[0.2        0.3        0.30769231], recall=[0.21428571 0.23076923 0.36363636], f1=[0.20689655 0.26086957 0.33333333], accuracy=0.26\n",
      "[*] predict with lr model\n",
      "precision=[0.625      0.42307692 1.        ], recall=[0.35714286 0.84615385 0.36363636], f1=[0.45454545 0.56410256 0.53333333], accuracy=0.53\n",
      "[*] predict with lrl1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.625      0.42307692 1.        ], recall=[0.35714286 0.84615385 0.36363636], f1=[0.45454545 0.56410256 0.53333333], accuracy=0.53\n",
      "[*] predict with lsvc model\n",
      "precision=[0.625      0.42307692 1.        ], recall=[0.35714286 0.84615385 0.36363636], f1=[0.45454545 0.56410256 0.53333333], accuracy=0.53\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.5        0.45454545 0.6       ], recall=[0.21428571 0.76923077 0.54545455], f1=[0.3        0.57142857 0.57142857], accuracy=0.50\n",
      "[*] predict with rf model\n",
      "precision=[0.55       0.42857143 0.63636364], recall=[0.78571429 0.23076923 0.63636364], f1=[0.64705882 0.3        0.63636364], accuracy=0.55\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[0.71428571 0.42307692 0.8       ], recall=[0.35714286 0.84615385 0.36363636], f1=[0.47619048 0.56410256 0.5       ], accuracy=0.53\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.61111111 0.55555556 0.63636364], recall=[0.78571429 0.38461538 0.63636364], f1=[0.6875     0.45454545 0.63636364], accuracy=0.61\n",
      "rec:['stage6', 767, 38, '+:11,0:13,-:14', 0.34210526315789475, 0.23684210526315788, 0.2631578947368421, 0.5263157894736842, 0.5263157894736842, 0.5263157894736842, 0.5, 0.5526315789473685, 0.5263157894736842, 0.6052631578947368]\n",
      "[*] predict with currank model\n",
      "precision=[0.   0.25 0.  ], recall=[0. 1. 0.], f1=[0.  0.4 0. ], accuracy=0.25\n",
      "[*] predict with avgrank model\n",
      "precision=[0.3 0.  0. ], recall=[0.375 0.    0.   ], f1=[0.33333333 0.         0.        ], accuracy=0.19\n",
      "[*] predict with dice model\n",
      "precision=[0.42857143 0.2        0.25      ], recall=[0.375 0.25  0.25 ], f1=[0.4        0.22222222 0.25      ], accuracy=0.31\n",
      "[*] predict with lr model\n",
      "precision=[0.66666667 0.25       1.        ], recall=[0.25 0.75 0.25], f1=[0.36363636 0.375      0.4       ], accuracy=0.38\n",
      "[*] predict with lrl1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[1.   0.25 0.5 ], recall=[0.25 0.75 0.25], f1=[0.4        0.375      0.33333333], accuracy=0.38\n",
      "[*] predict with lsvc model\n",
      "precision=[0.66666667 0.25       1.        ], recall=[0.25 0.75 0.25], f1=[0.36363636 0.375      0.4       ], accuracy=0.38\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.5 0.  0. ], recall=[1. 0. 0.], f1=[0.66666667 0.         0.        ], accuracy=0.50\n",
      "[*] predict with rf model\n",
      "precision=[0.5  0.25 0.5 ], recall=[0.375 0.25  0.75 ], f1=[0.42857143 0.25       0.6       ], accuracy=0.44\n",
      "[*] predict with lrbias model\n",
      "[LibLinear]precision=[1.   0.25 0.5 ], recall=[0.25 0.75 0.25], f1=[0.4        0.375      0.33333333], accuracy=0.38\n",
      "[*] predict with xgb model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/scratch/hpda/anaconda3/envs/predictor/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 48.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.5        0.2        0.42857143], recall=[0.25 0.25 0.75], f1=[0.33333333 0.22222222 0.54545455], accuracy=0.38\n",
      "rec:['stage7', 789, 16, '+:4,0:4,-:8', 0.25, 0.1875, 0.3125, 0.375, 0.375, 0.375, 0.5, 0.4375, 0.375, 0.375]\n"
     ]
    }
   ],
   "source": [
    "retdf = pd.DataFrame([],columns=cols)\n",
    "\n",
    "for stageid in range(8):\n",
    "    train, test, train_x, train_y, test_x, test_y =split_by_stageid(stagedata, stageid)\n",
    "    test_distribution = '+:%d,0:%d,-:%d'%(np.sum(test_y>0),np.sum(test_y==0),np.sum(test_y<0))\n",
    "    #print('Testset by stageid= %s, trainsize=%d, testsize=%d, dist=%s'%\n",
    "    #      (stageid, train_x.shape[0], test_x.shape[0], test_distribution))\n",
    "    \n",
    "    #record\n",
    "    rec = ['stage%d'%stageid,train_x.shape[0],test_x.shape[0],test_distribution]\n",
    "    \n",
    "    acc = [0 for x in range(len(classifiers))]\n",
    "    for idx, clf in enumerate(classifiers):\n",
    "        acc[idx] = classifier_model(clf)\n",
    "\n",
    "    rec.extend(acc)\n",
    "    print('rec:%s'%rec)\n",
    "    \n",
    "    #new df\n",
    "    df = pd.DataFrame([rec],columns=cols)\n",
    "    retdf = pd.concat([retdf, df])  \n",
    "    \n",
    "retdf.to_csv('crossvalid_stagedata_splitbystage.csv')\n",
    "df_stage = retdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runid</th>\n",
       "      <th>trainsize</th>\n",
       "      <th>testsize</th>\n",
       "      <th>testdistribution</th>\n",
       "      <th>currank</th>\n",
       "      <th>avgrank</th>\n",
       "      <th>dice</th>\n",
       "      <th>lr</th>\n",
       "      <th>lrl1</th>\n",
       "      <th>lsvc</th>\n",
       "      <th>lsvcl2</th>\n",
       "      <th>rf</th>\n",
       "      <th>lrbias</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stage0</td>\n",
       "      <td>153</td>\n",
       "      <td>652</td>\n",
       "      <td>+:221,0:167,-:264</td>\n",
       "      <td>0.256135</td>\n",
       "      <td>0.312883</td>\n",
       "      <td>0.363497</td>\n",
       "      <td>0.464724</td>\n",
       "      <td>0.450920</td>\n",
       "      <td>0.411043</td>\n",
       "      <td>0.434049</td>\n",
       "      <td>0.381902</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.366564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stage1</td>\n",
       "      <td>288</td>\n",
       "      <td>517</td>\n",
       "      <td>+:186,0:136,-:195</td>\n",
       "      <td>0.263056</td>\n",
       "      <td>0.307544</td>\n",
       "      <td>0.352031</td>\n",
       "      <td>0.452611</td>\n",
       "      <td>0.481625</td>\n",
       "      <td>0.475822</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.439072</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.462282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stage2</td>\n",
       "      <td>421</td>\n",
       "      <td>384</td>\n",
       "      <td>+:140,0:112,-:132</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.263021</td>\n",
       "      <td>0.317708</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.473958</td>\n",
       "      <td>0.497396</td>\n",
       "      <td>0.440104</td>\n",
       "      <td>0.466146</td>\n",
       "      <td>0.473958</td>\n",
       "      <td>0.427083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stage3</td>\n",
       "      <td>547</td>\n",
       "      <td>258</td>\n",
       "      <td>+:91,0:89,-:78</td>\n",
       "      <td>0.344961</td>\n",
       "      <td>0.228682</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.484496</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>0.480620</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.453488</td>\n",
       "      <td>0.472868</td>\n",
       "      <td>0.437984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stage4</td>\n",
       "      <td>657</td>\n",
       "      <td>148</td>\n",
       "      <td>+:48,0:53,-:47</td>\n",
       "      <td>0.358108</td>\n",
       "      <td>0.209459</td>\n",
       "      <td>0.344595</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.560811</td>\n",
       "      <td>0.560811</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.574324</td>\n",
       "      <td>0.459459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stage5</td>\n",
       "      <td>725</td>\n",
       "      <td>80</td>\n",
       "      <td>+:26,0:29,-:25</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stage6</td>\n",
       "      <td>767</td>\n",
       "      <td>38</td>\n",
       "      <td>+:11,0:13,-:14</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stage7</td>\n",
       "      <td>789</td>\n",
       "      <td>16</td>\n",
       "      <td>+:4,0:4,-:8</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    runid trainsize testsize   testdistribution   currank   avgrank      dice  \\\n",
       "0  stage0       153      652  +:221,0:167,-:264  0.256135  0.312883  0.363497   \n",
       "0  stage1       288      517  +:186,0:136,-:195  0.263056  0.307544  0.352031   \n",
       "0  stage2       421      384  +:140,0:112,-:132  0.291667  0.263021  0.317708   \n",
       "0  stage3       547      258     +:91,0:89,-:78  0.344961  0.228682  0.333333   \n",
       "0  stage4       657      148     +:48,0:53,-:47  0.358108  0.209459  0.344595   \n",
       "0  stage5       725       80     +:26,0:29,-:25  0.362500  0.200000  0.325000   \n",
       "0  stage6       767       38     +:11,0:13,-:14  0.342105  0.236842  0.263158   \n",
       "0  stage7       789       16        +:4,0:4,-:8  0.250000  0.187500  0.312500   \n",
       "\n",
       "         lr      lrl1      lsvc    lsvcl2        rf    lrbias       xgb  \n",
       "0  0.464724  0.450920  0.411043  0.434049  0.381902  0.447853  0.366564  \n",
       "0  0.452611  0.481625  0.475822  0.404255  0.439072  0.454545  0.462282  \n",
       "0  0.484375  0.473958  0.497396  0.440104  0.466146  0.473958  0.427083  \n",
       "0  0.484496  0.476744  0.480620  0.372093  0.453488  0.472868  0.437984  \n",
       "0  0.554054  0.560811  0.560811  0.500000  0.506757  0.574324  0.459459  \n",
       "0  0.575000  0.587500  0.575000  0.387500  0.600000  0.575000  0.487500  \n",
       "0  0.526316  0.526316  0.526316  0.500000  0.552632  0.526316  0.605263  \n",
       "0  0.375000  0.375000  0.375000  0.500000  0.437500  0.375000  0.375000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
