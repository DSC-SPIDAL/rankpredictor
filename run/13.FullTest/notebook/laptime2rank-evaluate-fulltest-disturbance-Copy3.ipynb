{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laptime2Rank-evaluate-fulltest-disturbance\n",
    "\n",
    "based on: Laptime2Rank-evaluate-fulltest\n",
    "\n",
    "rank prediction by laptime forecasting models\n",
    "\n",
    "support:\n",
    "+ train/test split by ratio or event\n",
    "+ incremental training evaluation(adjust ratio)\n",
    "+ go beyond curtrack and zerotrack by modeling the track status\n",
    "+ halfwin mode(0:no, 1:halfwin, 2:continous)\n",
    "+ split by stage, support all events (todo)\n",
    "\n",
    "+ disturbance analysis by adding disturbance to oracle trackstatus and lapstatus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import inspect\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pathlib import Path\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.distribution.multivariate_gaussian import MultivariateGaussianOutput\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.model.prophet import ProphetPredictor\n",
    "from gluonts.model.r_forecast import RForecastPredictor\n",
    "from indycar.model.NaivePredictor import NaivePredictor\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch_hdd/hpda/indycar/notebook/13.FullTest'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "random.seed()\n",
    "os.getcwd()\n",
    "#GPUID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(event, year):\n",
    "    inputfile = '../data/final/C_'+ event +'-' + year + '-final.csv'\n",
    "    outputprefix = year +'-' + event + '-'\n",
    "    dataset = pd.read_csv(inputfile)\n",
    "    #dataset.info(verbose=True)    \n",
    "    \n",
    "    final_lap = max(dataset.completed_laps)\n",
    "    total_laps = final_lap + 1\n",
    "\n",
    "    # get records for the cars that finish the race\n",
    "    completed_car_numbers= dataset[dataset.completed_laps == final_lap].car_number.values\n",
    "    completed_car_count = len(completed_car_numbers)\n",
    "\n",
    "    #print('count of completed cars:', completed_car_count)\n",
    "    #print('completed cars:', completed_car_numbers)\n",
    "\n",
    "    #make a copy\n",
    "    alldata = dataset.copy()\n",
    "    dataset = dataset[dataset['car_number'].isin(completed_car_numbers)]\n",
    "    rankdata = alldata.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "    \n",
    "    cldata = make_cl_data(dataset)\n",
    "    acldata = make_cl_data(alldata)\n",
    "\n",
    "    return alldata, rankdata, acldata\n",
    "\n",
    "# make indy car completed_laps dataset\n",
    "# car_number, completed_laps, rank, elapsed_time, rank_diff, elapsed_time_diff \n",
    "def make_cl_data(dataset):\n",
    "\n",
    "    # pick up data with valid rank\n",
    "    rankdata = dataset.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "\n",
    "    # resort by car_number, lap\n",
    "    uni_ds = rankdata.sort_values(by=['car_number', 'completed_laps', 'elapsed_time'], ascending=True)    \n",
    "    #uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \"current_status\", \"track_status\", \"lap_status\",\n",
    "    #                  \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "    #                  \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "    \n",
    "    uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \n",
    "                      \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "                      \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "        \n",
    "    carnumber = set(uni_ds['car_number'])\n",
    "    #print('cars:', carnumber)\n",
    "    #print('#cars=', len(carnumber))\n",
    "   \n",
    "    # faster solution , uni_ds already sorted by car_number and lap\n",
    "    uni_ds['rank_diff'] = uni_ds['rank'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['rank_diff'][mask] = 0\n",
    "    \n",
    "    uni_ds['time_diff'] = uni_ds['elapsed_time'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['time_diff'][mask] = 0\n",
    "    \n",
    "    #df = uni_ds[['car_number','completed_laps','rank','elapsed_time','rank_diff','time_diff']]\n",
    "    df = uni_ds[['car_number','completed_laps','rank','elapsed_time',\n",
    "                 'rank_diff','time_diff',\"current_status\", \"track_status\", \"lap_status\"]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def test_flag(a, bitflag):\n",
    "    return (a & bitflag) ==  bitflag\n",
    "\n",
    "#\n",
    "# remove NaN at the tail\n",
    "# there should be no nans in the middle of the ts\n",
    "COL_LAPTIME=0\n",
    "COL_RANK=1\n",
    "COL_TRACKSTATUS=2\n",
    "COL_LAPSTATUS=3\n",
    "COL_TIMEDIFF=4\n",
    "COL_CAUTION_LAPS_INSTINT=5\n",
    "COL_LAPS_INSTINT= 6\n",
    "\n",
    "# oracle mode\n",
    "MODE_ORACLE = 1024  # oracle = track + lap\n",
    "MODE_ORACLE_TRACKONLY = 1\n",
    "MODE_ORACLE_LAPONLY = 2   \n",
    "   \n",
    "\n",
    "# oracle mode for training\n",
    "MODE_NOLAP = 1   \n",
    "MODE_NOTRACK = 2\n",
    "\n",
    "# predicting mode\n",
    "MODE_TESTZERO = 4\n",
    "MODE_TESTCURTRACK = 8\n",
    "\n",
    "MODE_PREDTRACK = 16\n",
    "MODE_PREDPIT = 32\n",
    "\n",
    "# disturbe analysis\n",
    "MODE_DISTURB_CLEARTRACK = 64\n",
    "MODE_DISTURB_ADJUSTTRACK = 128\n",
    "MODE_DISTURB_ADJUSTPIT = 256\n",
    "\n",
    "\n",
    "_mode_map = {MODE_ORACLE:'MODE_ORACLE',MODE_ORACLE_TRACKONLY:'MODE_ORACLE_TRACKONLY',\n",
    "            MODE_ORACLE_LAPONLY:'MODE_ORACLE_LAPONLY',\n",
    "             MODE_TESTZERO:'MODE_TESTZERO',MODE_TESTCURTRACK:'MODE_TESTCURTRACK',\n",
    "             MODE_PREDTRACK:'MODE_PREDTRACK',MODE_PREDPIT:'MODE_PREDPIT',\n",
    "            MODE_DISTURB_CLEARTRACK:'MODE_DISTURB_CLEARTRACK',MODE_DISTURB_ADJUSTTRACK:'MODE_DISTURB_ADJUSTTRACK',\n",
    "            MODE_DISTURB_ADJUSTPIT:'MODE_DISTURB_ADJUSTPIT'}\n",
    "\n",
    "def get_modestr(a):\n",
    "    modestr = ''\n",
    "    for key in _mode_map:\n",
    "        if test_flag(a, key):\n",
    "            modestr += '%s,'%(_mode_map[key])\n",
    "            \n",
    "    return modestr\n",
    "\n",
    "# endpos -> vector of prediction_length\n",
    "_track_pred  = {}\n",
    "_track_true  = {}\n",
    "def init_track_model():\n",
    "    global _track_pred,_track_true\n",
    "    _track_pred = {}\n",
    "    _track_true  = {}\n",
    "    \n",
    "def get_track_model(track_rec, endpos, prediction_length, context_len=10):\n",
    "    \"\"\"\n",
    "    return the predicted track status\n",
    "    \"\"\"\n",
    "    global _track_pred,_track_true\n",
    "    # this is the perfect track model for Indy500 2018\n",
    "    track_model = [6,4,4,5,6,6,4]\n",
    "    if endpos in _track_pred:\n",
    "        return _track_pred[endpos]\n",
    "    else:\n",
    "        #get yflag lap count from the start pred point\n",
    "        yflaplen = 0\n",
    "        for i in range(1, context_len):\n",
    "            if track_rec[- prediction_length - i] == 1:\n",
    "                yflaplen += 1\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        #laps remain, fill into the future\n",
    "        trackpred = np.array([0 for x in range(prediction_length)])\n",
    "        \n",
    "        yflap_pred = random.choice(track_model)\n",
    "        if yflaplen > 0 and yflap_pred > yflaplen:\n",
    "            trackpred[:(yflap_pred - yflaplen)] = 1\n",
    "        _track_pred[endpos] = trackpred\n",
    "        \n",
    "        _track_true[endpos]  = track_rec[- prediction_length:].copy()\n",
    "        \n",
    "        return trackpred\n",
    "\n",
    "    \n",
    "# endpos -> vector of prediction_length\n",
    "_track_adjust  = {}\n",
    "def init_adjust_track_model():\n",
    "    global _track_adjust\n",
    "    _track_adjust = {}\n",
    "    \n",
    "def adjust_track_model(track_rec, endpos, prediction_length, tailpos):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        tailpos ; <0 end pos of 1\n",
    "    return the predicted track status\n",
    "    \"\"\"\n",
    "    global _track_adjust\n",
    "    # this is the perfect track model for Indy500 2018\n",
    "    track_model = [-1,0,1]\n",
    "    if endpos in _track_adjust:\n",
    "        return _track_adjust[endpos]\n",
    "    else:\n",
    "        yflap_adjust = random.choice(track_model)\n",
    "        \n",
    "        #laps remain, fill into the future\n",
    "        trackadjust = track_rec[-prediction_length:].copy()\n",
    "        if yflap_adjust == -1:\n",
    "            trackadjust[tailpos] = 0\n",
    "        elif yflap_adjust == 1:\n",
    "            trackadjust[tailpos] = 0\n",
    "            if (tailpos + 1) <= -1:\n",
    "                trackadjust[tailpos+1] = 1\n",
    "        \n",
    "        _track_adjust[endpos] = trackadjust\n",
    "        \n",
    "        return trackadjust\n",
    "    \n",
    "def adjust_pit_model(lap_rec, endpos, prediction_length):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        tailpos ; <0 end pos of 1\n",
    "    return the predicted lap status\n",
    "    \"\"\"\n",
    "    adjust_model = [-1,0,1]\n",
    "    lap_adjust = random.choice(adjust_model)\n",
    "        \n",
    "    #laps remain, fill into the future\n",
    "    lapadjust = lap_rec[-prediction_length:].copy()\n",
    "    for pos in range(0, prediction_length):\n",
    "        if lapadjust[pos] == 1:\n",
    "            # adjust this pit lap position\n",
    "            pos_adjust = random.choice(adjust_model)\n",
    "\n",
    "            if pos_adjust == -1:\n",
    "                if (pos - 1 >= 0):\n",
    "                    lapadjust[pos] = 0\n",
    "                    lapadjust[pos - 1] = 1\n",
    "            elif pos_adjust == 1:\n",
    "                if (pos + 1 < prediction_length):\n",
    "                    lapadjust[pos] = 0\n",
    "                    lapadjust[pos + 1] = 1\n",
    "\n",
    "    return lapadjust\n",
    "    \n",
    "# pit model is separate for each car\n",
    "def get_pit_model(cuation_laps_instint, laps_instint, prediction_length):\n",
    "    \"\"\"\n",
    "    return the predicted pit status\n",
    "    \"\"\"\n",
    "    # this is the perfect empirical pit model for Indy500 2018\n",
    "    pit_model_all = [[33, 32, 35, 32, 35, 34, 35, 34, 37, 32, 37, 30, 33, 36, 35, 33, 36, 30, 31, 33, 36, 37, 35, 34, 34, 33, 37, 35, 39, 32, 36, 35, 34, 32, 36, 32, 31, 36, 33, 33, 35, 37, 40, 32, 32, 34, 35, 36, 33, 37, 35, 37, 34, 35, 39, 32, 31, 37, 32, 35, 36, 39, 35, 36, 34, 35, 33, 33, 34, 32, 33, 34],\n",
    "                [45, 44, 46, 44, 43, 46, 45, 43, 41, 48, 46, 43, 47, 45, 49, 44, 48, 42, 44, 46, 45, 45, 43, 44, 44, 43, 46]]\n",
    "    pit_model_top8 = [[33, 32, 35, 33, 36, 33, 36, 33, 37, 35, 36, 33, 37, 34],\n",
    "                 [46, 45, 43, 48, 46, 45, 45, 43]]\n",
    "    \n",
    "    pit_model = pit_model_all\n",
    "    \n",
    "    if cuation_laps_instint>10:\n",
    "        #use low model\n",
    "        pred_pit_laps = random.choice(pit_model[0])\n",
    "    else:\n",
    "        pred_pit_laps = random.choice(pit_model[1])\n",
    "                \n",
    "    #laps remain, fill into the future\n",
    "    pitpred = np.array([0 for x in range(prediction_length)])\n",
    "    \n",
    "    if (pred_pit_laps > laps_instint) and (pred_pit_laps <= laps_instint + prediction_length):\n",
    "        pitpred[pred_pit_laps - laps_instint - 1] = 1\n",
    "         \n",
    "    return pitpred    \n",
    "    \n",
    "def make_dataset_byevent(runs, prediction_length, freq, \n",
    "                       useeid = False,\n",
    "                       run_ts=COL_LAPTIME, \n",
    "                       test_event = 'Indy500',\n",
    "                       test_cars = [],  \n",
    "                       use_global_dict = True,\n",
    "                       oracle_mode = MODE_ORACLE,\n",
    "                       half_moving_win = 0,\n",
    "                       train_ratio=0.8,\n",
    "                       verbose = False\n",
    "                ):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    input:\n",
    "        oracle_mode: false to simulate prediction in real by \n",
    "                set the covariates of track and lap status as nan in the testset\n",
    "        half_moving_win  ; extend to 0:-1 ,1:-1/2plen, 2:-plen\n",
    "    \n",
    "    \"\"\"    \n",
    "    init_track_model()\n",
    "    init_adjust_track_model()\n",
    "    \n",
    "    start = pd.Timestamp(\"01-01-2019\", freq=freq)  # can be different for each time series\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #select run\n",
    "    if runs>=0:\n",
    "        _laptime_data = [laptime_data[runs].copy()]\n",
    "    else:\n",
    "        _laptime_data = laptime_data.copy()\n",
    "    \n",
    "   \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        if events[_data[0]] == test_event:\n",
    "            test_mode = True\n",
    "        \n",
    "        else:\n",
    "            test_mode = False\n",
    "            \n",
    "            \n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        max_len = int(np.max(ts_len))\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'====event:{events[_data[0]]}, train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)}')\n",
    "                \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                if verbose:\n",
    "                    print(f'a short ts: carid={_data[1][rowid]}ï¼Œlen={totallen}')\n",
    "                continue                \n",
    "            \n",
    "            if use_global_dict:\n",
    "                carno = _data[1][rowid]\n",
    "                carid = global_carids[_data[1][rowid]]\n",
    "            else:\n",
    "                #simulation dataset, todo, fix the carids as decoder\n",
    "                carno = rowid\n",
    "                carid = rowid\n",
    "                \n",
    "            \n",
    "            if useeid:\n",
    "                static_cat = [carid, _data[0]]    \n",
    "            else:\n",
    "                static_cat = [carid]    \n",
    "                \n",
    "            # selection of features\n",
    "            if test_flag(oracle_mode, MODE_NOTRACK) or test_flag(oracle_mode, MODE_ORACLE_LAPONLY):                \n",
    "                rec[COL_TRACKSTATUS, :] = 0\n",
    "            if test_flag(oracle_mode, MODE_NOLAP) or test_flag(oracle_mode, MODE_ORACLE_TRACKONLY):                \n",
    "                rec[COL_LAPSTATUS, :] = 0\n",
    "\n",
    "            test_rec_cnt = 0\n",
    "            if not test_mode:\n",
    "                \n",
    "                # all go to train set\n",
    "                _train.append({'target': rec[run_ts,:].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [rec[COL_TRACKSTATUS,:],\n",
    "                                       rec[COL_LAPSTATUS,:]]\n",
    "                              }\n",
    "                              )\n",
    "            else:\n",
    "                # reset train_len\n",
    "                #context_len = prediction_length*2\n",
    "                #if context_len < 10:\n",
    "                #    context_len = 10\n",
    "                \n",
    "                context_len = train_len\n",
    "                \n",
    "                # multiple test ts(rolling window as half of the prediction_length)\n",
    "\n",
    "                #step = -int(prediction_length/2) if half_moving_win else -prediction_length\n",
    "                if half_moving_win == 1:\n",
    "                    step = -int(prediction_length/2)\n",
    "                elif half_moving_win == 2:\n",
    "                    step = -prediction_length\n",
    "                else:\n",
    "                    step = -1\n",
    "                \n",
    "                #bug fix, fixed the split point for all cars/ts\n",
    "                for endpos in range(max_len, context_len+prediction_length, \n",
    "                                    step):\n",
    "\n",
    "                    #check if enough for this ts\n",
    "                    if endpos > totallen:\n",
    "                        continue\n",
    "                    \n",
    "                    track_rec = rec[COL_TRACKSTATUS, :endpos].copy()\n",
    "                    lap_rec = rec[COL_LAPSTATUS, :endpos].copy()\n",
    "                    \n",
    "                    caution_laps_instint = int(rec[COL_CAUTION_LAPS_INSTINT, endpos -prediction_length - 1])\n",
    "                    laps_instint = int(rec[COL_LAPS_INSTINT, endpos -prediction_length - 1])\n",
    "                    \n",
    "\n",
    "                    # test mode\n",
    "                    if test_flag(oracle_mode, MODE_TESTCURTRACK):\n",
    "                        # since nan does not work, use cur-val instead\n",
    "                        track_rec[-prediction_length:] = track_rec[-prediction_length - 1]\n",
    "                        #track_rec[-prediction_length:] = random.randint(0,1)\n",
    "                        #lap_rec[-prediction_length:] = lap_rec[-prediction_length - 1]\n",
    "                        lap_rec[-prediction_length:] = 0\n",
    "                    elif test_flag(oracle_mode, MODE_TESTZERO):\n",
    "                        #set prediction part as nan\n",
    "                        #track_rec[-prediction_length:] = np.nan\n",
    "                        #lap_rec[-prediction_length:] = np.nan\n",
    "                        track_rec[-prediction_length:] = 0\n",
    "                        lap_rec[-prediction_length:] = 0        \n",
    "\n",
    "                    # predicting with status model\n",
    "                    if test_flag(oracle_mode, MODE_PREDTRACK):\n",
    "                        predrec = get_track_model(track_rec, endpos, prediction_length)\n",
    "                        track_rec[-prediction_length:] = predrec\n",
    "                        #lap_rec[-prediction_length:] = 0\n",
    "                        \n",
    "                    if test_flag(oracle_mode, MODE_PREDPIT):\n",
    "                        #predrec = get_track_model(track_rec, endpos, prediction_length)\n",
    "                        #track_rec[-prediction_length:] = predrec\n",
    "                        lap_rec[-prediction_length:] = get_pit_model(caution_laps_instint,\n",
    "                                                                    laps_instint,prediction_length)\n",
    "                        \n",
    "                        \n",
    "                    # disturbe analysis\n",
    "                    if test_flag(oracle_mode, MODE_DISTURB_CLEARTRACK):\n",
    "                        # clear the oracle track status\n",
    "                        # future 1s in trackstatus\n",
    "                        # pattern like 0 1 xx\n",
    "                        for _pos in range(-prediction_length + 1, -1):\n",
    "                            if track_rec[_pos - 1] == 0:\n",
    "                                track_rec[_pos] = 0\n",
    "                                \n",
    "                    if test_flag(oracle_mode, MODE_DISTURB_ADJUSTTRACK):\n",
    "                        # adjust the end position of track, or caution lap length\n",
    "                        # find the end of caution laps\n",
    "                        _tail = 0\n",
    "                        for _pos in range(-1,-prediction_length + 1,-1):\n",
    "                            if track_rec[_pos] == 1:\n",
    "                                #find the tail\n",
    "                                _tail = _pos\n",
    "                                break\n",
    "                        if _tail != 0:\n",
    "                            #found\n",
    "                            adjustrec = adjust_track_model(track_rec, endpos, prediction_length, _tail)\n",
    "                            track_rec[-prediction_length:] = adjustrec\n",
    "                        \n",
    "                    if test_flag(oracle_mode, MODE_DISTURB_ADJUSTPIT):\n",
    "                        # adjust the position of pit\n",
    "                        if np.sum(lap_rec[-prediction_length:]) > 0:\n",
    "                            adjustrec = adjust_pit_model(lap_rec, endpos, prediction_length)\n",
    "                            lap_rec[-prediction_length:] = adjustrec\n",
    "                        \n",
    "\n",
    "                    _test.append({'target': rec[run_ts,:endpos].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [track_rec,lap_rec]\n",
    "                                #'feat_dynamic_real': [rec[COL_TRACKSTATUS,:endpos],\n",
    "                                #       rec[COL_LAPSTATUS,:endpos]] \n",
    "                                 }\n",
    "                              )   \n",
    "                    test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            if verbose:\n",
    "                print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'train len:{len(train_set)}, test len:{len(test_set)}')\n",
    "    \n",
    "    train_ds = ListDataset(train_set, freq=freq)\n",
    "    test_ds = ListDataset(test_set, freq=freq)    \n",
    "    \n",
    "    return train_ds, test_ds, train_set, test_set\n",
    "\n",
    "def save_dataset(datafile,freq, prediction_length, cardinality, train_ds, test_ds):\n",
    "    with open(datafile, 'wb') as f:\n",
    "        #pack [global_carids, laptime_data]\n",
    "        savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "        #savedata = [freq, train_set, test_set]\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for Indy500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_ds,predictor):\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor=predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    return tss, forecasts\n",
    "\n",
    "   \n",
    "def run_prediction_ex(test_ds, prediction_length, model_name,trainid):\n",
    "    with mx.Context(mx.gpu(7)):    \n",
    "        pred_ret = []\n",
    "\n",
    "        rootdir = f'../models/remote/laptime-{trainid}/'\n",
    "        # deepAR-Oracle\n",
    "        if model_name == 'curtrack':\n",
    "            model=f'deepAR-Oracle-laptime-curtrack-indy-f1min-t{prediction_length}-e1000-r1_curtrack_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        elif model_name == 'zerotrack':\n",
    "            model=f'deepAR-Oracle-laptime-nolap-zerotrack-indy-f1min-t{prediction_length}-e1000-r1_zerotrack_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "            \n",
    "        # deepAR-Oracle\n",
    "        elif model_name == 'oracle':\n",
    "            model=f'deepAR-Oracle-laptime-all-indy-f1min-t{prediction_length}-e1000-r1_oracle_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        # deepAR\n",
    "        elif model_name == 'deepAR':\n",
    "            model=f'deepAR-laptime-all-indy-f1min-t{prediction_length}-e1000-r1_deepar_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        # naive\n",
    "        elif model_name == 'naive':\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  NaivePredictor(freq= freq, prediction_length = prediction_length)\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        # arima\n",
    "        elif model_name == 'arima':\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  RForecastPredictor(method_name='arima',freq= freq, \n",
    "                                            prediction_length = prediction_length,trunc_length=60)\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "        else:\n",
    "            print(f'error: model {model_name} not support yet!')\n",
    "\n",
    "        return pred_ret     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc rank\n",
    "def eval_rank_bytimediff(test_ds,tss,forecasts,prediction_length):\n",
    "    \"\"\"\n",
    "    timediff models\n",
    "    \n",
    "    works for one event only\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        #forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        \n",
    "        timediff_array = tss[idx].values.copy()\n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        forecasts_et[completed_laps][carno] = [timediff_array[-prediction_len:].copy(),\n",
    "                                                   forecast_laptime_mean.copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        time_diff = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            time_diff[0, carid, :] = forecasts_et[lap][carno][0].reshape((prediction_len))\n",
    "            time_diff[1, carid, :] = forecasts_et[lap][carno][1].reshape((prediction_len))\n",
    "\n",
    "        #calculate rank    \n",
    "        idx = np.argsort(time_diff[0], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        idx = np.argsort(time_diff[1], axis=0)\n",
    "        pred_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        rank_ret.append([lap, time_diff, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et\n",
    "    \n",
    "#calc rank\n",
    "def eval_rank(test_ds,tss,forecasts,prediction_length, start_offset):\n",
    "    \"\"\"\n",
    "    evaluate rank by laptime forecasting\n",
    "    \n",
    "    input:\n",
    "        test_ds       ; must be test set for a single event, because test_ds itself does not \n",
    "                        contain features to identify the eventid\n",
    "        start_offset[]; elapsed time for lap0, for one specific event\n",
    "        tss,forecasts ; forecast result\n",
    "        prediction_length ; \n",
    "    return:\n",
    "        rank_ret      ;  [lap, elapsed_time, true_rank, pred_rank] \n",
    "        forecasts_et  ;  {[completed_laps][carno]} ->(elapsed_time, elapsed_time_pred)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        #start_offset is global var\n",
    "        offset = start_offset[(start_offset['car_number']==carno)].elapsed_time.values[0] \n",
    "        #print('start_offset:', offset)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        #forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "\n",
    "        laptime_array = tss[idx].values.copy()\n",
    "        elapsed_time = np.cumsum(laptime_array) + offset\n",
    "\n",
    "        laptime_array = tss[idx].values.copy()\n",
    "        laptime_array[-prediction_len:] = forecast_laptime_mean \n",
    "        elapsed_time_hat = np.cumsum(laptime_array) + offset\n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        #forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len-1:].copy(),\n",
    "        #                                           elapsed_time_hat[-prediction_len-1:].copy()]\n",
    "        forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len:].copy(),\n",
    "                                                   elapsed_time_hat[-prediction_len:].copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        #elapsed_time = np.zeros((2, len(carlist), prediction_len+1))\n",
    "        elapsed_time = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            elapsed_time[0, carid, :] = forecasts_et[lap][carno][0]\n",
    "            elapsed_time[1, carid, :] = forecasts_et[lap][carno][1]\n",
    "\n",
    "        #calculate rank    \n",
    "        idx = np.argsort(elapsed_time[0], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        idx = np.argsort(elapsed_time[1], axis=0)\n",
    "        pred_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        rank_ret.append([lap, elapsed_time, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et\n",
    "   \n",
    "def get_acc(rank_ret,prediction_length):   \n",
    "    \"\"\"\n",
    "    input:\n",
    "        rank_ret: [lap, elapsed_time, true_rank, pred_rank], use [2][3] columns\n",
    "    return:\n",
    "        ((metrics...)\n",
    "         (record count...))\n",
    "         \n",
    "    the result can be used to calculate micro/macro metrics\n",
    "    \"\"\"\n",
    "    # evaluate\n",
    "    #top1 accuracy\n",
    "    top1acc = 0\n",
    "    top1acc_farmost = 0\n",
    "    top5acc = 0\n",
    "    top5acc_farmost = 0\n",
    "    tau = 0\n",
    "    rmse = 0.\n",
    "    \n",
    "    for rec in rank_ret:\n",
    "        trueRank = rec[2]\n",
    "        predRank = rec[3]\n",
    "\n",
    "        #top1 , rank = 0, first col is not prediction\n",
    "        top1acc += np.sum((trueRank==0) & (predRank==0)) \n",
    "        \n",
    "        top1acc_farmost += np.sum((trueRank[:,-1]==0) & (predRank[:,-1]==0))\n",
    "        \n",
    "        #top5\n",
    "        top5acc += np.sum((trueRank<5) & (predRank<5)) \n",
    "        \n",
    "        top5acc_farmost += np.sum((trueRank[:,-1]<5) & (predRank[:,-1]<5))\n",
    "        \n",
    "        # tau\n",
    "        tao, _ = stats.kendalltau(trueRank, predRank)\n",
    "        tau += tao\n",
    "        \n",
    "        #rmse\n",
    "        rmse += mean_squared_error(predRank,trueRank)\n",
    "        \n",
    "    recnt = len(rank_ret)\n",
    "    if recnt > 0:\n",
    "        top1acc = top1acc *1.0/ (recnt*prediction_length)\n",
    "        top1acc_farmost = top1acc_farmost *1.0/ recnt\n",
    "        top5acc = top5acc *1.0/ (5*recnt*prediction_length)\n",
    "        top5acc_farmost = top5acc_farmost *1.0/ (5*recnt)\n",
    "        tau = tau/recnt\n",
    "        rmse = rmse/recnt\n",
    "\n",
    "\n",
    "        print(f'total:{len(rank_ret)}, prediction_length:{prediction_length}') \n",
    "        print('top1acc=', top1acc,\n",
    "              'top1acc_farmost=', top1acc_farmost,\n",
    "              'top5acc=', top5acc,\n",
    "              'top5acc_farmost=', top5acc_farmost,\n",
    "             )\n",
    "        print('tau = ', tau,\n",
    "             'rmse = ', rmse)\n",
    "    \n",
    "    return ((top1acc,top1acc_farmost,top5acc,top5acc_farmost,tau,rmse),\n",
    "            (recnt*prediction_length,recnt,5*recnt*prediction_length,5*recnt,recnt,recnt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = [], datamode = MODE_ORACLE,models = ['oracle']):\n",
    "    \"\"\"\n",
    "    dependency: test_event, test on one event only\n",
    "    \n",
    "    \"\"\"\n",
    "    retdf = []\n",
    "    pred_ret = {}\n",
    "    ds_ret = {}\n",
    "    rank_result = {}\n",
    "    \n",
    "    ### create test dataset\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=datamode,\n",
    "                                         run_ts = COL_LAPTIME,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    for model in models:\n",
    "        print('exp:',inspect.stack()[0][3],'model:', model, 'datamode:', get_modestr(datamode))\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "\n",
    "        rank_ret, forecast_ret = eval_rank(test_ds,tss,forecasts,prediction_length,global_start_offset[test_event])\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,get_modestr(datamode),trainid]\n",
    "        ret.extend(metrics[0])\n",
    "        retdf.append(ret)\n",
    "        \n",
    "        rank_result[model] = (rank_ret,forecast_ret)\n",
    "    \n",
    "    return pred_ret, ds_ret, rank_result, retdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp_baseline(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):           \n",
    "    \"\"\"\n",
    "    dependency: test_event, test on one event only\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    models = ['oracle','deepAR','naive']\n",
    "    #,'arima']\n",
    "    retdf = []\n",
    "    pred_ret = {}\n",
    "    ds_ret = {}\n",
    "    rank_result = {}\n",
    "    \n",
    "    ### create test dataset\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_ORACLE,\n",
    "                                         run_ts = COL_LAPTIME,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    modestr = 'MODE_ORACLE' \n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "\n",
    "        rank_ret,forecast_ret = eval_rank(test_ds,tss,forecasts,prediction_length,global_start_offset[test_event])\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,modestr, trainid]\n",
    "        ret.extend(metrics[0])\n",
    "        retdf.append(ret)\n",
    "        \n",
    "        rank_result[model] = (rank_ret,forecast_ret)\n",
    "    \n",
    "    # special model with test_ds\n",
    "    models = ['curtrack']        \n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_TESTCURTRACK,\n",
    "                                         run_ts = COL_LAPTIME,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    modestr = 'MODE_TESTCURTRACK'\n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "        \n",
    "        rank_ret,forecast_ret = eval_rank(test_ds,tss,forecasts,prediction_length,global_start_offset[test_event])\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,modestr, trainid]\n",
    "        ret.extend(metrics[0])\n",
    "        retdf.append(ret)\n",
    "        \n",
    "        rank_result[model] = (rank_ret,forecast_ret)\n",
    "\n",
    "    # zerotrack\n",
    "    models = ['zerotrack']        \n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_TESTZERO,\n",
    "                                         run_ts = COL_LAPTIME,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    modestr = 'MODE_TESTZERO'\n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "        \n",
    "        rank_ret,forecast_ret = eval_rank(test_ds,tss,forecasts,prediction_length,global_start_offset[test_event])\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,modestr, trainid]\n",
    "        ret.extend(metrics[0])\n",
    "        retdf.append(ret)\n",
    "        \n",
    "        rank_result[model] = (rank_ret,forecast_ret)\n",
    "    \n",
    "        \n",
    "    return pred_ret, ds_ret, rank_result, retdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp_predtrack(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                                        test_event='Indy500', test_cars = []):\n",
    "    models = ['oracle','curtrack','zerotrack']\n",
    "    datamode = MODE_PREDTRACK\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)\n",
    "    \n",
    "\n",
    "def run_exp_predpit(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):\n",
    "    models = ['oracle','curtrack','zerotrack']\n",
    "    datamode=MODE_PREDPIT\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)\n",
    "\n",
    "#MODE_DISTURB_CLEARTRACK = 64\n",
    "#MODE_DISTURB_ADJUSTTRACK = 128\n",
    "#MODE_DISTURB_ADJUSTPIT = 256\n",
    "def run_exp_cleartrack(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):\n",
    "    models = ['oracle']\n",
    "    datamode=MODE_DISTURB_CLEARTRACK\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)\n",
    "\n",
    "def run_exp_adjusttrack(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):\n",
    "    \"\"\"\n",
    "    dependency: test_event, test on one event only\n",
    "    \n",
    "    \"\"\"\n",
    "    models = ['oracle']\n",
    "    datamode=MODE_DISTURB_CLEARTRACK + MODE_DISTURB_ADJUSTTRACK\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)\n",
    "\n",
    "def run_exp_adjustpit(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):\n",
    "    models = ['oracle']\n",
    "    datamode=MODE_DISTURB_ADJUSTPIT\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)\n",
    "    \n",
    "def run_exp_adjustall(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):\n",
    "    models = ['oracle']\n",
    "    datamode=MODE_DISTURB_CLEARTRACK +MODE_DISTURB_ADJUSTPIT +MODE_DISTURB_ADJUSTTRACK\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(runs, plens, half, trainids, train_ratio, testfunc, datamode='', models=[]):\n",
    "    \"\"\"\n",
    "    \n",
    "    input:\n",
    "        plens=[2,5,10]\n",
    "        half=[False]\n",
    "        #trainids = [\"indy500-r0.2\",\"indy500-r0.4\",\"indy500\"]\n",
    "        trainids = [\"r0.5\"]\n",
    "        #half=[True,False]\n",
    "        #plens=[2]\n",
    "        runs = 5\n",
    "        train_ratio=0.5 \n",
    "        exp_id='mean-splitbystage-predpit'\n",
    "        \n",
    "        testfunc ; run_exp_predpit, run_exp_predtrack, run_exp ...\n",
    "\n",
    "    return:\n",
    "    \n",
    "        dfret  ; average result of multiple runs\n",
    "                 dataframe['model' , 'prediction_length', 'halfmode','datamode','trainid',\n",
    "                         'top1acc','top1acc_farmost','top5acc','top5acc_farmost','tau','rmse',\n",
    "                         'top1acc_std','top1acc_farmost_std','top5acc_std','top5acc_farmost_std','tau_std','rmse_std']\n",
    "                          \n",
    "        alldata_ret  ; for debug\n",
    "            [runid][halfmode,plen,trainid] -> (pred_ret, test_ds, rank_ret)\n",
    "                pred_ret[model] ->ã€€[tss, forecasts]\n",
    "                test_ds[model] ->ã€€test_ds\n",
    "                rank_ret[model] -> ([lap, elapsed_time, true_rank, pred_rank],forecast_ret)\n",
    "                    forecast_ret[completed_laps][carno] -> (elapsed_time, elapsed_time_hat)\n",
    "    \n",
    "    \"\"\"\n",
    "    if plens == [] or half == [] or trainids == []:\n",
    "        print(\"error with empty settings\")\n",
    "        return\n",
    "    \n",
    "    #testfunc or (datamode & models)\n",
    "    if isinstance(testfunc,str) and (datamode == '' or models == []):\n",
    "        print(\"error with testfunc\")\n",
    "        return\n",
    "\n",
    "    allret = []\n",
    "    alldata_ret = []\n",
    "    for runid in range(runs):\n",
    "        exp_data = []\n",
    "        exp_result = []\n",
    "\n",
    "        for halfmode in half:\n",
    "            for plen in plens:\n",
    "                for trainid in trainids:\n",
    "                    print('='*10)\n",
    "                    if not isinstance(testfunc,str):\n",
    "                        pred_ret, test_ds, rank_ret, metric_ret = testfunc(plen, halfmode, \n",
    "                                                            train_ratio=train_ratio,\n",
    "                                                            trainid=trainid)\n",
    "                    else:\n",
    "                        pred_ret, test_ds, rank_ret, metric_ret = run_exp(plen, halfmode, \n",
    "                                                            train_ratio=train_ratio,\n",
    "                                                            trainid=trainid, \n",
    "                                                            datamode=datamode,\n",
    "                                                            models=models)\n",
    "                        \n",
    "\n",
    "                    #save \n",
    "                    exp_data.append((pred_ret, test_ds, rank_ret))\n",
    "                    exp_result.extend(metric_ret)\n",
    "\n",
    "        #save result\n",
    "        result = pd.DataFrame(exp_result, columns = ['model' , 'prediction_length', 'halfmode',\n",
    "                                           'datamode','trainid',\n",
    "                                           'top1acc','top1acc_farmost','top5acc',\n",
    "                                           'top5acc_farmost','tau','rmse'])\n",
    "\n",
    "        #result['runid'] = [runid for x in range(len(result))]\n",
    "        allret.append(result)\n",
    "        alldata_ret.append(exp_data)\n",
    "\n",
    "    #final\n",
    "    rowcnt = len(allret[0])\n",
    "    metrics = np.empty((runs, rowcnt, 6))\n",
    "    for runid, ret in enumerate(allret):\n",
    "        metrics[runid, :,:] = ret[['top1acc','top1acc_farmost','top5acc',\n",
    "                                           'top5acc_farmost','tau','rmse']].values\n",
    "\n",
    "\n",
    "    #average\n",
    "    averagemat = np.mean(metrics[:,:,:], axis=0)\n",
    "    stdmat = np.std(metrics[:,:,:], axis=0)\n",
    "    dfhead = allret[0][['model' , 'prediction_length', 'halfmode', 'datamode','trainid']]\n",
    "    \n",
    "    \n",
    "    dfaverage = pd.DataFrame(averagemat, columns = ['top1acc','top1acc_farmost','top5acc',\n",
    "                                       'top5acc_farmost','tau','rmse'])\n",
    "    dfstd = pd.DataFrame(stdmat, columns = ['top1acc_std','top1acc_farmost_std','top5acc_std',\n",
    "                                       'top5acc_farmost_std','tau_std','rmse_std'])\n",
    "    dfret = pd.concat([dfhead, dfaverage, dfstd], axis=1)\n",
    "\n",
    "    if exp_id != '':\n",
    "        dfret.to_csv(f'laptime2rank-evaluate-indy500-{exp_id}-result.csv', float_format='%.3f')\n",
    "\n",
    "    return dfret, alldata_ret\n",
    "\n",
    "\n",
    "def checkret_status(dataret, runid = 0, idx = 0):\n",
    "    \"\"\"\n",
    "    check the test_ds track and lap status\n",
    "    \n",
    "        alldata_ret  ; for debug\n",
    "            [runid][halfmode,plen,trainid] -> (pred_ret, test_ds, rank_ret)\n",
    "                pred_ret[model] ->ã€€[tss, forecasts]\n",
    "                test_ds[model] ->ã€€test_ds\n",
    "                rank_ret[model] -> ([lap, elapsed_time, true_rank, pred_rank],forecast_ret)\n",
    "                    forecast_ret[completed_laps][carno] -> (elapsed_time, elapsed_time_hat)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    _, plen = dataret[runid][idx][0]['oracle'][1][0].samples.shape\n",
    "    test_ds = dataret[runid][idx][1]['oracle']\n",
    "   \n",
    "    \n",
    "    ds_iter =  iter(test_ds)\n",
    "    yfcnt = 0\n",
    "    pitcnt = 0\n",
    "    for recid in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        \n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        \n",
    "        track_rec,lap_rec = test_rec['feat_dynamic_real']\n",
    "        yfcnt += np.sum(track_rec[-plen:])\n",
    "        pitcnt += np.sum(lap_rec[-plen:])\n",
    "        \n",
    "    print('yfcnt:', yfcnt, 'pitcnt:',pitcnt)\n",
    "\n",
    "def get_ref_oracle_testds_single(prediction_length, half_moving_win, train_ratio=0.8, \n",
    "                   test_event='Indy500', test_cars = []):           \n",
    "    ### create test dataset\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_ORACLE,\n",
    "                                         run_ts = COL_LAPTIME,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)    \n",
    "    return test_ds\n",
    "\n",
    "def get_ref_oracle_testds(plens, halfs, train_ratio=0.8, \n",
    "                   test_event='Indy500', test_cars = []):           \n",
    "    \n",
    "    testset = {}\n",
    "    for prediction_length in plens:\n",
    "        for half_moving_win in halfs:\n",
    "            train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_ORACLE,\n",
    "                                         run_ts = COL_LAPTIME,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)    \n",
    "            \n",
    "            # get key\n",
    "            key = '%d-%d'%(prediction_length,half_moving_win)\n",
    "            testset[key] = test_ds\n",
    "            \n",
    "    return testset\n",
    "\n",
    "\n",
    "def checkret_confusionmat_single(dataret, ref_oracle_testds, runid= 0, idx = 0):\n",
    "    \"\"\"\n",
    "    output the 4x4 confusion matrix split by track and lap status\n",
    "    \n",
    "    input:\n",
    "        ref_oracle_testds  ; oracle test ds\n",
    "    \n",
    "    \"\"\"\n",
    "    _, plen = dataret[runid][idx][0]['oracle'][1][0].samples.shape\n",
    "    test_ds = dataret[runid][idx][1]['oracle']\n",
    "    rank_ret = dataret[runid][idx][2]['oracle']\n",
    "    \n",
    "    if len(ref_oracle_testds) != len(test_ds):\n",
    "        print('error, size of testds mismatch', len(ref_oracle_testds), len(test_ds))\n",
    "        return\n",
    "    \n",
    "    # confusion matrix for <trackstatus, lapstatus> type: 00,01,10,11\n",
    "    # lap(start lap of prediction)  -> type\n",
    "    lapmap = {}\n",
    "    ds_iter =  iter(ref_oracle_testds)\n",
    "    for recid in range(len(ref_oracle_testds)):\n",
    "        test_rec = next(ds_iter) \n",
    "        \n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        \n",
    "        track_rec,lap_rec = test_rec['feat_dynamic_real']\n",
    "        yfcnt = np.sum(track_rec[-plen:])\n",
    "        pitcnt = np.sum(lap_rec[-plen:])    \n",
    "        \n",
    "        #laptype = ('0' if yfcnt==0 else '1') + ('0' if pitcnt==0 else '1')\n",
    "        \n",
    "        lap = len(track_rec) - plen + 1\n",
    "        if lap not in lapmap:\n",
    "            #lapmap[lap] = laptype\n",
    "            lapmap[lap] = (yfcnt, pitcnt)\n",
    "        else:\n",
    "            oldtype = lapmap[lap]\n",
    "            lapmap[lap] = (yfcnt + oldtype[0], pitcnt + oldtype[1])\n",
    "            \n",
    "    \n",
    "    #split the rank_ret by laptype\n",
    "    types=['00','10','01','11']\n",
    "    acc_ret = []\n",
    "    for laptype in types:\n",
    "        check_ret = []\n",
    "        for item in rank_ret:\n",
    "            typecnt = lapmap[item[0]]\n",
    "            \n",
    "            thetype = ('0' if typecnt[0]==0 else '1') + ('0' if typecnt[1]==0 else '1')\n",
    "            \n",
    "            if thetype == laptype:\n",
    "                check_ret.append(item)\n",
    "        # get acc\n",
    "        metrics = get_acc(check_ret,plen)\n",
    "        recret = [laptype, len(check_ret)]\n",
    "        recret.extend(metrics[0])\n",
    "        acc_ret.append(recret)\n",
    "    \n",
    "    dfacc = pd.DataFrame(acc_ret, columns = ['type','reccnt','top1acc','top1acc_farmost','top5acc',\n",
    "                                       'top5acc_farmost','tau','rmse'])\n",
    "    return dfacc\n",
    "\n",
    "\n",
    "\n",
    "def checkret_confusionmat(dataret, ref_testset, runid= 0, testid = ''):\n",
    "    \"\"\"\n",
    "    output the 4x4 confusion matrix split by track and lap status\n",
    "    \n",
    "    input:\n",
    "        ref_oracle_testds  ; oracle test ds\n",
    "    \n",
    "    \"\"\"\n",
    "    plen_length = len(dataret[runid])\n",
    "    \n",
    "    dflist = []\n",
    "    for idx in range(plen_length):\n",
    "        _, plen = dataret[runid][idx][0]['oracle'][1][0].samples.shape\n",
    "        test_ds = dataret[runid][idx][1]['oracle']\n",
    "        rank_ret = dataret[runid][idx][2]['oracle'][0]\n",
    "\n",
    "        key = '%d-%d'%(plen,0)\n",
    "        if key not in ref_testset:\n",
    "            print(f'error, {key} not found in ref_testset')\n",
    "            continue\n",
    "        \n",
    "        ref_oracle_testds = ref_testset[key]\n",
    "        if len(ref_oracle_testds) != len(test_ds):\n",
    "            print('error, size of testds mismatch', len(ref_oracle_testds), len(test_ds))\n",
    "            continue\n",
    "\n",
    "        # confusion matrix for <trackstatus, lapstatus> type: 00,01,10,11\n",
    "        # lap(start lap of prediction)  -> type\n",
    "        lapmap = {}\n",
    "        ds_iter =  iter(ref_oracle_testds)\n",
    "        for recid in range(len(ref_oracle_testds)):\n",
    "            test_rec = next(ds_iter) \n",
    "\n",
    "            carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "\n",
    "            track_rec,lap_rec = test_rec['feat_dynamic_real']\n",
    "            yfcnt = np.sum(track_rec[-plen:])\n",
    "            pitcnt = np.sum(lap_rec[-plen:])    \n",
    "\n",
    "            #laptype = ('0' if yfcnt==0 else '1') + ('0' if pitcnt==0 else '1')\n",
    "\n",
    "            lap = len(track_rec) - plen + 1\n",
    "            if lap not in lapmap:\n",
    "                #lapmap[lap] = laptype\n",
    "                lapmap[lap] = (yfcnt, pitcnt)\n",
    "            else:\n",
    "                oldtype = lapmap[lap]\n",
    "                lapmap[lap] = (yfcnt + oldtype[0], pitcnt + oldtype[1])\n",
    "\n",
    "\n",
    "        #split the rank_ret by laptype\n",
    "        types=['00','10','01','11']\n",
    "        acc_ret = []\n",
    "        for laptype in types:\n",
    "            check_ret = []\n",
    "            for item in rank_ret:\n",
    "                typecnt = lapmap[item[0]]\n",
    "\n",
    "                thetype = ('0' if typecnt[0]==0 else '1') + ('0' if typecnt[1]==0 else '1')\n",
    "\n",
    "                if thetype == laptype:\n",
    "                    check_ret.append(item)\n",
    "            # get acc\n",
    "            metrics = get_acc(check_ret,plen)\n",
    "            recret = [testid, plen, laptype, len(check_ret)]\n",
    "            recret.extend(metrics[0])\n",
    "            acc_ret.append(recret)\n",
    "\n",
    "        #add all test\n",
    "        metrics = get_acc(rank_ret,plen)\n",
    "        recret = [testid, plen, 'aa', len(rank_ret)]\n",
    "        recret.extend(metrics[0])\n",
    "        acc_ret.append(recret)\n",
    "        \n",
    "        _dfacc = pd.DataFrame(acc_ret, columns = ['testid','plen',\n",
    "                                'type','reccnt','top1acc','top1acc_farmost','top5acc',\n",
    "                                'top5acc_farmost','tau','rmse'])\n",
    "        \n",
    "        dflist.append(_dfacc)\n",
    "    \n",
    "    dfacc = pd.concat(dflist, axis=0)\n",
    "    \n",
    "    return dfacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# parameters\n",
    "#\n",
    "#year = '2017'\n",
    "year = '2018'\n",
    "#event = 'Toronto'\n",
    "#https://www.racing-reference.info/season-stats/2018/O/#\n",
    "events_totalmiles=[256,500,372,268,500,310]\n",
    "events_laplen = [1.022,2.5,1.5,0.894,2.5,1.25]\n",
    "events = ['Phoenix','Indy500','Texas','Iowa','Pocono','Gateway']\n",
    "#events = ['Gateway']\n",
    "\n",
    "#events = ['Indy500']\n",
    "#events = ['Phoenix']\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "#works for only one event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "stagedata = {}\n",
    "global_start_offset = {}\n",
    "global_carids = {}\n",
    "traindata = None\n",
    "\n",
    "cur_carid = 0\n",
    "for event in events:\n",
    "    #alldata, rankdata, acldata, flagdata\n",
    "    stagedata[event] = load_data(event, year)\n",
    "    \n",
    "    alldata, rankdata, acldata = stagedata[event]\n",
    "    #carlist = set(acldata['car_number'])\n",
    "    #laplist = set(acldata['completed_laps'])\n",
    "    #print('%s: carno=%d, lapnum=%d'%(event, len(carlist), len(laplist)))\n",
    "\n",
    "    #offset\n",
    "    global_start_offset[event] = rankdata[rankdata['completed_laps']==0][['car_number','elapsed_time']]\n",
    "    \n",
    "    #build the carid map\n",
    "    #for car in carlist:\n",
    "    #    if car not in global_carids:\n",
    "    #        global_carids[car] = cur_carid\n",
    "    #        cur_carid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from here\n",
    "import pickle\n",
    "with open('laptime_rank_timediff_pit-oracle-%s.pickle'%year, 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    global_carids, laptime_data = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"1min\"\n",
    "#decode global_carids\n",
    "decode_carids={carid:carno for carno, carid in global_carids.items()}\n",
    "    \n",
    "#useeid = False\n",
    "#interpolate = False\n",
    "#ipstr = '-ip' if interpolate else '-noip'\n",
    "#ipstr = '%s-%s'%('ip' if interpolate else 'noip', 'eid' if useeid else 'noeid')\n",
    "#if useeid:\n",
    "#    cardinality = [len(global_carids), len(laptime_data)]\n",
    "#else:\n",
    "#    cardinality = [len(global_carids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oracle test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotest(config):\n",
    "    acclist = []\n",
    "    dflist = []\n",
    "    for teststr in config.keys():\n",
    "        testfunc = teststr\n",
    "        datamode = config[teststr]\n",
    "\n",
    "        models = ['oracle']\n",
    "        df, dataret = run_test(runs, plens, half, trainids, train_ratio, testfunc, datamode=datamode,models=models)\n",
    "\n",
    "        #concat\n",
    "        acc = checkret_confusionmat(dataret, ref_testset, testid = teststr)\n",
    "        dflist.append(df)\n",
    "        acclist.append(acc)\n",
    "\n",
    "    dfret = pd.concat(dflist, axis=0)\n",
    "    dfacc = pd.concat(acclist, axis=0)\n",
    "    return dfret, dfacc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "#half=[True, False]\n",
    "#plens=[2,5,10,20,30]\n",
    "plens=[2,5,10]\n",
    "half=[0]\n",
    "trainids = [\"indy500\"]\n",
    "#trainids = [\"r0.5\",\"r0.6\"]\n",
    "runs = 1\n",
    "train_ratio=0.4\n",
    "\n",
    "#trainids = [\"indy500\"]\n",
    "#runs = 1\n",
    "#plens=[2]\n",
    "exp_id=''\n",
    "\n",
    "config = {'fulloracle':MODE_ORACLE,'notracklap':MODE_NOTRACK + MODE_NOLAP,\n",
    "         'laponly':MODE_ORACLE_LAPONLY, 'trackonly':MODE_ORACLE_TRACKONLY,\n",
    "          'fullpred':MODE_PREDTRACK + MODE_PREDPIT,\n",
    "          'predtrack':MODE_PREDTRACK + MODE_ORACLE_TRACKONLY,\n",
    "          'predpit':MODE_PREDPIT + MODE_ORACLE_LAPONLY          \n",
    "         }\n",
    "\n",
    "ref_testset = get_ref_oracle_testds(plens, half, train_ratio=train_ratio)\n",
    "\n",
    "dfret, dfacc = dotest(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfacc.to_csv('laptime2rank-evaluate-indy500-mean-splitbyevent-fulltest-contigency-r1-t0.4-result.csv', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfret.to_csv('laptime2rank-evaluate-indy500-mean-splitbyevent-fulltest-r1-t0.4-result.csv', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODE_DISTURB_CLEARTRACK = 64\n",
    "#MODE_DISTURB_ADJUSTTRACK = 128\n",
    "#MODE_DISTURB_ADJUSTPIT = 256\n",
    "\n",
    "config_adjust = {'cleartrack':MODE_DISTURB_CLEARTRACK,'adjusttrack':MODE_DISTURB_CLEARTRACK + MODE_DISTURB_ADJUSTTRACK,\n",
    "         'adjustpit':MODE_DISTURB_ADJUSTPIT, 'adjustall':MODE_DISTURB_CLEARTRACK+ MODE_DISTURB_ADJUSTTRACK+MODE_DISTURB_ADJUSTPIT,\n",
    "         }\n",
    "\n",
    "adjust_dfret, adjust_dfacc = dotest(config_adjust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.concat([dfacc, adjust_dfacc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "train len:0, test len:3142\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_LAPONLY,MODE_DISTURB_ADJUSTPIT,\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3142, forecasts len=3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:118, prediction_length:2\n",
      "top1acc= 0.7796610169491526 top1acc_farmost= 0.8050847457627118 top5acc= 0.8966101694915254 top5acc_farmost= 0.8847457627118644\n",
      "tau =  0.8795857143136794 rmse =  6.5626132526491485\n",
      "==========\n",
      "train len:0, test len:3055\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_LAPONLY,MODE_DISTURB_ADJUSTPIT,\n",
      "predicting model=oracle, plen=5\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3055, forecasts len=3055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:115, prediction_length:5\n",
      "top1acc= 0.6608695652173913 top1acc_farmost= 0.5304347826086957 top5acc= 0.8292173913043478 top5acc_farmost= 0.7669565217391304\n",
      "tau =  0.8128019735219131 rmse =  11.813716572451154\n",
      "==========\n",
      "train len:0, test len:2910\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_LAPONLY,MODE_DISTURB_ADJUSTPIT,\n",
      "predicting model=oracle, plen=10\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=2910, forecasts len=2910\n",
      "total:110, prediction_length:10\n",
      "top1acc= 0.5427272727272727 top1acc_farmost= 0.4818181818181818 top5acc= 0.7718181818181818 top5acc_farmost= 0.6909090909090909\n",
      "tau =  0.7442452303387397 rmse =  16.72662359440771\n",
      "total:27, prediction_length:2\n",
      "top1acc= 0.8333333333333334 top1acc_farmost= 0.8148148148148148 top5acc= 0.9185185185185185 top5acc_farmost= 0.9037037037037037\n",
      "tau =  0.897787303968478 rmse =  6.0042863665169195\n",
      "total:11, prediction_length:2\n",
      "top1acc= 0.7727272727272727 top1acc_farmost= 0.8181818181818182 top5acc= 0.7909090909090909 top5acc_farmost= 0.8\n",
      "tau =  0.7510008670878235 rmse =  19.820255115255115\n",
      "total:49, prediction_length:2\n",
      "top1acc= 0.7755102040816326 top1acc_farmost= 0.8571428571428571 top5acc= 0.9020408163265307 top5acc_farmost= 0.9020408163265307\n",
      "tau =  0.8920352971024574 rmse =  5.100464243097107\n",
      "total:31, prediction_length:2\n",
      "top1acc= 0.7419354838709677 top1acc_farmost= 0.7096774193548387 top5acc= 0.9064516129032258 top5acc_farmost= 0.8709677419354839\n",
      "tau =  0.8896812253509306 rmse =  4.655712185067023\n",
      "total:118, prediction_length:2\n",
      "top1acc= 0.7796610169491526 top1acc_farmost= 0.8050847457627118 top5acc= 0.8966101694915254 top5acc_farmost= 0.8847457627118644\n",
      "tau =  0.8795857143136794 rmse =  6.5626132526491485\n",
      "total:13, prediction_length:5\n",
      "top1acc= 0.8153846153846154 top1acc_farmost= 0.7692307692307693 top5acc= 0.8184615384615385 top5acc_farmost= 0.7230769230769231\n",
      "tau =  0.7820073428487222 rmse =  17.91317317165593\n",
      "total:2, prediction_length:5\n",
      "top1acc= 0.0 top1acc_farmost= 0.0 top5acc= 0.36 top5acc_farmost= 0.0\n",
      "tau =  0.436 rmse =  48.15384615384616\n",
      "total:54, prediction_length:5\n",
      "top1acc= 0.7111111111111111 top1acc_farmost= 0.5740740740740741 top5acc= 0.8725925925925926 top5acc_farmost= 0.837037037037037\n",
      "tau =  0.8479175505448192 rmse =  8.035797713136375\n",
      "total:46, prediction_length:5\n",
      "top1acc= 0.5869565217391305 top1acc_farmost= 0.43478260869565216 top5acc= 0.8017391304347826 top5acc_farmost= 0.7304347826086957\n",
      "tau =  0.7966648645340516 rmse =  12.94489969094128\n",
      "total:115, prediction_length:5\n",
      "top1acc= 0.6608695652173913 top1acc_farmost= 0.5304347826086957 top5acc= 0.8292173913043478 top5acc_farmost= 0.7669565217391304\n",
      "tau =  0.8128019735219131 rmse =  11.813716572451154\n",
      "total:2, prediction_length:10\n",
      "top1acc= 1.0 top1acc_farmost= 1.0 top5acc= 0.94 top5acc_farmost= 0.9\n",
      "tau =  0.9230026455026454 rmse =  2.4892857142857143\n",
      "total:51, prediction_length:10\n",
      "top1acc= 0.6411764705882353 top1acc_farmost= 0.5882352941176471 top5acc= 0.8113725490196079 top5acc_farmost= 0.7647058823529411\n",
      "tau =  0.7588062665679297 rmse =  16.62505978943301\n",
      "total:57, prediction_length:10\n",
      "top1acc= 0.43859649122807015 top1acc_farmost= 0.3684210526315789 top5acc= 0.7305263157894737 top5acc_farmost= 0.6175438596491228\n",
      "tau =  0.7249447447595024 rmse =  17.31705218763495\n",
      "total:110, prediction_length:10\n",
      "top1acc= 0.5427272727272727 top1acc_farmost= 0.4818181818181818 top5acc= 0.7718181818181818 top5acc_farmost= 0.6909090909090909\n",
      "tau =  0.7442452303387397 rmse =  16.72662359440771\n"
     ]
    }
   ],
   "source": [
    "config_t = {'adjust_laponly':MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "         }\n",
    "\n",
    "t_dfret, t_dfacc = dotest(config_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plens=[2,5,10]\n",
    "half=[0]\n",
    "trainids = [\"indy500-r0.2\",\"indy500-r0.4\",\"indy500\"]\n",
    "#trainids = [\"r0.5\",\"r0.6\"]\n",
    "runs = 5\n",
    "train_ratio=0.4\n",
    "\n",
    "testfunc = 'trackonly'\n",
    "datamode = MODE_ORACLE_TRACKONLY\n",
    "models = ['oracle']\n",
    "exp_id=f'mean-splitbyevent-{testfunc}-r{runs}-t{train_ratio}'\n",
    "run_test(runs, plens, half, trainids, train_ratio, testfunc, datamode=datamode,models=models)\n",
    "\n",
    "testfunc = 'laponly'\n",
    "datamode = MODE_ORACLE_LAPONLY\n",
    "models = ['oracle']\n",
    "exp_id=f'mean-splitbyevent-{testfunc}-r{runs}-t{train_ratio}'\n",
    "run_test(runs, plens, half, trainids, train_ratio, testfunc, datamode=datamode,models=models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plens=[2,5,10]\n",
    "half=[0]\n",
    "trainids = [\"indy500-r0.2\",\"indy500-r0.4\",\"indy500\"]\n",
    "#trainids = [\"r0.5\",\"r0.6\"]\n",
    "runs = 5\n",
    "train_ratio=0.4\n",
    "\n",
    "testfunc = 'notracklap'\n",
    "datamode = MODE_NOTRACK + MODE_NOLAP\n",
    "models = ['oracle']\n",
    "exp_id=f'mean-splitbyevent-{testfunc}-r{runs}-t{train_ratio}'\n",
    "run_test(runs, plens, half, trainids, train_ratio, testfunc, datamode=datamode,models=models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#half=[True, False]\n",
    "#plens=[2,5,10,20,30]\n",
    "plens=[2,5,10]\n",
    "half=[0]\n",
    "trainids = [\"indy500-r0.2\",\"indy500-r0.4\",\"indy500\"]\n",
    "#trainids = [\"r0.5\",\"r0.6\"]\n",
    "runs = 5\n",
    "train_ratio=0.4\n",
    "\n",
    "#trainids = [\"indy500\"]\n",
    "#runs = 1\n",
    "#plens=[2]\n",
    "\n",
    "testfunc = run_exp_cleartrack\n",
    "exp_id=f'mean-splitbyevent-adjustcleartrack-r{runs}-t{train_ratio}'\n",
    "test_result[exp_id] = run_test(runs, plens, half, trainids, train_ratio, testfunc)\n",
    "\n",
    "testfunc = run_exp_adjusttrack\n",
    "exp_id=f'mean-splitbyevent-adjusttrack-r{runs}-t{train_ratio}'\n",
    "test_result[exp_id] = run_test(runs, plens, half, trainids, train_ratio, testfunc)\n",
    "\n",
    "testfunc = run_exp_adjustpit\n",
    "exp_id=f'mean-splitbyevent-adjustpit-r{runs}-t{train_ratio}'\n",
    "test_result[exp_id] = run_test(runs, plens, half, trainids, train_ratio, testfunc)\n",
    "\n",
    "testfunc = run_exp_adjustall\n",
    "exp_id=f'mean-splitbyevent-adjustall-r{runs}-t{train_ratio}'\n",
    "test_result[exp_id] = run_test(runs, plens, half, trainids, train_ratio, testfunc)\n",
    "\n",
    "#testfunc = run_exp\n",
    "#exp_id=f'mean-splitbyevent-baseline-r{runs}-t{train_ratio}'\n",
    "#test_result[exp_id] = run_test(runs, plens, half, trainids, train_ratio, testfunc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#half=[True, False]\n",
    "#plens=[2,5,10,20,30]\n",
    "plens=[2,5,10]\n",
    "half=[0]\n",
    "#trainids = [\"indy500-r0.2\",\"indy500-r0.4\",\"indy500\"]\n",
    "trainids = [\"r0.5\",\"r0.6\",\"r0.7\"]\n",
    "runs = 5\n",
    "train_ratio=0.7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the car list number for -100 test record\n",
    "ret[0][0][2]['oracle'][-100][2].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ret[0][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=(3,4)\n",
    "a+(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfacc[dfacc['plen']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "#half=[True, False]\n",
    "#plens=[2,5,10,20,30]\n",
    "plens=[2]\n",
    "half=[0]\n",
    "trainids = [\"indy500\"]\n",
    "#trainids = [\"r0.5\",\"r0.6\"]\n",
    "runs = 1\n",
    "train_ratio=0.4\n",
    "\n",
    "#trainids = [\"indy500\"]\n",
    "#runs = 1\n",
    "#plens=[2]\n",
    "\n",
    "testfunc = 'notracklap'\n",
    "datamode = MODE_NOTRACK + MODE_NOLAP\n",
    "datamode = MODE_ORACLE\n",
    "models = ['oracle']\n",
    "exp_id=f'mean-splitbyevent-test-r{runs}-t{train_ratio}'\n",
    "df, ret = run_test(runs, plens, half, trainids, train_ratio, testfunc, datamode=datamode,models=models)\n",
    "\n",
    "#check the car list number for -100 test record\n",
    "# it should be 24\n",
    "print('carlist shape in testset:',ret[0][0][2]['oracle'][-100][2].shape)\n",
    "\n",
    "checkret_status(ret)\n",
    "\n",
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testid</th>\n",
       "      <th>plen</th>\n",
       "      <th>type</th>\n",
       "      <th>reccnt</th>\n",
       "      <th>top1acc</th>\n",
       "      <th>top1acc_farmost</th>\n",
       "      <th>top5acc</th>\n",
       "      <th>top5acc_farmost</th>\n",
       "      <th>tau</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fulloracle</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.758475</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.868644</td>\n",
       "      <td>0.835593</td>\n",
       "      <td>0.873552</td>\n",
       "      <td>6.933705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fulloracle</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>115</td>\n",
       "      <td>0.648696</td>\n",
       "      <td>0.495652</td>\n",
       "      <td>0.826435</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.838527</td>\n",
       "      <td>8.874553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fulloracle</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>110</td>\n",
       "      <td>0.600909</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.787273</td>\n",
       "      <td>0.703636</td>\n",
       "      <td>0.767642</td>\n",
       "      <td>13.357509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notracklap</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.699153</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.840678</td>\n",
       "      <td>0.805085</td>\n",
       "      <td>0.844231</td>\n",
       "      <td>10.616225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notracklap</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>115</td>\n",
       "      <td>0.535652</td>\n",
       "      <td>0.382609</td>\n",
       "      <td>0.725565</td>\n",
       "      <td>0.580870</td>\n",
       "      <td>0.729321</td>\n",
       "      <td>21.859160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notracklap</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>110</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.350909</td>\n",
       "      <td>0.586430</td>\n",
       "      <td>36.540228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laponly</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.834746</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.906780</td>\n",
       "      <td>0.888136</td>\n",
       "      <td>0.893364</td>\n",
       "      <td>5.393602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laponly</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>115</td>\n",
       "      <td>0.735652</td>\n",
       "      <td>0.556522</td>\n",
       "      <td>0.854609</td>\n",
       "      <td>0.779130</td>\n",
       "      <td>0.834299</td>\n",
       "      <td>9.843977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laponly</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>110</td>\n",
       "      <td>0.643636</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>0.803091</td>\n",
       "      <td>0.703636</td>\n",
       "      <td>0.773748</td>\n",
       "      <td>13.820277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trackonly</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.567797</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.805085</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.826793</td>\n",
       "      <td>11.723732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trackonly</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>115</td>\n",
       "      <td>0.466087</td>\n",
       "      <td>0.330435</td>\n",
       "      <td>0.684870</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.711374</td>\n",
       "      <td>22.771453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trackonly</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>110</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.154545</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.387273</td>\n",
       "      <td>0.581601</td>\n",
       "      <td>35.583640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fullpred</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.597458</td>\n",
       "      <td>0.533898</td>\n",
       "      <td>0.787288</td>\n",
       "      <td>0.733898</td>\n",
       "      <td>0.804472</td>\n",
       "      <td>14.886691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fullpred</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>115</td>\n",
       "      <td>0.450435</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>0.649739</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.671752</td>\n",
       "      <td>28.040916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fullpred</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>110</td>\n",
       "      <td>0.360909</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>0.552727</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.541717</td>\n",
       "      <td>41.894822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predtrack</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.631356</td>\n",
       "      <td>0.559322</td>\n",
       "      <td>0.811864</td>\n",
       "      <td>0.766102</td>\n",
       "      <td>0.834193</td>\n",
       "      <td>10.949416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predtrack</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>115</td>\n",
       "      <td>0.453913</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.680348</td>\n",
       "      <td>0.499130</td>\n",
       "      <td>0.710459</td>\n",
       "      <td>22.714788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predtrack</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>110</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.598364</td>\n",
       "      <td>0.374545</td>\n",
       "      <td>0.597386</td>\n",
       "      <td>34.483740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predpit</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.673729</td>\n",
       "      <td>0.601695</td>\n",
       "      <td>0.841525</td>\n",
       "      <td>0.789831</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>12.612754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predpit</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>115</td>\n",
       "      <td>0.506087</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.681391</td>\n",
       "      <td>0.514783</td>\n",
       "      <td>0.668795</td>\n",
       "      <td>29.335118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predpit</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>110</td>\n",
       "      <td>0.350909</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.321818</td>\n",
       "      <td>0.527839</td>\n",
       "      <td>44.675081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleartrack</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.703390</td>\n",
       "      <td>0.872881</td>\n",
       "      <td>0.842373</td>\n",
       "      <td>0.874123</td>\n",
       "      <td>6.805987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleartrack</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>115</td>\n",
       "      <td>0.664348</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.821913</td>\n",
       "      <td>0.746087</td>\n",
       "      <td>0.837569</td>\n",
       "      <td>8.905125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleartrack</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>110</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.721818</td>\n",
       "      <td>0.779913</td>\n",
       "      <td>12.396484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjusttrack</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.865254</td>\n",
       "      <td>0.833898</td>\n",
       "      <td>0.872821</td>\n",
       "      <td>7.025418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjusttrack</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>115</td>\n",
       "      <td>0.653913</td>\n",
       "      <td>0.486957</td>\n",
       "      <td>0.825391</td>\n",
       "      <td>0.740870</td>\n",
       "      <td>0.839553</td>\n",
       "      <td>8.872739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjusttrack</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>110</td>\n",
       "      <td>0.622727</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>0.793636</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.775307</td>\n",
       "      <td>12.729736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjustpit</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>0.855932</td>\n",
       "      <td>0.833898</td>\n",
       "      <td>0.859351</td>\n",
       "      <td>8.288525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjustpit</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>115</td>\n",
       "      <td>0.580870</td>\n",
       "      <td>0.469565</td>\n",
       "      <td>0.796522</td>\n",
       "      <td>0.728696</td>\n",
       "      <td>0.813448</td>\n",
       "      <td>11.106380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjustpit</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>110</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>0.754909</td>\n",
       "      <td>0.698182</td>\n",
       "      <td>0.742407</td>\n",
       "      <td>15.893473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjustall</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>0.703390</td>\n",
       "      <td>0.851695</td>\n",
       "      <td>0.825424</td>\n",
       "      <td>0.862186</td>\n",
       "      <td>7.919921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjustall</td>\n",
       "      <td>5</td>\n",
       "      <td>aa</td>\n",
       "      <td>115</td>\n",
       "      <td>0.577391</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.803130</td>\n",
       "      <td>0.735652</td>\n",
       "      <td>0.816582</td>\n",
       "      <td>10.864248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjustall</td>\n",
       "      <td>10</td>\n",
       "      <td>aa</td>\n",
       "      <td>110</td>\n",
       "      <td>0.577273</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.768364</td>\n",
       "      <td>0.714545</td>\n",
       "      <td>0.754496</td>\n",
       "      <td>14.892383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        testid  plen type  reccnt   top1acc  top1acc_farmost   top5acc  \\\n",
       "4   fulloracle     2   aa     118  0.758475         0.737288  0.868644   \n",
       "4   fulloracle     5   aa     115  0.648696         0.495652  0.826435   \n",
       "4   fulloracle    10   aa     110  0.600909         0.436364  0.787273   \n",
       "4   notracklap     2   aa     118  0.699153         0.644068  0.840678   \n",
       "4   notracklap     5   aa     115  0.535652         0.382609  0.725565   \n",
       "4   notracklap    10   aa     110  0.360000         0.136364  0.584000   \n",
       "4      laponly     2   aa     118  0.834746         0.796610  0.906780   \n",
       "4      laponly     5   aa     115  0.735652         0.556522  0.854609   \n",
       "4      laponly    10   aa     110  0.643636         0.481818  0.803091   \n",
       "4    trackonly     2   aa     118  0.567797         0.491525  0.805085   \n",
       "4    trackonly     5   aa     115  0.466087         0.330435  0.684870   \n",
       "4    trackonly    10   aa     110  0.363636         0.154545  0.590000   \n",
       "4     fullpred     2   aa     118  0.597458         0.533898  0.787288   \n",
       "4     fullpred     5   aa     115  0.450435         0.313043  0.649739   \n",
       "4     fullpred    10   aa     110  0.360909         0.172727  0.552727   \n",
       "4    predtrack     2   aa     118  0.631356         0.559322  0.811864   \n",
       "4    predtrack     5   aa     115  0.453913         0.321739  0.680348   \n",
       "4    predtrack    10   aa     110  0.370000         0.163636  0.598364   \n",
       "4      predpit     2   aa     118  0.673729         0.601695  0.841525   \n",
       "4      predpit     5   aa     115  0.506087         0.321739  0.681391   \n",
       "4      predpit    10   aa     110  0.350909         0.172727  0.548000   \n",
       "4   cleartrack     2   aa     118  0.754237         0.703390  0.872881   \n",
       "4   cleartrack     5   aa     115  0.664348         0.504348  0.821913   \n",
       "4   cleartrack    10   aa     110  0.630000         0.500000  0.796000   \n",
       "4  adjusttrack     2   aa     118  0.750000         0.711864  0.865254   \n",
       "4  adjusttrack     5   aa     115  0.653913         0.486957  0.825391   \n",
       "4  adjusttrack    10   aa     110  0.622727         0.481818  0.793636   \n",
       "4    adjustpit     2   aa     118  0.711864         0.720339  0.855932   \n",
       "4    adjustpit     5   aa     115  0.580870         0.469565  0.796522   \n",
       "4    adjustpit    10   aa     110  0.536364         0.463636  0.754909   \n",
       "4    adjustall     2   aa     118  0.720339         0.703390  0.851695   \n",
       "4    adjustall     5   aa     115  0.577391         0.478261  0.803130   \n",
       "4    adjustall    10   aa     110  0.577273         0.518182  0.768364   \n",
       "\n",
       "   top5acc_farmost       tau       rmse  \n",
       "4         0.835593  0.873552   6.933705  \n",
       "4         0.739130  0.838527   8.874553  \n",
       "4         0.703636  0.767642  13.357509  \n",
       "4         0.805085  0.844231  10.616225  \n",
       "4         0.580870  0.729321  21.859160  \n",
       "4         0.350909  0.586430  36.540228  \n",
       "4         0.888136  0.893364   5.393602  \n",
       "4         0.779130  0.834299   9.843977  \n",
       "4         0.703636  0.773748  13.820277  \n",
       "4         0.754237  0.826793  11.723732  \n",
       "4         0.521739  0.711374  22.771453  \n",
       "4         0.387273  0.581601  35.583640  \n",
       "4         0.733898  0.804472  14.886691  \n",
       "4         0.480000  0.671752  28.040916  \n",
       "4         0.336364  0.541717  41.894822  \n",
       "4         0.766102  0.834193  10.949416  \n",
       "4         0.499130  0.710459  22.714788  \n",
       "4         0.374545  0.597386  34.483740  \n",
       "4         0.789831  0.828571  12.612754  \n",
       "4         0.514783  0.668795  29.335118  \n",
       "4         0.321818  0.527839  44.675081  \n",
       "4         0.842373  0.874123   6.805987  \n",
       "4         0.746087  0.837569   8.905125  \n",
       "4         0.721818  0.779913  12.396484  \n",
       "4         0.833898  0.872821   7.025418  \n",
       "4         0.740870  0.839553   8.872739  \n",
       "4         0.727273  0.775307  12.729736  \n",
       "4         0.833898  0.859351   8.288525  \n",
       "4         0.728696  0.813448  11.106380  \n",
       "4         0.698182  0.742407  15.893473  \n",
       "4         0.825424  0.862186   7.919921  \n",
       "4         0.735652  0.816582  10.864248  \n",
       "4         0.714545  0.754496  14.892383  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfall[dfall['type']=='aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
