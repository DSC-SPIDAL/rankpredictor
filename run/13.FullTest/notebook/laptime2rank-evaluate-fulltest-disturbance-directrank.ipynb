{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laptime2Rank-evaluate-fulltest-disturbance\n",
    "\n",
    "based on: Laptime2Rank-evaluate-fulltest\n",
    "\n",
    "rank prediction by laptime forecasting models\n",
    "\n",
    "support:\n",
    "+ train/test split by ratio or event\n",
    "+ incremental training evaluation(adjust ratio)\n",
    "+ go beyond curtrack and zerotrack by modeling the track status\n",
    "+ halfwin mode(0:no, 1:halfwin, 2:continous)\n",
    "+ split by stage, support all events (todo)\n",
    "\n",
    "+ disturbance analysis by adding disturbance to oracle trackstatus and lapstatus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import inspect\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pathlib import Path\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.distribution.multivariate_gaussian import MultivariateGaussianOutput\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.model.prophet import ProphetPredictor\n",
    "from gluonts.model.r_forecast import RForecastPredictor\n",
    "from indycar.model.NaivePredictor import NaivePredictor\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch_hdd/hpda/indycar/notebook/13.FullTest'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "random.seed()\n",
    "os.getcwd()\n",
    "#GPUID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(event, year):\n",
    "    inputfile = '../data/final/C_'+ event +'-' + year + '-final.csv'\n",
    "    outputprefix = year +'-' + event + '-'\n",
    "    dataset = pd.read_csv(inputfile)\n",
    "    #dataset.info(verbose=True)    \n",
    "    \n",
    "    final_lap = max(dataset.completed_laps)\n",
    "    total_laps = final_lap + 1\n",
    "\n",
    "    # get records for the cars that finish the race\n",
    "    completed_car_numbers= dataset[dataset.completed_laps == final_lap].car_number.values\n",
    "    completed_car_count = len(completed_car_numbers)\n",
    "\n",
    "    #print('count of completed cars:', completed_car_count)\n",
    "    #print('completed cars:', completed_car_numbers)\n",
    "\n",
    "    #make a copy\n",
    "    alldata = dataset.copy()\n",
    "    dataset = dataset[dataset['car_number'].isin(completed_car_numbers)]\n",
    "    rankdata = alldata.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "    \n",
    "    cldata = make_cl_data(dataset)\n",
    "    acldata = make_cl_data(alldata)\n",
    "\n",
    "    return alldata, rankdata, acldata\n",
    "\n",
    "# make indy car completed_laps dataset\n",
    "# car_number, completed_laps, rank, elapsed_time, rank_diff, elapsed_time_diff \n",
    "def make_cl_data(dataset):\n",
    "\n",
    "    # pick up data with valid rank\n",
    "    rankdata = dataset.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "\n",
    "    # resort by car_number, lap\n",
    "    uni_ds = rankdata.sort_values(by=['car_number', 'completed_laps', 'elapsed_time'], ascending=True)    \n",
    "    #uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \"current_status\", \"track_status\", \"lap_status\",\n",
    "    #                  \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "    #                  \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "    \n",
    "    uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \n",
    "                      \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "                      \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "        \n",
    "    carnumber = set(uni_ds['car_number'])\n",
    "    #print('cars:', carnumber)\n",
    "    #print('#cars=', len(carnumber))\n",
    "   \n",
    "    # faster solution , uni_ds already sorted by car_number and lap\n",
    "    uni_ds['rank_diff'] = uni_ds['rank'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['rank_diff'][mask] = 0\n",
    "    \n",
    "    uni_ds['time_diff'] = uni_ds['elapsed_time'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['time_diff'][mask] = 0\n",
    "    \n",
    "    #df = uni_ds[['car_number','completed_laps','rank','elapsed_time','rank_diff','time_diff']]\n",
    "    df = uni_ds[['car_number','completed_laps','rank','elapsed_time',\n",
    "                 'rank_diff','time_diff',\"current_status\", \"track_status\", \"lap_status\"]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def test_flag(a, bitflag):\n",
    "    return (a & bitflag) ==  bitflag\n",
    "\n",
    "#\n",
    "# remove NaN at the tail\n",
    "# there should be no nans in the middle of the ts\n",
    "COL_LAPTIME=0\n",
    "COL_RANK=1\n",
    "COL_TRACKSTATUS=2\n",
    "COL_LAPSTATUS=3\n",
    "COL_TIMEDIFF=4\n",
    "COL_CAUTION_LAPS_INSTINT=5\n",
    "COL_LAPS_INSTINT= 6\n",
    "\n",
    "# oracle mode\n",
    "MODE_ORACLE = 1024  # oracle = track + lap\n",
    "MODE_ORACLE_TRACKONLY = 1\n",
    "MODE_ORACLE_LAPONLY = 2   \n",
    "   \n",
    "\n",
    "# oracle mode for training\n",
    "MODE_NOLAP = 1   \n",
    "MODE_NOTRACK = 2\n",
    "\n",
    "# predicting mode\n",
    "MODE_TESTZERO = 4\n",
    "MODE_TESTCURTRACK = 8\n",
    "\n",
    "MODE_PREDTRACK = 16\n",
    "MODE_PREDPIT = 32\n",
    "\n",
    "# disturbe analysis\n",
    "MODE_DISTURB_CLEARTRACK = 64\n",
    "MODE_DISTURB_ADJUSTTRACK = 128\n",
    "MODE_DISTURB_ADJUSTPIT = 256\n",
    "\n",
    "\n",
    "_mode_map = {MODE_ORACLE:'MODE_ORACLE',MODE_ORACLE_TRACKONLY:'MODE_ORACLE_TRACKONLY',\n",
    "            MODE_ORACLE_LAPONLY:'MODE_ORACLE_LAPONLY',\n",
    "             MODE_TESTZERO:'MODE_TESTZERO',MODE_TESTCURTRACK:'MODE_TESTCURTRACK',\n",
    "             MODE_PREDTRACK:'MODE_PREDTRACK',MODE_PREDPIT:'MODE_PREDPIT',\n",
    "            MODE_DISTURB_CLEARTRACK:'MODE_DISTURB_CLEARTRACK',MODE_DISTURB_ADJUSTTRACK:'MODE_DISTURB_ADJUSTTRACK',\n",
    "            MODE_DISTURB_ADJUSTPIT:'MODE_DISTURB_ADJUSTPIT'}\n",
    "\n",
    "def get_modestr(a):\n",
    "    modestr = ''\n",
    "    for key in _mode_map:\n",
    "        if test_flag(a, key):\n",
    "            modestr += '%s,'%(_mode_map[key])\n",
    "            \n",
    "    return modestr\n",
    "\n",
    "# endpos -> vector of prediction_length\n",
    "_track_pred  = {}\n",
    "_track_true  = {}\n",
    "def init_track_model():\n",
    "    global _track_pred,_track_true\n",
    "    _track_pred = {}\n",
    "    _track_true  = {}\n",
    "    \n",
    "def get_track_model(track_rec, endpos, prediction_length, context_len=10):\n",
    "    \"\"\"\n",
    "    return the predicted track status\n",
    "    \"\"\"\n",
    "    global _track_pred,_track_true\n",
    "    # this is the perfect track model for Indy500 2018\n",
    "    track_model = [6,4,4,5,6,6,4]\n",
    "    if endpos in _track_pred:\n",
    "        return _track_pred[endpos]\n",
    "    else:\n",
    "        #get yflag lap count from the start pred point\n",
    "        yflaplen = 0\n",
    "        for i in range(1, context_len):\n",
    "            if track_rec[- prediction_length - i] == 1:\n",
    "                yflaplen += 1\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        #laps remain, fill into the future\n",
    "        trackpred = np.array([0 for x in range(prediction_length)])\n",
    "        \n",
    "        yflap_pred = random.choice(track_model)\n",
    "        if yflaplen > 0 and yflap_pred > yflaplen:\n",
    "            trackpred[:(yflap_pred - yflaplen)] = 1\n",
    "        _track_pred[endpos] = trackpred\n",
    "        \n",
    "        _track_true[endpos]  = track_rec[- prediction_length:].copy()\n",
    "        \n",
    "        return trackpred\n",
    "\n",
    "    \n",
    "# endpos -> vector of prediction_length\n",
    "_track_adjust  = {}\n",
    "def init_adjust_track_model():\n",
    "    global _track_adjust\n",
    "    _track_adjust = {}\n",
    "    \n",
    "def adjust_track_model(track_rec, endpos, prediction_length, tailpos):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        tailpos ; <0 end pos of 1\n",
    "    return the predicted track status\n",
    "    \"\"\"\n",
    "    global _track_adjust\n",
    "    # this is the perfect track model for Indy500 2018\n",
    "    track_model = [-1,0,1]\n",
    "    if endpos in _track_adjust:\n",
    "        return _track_adjust[endpos]\n",
    "    else:\n",
    "        yflap_adjust = random.choice(track_model)\n",
    "        \n",
    "        #laps remain, fill into the future\n",
    "        trackadjust = track_rec[-prediction_length:].copy()\n",
    "        if yflap_adjust == -1:\n",
    "            trackadjust[tailpos] = 0\n",
    "        elif yflap_adjust == 1:\n",
    "            trackadjust[tailpos] = 0\n",
    "            if (tailpos + 1) <= -1:\n",
    "                trackadjust[tailpos+1] = 1\n",
    "        \n",
    "        _track_adjust[endpos] = trackadjust\n",
    "        \n",
    "        return trackadjust\n",
    "\n",
    "# carno -> lap_status\n",
    "_lap_adjust = {}    \n",
    "_empirical_model = {}\n",
    "def init_adjust_pitmodel():\n",
    "    global _lap_adjust\n",
    "    _lap_adjust = {}    \n",
    "    _empirical_model = {}\n",
    "\n",
    "def get_adjust_lapstatus(carno, lapstatus, force = True):\n",
    "    \"\"\"\n",
    "    init the lapstatus for each car, save it for future reference\n",
    "    \n",
    "    input:\n",
    "        carno;\n",
    "        lapstatus  ; the trueth\n",
    "    \n",
    "    \"\"\"\n",
    "    if carno not in _lap_adjust:\n",
    "        #adjust it\n",
    "        lapadjust = lapstatus.copy()\n",
    "        for pos in range(0, len(lapstatus)):\n",
    "            if lapadjust[pos] == 1:\n",
    "\n",
    "                success = False\n",
    "\n",
    "                while(not success):\n",
    "                    # adjust this pit lap position\n",
    "                    pos_adjust = get_random_choice(_adjust_model)\n",
    "\n",
    "                    new_pos = pos + pos_adjust\n",
    "\n",
    "                    if new_pos >= 0 and new_pos < len(lapstatus):\n",
    "                        #valid\n",
    "                        lapadjust[pos] = 0\n",
    "                        lapadjust[new_pos] = 1\n",
    "                        success = True\n",
    "                        \n",
    "                        #add statistics\n",
    "                        if pos_adjust not in _empirical_model:\n",
    "                            _empirical_model[pos_adjust] = 1\n",
    "                        else:\n",
    "                            _empirical_model[pos_adjust] += 1\n",
    "\n",
    "                    if force==False:\n",
    "                        break\n",
    "\n",
    "        _lap_adjust[carno] = lapadjust\n",
    "\n",
    "    return _lap_adjust[carno]\n",
    "        \n",
    "        \n",
    "def build_random_model(modeldict):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        modeldict ; {val: probability}\n",
    "    return:\n",
    "        model  ;  [val, cdf]\n",
    "    \"\"\"\n",
    "    # val, cdf\n",
    "    cdf = 0\n",
    "    model = np.zeros((len(modeldict), 2))\n",
    "    for idx, val in enumerate(sorted(modeldict.keys())):\n",
    "        model[idx, 0] = val\n",
    "        model[idx, 1] = cdf + modeldict[val]\n",
    "        cdf = model[idx, 1]\n",
    "        \n",
    "    #normalize\n",
    "    model[:, 1] = model[:, 1]/cdf\n",
    "    return model\n",
    "    \n",
    "def print_model(model, iscdf=True):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        model  ;  [val, cdf]\n",
    "    \"\"\"\n",
    "    sorted_model = model[np.argsort(model[:, 0])]\n",
    "    cdf = 0\n",
    "    \n",
    "    sumval = 1.\n",
    "    if not iscdf:\n",
    "        sumval = np.sum(sorted_model[:,1])\n",
    "    \n",
    "    ret = []\n",
    "    for row in sorted_model:\n",
    "        ret.append((row[0], (row[1]-cdf)/sumval))\n",
    "        if iscdf:\n",
    "            cdf = row[1]\n",
    "    #output\n",
    "    print(['%d:%.3f'%(x[0],x[1]) for x in ret])\n",
    "    \n",
    "    \n",
    "def get_random_choice(model):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        model  ;  [val, cdf]\n",
    "    return:\n",
    "        val according to its probability\n",
    "    \"\"\"\n",
    "    \n",
    "    target = np.random.rand()\n",
    "    idx = np.sum(model[:,1] < target)\n",
    "    return int(model[idx,0])\n",
    "    \n",
    "#_modeldict={-2:0.1,-1:0.2,0:0.4, 1:0.2, 2:0.1 }\n",
    "_modeldict={-2:0.1,-1:0.2,0:0.05, 1:0.2, 2:0.1 }\n",
    "_adjust_model = build_random_model(_modeldict)\n",
    "\n",
    "def adjust_pit_model(lap_rec, prediction_length, force=True):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        tailpos ; <0 end pos of 1\n",
    "    return the predicted lap status\n",
    "    \"\"\"\n",
    "    #laps remain, fill into the future\n",
    "    lapadjust = lap_rec[-prediction_length:].copy()\n",
    "    for pos in range(0, prediction_length):\n",
    "        if lapadjust[pos] == 1:\n",
    "            \n",
    "            success = False\n",
    "            \n",
    "            while(not success):\n",
    "                # adjust this pit lap position\n",
    "                pos_adjust = get_random_choice(_adjust_model)\n",
    "\n",
    "                new_pos = pos + pos_adjust\n",
    "\n",
    "                if new_pos >= 0 and new_pos < prediction_length:\n",
    "                    #valid\n",
    "                    lapadjust[pos] = 0\n",
    "                    lapadjust[new_pos] = 1\n",
    "                    success = True\n",
    "                    \n",
    "                if force==False:\n",
    "                    break\n",
    "                    \n",
    "    return lapadjust\n",
    "\n",
    "def adjust_pit_model_fix(lap_rec, endpos, prediction_length):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        tailpos ; <0 end pos of 1\n",
    "    return the predicted lap status\n",
    "    \"\"\"\n",
    "    adjust_model = [-1,0,1]\n",
    "    lap_adjust = random.choice(adjust_model)\n",
    "        \n",
    "    #laps remain, fill into the future\n",
    "    lapadjust = lap_rec[-prediction_length:].copy()\n",
    "    for pos in range(0, prediction_length):\n",
    "        if lapadjust[pos] == 1:\n",
    "            # adjust this pit lap position\n",
    "            pos_adjust = random.choice(adjust_model)\n",
    "\n",
    "            if pos_adjust == -1:\n",
    "                if (pos - 1 >= 0):\n",
    "                    lapadjust[pos] = 0\n",
    "                    lapadjust[pos - 1] = 1\n",
    "            elif pos_adjust == 1:\n",
    "                if (pos + 1 < prediction_length):\n",
    "                    lapadjust[pos] = 0\n",
    "                    lapadjust[pos + 1] = 1\n",
    "\n",
    "    return lapadjust\n",
    "    \n",
    "# pit model is separate for each car\n",
    "def get_pit_model(cuation_laps_instint, laps_instint, prediction_length):\n",
    "    \"\"\"\n",
    "    return the predicted pit status\n",
    "    \"\"\"\n",
    "    # this is the perfect empirical pit model for Indy500 2018\n",
    "    pit_model_all = [[33, 32, 35, 32, 35, 34, 35, 34, 37, 32, 37, 30, 33, 36, 35, 33, 36, 30, 31, 33, 36, 37, 35, 34, 34, 33, 37, 35, 39, 32, 36, 35, 34, 32, 36, 32, 31, 36, 33, 33, 35, 37, 40, 32, 32, 34, 35, 36, 33, 37, 35, 37, 34, 35, 39, 32, 31, 37, 32, 35, 36, 39, 35, 36, 34, 35, 33, 33, 34, 32, 33, 34],\n",
    "                [45, 44, 46, 44, 43, 46, 45, 43, 41, 48, 46, 43, 47, 45, 49, 44, 48, 42, 44, 46, 45, 45, 43, 44, 44, 43, 46]]\n",
    "    pit_model_top8 = [[33, 32, 35, 33, 36, 33, 36, 33, 37, 35, 36, 33, 37, 34],\n",
    "                 [46, 45, 43, 48, 46, 45, 45, 43]]\n",
    "    \n",
    "    pit_model = pit_model_all\n",
    "    \n",
    "    if cuation_laps_instint>10:\n",
    "        #use low model\n",
    "        pred_pit_laps = random.choice(pit_model[0])\n",
    "    else:\n",
    "        pred_pit_laps = random.choice(pit_model[1])\n",
    "                \n",
    "    #laps remain, fill into the future\n",
    "    pitpred = np.array([0 for x in range(prediction_length)])\n",
    "    \n",
    "    if (pred_pit_laps > laps_instint) and (pred_pit_laps <= laps_instint + prediction_length):\n",
    "        pitpred[pred_pit_laps - laps_instint - 1] = 1\n",
    "         \n",
    "    return pitpred    \n",
    "    \n",
    "def make_dataset_byevent(runs, prediction_length, freq, \n",
    "                       useeid = False,\n",
    "                       run_ts=COL_LAPTIME, \n",
    "                       test_event = 'Indy500',\n",
    "                       test_cars = [],  \n",
    "                       use_global_dict = True,\n",
    "                       oracle_mode = MODE_ORACLE,\n",
    "                       half_moving_win = 0,\n",
    "                       train_ratio=0.8,\n",
    "                       verbose = True\n",
    "                ):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    input:\n",
    "        oracle_mode: false to simulate prediction in real by \n",
    "                set the covariates of track and lap status as nan in the testset\n",
    "        half_moving_win  ; extend to 0:-1 ,1:-1/2plen, 2:-plen\n",
    "    \n",
    "    \"\"\"    \n",
    "    init_track_model()\n",
    "    init_adjust_track_model()\n",
    "    \n",
    "    start = pd.Timestamp(\"01-01-2019\", freq=freq)  # can be different for each time series\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #select run\n",
    "    if runs>=0:\n",
    "        _laptime_data = [laptime_data[runs].copy()]\n",
    "    else:\n",
    "        _laptime_data = laptime_data.copy()\n",
    "    \n",
    "   \n",
    "    #add statistics for adjust test\n",
    "    # trackstatus, lapstatus\n",
    "    mae = [0,0]\n",
    "    \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        if events[_data[0]] == test_event:\n",
    "            test_mode = True\n",
    "        \n",
    "        else:\n",
    "            test_mode = False\n",
    "            \n",
    "            \n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        max_len = int(np.max(ts_len))\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'====event:{events[_data[0]]}, train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)}')\n",
    "\n",
    "        #rerank due to short ts removed\n",
    "        if run_ts == COL_RANK:\n",
    "            sel_rows = []\n",
    "            for rowid in range(_data[2].shape[0]):\n",
    "                # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "                rec = _data[2][rowid].copy()\n",
    "\n",
    "                totallen = rec.shape[1]\n",
    "                if ( totallen < train_len + prediction_length):\n",
    "                    print(f'rerank a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                    continue \n",
    "                else:\n",
    "                    sel_rows.append(rowid)\n",
    "                    \n",
    "            #get selected matrix\n",
    "            sel_idx = np.array(sel_rows)\n",
    "            selmat = _data[2][sel_idx]\n",
    "            \n",
    "            mask = np.isnan(selmat[:,COL_RANK,:])\n",
    "            \n",
    "            idx = np.argsort(selmat[:,COL_RANK,:], axis=0)\n",
    "            true_rank = np.argsort(idx, axis=0).astype(np.float)\n",
    "            true_rank[mask] = np.nan\n",
    "            \n",
    "            #set it back\n",
    "            _data[2][sel_idx][:,COL_RANK,:] = true_rank            \n",
    "            \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            rec_raw = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                if verbose:\n",
    "                    print(f'a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                continue                \n",
    "            \n",
    "            if use_global_dict:\n",
    "                carno = _data[1][rowid]\n",
    "                carid = global_carids[_data[1][rowid]]\n",
    "            else:\n",
    "                #simulation dataset, todo, fix the carids as decoder\n",
    "                carno = rowid\n",
    "                carid = rowid\n",
    "                \n",
    "            \n",
    "            if useeid:\n",
    "                static_cat = [carid, _data[0]]    \n",
    "            else:\n",
    "                static_cat = [carid]    \n",
    "                \n",
    "            \n",
    "            # adjust for disturbance analysis\n",
    "            if test_mode and test_flag(oracle_mode, MODE_DISTURB_ADJUSTPIT):\n",
    "                lap_status = rec[COL_LAPSTATUS, :].copy()\n",
    "                rec[COL_LAPSTATUS, :] = get_adjust_lapstatus(carno, lap_status)\n",
    "                \n",
    "            # selection of features\n",
    "            if test_flag(oracle_mode, MODE_NOTRACK) or test_flag(oracle_mode, MODE_ORACLE_LAPONLY):                \n",
    "                rec[COL_TRACKSTATUS, :] = 0\n",
    "            if test_flag(oracle_mode, MODE_NOLAP) or test_flag(oracle_mode, MODE_ORACLE_TRACKONLY):                \n",
    "                rec[COL_LAPSTATUS, :] = 0\n",
    "\n",
    "            test_rec_cnt = 0\n",
    "            if not test_mode:\n",
    "                \n",
    "                # all go to train set\n",
    "                _train.append({'target': rec[run_ts,:].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [rec[COL_TRACKSTATUS,:],\n",
    "                                       rec[COL_LAPSTATUS,:]]\n",
    "                              }\n",
    "                              )\n",
    "            else:\n",
    "                # reset train_len\n",
    "                #context_len = prediction_length*2\n",
    "                #if context_len < 10:\n",
    "                #    context_len = 10\n",
    "                \n",
    "                context_len = train_len\n",
    "                \n",
    "                # multiple test ts(rolling window as half of the prediction_length)\n",
    "\n",
    "                #step = -int(prediction_length/2) if half_moving_win else -prediction_length\n",
    "                if half_moving_win == 1:\n",
    "                    step = -int(prediction_length/2)\n",
    "                elif half_moving_win == 2:\n",
    "                    step = -prediction_length\n",
    "                else:\n",
    "                    step = -1\n",
    "                \n",
    "                #bug fix, fixed the split point for all cars/ts\n",
    "                for endpos in range(max_len, context_len+prediction_length, \n",
    "                                    step):\n",
    "\n",
    "                    #check if enough for this ts\n",
    "                    if endpos > totallen:\n",
    "                        continue\n",
    "                    \n",
    "                    track_rec = rec[COL_TRACKSTATUS, :endpos].copy()\n",
    "                    lap_rec = rec[COL_LAPSTATUS, :endpos].copy()\n",
    "                    \n",
    "                    caution_laps_instint = int(rec[COL_CAUTION_LAPS_INSTINT, endpos -prediction_length - 1])\n",
    "                    laps_instint = int(rec[COL_LAPS_INSTINT, endpos -prediction_length - 1])\n",
    "                    \n",
    "\n",
    "                    # test mode\n",
    "                    if test_flag(oracle_mode, MODE_TESTCURTRACK):\n",
    "                        # since nan does not work, use cur-val instead\n",
    "                        track_rec[-prediction_length:] = track_rec[-prediction_length - 1]\n",
    "                        #track_rec[-prediction_length:] = random.randint(0,1)\n",
    "                        #lap_rec[-prediction_length:] = lap_rec[-prediction_length - 1]\n",
    "                        lap_rec[-prediction_length:] = 0\n",
    "                    elif test_flag(oracle_mode, MODE_TESTZERO):\n",
    "                        #set prediction part as nan\n",
    "                        #track_rec[-prediction_length:] = np.nan\n",
    "                        #lap_rec[-prediction_length:] = np.nan\n",
    "                        track_rec[-prediction_length:] = 0\n",
    "                        lap_rec[-prediction_length:] = 0        \n",
    "\n",
    "                    # predicting with status model\n",
    "                    if test_flag(oracle_mode, MODE_PREDTRACK):\n",
    "                        predrec = get_track_model(track_rec, endpos, prediction_length)\n",
    "                        track_rec[-prediction_length:] = predrec\n",
    "                        #lap_rec[-prediction_length:] = 0\n",
    "                        \n",
    "                    if test_flag(oracle_mode, MODE_PREDPIT):\n",
    "                        #predrec = get_track_model(track_rec, endpos, prediction_length)\n",
    "                        #track_rec[-prediction_length:] = predrec\n",
    "                        lap_rec[-prediction_length:] = get_pit_model(caution_laps_instint,\n",
    "                                                                    laps_instint,prediction_length)\n",
    "                        \n",
    "                        \n",
    "                    # disturbe analysis\n",
    "                    if test_flag(oracle_mode, MODE_DISTURB_CLEARTRACK):\n",
    "                        # clear the oracle track status\n",
    "                        # future 1s in trackstatus\n",
    "                        # pattern like 0 1 xx\n",
    "                        for _pos in range(-prediction_length + 1, -1):\n",
    "                            if track_rec[_pos - 1] == 0:\n",
    "                                track_rec[_pos] = 0\n",
    "                                \n",
    "                    if test_flag(oracle_mode, MODE_DISTURB_ADJUSTTRACK):\n",
    "                        # adjust the end position of track, or caution lap length\n",
    "                        # find the end of caution laps\n",
    "                        _tail = 0\n",
    "                        for _pos in range(-1,-prediction_length + 1,-1):\n",
    "                            if track_rec[_pos] == 1:\n",
    "                                #find the tail\n",
    "                                _tail = _pos\n",
    "                                break\n",
    "                        if _tail != 0:\n",
    "                            #found\n",
    "                            adjustrec = adjust_track_model(track_rec, endpos, prediction_length, _tail)\n",
    "                            track_rec[-prediction_length:] = adjustrec\n",
    "                        \n",
    "                    #if test_flag(oracle_mode, MODE_DISTURB_ADJUSTPIT):\n",
    "                    #    # adjust the position of pit\n",
    "                    #    if np.sum(lap_rec[-prediction_length:]) > 0:\n",
    "                    #        adjustrec = adjust_pit_model(lap_rec, endpos, prediction_length)\n",
    "                    #        lap_rec[-prediction_length:] = adjustrec\n",
    "                        \n",
    "                    #okay, end of adjustments, test difference here\n",
    "                    # rec_raw .vs. track_rec, lap_rec\n",
    "                    track_rec_raw = rec_raw[COL_TRACKSTATUS, :endpos]\n",
    "                    lap_rec_raw = rec_raw[COL_LAPSTATUS, :endpos]\n",
    "                    \n",
    "                    mae[0] = mae[0] + np.nansum(np.abs(track_rec[-prediction_length:] - track_rec_raw[-prediction_length:]))\n",
    "                    mae[1] = mae[1] + np.nansum(np.abs(lap_rec[-prediction_length:] - lap_rec_raw[-prediction_length:]))\n",
    "\n",
    "                    _test.append({'target': rec[run_ts,:endpos].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [track_rec,lap_rec]\n",
    "                                #'feat_dynamic_real': [rec[COL_TRACKSTATUS,:endpos],\n",
    "                                #       rec[COL_LAPSTATUS,:endpos]] \n",
    "                                 }\n",
    "                              )   \n",
    "                    test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            if verbose:\n",
    "                print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'train len:{len(train_set)}, test len:{len(test_set)}, mae_track:{mae[0]},mae_lap:{mae[1]},')\n",
    "    \n",
    "    train_ds = ListDataset(train_set, freq=freq)\n",
    "    test_ds = ListDataset(test_set, freq=freq)    \n",
    "    \n",
    "    return train_ds, test_ds, train_set, test_set\n",
    "\n",
    "def save_dataset(datafile,freq, prediction_length, cardinality, train_ds, test_ds):\n",
    "    with open(datafile, 'wb') as f:\n",
    "        #pack [global_carids, laptime_data]\n",
    "        savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "        #savedata = [freq, train_set, test_set]\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for Indy500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_ds,predictor):\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor=predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    return tss, forecasts\n",
    "\n",
    "   \n",
    "def run_prediction_ex(test_ds, prediction_length, model_name,trainid):\n",
    "    with mx.Context(mx.gpu(7)):    \n",
    "        pred_ret = []\n",
    "\n",
    "        #rootdir = f'../models/remote/rawrank-{trainid}/'\n",
    "        rootdir = f'../models/remote/rank-{trainid}/'\n",
    "        # deepAR-Oracle\n",
    "        if model_name == 'curtrack':\n",
    "            model=f'deepAR-Oracle-rank-curtrack-indy-f1min-t{prediction_length}-e1000-r1_curtrack_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        elif model_name == 'zerotrack':\n",
    "            model=f'deepAR-Oracle-rank-nolap-zerotrack-indy-f1min-t{prediction_length}-e1000-r1_zerotrack_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "            \n",
    "        # deepAR-Oracle\n",
    "        elif model_name == 'oracle':\n",
    "            model=f'deepAR-Oracle-rank-all-indy-f1min-t{prediction_length}-e1000-r1_oracle_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "        # deepAR-Oracle\n",
    "        elif model_name == 'oracle-laponly':\n",
    "            model=f'deepAR-Oracle-rank-all-indy-f1min-t{prediction_length}-e1000-r1_oracle-laponly_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "        # deepAR-Oracle\n",
    "        elif model_name == 'oracle-trackonly':\n",
    "            model=f'deepAR-Oracle-rank-all-indy-f1min-t{prediction_length}-e1000-r1_oracle-trackonly_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "        # deepAR\n",
    "        elif model_name == 'deepAR':\n",
    "            model=f'deepAR-rank-all-indy-f1min-t{prediction_length}-e1000-r1_deepar_t{prediction_length}'\n",
    "            modeldir = rootdir + model\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  Predictor.deserialize(Path(modeldir))\n",
    "            print(f'loading model...done!, ctx:{predictor.ctx}')\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        # naive\n",
    "        elif model_name == 'naive':\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  NaivePredictor(freq= freq, prediction_length = prediction_length)\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "\n",
    "        # arima\n",
    "        elif model_name == 'arima':\n",
    "            print(f'predicting model={model_name}, plen={prediction_length}')\n",
    "            predictor =  RForecastPredictor(method_name='arima',freq= freq, \n",
    "                                            prediction_length = prediction_length,trunc_length=60)\n",
    "            tss, forecasts = predict(test_ds,predictor)\n",
    "            pred_ret = [tss, forecasts]\n",
    "        else:\n",
    "            print(f'error: model {model_name} not support yet!')\n",
    "\n",
    "        return pred_ret     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc rank\n",
    "def eval_rank_bytimediff(test_ds,tss,forecasts,prediction_length):\n",
    "    \"\"\"\n",
    "    timediff models\n",
    "    \n",
    "    works for one event only\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        #forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        \n",
    "        timediff_array = tss[idx].values.copy()\n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        forecasts_et[completed_laps][carno] = [timediff_array[-prediction_len:].copy(),\n",
    "                                                   forecast_laptime_mean.copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        time_diff = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            time_diff[0, carid, :] = forecasts_et[lap][carno][0].reshape((prediction_len))\n",
    "            time_diff[1, carid, :] = forecasts_et[lap][carno][1].reshape((prediction_len))\n",
    "\n",
    "        #calculate rank    \n",
    "        idx = np.argsort(time_diff[0], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        idx = np.argsort(time_diff[1], axis=0)\n",
    "        pred_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        rank_ret.append([lap, time_diff, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et\n",
    "    \n",
    "#calc rank\n",
    "def eval_rank(test_ds,tss,forecasts,prediction_length, start_offset):\n",
    "    \"\"\"\n",
    "    evaluate rank by laptime forecasting\n",
    "    \n",
    "    input:\n",
    "        test_ds       ; must be test set for a single event, because test_ds itself does not \n",
    "                        contain features to identify the eventid\n",
    "        start_offset[]; elapsed time for lap0, for one specific event\n",
    "        tss,forecasts ; forecast result\n",
    "        prediction_length ; \n",
    "    return:\n",
    "        rank_ret      ;  [lap, elapsed_time, true_rank, pred_rank] \n",
    "        forecasts_et  ;  {[completed_laps][carno]} ->(elapsed_time, elapsed_time_pred)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    carlist = []\n",
    "\n",
    "    # carno-lap# -> elapsed_time[] array\n",
    "    forecasts_et = dict()\n",
    "\n",
    "    ds_iter =  iter(test_ds)\n",
    "    for idx in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        #global carid\n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        #print('car no:', carno)\n",
    "\n",
    "        if carno not in carlist:\n",
    "            carlist.append(carno)\n",
    "\n",
    "        #start_offset is global var\n",
    "        if isinstance(start_offset, list):\n",
    "            offset = start_offset[(start_offset['car_number']==carno)].elapsed_time.values[0] \n",
    "        \n",
    "            \n",
    "        #print('start_offset:', offset)\n",
    "\n",
    "        # calc elapsed time\n",
    "        prediction_len = forecasts[idx].samples.shape[1]\n",
    "        if prediction_length != prediction_len:\n",
    "            print('error: prediction_len does not match, {prediction_length}:{prediction_len}')\n",
    "            return []\n",
    "        \n",
    "        forecast_laptime_mean = np.mean(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "        #forecast_laptime_mean = np.median(forecasts[idx].samples, axis=0).reshape((prediction_len,1))\n",
    "\n",
    "        if isinstance(start_offset, list):\n",
    "            laptime_array = tss[idx].values.copy()\n",
    "            elapsed_time = np.cumsum(laptime_array) + offset\n",
    "\n",
    "            laptime_array = tss[idx].values.copy()\n",
    "            laptime_array[-prediction_len:] = forecast_laptime_mean \n",
    "            elapsed_time_hat = np.cumsum(laptime_array) + offset\n",
    "        else:\n",
    "            # rank directly\n",
    "            elapsed_time  = tss[idx].values.copy()\n",
    "\n",
    "            elapsed_time_hat = tss[idx].values.copy()\n",
    "            elapsed_time_hat[-prediction_len:] = forecast_laptime_mean             \n",
    "\n",
    "        #save the prediction\n",
    "        completed_laps = len(tss[idx]) - prediction_len + 1\n",
    "        #print('car no:', carno, 'completed_laps:', completed_laps)\n",
    "        #key = '%s-%s'%(carno, completed_laps)\n",
    "        #forecasts_et[key] = elapsed_time[-prediction_len:].copy()\n",
    "        if completed_laps not in forecasts_et:\n",
    "            forecasts_et[completed_laps] = {}\n",
    "        #forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len-1:].copy(),\n",
    "        #                                           elapsed_time_hat[-prediction_len-1:].copy()]\n",
    "        forecasts_et[completed_laps][carno] = [elapsed_time[-prediction_len:].copy(),\n",
    "                                                   elapsed_time_hat[-prediction_len:].copy()]\n",
    "\n",
    "\n",
    "    # calc rank\n",
    "    rank_ret = []\n",
    "    for lap in forecasts_et.keys():\n",
    "        #get car list for this lap\n",
    "        carlist = list(forecasts_et[lap].keys())\n",
    "        #print('carlist:', carlist)\n",
    "\n",
    "        caridmap={key:idx for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #fill in data\n",
    "        #elapsed_time = np.zeros((2, len(carlist), prediction_len+1))\n",
    "        elapsed_time = np.zeros((2, len(carlist), prediction_len))\n",
    "        for carno in carlist:\n",
    "            carid = caridmap[carno]\n",
    "            elapsed_time[0, carid, :] = forecasts_et[lap][carno][0].reshape((prediction_len))\n",
    "            elapsed_time[1, carid, :] = forecasts_et[lap][carno][1].reshape((prediction_len))\n",
    "\n",
    "        #calculate rank    \n",
    "        idx = np.argsort(elapsed_time[0], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        idx = np.argsort(elapsed_time[1], axis=0)\n",
    "        pred_rank = np.argsort(idx, axis=0)\n",
    "\n",
    "        rank_ret.append([lap, elapsed_time, true_rank, pred_rank])\n",
    "        \n",
    "    return rank_ret,forecasts_et\n",
    "   \n",
    "def get_acc(rank_ret,prediction_length, verbose = False):   \n",
    "    \"\"\"\n",
    "    input:\n",
    "        rank_ret: [lap, elapsed_time, true_rank, pred_rank], use [2][3] columns\n",
    "    return:\n",
    "        ((metrics...)\n",
    "         (record count...))\n",
    "         \n",
    "    the result can be used to calculate micro/macro metrics\n",
    "    \"\"\"\n",
    "    # evaluate\n",
    "    #top1 accuracy\n",
    "    top1acc = 0\n",
    "    top1acc_farmost = 0\n",
    "    top5acc = 0\n",
    "    top5acc_farmost = 0\n",
    "    tau = 0\n",
    "    rmse = 0.\n",
    "    \n",
    "    for rec in rank_ret:\n",
    "        trueRank = rec[2]\n",
    "        predRank = rec[3]\n",
    "\n",
    "        #top1 , rank = 0, first col is not prediction\n",
    "        top1acc += np.sum((trueRank==0) & (predRank==0)) \n",
    "        \n",
    "        top1acc_farmost += np.sum((trueRank[:,-1]==0) & (predRank[:,-1]==0))\n",
    "        \n",
    "        #top5\n",
    "        top5acc += np.sum((trueRank<5) & (predRank<5)) \n",
    "        \n",
    "        top5acc_farmost += np.sum((trueRank[:,-1]<5) & (predRank[:,-1]<5))\n",
    "        \n",
    "        # tau\n",
    "        tao, _ = stats.kendalltau(trueRank, predRank)\n",
    "        tau += tao\n",
    "        \n",
    "        #rmse\n",
    "        rmse += mean_squared_error(predRank,trueRank)\n",
    "        \n",
    "    recnt = len(rank_ret)\n",
    "    if recnt > 0:\n",
    "        top1acc = top1acc *1.0/ (recnt*prediction_length)\n",
    "        top1acc_farmost = top1acc_farmost *1.0/ recnt\n",
    "        top5acc = top5acc *1.0/ (5*recnt*prediction_length)\n",
    "        top5acc_farmost = top5acc_farmost *1.0/ (5*recnt)\n",
    "        tau = tau/recnt\n",
    "        rmse = rmse/recnt\n",
    "\n",
    "        if verbose:\n",
    "            print(f'total:{len(rank_ret)}, prediction_length:{prediction_length}') \n",
    "            print('top1acc=', top1acc,\n",
    "                  'top1acc_farmost=', top1acc_farmost,\n",
    "                  'top5acc=', top5acc,\n",
    "                  'top5acc_farmost=', top5acc_farmost,\n",
    "                 )\n",
    "            print('tau = ', tau,\n",
    "                 'rmse = ', rmse)\n",
    "    \n",
    "    return ((top1acc,top1acc_farmost,top5acc,top5acc_farmost,tau,rmse),\n",
    "            (recnt*prediction_length,recnt,5*recnt*prediction_length,5*recnt,recnt,recnt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = [], datamode = MODE_ORACLE,models = ['oracle']):\n",
    "    \"\"\"\n",
    "    dependency: test_event, test on one event only\n",
    "    \n",
    "    \"\"\"\n",
    "    retdf = []\n",
    "    pred_ret = {}\n",
    "    ds_ret = {}\n",
    "    rank_result = {}\n",
    "    \n",
    "    ### create test dataset\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=datamode,\n",
    "                                         run_ts = COL_RANK,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    for model in models:\n",
    "        print('exp:',inspect.stack()[0][3],'model:', model, 'datamode:', get_modestr(datamode))\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "\n",
    "        rank_ret, forecast_ret = eval_rank(test_ds,tss,forecasts,prediction_length,0)\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,get_modestr(datamode),trainid]\n",
    "        ret.extend(metrics[0])\n",
    "        retdf.append(ret)\n",
    "        \n",
    "        rank_result[model] = (rank_ret,forecast_ret)\n",
    "    \n",
    "    return pred_ret, ds_ret, rank_result, retdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp_baseline(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):           \n",
    "    \"\"\"\n",
    "    dependency: test_event, test on one event only\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #models = ['oracle','deepAR','naive']\n",
    "    models = ['deepAR','naive']\n",
    "    #,'arima']\n",
    "    retdf = []\n",
    "    pred_ret = {}\n",
    "    ds_ret = {}\n",
    "    rank_result = {}\n",
    "    \n",
    "    ### create test dataset\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_ORACLE,\n",
    "                                         run_ts = COL_RANK,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    modestr = 'MODE_ORACLE' \n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "\n",
    "        rank_ret,forecast_ret = eval_rank(test_ds,tss,forecasts,prediction_length,0)\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,modestr, trainid]\n",
    "        ret.extend(metrics[0])\n",
    "        retdf.append(ret)\n",
    "        \n",
    "        rank_result[model] = (rank_ret,forecast_ret)\n",
    "    \n",
    "    return pred_ret, ds_ret, rank_result, retdf\n",
    "\n",
    "    # special model with test_ds\n",
    "    models = ['curtrack']        \n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_TESTCURTRACK,\n",
    "                                         run_ts = COL_LAPTIME,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    modestr = 'MODE_TESTCURTRACK'\n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "        \n",
    "        rank_ret,forecast_ret = eval_rank(test_ds,tss,forecasts,prediction_length,0)\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,modestr, trainid]\n",
    "        ret.extend(metrics[0])\n",
    "        retdf.append(ret)\n",
    "        \n",
    "        rank_result[model] = (rank_ret,forecast_ret)\n",
    "\n",
    "    # zerotrack\n",
    "    models = ['zerotrack']        \n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_TESTZERO,\n",
    "                                         run_ts = COL_LAPTIME,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "    \n",
    "    modestr = 'MODE_TESTZERO'\n",
    "    for model in models:\n",
    "        print('model:', model)\n",
    "        tss, forecasts = run_prediction_ex(test_ds, prediction_length, model,trainid=trainid)\n",
    "        pred_ret[model] = [tss, forecasts]\n",
    "        ds_ret[model] = test_ds\n",
    "        \n",
    "        rank_ret,forecast_ret = eval_rank(test_ds,tss,forecasts,prediction_length,0)\n",
    "        metrics = get_acc(rank_ret,prediction_length)\n",
    "        ret = [model, prediction_length, half_moving_win,modestr, trainid]\n",
    "        ret.extend(metrics[0])\n",
    "        retdf.append(ret)\n",
    "        \n",
    "        rank_result[model] = (rank_ret,forecast_ret)\n",
    "    \n",
    "        \n",
    "    return pred_ret, ds_ret, rank_result, retdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp_predtrack(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                                        test_event='Indy500', test_cars = []):\n",
    "    models = ['oracle','curtrack','zerotrack']\n",
    "    datamode = MODE_PREDTRACK\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)\n",
    "    \n",
    "\n",
    "def run_exp_predpit(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):\n",
    "    models = ['oracle','curtrack','zerotrack']\n",
    "    datamode=MODE_PREDPIT\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)\n",
    "\n",
    "#MODE_DISTURB_CLEARTRACK = 64\n",
    "#MODE_DISTURB_ADJUSTTRACK = 128\n",
    "#MODE_DISTURB_ADJUSTPIT = 256\n",
    "def run_exp_cleartrack(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):\n",
    "    models = ['oracle']\n",
    "    datamode=MODE_DISTURB_CLEARTRACK\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)\n",
    "\n",
    "def run_exp_adjusttrack(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):\n",
    "    \"\"\"\n",
    "    dependency: test_event, test on one event only\n",
    "    \n",
    "    \"\"\"\n",
    "    models = ['oracle']\n",
    "    datamode=MODE_DISTURB_CLEARTRACK + MODE_DISTURB_ADJUSTTRACK\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)\n",
    "\n",
    "def run_exp_adjustpit(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):\n",
    "    models = ['oracle']\n",
    "    datamode=MODE_DISTURB_ADJUSTPIT\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)\n",
    "    \n",
    "def run_exp_adjustall(prediction_length, half_moving_win, train_ratio=0.8, trainid=\"r0.8\",\n",
    "                   test_event='Indy500', test_cars = []):\n",
    "    models = ['oracle']\n",
    "    datamode=MODE_DISTURB_CLEARTRACK +MODE_DISTURB_ADJUSTPIT +MODE_DISTURB_ADJUSTTRACK\n",
    "    return run_exp(prediction_length, half_moving_win, train_ratio=train_ratio, trainid=trainid,\n",
    "                   test_event=test_event, test_cars = test_cars, datamode = datamode,models = models)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(runs, plens, half, trainids, train_ratio, testfunc, datamode='', models=[]):\n",
    "    \"\"\"\n",
    "    \n",
    "    input:\n",
    "        plens=[2,5,10]\n",
    "        half=[False]\n",
    "        #trainids = [\"indy500-r0.2\",\"indy500-r0.4\",\"indy500\"]\n",
    "        trainids = [\"r0.5\"]\n",
    "        #half=[True,False]\n",
    "        #plens=[2]\n",
    "        runs = 5\n",
    "        train_ratio=0.5 \n",
    "        exp_id='mean-splitbystage-predpit'\n",
    "        \n",
    "        testfunc ; run_exp_predpit, run_exp_predtrack, run_exp ...\n",
    "\n",
    "    return:\n",
    "    \n",
    "        dfret  ; average result of multiple runs\n",
    "                 dataframe['model' , 'prediction_length', 'halfmode','datamode','trainid',\n",
    "                         'top1acc','top1acc_farmost','top5acc','top5acc_farmost','tau','rmse',\n",
    "                         'top1acc_std','top1acc_farmost_std','top5acc_std','top5acc_farmost_std','tau_std','rmse_std']\n",
    "                          \n",
    "        alldata_ret  ; for debug\n",
    "            [runid][halfmode,plen,trainid] -> (pred_ret, test_ds, rank_ret)\n",
    "                pred_ret[model] ->　[tss, forecasts]\n",
    "                test_ds[model] ->　test_ds\n",
    "                rank_ret[model] -> ([lap, elapsed_time, true_rank, pred_rank],forecast_ret)\n",
    "                    forecast_ret[completed_laps][carno] -> (elapsed_time, elapsed_time_hat)\n",
    "    \n",
    "    \"\"\"\n",
    "    if plens == [] or half == [] or trainids == []:\n",
    "        print(\"error with empty settings\")\n",
    "        return\n",
    "    \n",
    "    #testfunc or (datamode & models)\n",
    "    if isinstance(testfunc,str) and (datamode == '' or models == []):\n",
    "        print(\"error with testfunc\")\n",
    "        return\n",
    "\n",
    "    allret = []\n",
    "    alldata_ret = []\n",
    "    for runid in range(runs):\n",
    "        exp_data = []\n",
    "        exp_result = []\n",
    "\n",
    "        for halfmode in half:\n",
    "            for plen in plens:\n",
    "                for trainid in trainids:\n",
    "                    print('='*10)\n",
    "                    if not isinstance(testfunc,str):\n",
    "                        pred_ret, test_ds, rank_ret, metric_ret = testfunc(plen, halfmode, \n",
    "                                                            train_ratio=train_ratio,\n",
    "                                                            trainid=trainid)\n",
    "                    else:\n",
    "                        pred_ret, test_ds, rank_ret, metric_ret = run_exp(plen, halfmode, \n",
    "                                                            train_ratio=train_ratio,\n",
    "                                                            trainid=trainid, \n",
    "                                                            datamode=datamode,\n",
    "                                                            models=models)\n",
    "                        \n",
    "\n",
    "                    #save \n",
    "                    exp_data.append((pred_ret, test_ds, rank_ret))\n",
    "                    exp_result.extend(metric_ret)\n",
    "\n",
    "        #save result\n",
    "        result = pd.DataFrame(exp_result, columns = ['model' , 'prediction_length', 'halfmode',\n",
    "                                           'datamode','trainid',\n",
    "                                           'top1acc','top1acc_farmost','top5acc',\n",
    "                                           'top5acc_farmost','tau','rmse'])\n",
    "\n",
    "        #result['runid'] = [runid for x in range(len(result))]\n",
    "        allret.append(result)\n",
    "        alldata_ret.append(exp_data)\n",
    "\n",
    "    #final\n",
    "    rowcnt = len(allret[0])\n",
    "    metrics = np.empty((runs, rowcnt, 6))\n",
    "    for runid, ret in enumerate(allret):\n",
    "        metrics[runid, :,:] = ret[['top1acc','top1acc_farmost','top5acc',\n",
    "                                           'top5acc_farmost','tau','rmse']].values\n",
    "\n",
    "\n",
    "    #average\n",
    "    averagemat = np.mean(metrics[:,:,:], axis=0)\n",
    "    stdmat = np.std(metrics[:,:,:], axis=0)\n",
    "    dfhead = allret[0][['model' , 'prediction_length', 'halfmode', 'datamode','trainid']]\n",
    "    \n",
    "    \n",
    "    dfaverage = pd.DataFrame(averagemat, columns = ['top1acc','top1acc_farmost','top5acc',\n",
    "                                       'top5acc_farmost','tau','rmse'])\n",
    "    dfstd = pd.DataFrame(stdmat, columns = ['top1acc_std','top1acc_farmost_std','top5acc_std',\n",
    "                                       'top5acc_farmost_std','tau_std','rmse_std'])\n",
    "    dfret = pd.concat([dfhead, dfaverage, dfstd], axis=1)\n",
    "\n",
    "    if exp_id != '':\n",
    "        dfret.to_csv(f'rank-evaluate-indy500-{exp_id}-result.csv', float_format='%.3f')\n",
    "\n",
    "    return dfret, alldata_ret\n",
    "\n",
    "\n",
    "def checkret_status(dataret, runid = 0, idx = 0):\n",
    "    \"\"\"\n",
    "    check the test_ds track and lap status\n",
    "    \n",
    "        alldata_ret  ; for debug\n",
    "            [runid][halfmode,plen,trainid] -> (pred_ret, test_ds, rank_ret)\n",
    "                pred_ret[model] ->　[tss, forecasts]\n",
    "                test_ds[model] ->　test_ds\n",
    "                rank_ret[model] -> ([lap, elapsed_time, true_rank, pred_rank],forecast_ret)\n",
    "                    forecast_ret[completed_laps][carno] -> (elapsed_time, elapsed_time_hat)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    _, plen = dataret[runid][idx][0]['oracle'][1][0].samples.shape\n",
    "    test_ds = dataret[runid][idx][1]['oracle']\n",
    "   \n",
    "    \n",
    "    ds_iter =  iter(test_ds)\n",
    "    yfcnt = 0\n",
    "    pitcnt = 0\n",
    "    for recid in range(len(test_ds)):\n",
    "        test_rec = next(ds_iter)\n",
    "        \n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        \n",
    "        track_rec,lap_rec = test_rec['feat_dynamic_real']\n",
    "        yfcnt += np.sum(track_rec[-plen:])\n",
    "        pitcnt += np.sum(lap_rec[-plen:])\n",
    "        \n",
    "    print('yfcnt:', yfcnt, 'pitcnt:',pitcnt)\n",
    "\n",
    "def get_ref_oracle_testds_single(prediction_length, half_moving_win, train_ratio=0.8, \n",
    "                   test_event='Indy500', test_cars = []):           \n",
    "    ### create test dataset\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_ORACLE,\n",
    "                                         run_ts = COL_RANK,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)    \n",
    "    return test_ds\n",
    "\n",
    "def get_ref_oracle_testds(plens, halfs, train_ratio=0.8, \n",
    "                   test_event='Indy500', test_cars = []):           \n",
    "    \n",
    "    testset = {}\n",
    "    for prediction_length in plens:\n",
    "        for half_moving_win in halfs:\n",
    "            train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=MODE_ORACLE,\n",
    "                                         run_ts = COL_RANK,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)    \n",
    "            \n",
    "            # get key\n",
    "            key = '%d-%d'%(prediction_length,half_moving_win)\n",
    "            testset[key] = test_ds\n",
    "            \n",
    "    return testset\n",
    "\n",
    "\n",
    "\n",
    "def checkret_confusionmat_single(dataret, ref_oracle_testds, runid= 0, idx = 0):\n",
    "    \"\"\"\n",
    "    output the 4x4 confusion matrix split by track and lap status\n",
    "    \n",
    "    input:\n",
    "        ref_oracle_testds  ; oracle test ds\n",
    "    \n",
    "    \"\"\"\n",
    "    _, plen = dataret[runid][idx][0]['oracle'][1][0].samples.shape\n",
    "    test_ds = dataret[runid][idx][1]['oracle']\n",
    "    rank_ret = dataret[runid][idx][2]['oracle']\n",
    "    \n",
    "    if len(ref_oracle_testds) != len(test_ds):\n",
    "        print('error, size of testds mismatch', len(ref_oracle_testds), len(test_ds))\n",
    "        return\n",
    "    \n",
    "    # confusion matrix for <trackstatus, lapstatus> type: 00,01,10,11\n",
    "    # lap(start lap of prediction)  -> type\n",
    "    lapmap = {}\n",
    "    ds_iter =  iter(ref_oracle_testds)\n",
    "    for recid in range(len(ref_oracle_testds)):\n",
    "        test_rec = next(ds_iter) \n",
    "        \n",
    "        carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "        \n",
    "        track_rec,lap_rec = test_rec['feat_dynamic_real']\n",
    "        yfcnt = np.sum(track_rec[-plen:])\n",
    "        pitcnt = np.sum(lap_rec[-plen:])    \n",
    "        \n",
    "        #laptype = ('0' if yfcnt==0 else '1') + ('0' if pitcnt==0 else '1')\n",
    "        \n",
    "        lap = len(track_rec) - plen + 1\n",
    "        if lap not in lapmap:\n",
    "            #lapmap[lap] = laptype\n",
    "            lapmap[lap] = (yfcnt, pitcnt)\n",
    "        else:\n",
    "            oldtype = lapmap[lap]\n",
    "            lapmap[lap] = (yfcnt + oldtype[0], pitcnt + oldtype[1])\n",
    "            \n",
    "    \n",
    "    #split the rank_ret by laptype\n",
    "    types=['00','10','01','11']\n",
    "    acc_ret = []\n",
    "    for laptype in types:\n",
    "        check_ret = []\n",
    "        for item in rank_ret:\n",
    "            typecnt = lapmap[item[0]]\n",
    "            \n",
    "            thetype = ('0' if typecnt[0]==0 else '1') + ('0' if typecnt[1]==0 else '1')\n",
    "            \n",
    "            if thetype == laptype:\n",
    "                check_ret.append(item)\n",
    "        # get acc\n",
    "        metrics = get_acc(check_ret,plen)\n",
    "        recret = [laptype, len(check_ret)]\n",
    "        recret.extend(metrics[0])\n",
    "        acc_ret.append(recret)\n",
    "    \n",
    "    dfacc = pd.DataFrame(acc_ret, columns = ['type','reccnt','top1acc','top1acc_farmost','top5acc',\n",
    "                                       'top5acc_farmost','tau','rmse'])\n",
    "    return dfacc\n",
    "\n",
    "\n",
    "\n",
    "def checkret_confusionmat(dataret, ref_testset, runid= 0, testid = '', model='oracle'):\n",
    "    \"\"\"\n",
    "    output the 4x4 confusion matrix split by track and lap status\n",
    "    \n",
    "    input:\n",
    "        ref_oracle_testds  ; oracle test ds\n",
    "    \n",
    "    \"\"\"\n",
    "    plen_length = len(dataret[runid])\n",
    "    \n",
    "    dflist = []\n",
    "    for idx in range(plen_length):\n",
    "        _, plen = dataret[runid][idx][0][model][1][0].samples.shape\n",
    "        test_ds = dataret[runid][idx][1][model]\n",
    "        rank_ret = dataret[runid][idx][2][model][0]\n",
    "\n",
    "        key = '%d-%d'%(plen,0)\n",
    "        if key not in ref_testset:\n",
    "            print(f'error, {key} not found in ref_testset')\n",
    "            continue\n",
    "        \n",
    "        ref_oracle_testds = ref_testset[key]\n",
    "        if len(ref_oracle_testds) != len(test_ds):\n",
    "            print('error, size of testds mismatch', len(ref_oracle_testds), len(test_ds))\n",
    "            continue\n",
    "\n",
    "        # confusion matrix for <trackstatus, lapstatus> type: 00,01,10,11\n",
    "        # lap(start lap of prediction)  -> type\n",
    "        lapmap = {}\n",
    "        ds_iter =  iter(ref_oracle_testds)\n",
    "        for recid in range(len(ref_oracle_testds)):\n",
    "            test_rec = next(ds_iter) \n",
    "\n",
    "            carno = decode_carids[test_rec['feat_static_cat'][0]]\n",
    "\n",
    "            track_rec,lap_rec = test_rec['feat_dynamic_real']\n",
    "            yfcnt = np.sum(track_rec[-plen:])\n",
    "            pitcnt = np.sum(lap_rec[-plen:])    \n",
    "\n",
    "            #laptype = ('0' if yfcnt==0 else '1') + ('0' if pitcnt==0 else '1')\n",
    "\n",
    "            lap = len(track_rec) - plen + 1\n",
    "            if lap not in lapmap:\n",
    "                #lapmap[lap] = laptype\n",
    "                lapmap[lap] = (yfcnt, pitcnt)\n",
    "            else:\n",
    "                oldtype = lapmap[lap]\n",
    "                lapmap[lap] = (yfcnt + oldtype[0], pitcnt + oldtype[1])\n",
    "\n",
    "\n",
    "        #split the rank_ret by laptype\n",
    "        types=['00','10','01','11']\n",
    "        acc_ret = []\n",
    "        for laptype in types:\n",
    "            check_ret = []\n",
    "            for item in rank_ret:\n",
    "                typecnt = lapmap[item[0]]\n",
    "\n",
    "                thetype = ('0' if typecnt[0]==0 else '1') + ('0' if typecnt[1]==0 else '1')\n",
    "\n",
    "                if thetype == laptype:\n",
    "                    check_ret.append(item)\n",
    "            # get acc\n",
    "            metrics = get_acc(check_ret,plen)\n",
    "            recret = [testid, plen, laptype, len(check_ret)]\n",
    "            recret.extend(metrics[0])\n",
    "            acc_ret.append(recret)\n",
    "\n",
    "        #add all test\n",
    "        metrics = get_acc(rank_ret,plen)\n",
    "        recret = [testid, plen, 'aa', len(rank_ret)]\n",
    "        recret.extend(metrics[0])\n",
    "        acc_ret.append(recret)\n",
    "        \n",
    "        _dfacc = pd.DataFrame(acc_ret, columns = ['testid','plen',\n",
    "                                'type','reccnt','top1acc','top1acc_farmost','top5acc',\n",
    "                                'top5acc_farmost','tau','rmse'])\n",
    "        \n",
    "        dflist.append(_dfacc)\n",
    "    \n",
    "    dfacc = pd.concat(dflist, axis=0)\n",
    "    \n",
    "    return dfacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# parameters\n",
    "#\n",
    "#year = '2017'\n",
    "year = '2018'\n",
    "#event = 'Toronto'\n",
    "#https://www.racing-reference.info/season-stats/2018/O/#\n",
    "events_totalmiles=[256,500,372,268,500,310]\n",
    "events_laplen = [1.022,2.5,1.5,0.894,2.5,1.25]\n",
    "events = ['Phoenix','Indy500','Texas','Iowa','Pocono','Gateway']\n",
    "#events = ['Gateway']\n",
    "\n",
    "#events = ['Indy500']\n",
    "#events = ['Phoenix']\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "#works for only one event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "stagedata = {}\n",
    "global_start_offset = {}\n",
    "global_carids = {}\n",
    "traindata = None\n",
    "\n",
    "cur_carid = 0\n",
    "for event in events:\n",
    "    #alldata, rankdata, acldata, flagdata\n",
    "    stagedata[event] = load_data(event, year)\n",
    "    \n",
    "    alldata, rankdata, acldata = stagedata[event]\n",
    "    #carlist = set(acldata['car_number'])\n",
    "    #laplist = set(acldata['completed_laps'])\n",
    "    #print('%s: carno=%d, lapnum=%d'%(event, len(carlist), len(laplist)))\n",
    "\n",
    "    #offset\n",
    "    global_start_offset[event] = rankdata[rankdata['completed_laps']==0][['car_number','elapsed_time']]\n",
    "    \n",
    "    #build the carid map\n",
    "    #for car in carlist:\n",
    "    #    if car not in global_carids:\n",
    "    #        global_carids[car] = cur_carid\n",
    "    #        cur_carid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from here\n",
    "import pickle\n",
    "with open('laptime_rank_timediff_pit-oracle-%s.pickle'%year, 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    global_carids, laptime_data = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"1min\"\n",
    "#decode global_carids\n",
    "decode_carids={carid:carno for carno, carid in global_carids.items()}\n",
    "    \n",
    "#useeid = False\n",
    "#interpolate = False\n",
    "#ipstr = '-ip' if interpolate else '-noip'\n",
    "#ipstr = '%s-%s'%('ip' if interpolate else 'noip', 'eid' if useeid else 'noeid')\n",
    "#if useeid:\n",
    "#    cardinality = [len(global_carids), len(laptime_data)]\n",
    "#else:\n",
    "#    cardinality = [len(global_carids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oracle test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_testds(datamode, test_event='Indy500', test_cars=[]):\n",
    "    \"\"\"\n",
    "    report mae, etc\n",
    "    \"\"\"\n",
    "    for prediction_length in plens:\n",
    "        for half_moving_win in half:\n",
    "            train_ds, test_ds,_,_ = make_dataset_byevent(events_id[test_event], prediction_length,freq, \n",
    "                                         oracle_mode=datamode,\n",
    "                                         run_ts = COL_RANK,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win= half_moving_win,\n",
    "                                         train_ratio=train_ratio)\n",
    "def dotest(config):\n",
    "    acclist = []\n",
    "    dflist = []\n",
    "    for teststr in config.keys():\n",
    "        testfunc = teststr\n",
    "        datamode = config[teststr]\n",
    "\n",
    "        models = ['oracle']\n",
    "        df, dataret = run_test(runs, plens, half, trainids, train_ratio, testfunc, datamode=datamode,models=models)\n",
    "\n",
    "        #concat\n",
    "        acc = checkret_confusionmat(dataret, ref_testset, testid = teststr)\n",
    "        dflist.append(df)\n",
    "        acclist.append(acc)\n",
    "\n",
    "    dfret = pd.concat(dflist, axis=0)\n",
    "    dfacc = pd.concat(acclist, axis=0)\n",
    "    return dfret, dfacc\n",
    "\n",
    "def dotest_baseline():\n",
    "    acclist = []\n",
    "    dflist = []\n",
    "    testfunc = 'baseline'\n",
    "    datamode = MODE_ORACLE\n",
    "\n",
    "    models = ['deepAR']\n",
    "    #df, dataret = run_test(runs, plens, half, trainids, train_ratio, run_exp_baseline, datamode=datamode)\n",
    "    df, dataret = run_test(runs, plens, half, trainids, train_ratio, testfunc, datamode=datamode,models=models)\n",
    "\n",
    "    #concat\n",
    "    acc = checkret_confusionmat(dataret, ref_testset, testid = 'baseline',model=models[0])\n",
    "    dflist.append(df)\n",
    "    acclist.append(acc)\n",
    "    \n",
    "    models = ['naive']\n",
    "    #df, dataret = run_test(runs, plens, half, trainids, train_ratio, run_exp_baseline, datamode=datamode)\n",
    "    df, dataret = run_test(runs, plens, half, trainids, train_ratio, testfunc, datamode=datamode,models=models)\n",
    "\n",
    "    #concat\n",
    "    acc = checkret_confusionmat(dataret, ref_testset, testid = 'baseline',model=models[0])\n",
    "    dflist.append(df)\n",
    "    acclist.append(acc)\n",
    "\n",
    "    dfret = pd.concat(dflist, axis=0)\n",
    "    dfacc = pd.concat(acclist, axis=0)\n",
    "    return dfret, dfacc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:0.0,mae_lap:0.0,\n",
      "==========\n",
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:0.0,mae_lap:0.0,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp: run_exp model: oracle datamode: MODE_ORACLE,\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3142, forecasts len=3142\n",
      "==========\n",
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:1306.0,mae_lap:222.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY,MODE_ORACLE_LAPONLY,\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3142, forecasts len=3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:1306.0,mae_lap:0.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_LAPONLY,\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3142, forecasts len=3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:0.0,mae_lap:222.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY,\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3142, forecasts len=3142\n",
      "==========\n",
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:693.0,mae_lap:275.0,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp: run_exp model: oracle datamode: MODE_PREDTRACK,MODE_PREDPIT,\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3142, forecasts len=3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:709.0,mae_lap:222.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_TRACKONLY,MODE_PREDTRACK,\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3142, forecasts len=3142\n",
      "==========\n",
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:1306.0,mae_lap:282.0,\n",
      "exp: run_exp model: oracle datamode: MODE_ORACLE_LAPONLY,MODE_PREDPIT,\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3142, forecasts len=3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:508.0,mae_lap:222.0,\n",
      "exp: run_exp model: oracle datamode: MODE_TESTCURTRACK,\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3142, forecasts len=3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:1306.0,mae_lap:222.0,\n",
      "exp: run_exp model: oracle datamode: MODE_TESTZERO,\n",
      "predicting model=oracle, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3142, forecasts len=3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: deepAR datamode: MODE_ORACLE,\n",
      "predicting model=deepAR, plen=2\n",
      "loading model...done!, ctx:gpu(0)\n",
      "tss len=3142, forecasts len=3142\n",
      "==========\n",
      "====event:Indy500, train_len=80, max_len=200, min_len=200\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:3, totallen:146, nancount:54, test_reccnt:64\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:7, totallen:193, nancount:7, test_reccnt:111\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=10，len=57\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=13，len=67\n",
      "carno:14, totallen:187, nancount:13, test_reccnt:105\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:17, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:18, totallen:137, nancount:63, test_reccnt:55\n",
      "carno:19, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:21, totallen:199, nancount:1, test_reccnt:117\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:24, totallen:154, nancount:46, test_reccnt:72\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:26, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:118\n",
      "a short ts: carid=30，len=46\n",
      "carno:32, totallen:110, nancount:90, test_reccnt:28\n",
      "a short ts: carid=33，len=46\n",
      "carno:59, totallen:198, nancount:2, test_reccnt:116\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:118\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:118\n",
      "train len:0, test len:3142, mae_track:0.0,mae_lap:0.0,\n",
      "exp: run_exp model: naive datamode: MODE_ORACLE,\n",
      "predicting model=naive, plen=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/NaivePredictor.py:60: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  start_date=start + target_len,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=3142, forecasts len=3142\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testref' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6b137e9f8bff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtestret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdotest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mbaselineret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaselineacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdotest_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdfret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaselineret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mdfacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaselineacc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testref' is not defined"
     ]
    }
   ],
   "source": [
    "### test\n",
    "#half=[True, False]\n",
    "#plens=[2,5,10,20,30]\n",
    "plens=[2,5,10]\n",
    "plens=[2]\n",
    "half=[0]\n",
    "trainids = [\"indy500\"]\n",
    "#trainids = [\"r0.5\",\"r0.6\"]\n",
    "runs = 1\n",
    "train_ratio=0.4\n",
    "\n",
    "#trainids = [\"indy500\"]\n",
    "#runs = 1\n",
    "#plens=[2]\n",
    "exp_id=''\n",
    "\n",
    "config = {'fulloracle':MODE_ORACLE,'notracklap':MODE_NOTRACK + MODE_NOLAP,\n",
    "         'laponly':MODE_ORACLE_LAPONLY, 'trackonly':MODE_ORACLE_TRACKONLY,\n",
    "          'fullpred':MODE_PREDTRACK + MODE_PREDPIT,\n",
    "          'predtrack':MODE_PREDTRACK + MODE_ORACLE_TRACKONLY,\n",
    "          'predpit':MODE_PREDPIT + MODE_ORACLE_LAPONLY,\n",
    "          'curtrack':MODE_TESTCURTRACK,\n",
    "          'zerotrack':MODE_TESTZERO\n",
    "         }\n",
    "\n",
    "ref_testset = get_ref_oracle_testds(plens, half, train_ratio=train_ratio)\n",
    "\n",
    "testret, testacc = dotest(config)\n",
    "baselineret, baselineacc = dotest_baseline()\n",
    "dfret = pd.concat([testret, baselineret], axis=0)\n",
    "dfacc = pd.concat([testacc, baselineacc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfret = pd.concat([testret, baselineret], axis=0)\n",
    "dfacc = pd.concat([testacc, baselineacc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfacc.to_csv('rank-evaluate-indy500-mean-splitbyevent-fulltest-contigency-r1-t0.4-result.csv', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfret.to_csv('rank-evaluate-indy500-mean-splitbyevent-fulltest-r1-t0.4-result.csv', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testid</th>\n",
       "      <th>plen</th>\n",
       "      <th>type</th>\n",
       "      <th>reccnt</th>\n",
       "      <th>top1acc</th>\n",
       "      <th>top1acc_farmost</th>\n",
       "      <th>top5acc</th>\n",
       "      <th>top5acc_farmost</th>\n",
       "      <th>tau</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fulloracle</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.800847</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.875424</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.872107</td>\n",
       "      <td>9.304655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notracklap</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.873729</td>\n",
       "      <td>0.835593</td>\n",
       "      <td>0.872040</td>\n",
       "      <td>9.482503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laponly</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.686441</td>\n",
       "      <td>0.879661</td>\n",
       "      <td>0.845763</td>\n",
       "      <td>0.872591</td>\n",
       "      <td>9.367028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trackonly</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.874576</td>\n",
       "      <td>0.840678</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>9.358165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fullpred</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.873729</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.870186</td>\n",
       "      <td>9.686827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predtrack</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.741525</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.872881</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>0.872032</td>\n",
       "      <td>9.459029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predpit</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.872034</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>0.868798</td>\n",
       "      <td>9.727642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>curtrack</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.872034</td>\n",
       "      <td>0.835593</td>\n",
       "      <td>0.869702</td>\n",
       "      <td>9.704097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zerotrack</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.733051</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.872881</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>0.870964</td>\n",
       "      <td>9.606027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.686441</td>\n",
       "      <td>0.877966</td>\n",
       "      <td>0.842373</td>\n",
       "      <td>0.879677</td>\n",
       "      <td>8.986590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline</td>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "      <td>118</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.880508</td>\n",
       "      <td>0.845763</td>\n",
       "      <td>0.898598</td>\n",
       "      <td>8.151034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       testid  plen type  reccnt   top1acc  top1acc_farmost   top5acc  \\\n",
       "4  fulloracle     2   aa     118  0.800847         0.728814  0.875424   \n",
       "4  notracklap     2   aa     118  0.745763         0.677966  0.873729   \n",
       "4     laponly     2   aa     118  0.754237         0.686441  0.879661   \n",
       "4   trackonly     2   aa     118  0.737288         0.669492  0.874576   \n",
       "4    fullpred     2   aa     118  0.737288         0.661017  0.873729   \n",
       "4   predtrack     2   aa     118  0.741525         0.669492  0.872881   \n",
       "4     predpit     2   aa     118  0.737288         0.669492  0.872034   \n",
       "4    curtrack     2   aa     118  0.737288         0.669492  0.872034   \n",
       "4   zerotrack     2   aa     118  0.733051         0.669492  0.872881   \n",
       "4    baseline     2   aa     118  0.728814         0.686441  0.877966   \n",
       "4    baseline     2   aa     118  0.745763         0.677966  0.880508   \n",
       "\n",
       "   top5acc_farmost       tau      rmse  \n",
       "4         0.838983  0.872107  9.304655  \n",
       "4         0.835593  0.872040  9.482503  \n",
       "4         0.845763  0.872591  9.367028  \n",
       "4         0.840678  0.873333  9.358165  \n",
       "4         0.838983  0.870186  9.686827  \n",
       "4         0.837288  0.872032  9.459029  \n",
       "4         0.837288  0.868798  9.727642  \n",
       "4         0.835593  0.869702  9.704097  \n",
       "4         0.837288  0.870964  9.606027  \n",
       "4         0.842373  0.879677  8.986590  \n",
       "4         0.845763  0.898598  8.151034  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfacc[dfacc['type']=='aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prediction_length</th>\n",
       "      <th>halfmode</th>\n",
       "      <th>datamode</th>\n",
       "      <th>trainid</th>\n",
       "      <th>top1acc</th>\n",
       "      <th>top1acc_farmost</th>\n",
       "      <th>top5acc</th>\n",
       "      <th>top5acc_farmost</th>\n",
       "      <th>tau</th>\n",
       "      <th>rmse</th>\n",
       "      <th>top1acc_std</th>\n",
       "      <th>top1acc_farmost_std</th>\n",
       "      <th>top5acc_std</th>\n",
       "      <th>top5acc_farmost_std</th>\n",
       "      <th>tau_std</th>\n",
       "      <th>rmse_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oracle</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MODE_ORACLE,</td>\n",
       "      <td>indy500</td>\n",
       "      <td>0.800847</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.875424</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.872107</td>\n",
       "      <td>9.304655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oracle</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MODE_ORACLE_TRACKONLY,MODE_ORACLE_LAPONLY,</td>\n",
       "      <td>indy500</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.873729</td>\n",
       "      <td>0.835593</td>\n",
       "      <td>0.872040</td>\n",
       "      <td>9.482503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oracle</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MODE_ORACLE_LAPONLY,</td>\n",
       "      <td>indy500</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.686441</td>\n",
       "      <td>0.879661</td>\n",
       "      <td>0.845763</td>\n",
       "      <td>0.872591</td>\n",
       "      <td>9.367028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oracle</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MODE_ORACLE_TRACKONLY,</td>\n",
       "      <td>indy500</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.874576</td>\n",
       "      <td>0.840678</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>9.358165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oracle</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MODE_PREDTRACK,MODE_PREDPIT,</td>\n",
       "      <td>indy500</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.873729</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.870186</td>\n",
       "      <td>9.686827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oracle</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MODE_ORACLE_TRACKONLY,MODE_PREDTRACK,</td>\n",
       "      <td>indy500</td>\n",
       "      <td>0.741525</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.872881</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>0.872032</td>\n",
       "      <td>9.459029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oracle</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MODE_ORACLE_LAPONLY,MODE_PREDPIT,</td>\n",
       "      <td>indy500</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.872034</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>0.868798</td>\n",
       "      <td>9.727642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oracle</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MODE_TESTCURTRACK,</td>\n",
       "      <td>indy500</td>\n",
       "      <td>0.737288</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.872034</td>\n",
       "      <td>0.835593</td>\n",
       "      <td>0.869702</td>\n",
       "      <td>9.704097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oracle</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MODE_TESTZERO,</td>\n",
       "      <td>indy500</td>\n",
       "      <td>0.733051</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.872881</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>0.870964</td>\n",
       "      <td>9.606027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepAR</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MODE_ORACLE,</td>\n",
       "      <td>indy500</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.686441</td>\n",
       "      <td>0.877966</td>\n",
       "      <td>0.842373</td>\n",
       "      <td>0.879677</td>\n",
       "      <td>8.986590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MODE_ORACLE,</td>\n",
       "      <td>indy500</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.880508</td>\n",
       "      <td>0.845763</td>\n",
       "      <td>0.898598</td>\n",
       "      <td>8.151034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  prediction_length  halfmode  \\\n",
       "0  oracle                  2         0   \n",
       "0  oracle                  2         0   \n",
       "0  oracle                  2         0   \n",
       "0  oracle                  2         0   \n",
       "0  oracle                  2         0   \n",
       "0  oracle                  2         0   \n",
       "0  oracle                  2         0   \n",
       "0  oracle                  2         0   \n",
       "0  oracle                  2         0   \n",
       "0  deepAR                  2         0   \n",
       "0   naive                  2         0   \n",
       "\n",
       "                                     datamode  trainid   top1acc  \\\n",
       "0                                MODE_ORACLE,  indy500  0.800847   \n",
       "0  MODE_ORACLE_TRACKONLY,MODE_ORACLE_LAPONLY,  indy500  0.745763   \n",
       "0                        MODE_ORACLE_LAPONLY,  indy500  0.754237   \n",
       "0                      MODE_ORACLE_TRACKONLY,  indy500  0.737288   \n",
       "0                MODE_PREDTRACK,MODE_PREDPIT,  indy500  0.737288   \n",
       "0       MODE_ORACLE_TRACKONLY,MODE_PREDTRACK,  indy500  0.741525   \n",
       "0           MODE_ORACLE_LAPONLY,MODE_PREDPIT,  indy500  0.737288   \n",
       "0                          MODE_TESTCURTRACK,  indy500  0.737288   \n",
       "0                              MODE_TESTZERO,  indy500  0.733051   \n",
       "0                                MODE_ORACLE,  indy500  0.728814   \n",
       "0                                MODE_ORACLE,  indy500  0.745763   \n",
       "\n",
       "   top1acc_farmost   top5acc  top5acc_farmost       tau      rmse  \\\n",
       "0         0.728814  0.875424         0.838983  0.872107  9.304655   \n",
       "0         0.677966  0.873729         0.835593  0.872040  9.482503   \n",
       "0         0.686441  0.879661         0.845763  0.872591  9.367028   \n",
       "0         0.669492  0.874576         0.840678  0.873333  9.358165   \n",
       "0         0.661017  0.873729         0.838983  0.870186  9.686827   \n",
       "0         0.669492  0.872881         0.837288  0.872032  9.459029   \n",
       "0         0.669492  0.872034         0.837288  0.868798  9.727642   \n",
       "0         0.669492  0.872034         0.835593  0.869702  9.704097   \n",
       "0         0.669492  0.872881         0.837288  0.870964  9.606027   \n",
       "0         0.686441  0.877966         0.842373  0.879677  8.986590   \n",
       "0         0.677966  0.880508         0.845763  0.898598  8.151034   \n",
       "\n",
       "   top1acc_std  top1acc_farmost_std  top5acc_std  top5acc_farmost_std  \\\n",
       "0          0.0                  0.0          0.0                  0.0   \n",
       "0          0.0                  0.0          0.0                  0.0   \n",
       "0          0.0                  0.0          0.0                  0.0   \n",
       "0          0.0                  0.0          0.0                  0.0   \n",
       "0          0.0                  0.0          0.0                  0.0   \n",
       "0          0.0                  0.0          0.0                  0.0   \n",
       "0          0.0                  0.0          0.0                  0.0   \n",
       "0          0.0                  0.0          0.0                  0.0   \n",
       "0          0.0                  0.0          0.0                  0.0   \n",
       "0          0.0                  0.0          0.0                  0.0   \n",
       "0          0.0                  0.0          0.0                  0.0   \n",
       "\n",
       "   tau_std  rmse_std  \n",
       "0      0.0       0.0  \n",
       "0      0.0       0.0  \n",
       "0      0.0       0.0  \n",
       "0      0.0       0.0  \n",
       "0      0.0       0.0  \n",
       "0      0.0       0.0  \n",
       "0      0.0       0.0  \n",
       "0      0.0       0.0  \n",
       "0      0.0       0.0  \n",
       "0      0.0       0.0  \n",
       "0      0.0       0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plens=[2]\n",
    "config_t = {'zerotrack':MODE_TESTZERO\n",
    "         }\n",
    "\n",
    "dfret_curtrack, dfacc_curtrack = dotest(config_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODE_DISTURB_CLEARTRACK = 64\n",
    "#MODE_DISTURB_ADJUSTTRACK = 128\n",
    "#MODE_DISTURB_ADJUSTPIT = 256\n",
    "\n",
    "config_adjust = {'cleartrack':MODE_DISTURB_CLEARTRACK,'adjusttrack':MODE_DISTURB_CLEARTRACK + MODE_DISTURB_ADJUSTTRACK,\n",
    "         'adjustpit':MODE_DISTURB_ADJUSTPIT, 'adjustall':MODE_DISTURB_CLEARTRACK+ MODE_DISTURB_ADJUSTTRACK+MODE_DISTURB_ADJUSTPIT,\n",
    "         }\n",
    "\n",
    "adjust_dfret, adjust_dfacc = dotest(config_adjust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.concat([dfacc, adjust_dfacc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_t = {'adjust_laponly':MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "         }\n",
    "\n",
    "t_dfret, t_dfacc = dotest(config_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_t = {'predpit':MODE_PREDPIT + MODE_ORACLE_LAPONLY\n",
    "         }\n",
    "\n",
    "t2_dfret, t2_dfacc = dotest(config_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjust pit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_modeldict={-3:0.1, -2:0.15,-1:0.2,0:0.05, 1:0.2, 2:0.15,3:0.1 }\n",
    "_adjust_model = build_random_model(_modeldict)\n",
    "datamode = MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "check_testds(datamode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_t = {'newadjust_laponly':MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "         }\n",
    "\n",
    "t3_dfret, t3_dfacc = dotest(config_t)\n",
    "test_dfacc = pd.concat([t_dfacc,t2_dfacc,t3_dfacc], axis=0)\n",
    "test_dfacc[test_dfacc['type']=='aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_modeldict={-3:0.0, -2:0.15,-1:0.2,0:0.2, 1:0.2, 2:0.15,3:0.0 }\n",
    "_adjust_model = build_random_model(_modeldict)\n",
    "init_adjust_pitmodel()\n",
    "datamode = MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "check_testds(datamode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_t = {'newadjust_laponly':MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "         }\n",
    "\n",
    "t3_dfret, t3_dfacc = dotest(config_t)\n",
    "test_dfacc = pd.concat([t_dfacc,t2_dfacc,t3_dfacc], axis=0)\n",
    "test_dfacc[test_dfacc['type']=='aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_modeldict={-4:0.05, -3:0.1, -2:0.2,-1:0.3, 0:0.2, 1:0.1, 2:0.1 }\n",
    "_adjust_model = build_random_model(_modeldict)\n",
    "init_adjust_pitmodel()\n",
    "datamode = MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "check_testds(datamode)\n",
    "\n",
    "real_model = build_random_model(_empirical_model)\n",
    "print('adjust model:')\n",
    "print_model(_adjust_model, iscdf=True)\n",
    "print('real adjust model:')\n",
    "print_model(real_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_t = {'newadjust_laponly':MODE_DISTURB_ADJUSTPIT + MODE_ORACLE_LAPONLY\n",
    "         }\n",
    "\n",
    "t3_dfret, t3_dfacc = dotest(config_t)\n",
    "test_dfacc = pd.concat([t_dfacc,t2_dfacc,t3_dfacc], axis=0)\n",
    "test_dfacc[test_dfacc['type']=='aa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall[dfall['type']=='aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldict={-2:0.1,-1:0.2,0:0.4, 1:0.2, 2:0.1 }\n",
    "model = build_random_model(modeldict)\n",
    "a = np.array([get_random_choice(model) for x in range(1000)])\n",
    "for val in modeldict.keys():\n",
    "    print(val, np.sum(a==val) / 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfacc[dfacc['type']=='aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineacc[baselineacc['type']=='aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfret, dfacc = dotest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineret, baselineacc = dotest_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3_dfret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_df, naive_dataret = run_test(1, [2],[0], trainids, 0.4, 'naive', datamode=MODE_ORACLE,models=['naive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ret = naive_dataret[0][0][2]['naive'][0]\n",
    "rank_ret[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ret[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw\n",
    "dfret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfret_curtrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
