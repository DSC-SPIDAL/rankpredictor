{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### telemetry ts dataset\n",
    "\n",
    "build a time series dataset across all the oval races, including telemetry\n",
    "\n",
    "distance, vspeed(vehicle speed), espeed(engine speed), brake, throttle, etc.\n",
    "\n",
    "when this dataset aims to be used in forecasting, covariates of the racing status can not be included, such as track_status and current_status\n",
    "\n",
    "+  [(eventid,carids: carno -> rowid, telemetry_array)]\n",
    "\n",
    "telemetry_array := [[time_seq_id, distance, vspeed]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/hpda/indycar/notebook/9.DeepModels'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# parameters\n",
    "#\n",
    "#year = '2017'\n",
    "year = '2018'\n",
    "#event = 'Toronto'\n",
    "#https://www.racing-reference.info/season-stats/2018/O/#\n",
    "events_totalmiles=[256,500,372,268,500,310]\n",
    "events_laplen = [1.022,2.5,1.5,0.894,2.5,1.25]\n",
    "events = ['Phoenix','Indy500','Texas','Iowa','Pocono','Gateway']\n",
    "#events = ['Gateway']\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "#events = ['Indy500']\n",
    "#events = ['Phoenix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make indy car completed_laps dataset\n",
    "# car_number, completed_laps, rank, elapsed_time, rank_diff, elapsed_time_diff \n",
    "def make_cl_data(dataset):\n",
    "\n",
    "    # pick up data with valid rank\n",
    "    rankdata = dataset.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "\n",
    "    # resort by car_number, lap\n",
    "    uni_ds = rankdata.sort_values(by=['car_number', 'completed_laps', 'elapsed_time'], ascending=True)    \n",
    "    uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \"current_status\", \"track_status\", \"lap_status\",\n",
    "                      \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "                      \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "    \n",
    "    carnumber = set(uni_ds['car_number'])\n",
    "    print('cars:', carnumber)\n",
    "    print('#cars=', len(carnumber))\n",
    "   \n",
    "    # faster solution , uni_ds already sorted by car_number and lap\n",
    "    uni_ds['rank_diff'] = uni_ds['rank'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['rank_diff'][mask] = 0\n",
    "    \n",
    "    uni_ds['time_diff'] = uni_ds['elapsed_time'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['time_diff'][mask] = 0\n",
    "    \n",
    "    df = uni_ds[['car_number','completed_laps','rank','elapsed_time','rank_diff','time_diff']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def make_lapstatus_data(dataset):\n",
    "    final_lap = max(dataset.completed_laps)\n",
    "    total_laps = final_lap + 1\n",
    "\n",
    "    # get records for the cars that finish the race\n",
    "    completed_car_numbers= dataset[dataset.completed_laps == final_lap].car_number.values\n",
    "    completed_car_count = len(completed_car_numbers)\n",
    "\n",
    "    print('count of completed cars:', completed_car_count)\n",
    "    print('completed cars:', completed_car_numbers)\n",
    "    \n",
    "    #pick up one of them\n",
    "    onecar = dataset[dataset['car_number']==completed_car_numbers[0]]\n",
    "    onecar = onecar.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "    return onecar[['completed_laps','track_status']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(event, year):\n",
    "    inputfile = '../data/final/C_'+ event +'-' + year + '-final.csv'\n",
    "    outputprefix = year +'-' + event + '-'\n",
    "    dataset = pd.read_csv(inputfile)\n",
    "    #dataset.info(verbose=True)    \n",
    "    \n",
    "    final_lap = max(dataset.completed_laps)\n",
    "    total_laps = final_lap + 1\n",
    "\n",
    "    # get records for the cars that finish the race\n",
    "    completed_car_numbers= dataset[dataset.completed_laps == final_lap].car_number.values\n",
    "    completed_car_count = len(completed_car_numbers)\n",
    "\n",
    "    print('count of completed cars:', completed_car_count)\n",
    "    print('completed cars:', completed_car_numbers)\n",
    "\n",
    "    #make a copy\n",
    "    alldata = dataset.copy()\n",
    "    dataset = dataset[dataset['car_number'].isin(completed_car_numbers)]\n",
    "    rankdata = alldata.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "    \n",
    "    cldata = make_cl_data(dataset)\n",
    "    flagdata = make_lapstatus_data(dataset)\n",
    "    acldata = make_cl_data(alldata)\n",
    "\n",
    "    return alldata, rankdata, acldata, flagdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overall view of laptime scatter plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cardata(curcarno, ycol='time_diff'):\n",
    "    car = acldata[acldata['car_number']==curcarno]\n",
    "    #print(car['time_diff'].describe())\n",
    "    \n",
    "    cols=['completed_laps','rank','car_number','lap_status','track_status',\n",
    "    'pit_stop_count','current_status','start_position']\n",
    "    colid={key:idx for idx, key in enumerate(cols)}\n",
    "\n",
    "    cardata = rankdata[rankdata['car_number'] == curcarno]\n",
    "\n",
    "    carstatus = [[row[0], row[1],row[2],row[3],row[4],row[5],row[6],row[7]] for row in cardata[\n",
    "        ['completed_laps','rank','car_number','lap_status','track_status',\n",
    "        'pit_stop_count','current_status','start_position']].values]\n",
    "    \n",
    "    x = car['completed_laps'][1:].values\n",
    "    y = car[ycol][1:].values\n",
    "\n",
    "    pits=[]\n",
    "    yellowflags=[]\n",
    "    lastflag = 'x'\n",
    "    for row in carstatus:\n",
    "        lap = int(row[colid['completed_laps']])\n",
    "\n",
    "        if row[colid['lap_status']]=='P':\n",
    "            pits.append(lap)\n",
    "\n",
    "        if row[colid['track_status']]=='Y':\n",
    "            if lastflag != 'Y':       \n",
    "                #start\n",
    "                yellowflags.append(lap)\n",
    "        else:\n",
    "            if lastflag == 'Y':       \n",
    "                #end\n",
    "                yellowflags.append(lap)        \n",
    "        lastflag = row[colid['track_status']]\n",
    "\n",
    "    #pit lap\n",
    "    pits = np.array(pits)\n",
    "    #start, end lap\n",
    "    #\n",
    "    yellowflags = np.array(yellowflags)\n",
    "    if (yellowflags.shape[0] % 2)==1:\n",
    "        print('crash?:carno=', curcarno)\n",
    "        yellowflags = []\n",
    "    else:\n",
    "        yellowflags = np.array(yellowflags).reshape((-1,2))    \n",
    "    \n",
    "    return car, x, y, pits, yellowflags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bulid the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_laptime_dataset(stagedata):\n",
    "    \"\"\"\n",
    "    input: (alldata, rankdata, acldata, flagdata)\n",
    "    output: laptime & rank data\n",
    "    \n",
    "    [(\n",
    "    eventid,\n",
    "    carids : rowid -> carno,\n",
    "    laptime : #car_number x #totallaps (padded by Nan)),\n",
    "    rank : #car_number x #totallaps (padded by Nan)\n",
    "    )]\n",
    "    \"\"\"\n",
    "    laptime_data = []\n",
    "    for event in stagedata.keys():\n",
    "        \n",
    "        laptime_rec = []\n",
    "        eventid = events_id[event]\n",
    "        \n",
    "        alldata, rankdata, acldata, flagdata = stagedata[event]\n",
    "        carlist = set(acldata['car_number'])\n",
    "        laplist = set(acldata['completed_laps'])\n",
    "        totalcars = len(carlist)\n",
    "        totallaps = len(laplist)\n",
    "\n",
    "        #carnumber -> carid\n",
    "        carids={key:idx for idx, key in enumerate(carlist)}\n",
    "        decode_carids={idx:key for idx, key in enumerate(carlist)}\n",
    "        \n",
    "        #array: car_number x lap\n",
    "        #laptime = np.zeros((totalcars, totallaps-1))\n",
    "        #rank = np.zeros((totalcars, totallaps-1))\n",
    "        laptime = np.empty((totalcars, totallaps-1))\n",
    "        rank = np.empty((totalcars, totallaps-1))\n",
    "        laptime[:] = np.NaN\n",
    "        rank[:] = np.NaN\n",
    "        \n",
    "        \n",
    "        lapdata = acldata[['car_number','completed_laps','time_diff','rank']].to_numpy()\n",
    "        \n",
    "        for row in lapdata:\n",
    "            #completed_laps\n",
    "            if int(row[1]) == 0:\n",
    "                continue\n",
    "                \n",
    "            #add to laptime array\n",
    "            # array[car_number, completed_laps] = time_diff\n",
    "            laptime[carids[row[0]], int(row[1])-1] = row[2]\n",
    "            rank[carids[row[0]], int(row[1])-1] = row[3]\n",
    "\n",
    "        #add one record\n",
    "        laptime_data.append([eventid, decode_carids, laptime,rank])\n",
    "        # push this event into stage dataframe\n",
    "        print('event=%s, records=%s'%(event, laptime.shape))\n",
    "        \n",
    "        \n",
    "    return laptime_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of completed cars: 11\n",
      "completed cars: [ 1  6 27  9 28  5 20 14 15 22 30]\n",
      "cars: {1, 5, 6, 9, 14, 15, 20, 22, 27, 28, 30}\n",
      "#cars= 11\n",
      "count of completed cars: 11\n",
      "completed cars: [ 1  6 27  9 28  5 20 14 15 22 30]\n",
      "cars: {1, 4, 5, 6, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 32, 59, 88, 98}\n",
      "#cars= 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/scratch/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoenix: carno=23, lapnum=251\n",
      "count of completed cars: 18\n",
      "completed cars: [12 20  9 27 28 22 29  1  6 15 66 98  4 88 25 60 64 23]\n",
      "cars: {64, 1, 66, 98, 4, 6, 9, 12, 60, 15, 20, 22, 23, 88, 25, 27, 28, 29}\n",
      "#cars= 18\n",
      "count of completed cars: 18\n",
      "completed cars: [12 20  9 27 28 22 29  1  6 15 66 98  4 88 25 60 64 23]\n",
      "cars: {1, 3, 4, 6, 7, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 59, 60, 64, 66, 88, 98}\n",
      "#cars= 33\n",
      "Indy500: carno=33, lapnum=201\n",
      "count of completed cars: 9\n",
      "completed cars: [ 9 22 27  5 28 15 30 18 10]\n",
      "cars: {5, 9, 10, 15, 18, 22, 27, 28, 30}\n",
      "#cars= 9\n",
      "count of completed cars: 9\n",
      "completed cars: [ 9 22 27  5 28 15 30 18 10]\n",
      "cars: {1, 3, 4, 5, 6, 7, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 47, 55, 57, 59, 60, 68, 73, 83, 88, 98}\n",
      "#cars= 32\n",
      "Texas: carno=32, lapnum=249\n",
      "count of completed cars: 5\n",
      "completed cars: [ 5 21 30  1  6]\n",
      "cars: {1, 5, 6, 21, 30}\n",
      "#cars= 5\n",
      "count of completed cars: 5\n",
      "completed cars: [ 5 21 30  1  6]\n",
      "cars: {1, 4, 5, 6, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 59, 88, 98}\n",
      "#cars= 22\n",
      "Iowa: carno=22, lapnum=301\n",
      "count of completed cars: 4\n",
      "completed cars: [27 12  9 18]\n",
      "cars: {9, 18, 27, 12}\n",
      "#cars= 4\n",
      "count of completed cars: 4\n",
      "completed cars: [27 12  9 18]\n",
      "cars: {1, 4, 5, 6, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 59, 88, 98}\n",
      "#cars= 22\n",
      "Pocono: carno=22, lapnum=201\n",
      "count of completed cars: 8\n",
      "completed cars: [12 27  9 22 26 21  1 10]\n",
      "cars: {1, 9, 10, 12, 21, 22, 26, 27}\n",
      "#cars= 8\n",
      "count of completed cars: 8\n",
      "completed cars: [12 27  9 22 26 21  1 10]\n",
      "cars: {1, 4, 5, 9, 10, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 28, 30, 59, 88, 98}\n",
      "#cars= 21\n",
      "Gateway: carno=21, lapnum=249\n"
     ]
    }
   ],
   "source": [
    "stagedata = {}\n",
    "global_carids = {}\n",
    "traindata = None\n",
    "cur_carid = 0\n",
    "for event in events:\n",
    "    #alldata, rankdata, acldata, flagdata\n",
    "    stagedata[event] = load_data(event, year)\n",
    "    \n",
    "    alldata, rankdata, acldata, flagdata = stagedata[event]\n",
    "    carlist = set(acldata['car_number'])\n",
    "    laplist = set(acldata['completed_laps'])\n",
    "    print('%s: carno=%d, lapnum=%d'%(event, len(carlist), len(laplist)))\n",
    "\n",
    "    #build the carid map\n",
    "    for car in carlist:\n",
    "        if car not in global_carids:\n",
    "            global_carids[car] = cur_carid\n",
    "            cur_carid += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alldata, rankdata, acldata, flagdata = stagedata['Indy500']\n",
    "#acldata[acldata['car_number']==12].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_telemetry_dataset(stagedata, frequency = 1):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        stagedata: (alldata, rankdata, acldata, flagdata)\n",
    "        frequency: 1s by default\n",
    "    \n",
    "    output: vspeed & distance data\n",
    "    \n",
    "    [(\n",
    "    eventid,\n",
    "    carids : rowid -> carno,\n",
    "    vspeed : #car_number x variable length\n",
    "    distance : #car_number x variable length\n",
    "    )]\n",
    "    \"\"\"\n",
    "    telemetry_data = []\n",
    "    for event in stagedata.keys():\n",
    "        eventid = events_id[event]\n",
    "        \n",
    "        alldata, rankdata, acldata, flagdata = stagedata[event]\n",
    "        #carnumber -> carid\n",
    "        carlist = set(acldata['car_number'])\n",
    "        carids={key:idx for idx, key in enumerate(carlist)}\n",
    "        decode_carids={idx:key for idx, key in enumerate(carlist)}\n",
    "        \n",
    "        # multiple ts for this event\n",
    "        ts_event = []\n",
    "        for carno in carlist:\n",
    "            #get completed_laps\n",
    "            elapsed_time = np.max(acldata[acldata['car_number'] == carno][['elapsed_time']].values)\n",
    "        \n",
    "            # load data for this car\n",
    "            #  timestamp\\t distance \\t vspeed\n",
    "            # 16:23:00.588    3705.16 153.780 10416   3       0       109.5   0.04\n",
    "            inputfile = f'../data/telemetry/{event}-{year}-{carno}.csv'\n",
    "            try:\n",
    "                _data = pd.read_csv(inputfile,delimiter='\\t', header=None)\n",
    "            except:\n",
    "                #Texas-car-3\n",
    "                print('failed to read telemetry:', inputfile)\n",
    "                ts_event.append(np.array([[0,np.nan, np.nan]]))\n",
    "                continue\n",
    "            \n",
    "            # calc the time differences(in seconds)\n",
    "            _data[0]=pd.to_datetime(_data[0])\n",
    "            _data[8] = (_data[0] - _data[0].iloc[0]).dt.total_seconds()\n",
    "            _data[9] = _data[8].astype(int)\n",
    "\n",
    "            ts_length = int(elapsed_time)\n",
    "            #ts = []\n",
    "            ts = np.zeros((ts_length,3))\n",
    "            ts[:] = np.nan\n",
    "            \n",
    "            cur_id = 0\n",
    "            _data_array = _data[[9,1,2]].to_numpy()\n",
    "            last_id = _data_array.shape[0]\n",
    "            for id in range(ts_length):\n",
    "                while((cur_id < last_id) and (_data_array[cur_id][0] < id)):\n",
    "                    cur_id += 1\n",
    "\n",
    "                if cur_id == last_id:\n",
    "                    break\n",
    "                    \n",
    "                if _data_array[cur_id][0] > id:\n",
    "                    #not found, missing data\n",
    "                    #ts.append([id, np.nan, np.nan])\n",
    "                    ts[id,:] = [id, np.nan, np.nan]\n",
    "                else:\n",
    "                    #ts.append([id, _data_array[cur_id][1], _data_array[cur_id][2]])            \n",
    "                    ts[id,:] = [id, _data_array[cur_id][1], _data_array[cur_id][2]]            \n",
    "                    \n",
    "            \n",
    "            # deal with this ts\n",
    "            # ts_event.append(np.array(ts))\n",
    "            ts_event.append(ts)\n",
    "\n",
    "        #add one record\n",
    "        telemetry_data.append([eventid, decode_carids, ts_event])\n",
    "        # push this event into stage dataframe\n",
    "        print('event=%s, records=%s'%(event, len(telemetry_data[-1][2])))\n",
    "        \n",
    "        \n",
    "    return telemetry_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event=Phoenix, records=23\n",
      "event=Indy500, records=33\n",
      "failed to read telemetry: ../data/telemetry/Texas-2018-3.csv\n",
      "failed to read telemetry: ../data/telemetry/Texas-2018-7.csv\n",
      "failed to read telemetry: ../data/telemetry/Texas-2018-25.csv\n",
      "failed to read telemetry: ../data/telemetry/Texas-2018-47.csv\n",
      "failed to read telemetry: ../data/telemetry/Texas-2018-55.csv\n",
      "failed to read telemetry: ../data/telemetry/Texas-2018-57.csv\n",
      "failed to read telemetry: ../data/telemetry/Texas-2018-60.csv\n",
      "failed to read telemetry: ../data/telemetry/Texas-2018-68.csv\n",
      "failed to read telemetry: ../data/telemetry/Texas-2018-73.csv\n",
      "failed to read telemetry: ../data/telemetry/Texas-2018-83.csv\n",
      "event=Texas, records=32\n",
      "event=Iowa, records=22\n",
      "failed to read telemetry: ../data/telemetry/Pocono-2018-23.csv\n",
      "event=Pocono, records=22\n",
      "event=Gateway, records=21\n"
     ]
    }
   ],
   "source": [
    "telemetry_data = get_telemetry_dataset(stagedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#stintdf.to_csv('laptime-%s.csv'%year)\n",
    "with open('telemetry-%s.pickle'%year, 'wb') as f:\n",
    "    #pack [global_carids, laptime_data]\n",
    "    savedata = [global_carids, telemetry_data]\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([6239.  , 1387.81,  164.25]),\n",
       " array([6255.,   nan,   nan]),\n",
       " array([nan, nan, nan]),\n",
       " array([6242.  , 1404.09,  160.01]),\n",
       " array([6243.  , 1412.88,  165.42]),\n",
       " array([nan, nan, nan]),\n",
       " array([nan, nan, nan]),\n",
       " array([6249.  , 1397.38,  160.75]),\n",
       " array([6249.  , 1369.53,  159.59]),\n",
       " array([6250.  , 1350.97,  158.67]),\n",
       " array([ 891.  , 1509.9 ,  103.03]),\n",
       " array([6248.  , 1338.09,  159.72]),\n",
       " array([6251.  , 1339.94,  153.17]),\n",
       " array([6249.  , 1358.13,  157.59]),\n",
       " array([6252.  , 1334.94,  156.66]),\n",
       " array([6254.  , 1412.75,  152.74]),\n",
       " array([6242.  , 1383.06,  161.42]),\n",
       " array([6243.  , 1389.  ,  165.15]),\n",
       " array([6250.  , 1370.34,  158.55]),\n",
       " array([4428.  ,  149.88,    0.  ]),\n",
       " array([6254.  , 1377.44,  151.88]),\n",
       " array([6253.  , 1348.31,  154.4 ]),\n",
       " array([6249.  , 1343.91,  160.62])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 0\n",
    "[x[-1] for x in telemetry_data[id][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(telemetry_data[id][2][6][:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_data[id][2][6][-5810:-5800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#events = ['Phoenix','Indy500','Texas','Iowa','Pocono','Gateway']\n",
    "alldata, rankdata, acldata, flagdata = stagedata['Gateway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acldata[acldata['car_number']==14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event='Indy500'\n",
    "carno=12\n",
    "year=2018\n",
    "inputfile = f'../data/telemetry/{event}-{year}-{carno}.csv'\n",
    "_data = pd.read_csv(inputfile,delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data[0]=pd.to_datetime(_data[0])\n",
    "_data[8] = (_data[0] - _data[0].iloc[0]).dt.total_seconds()\n",
    "_data[9] = _data[8].astype(int)\n",
    "\n",
    "ts_length = 10\n",
    "ts = []\n",
    "cur_id = 0\n",
    "_data_array = _data[[9,1,2]].to_numpy()\n",
    "last_id = _data_array.shape[0]\n",
    "for id in range(ts_length):\n",
    "    while((cur_id < last_id) and (_data_array[cur_id][0] < id)):\n",
    "        cur_id += 1\n",
    "        \n",
    "    if _data_array[cur_id][0] > id:\n",
    "        #not found, missing data\n",
    "        ts.append([id, np.Nan, np.Nan])\n",
    "    else:\n",
    "        ts.append([id, _data_array[cur_id][1], _data_array[cur_id][2]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data[0]=pd.to_datetime(_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data_array = _data[[9,1,2]].to_numpy()\n",
    "_data_array[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data[8] = (_data[0] - _data[0].iloc[0]).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data[9] = _data[8].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##debug data format\n",
    "def _timestr(timestamp, scale=10000):\n",
    "    s, ms = divmod(timestamp, scale)\n",
    "    hours, remainder = divmod(s, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    timestr = '{:02}:{:02}:{:02}.{:04}'.format(int(hours), int(minutes), int(seconds), int(ms))\n",
    "    return timestr\n",
    "\n",
    "def _gettime(timestr, scale=1000.):\n",
    "    tmms = 0\n",
    "    tmall = timestr.split('.')\n",
    "    tms = [int(x) for x in tmall[0].split(':')]\n",
    "    if len(tms) == 3 and len(tmall) == 2:\n",
    "        tmms = (tms[0] * 3600 + tms[1] * 60 + tms[2])*scale + float(tmall[1])\n",
    "    return tmms\n",
    "\n",
    "def decode_cmd(cmd, idx, deli=chr(0xa6)):\n",
    "    items = cmd.split(deli)\n",
    "    print(str(_hex2int(items[idx])*1.0/10000))\n",
    "  \n",
    "def _hex2int(hexstr): \n",
    "    return int(hexstr, 16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd=\"$C?U?200F7?R.I?7?1?2?F7?4438D18?4039D?T?3DC05?D9?0?1?B6?0?7?3DC05?Active?K?4?EE?3?0\"\n",
    "decode_cmd(cmd,8,'?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd='$C?U?20015?R.I?3?1?2?15?748B24?3EE16?T?3E8ED?10?AE15?0?7D0A?0?3?3E8ED?Active?G?0?0?3?0'\n",
    "decode_cmd(cmd,8,'?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
