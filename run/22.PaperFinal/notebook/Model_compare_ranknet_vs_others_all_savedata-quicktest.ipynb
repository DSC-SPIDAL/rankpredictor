{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate a model by draw prediction visually for a lond horizon\n",
    "\n",
    "base: 11./evaluate_model_visualdraw\n",
    "\n",
    "+ visualization of pitagemodel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "ERROR:fbprophet:Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pathlib import Path\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.distribution.multivariate_gaussian import MultivariateGaussianOutput\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.model.prophet import ProphetPredictor\n",
    "from gluonts.model.r_forecast import RForecastPredictor\n",
    "from indycar.model.NaivePredictor import NaivePredictor\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import indycar.model.evaluate_fulltest_fastrun_paper as ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/hpda/indycar/notebook/22.PaperFinal-r002'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prob_forecasts(ts_entry, forecast_entry, outputfile):\n",
    "\n",
    "    plot_length = context_length \n",
    "    prediction_intervals = (50.0, 90.0)\n",
    "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "\n",
    "    figcnt = len(ts_entry)\n",
    "\n",
    "    #fig, axs = plt.subplots(figcnt, 1, figsize=(10, 7))\n",
    "\n",
    "    #for idx in range(figcnt):\n",
    "\n",
    "    #    ts_entry[idx][-plot_length:].plot(ax=axs[idx])  # plot the time series\n",
    "    #    forecast_entry[idx].plot(prediction_intervals=prediction_intervals, color='g')\n",
    "    #    axs[idx].grid(which=\"both\")\n",
    "    #    axs[idx].legend(legend, loc=\"upper left\")\n",
    "    \n",
    "    for idx in range(figcnt):\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(10, 7))\n",
    "        #ts_entry[idx][-plot_length:].plot(ax=axs)  # plot the time series\n",
    "        #forecast_entry[idx].plot(prediction_intervals=prediction_intervals, color='g')\n",
    "        ts_entry[idx].iloc[-plot_length:,0].plot(ax=axs)  # plot the time series\n",
    "        forecast_entry[idx].copy_dim(0).plot(prediction_intervals=prediction_intervals, color='g')\n",
    "        \n",
    "        plt.grid(which=\"both\")\n",
    "        plt.legend(legend, loc=\"upper left\")\n",
    "        plt.savefig(outputfile + '-%d.pdf'%idx)\n",
    "        plt.show()\n",
    "\n",
    "def evaluate_model(predictor, evaluator, test_ds, outputfile):\n",
    "    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor=predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "    \n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    #convert to univariate format\n",
    "    # tss: <ts_len, #feature>\n",
    "    # forecasts.sample: < 100, prediction_length, #feature>\n",
    "   \n",
    "    #tss_n = []\n",
    "    #for ts in tss:\n",
    "    #    tse = ts.to_numpy()\n",
    "    #    tss_n.append(tse[:,0].reshape((tse.shape[0])))\n",
    "    #cast_n = []\n",
    "    #for fc in forecasts:\n",
    "    #    nfc = fc\n",
    "    #    fcs = fc.samples.shape\n",
    "    #    nsamples = fc.samples[:,:,0].reshape((fcs[0], fcs[1]))\n",
    "    #    nfc.samples = nsamples\n",
    "    #    cast_n.append(nfc)\n",
    "    #tss = tss_n\n",
    "    #forecasts = cast_n\n",
    "\n",
    "\n",
    "    # car12@rank1, car1@rank16, car7@rank33, the index is 7,0,4 accordingly\n",
    "    # Indy500 Car 12 WillPower\n",
    "    #offset = 52-7\n",
    "    offset = 0\n",
    "    ts_entry = [tss[7+offset],tss[0+offset],tss[4+offset]]\n",
    "    forecast_entry = [forecasts[7+offset],forecasts[0+offset],forecasts[4+offset]]\n",
    "\n",
    "    #debug\n",
    "    #print(f'ts_entry shape:{ts_entry[0].shape}, forecast:{forecast_entry[0].samples.shape}')\n",
    "\n",
    "    plot_prob_forecasts(ts_entry, forecast_entry, outputfile)\n",
    "    \n",
    "    #evaluator = MultivariateEvaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "    agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n",
    "    \n",
    "    \n",
    "    print(json.dumps(agg_metrics, indent=4))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct long prediction result\n",
    "def plot_prob_forecasts_ex(ts_entry, forecast_entry, outputfile):\n",
    "\n",
    "    plot_length = int(forecast_entry[0].samples.shape[1] *1.2) \n",
    "    #plot_length = forecast_entry[0].samples.shape[1] + 10 \n",
    "    \n",
    "    prediction_intervals = (50.0, 90.0)\n",
    "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "\n",
    "    figcnt = len(ts_entry)\n",
    "    for idx in range(figcnt):\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(20, 7))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #ts_entry[idx][-plot_length:].plot(ax=axs)  # plot the time series\n",
    "        #forecast_entry[idx].plot(prediction_intervals=prediction_intervals, color='g')\n",
    "        ts_entry[idx].iloc[-plot_length:,0].plot(ax=axs, linewidth=1)  # plot the time series\n",
    "        forecast_entry[idx].copy_dim(0).plot(prediction_intervals=prediction_intervals, color='g')\n",
    "        \n",
    "\n",
    "        #axs.set_xlim((80,110))\n",
    "        \n",
    "        plt.grid(which=\"both\")\n",
    "        plt.legend(legend, loc=\"upper left\")\n",
    "        \n",
    "        if outputfile != '':\n",
    "            plt.savefig(outputfile + '-%d.pdf'%idx)\n",
    "        \n",
    "        # set the x ticks\n",
    "        #xtickslocs = plt.gca().get_xticks()\n",
    "        #print(xtickslocs)\n",
    "        #ticks = [tick for tick in plt.gca().get_xticklabels()]\n",
    "        #print(ticks)        \n",
    "        \n",
    "        locs, labels = plt.xticks() \n",
    "        #plt.xticks(locs, range(len(locs)))\n",
    "        start_loc = locs[0]        \n",
    "        offset = range(0, 200, 10)\n",
    "        #new_locs = range(start_loc , start_loc+200, 10)\n",
    "        new_locs = [start_loc + x for x in offset]\n",
    "        #new_labels = [str(x-start_loc + 1) for x in new_locs]\n",
    "        new_labels = [str(x) for x in offset]\n",
    "        plt.xticks(new_locs, new_labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_predict(output,predictor):\n",
    "    \"\"\"\n",
    "    use the farest samples only\n",
    "    \n",
    "    input:\n",
    "        test_ds\n",
    "        predictor\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def get_start(idx):\n",
    "        td = forecasts[idx].start_date - start_time\n",
    "        return td.days*24*60 + td.seconds//60\n",
    "    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor=predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    start_time, row = next(tss[0].iterrows())\n",
    "\n",
    "    first_start = get_start(-1)\n",
    "    last_start = get_start(0)\n",
    "    print(first_start, last_start)    \n",
    "    \n",
    "    import copy\n",
    "    target = copy.deepcopy(forecasts[-1])\n",
    "\n",
    "    #100, 10\n",
    "    nsample, npredict = target.samples.shape\n",
    "    print('sampel# x predictlen: ', nsample, npredict)\n",
    "    \n",
    "    newsamples = np.zeros((nsample, last_start - first_start + npredict))\n",
    "    newsamples[:,:] = np.nan\n",
    "\n",
    "    for idx in range(len(forecasts)):\n",
    "        #copy samples\n",
    "        start_pos = get_start(idx)\n",
    "\n",
    "        pos = start_pos - first_start\n",
    "        #copy sample to block\n",
    "        #newsamples[:, pos:pos + npredict] = forecasts[idx].samples\n",
    "        newsamples[:, pos + npredict - 1] = forecasts[idx].samples[:,-1]\n",
    "        \n",
    "\n",
    "    target.samples = newsamples\n",
    "\n",
    "    #plot_prob_forecasts_ex([tss[0]],[target],output)\n",
    "    \n",
    "    return target, tss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_data(datafile,dfs):\n",
    "    with open(datafile, 'wb') as f:\n",
    "        #pack [global_carids, laptime_data]\n",
    "        savedata = dfs\n",
    "        #savedata = [freq, train_set, test_set]\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_predict_bymloutput_multirun(output, dfin, sampleCnt=100):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        test_ds\n",
    "        predictor\n",
    "    \n",
    "    \"\"\"\n",
    "    def get_start(idx):\n",
    "        td = forecasts[idx].start_date - start_time\n",
    "        return td.days*24*60 + td.seconds//60\n",
    "    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor= _predictor,  # predictor\n",
    "        num_samples=sampleCnt,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    start_time, row = next(tss[0].iterrows())\n",
    "\n",
    "    first_start = get_start(-1)\n",
    "    last_start = get_start(0)\n",
    "    print('first start:', first_start, 'last start:', last_start)    \n",
    "    \n",
    "    import copy\n",
    "    target = copy.deepcopy(forecasts[-1])\n",
    "\n",
    "    #100, 10\n",
    "    nsample, npredict = target.samples.shape\n",
    "    print('sampel# x predictlen: ', nsample, npredict)\n",
    "    \n",
    "    newsamples = np.zeros((nsample, last_start - first_start + npredict))\n",
    "    newsamples[:,:] = np.nan\n",
    "    \n",
    "    for idx in range(len(forecasts)):\n",
    "        #copy samples\n",
    "        start_pos = get_start(idx)\n",
    "\n",
    "        pos = start_pos - first_start + npredict - 1\n",
    "        #copy sample to block\n",
    "        #newsamples[:, pos:pos + npredict] = forecasts[idx].samples\n",
    "        #newsamples[:, pos + npredict - 1] = forecasts[idx].samples[:,-1]\n",
    "        \n",
    "        # get prediction from ml output\n",
    "        # pos = laps\n",
    "        # 1 ... 10 | 11 <- start pos in forecasts\n",
    "        # 0 ...  9 | 10 <- 9 is the startlap\n",
    "        #\n",
    "        startlap = start_pos  - 2\n",
    "        #print('start pos:', start_pos, 'pos:',pos, 'startlap:', startlap)\n",
    "        \n",
    "        _rec = dfin[dfin['startlap']== startlap]\n",
    "        if len(_rec) > 0:\n",
    "            # rank start from 1 for visualization\n",
    "            pred_val = _rec.pred_endrank.values\n",
    "            \n",
    "            #pred_val = _rec.pred_endrank.values\n",
    "            #make sure shape match, 100 samples\n",
    "            \n",
    "            #newsamples[:, pos + npredict - 1] = pred_val + 1\n",
    "            newsamples[:, pos] = pred_val + 1\n",
    "            #print('startlap:', startlap, 'predrank:', pred_val)\n",
    "\n",
    "    target.samples = newsamples\n",
    "    \n",
    "    print('multirun target samples:', target.samples.shape)\n",
    "\n",
    "    #plot_prob_forecasts_ex([tss[0]],[target],output)\n",
    "    \n",
    "    return target,tss[0]\n",
    "\n",
    "def long_predict_bymloutput(output, dfin):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        test_ds\n",
    "        predictor\n",
    "    \n",
    "    \"\"\"\n",
    "    def get_start(idx):\n",
    "        td = forecasts[idx].start_date - start_time\n",
    "        return td.days*24*60 + td.seconds//60\n",
    "    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor= _predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    start_time, row = next(tss[0].iterrows())\n",
    "\n",
    "    first_start = get_start(-1)\n",
    "    last_start = get_start(0)\n",
    "    print('first start:', first_start, 'last start:', last_start)    \n",
    "    \n",
    "    import copy\n",
    "    target = copy.deepcopy(forecasts[-1])\n",
    "\n",
    "    #100, 10\n",
    "    nsample, npredict = target.samples.shape\n",
    "    print('sampel# x predictlen: ', nsample, npredict)\n",
    "    \n",
    "    newsamples = np.zeros((nsample, last_start - first_start + npredict))\n",
    "    newsamples[:,:] = np.nan\n",
    "    \n",
    "    for idx in range(len(forecasts)):\n",
    "        #copy samples\n",
    "        start_pos = get_start(idx)\n",
    "\n",
    "        pos = start_pos - first_start + npredict - 1\n",
    "        #copy sample to block\n",
    "        #newsamples[:, pos:pos + npredict] = forecasts[idx].samples\n",
    "        #newsamples[:, pos + npredict - 1] = forecasts[idx].samples[:,-1]\n",
    "        \n",
    "        # get prediction from ml output\n",
    "        # pos = laps\n",
    "        # 1 ... 10 | 11 <- start pos in forecasts\n",
    "        # 0 ...  9 | 10 <- 9 is the startlap\n",
    "        #\n",
    "        startlap = start_pos  - 2\n",
    "        #print('start pos:', start_pos, 'pos:',pos, 'startlap:', startlap)\n",
    "        \n",
    "        _rec = dfin[dfin['startlap']== startlap]\n",
    "        if len(_rec) > 0:\n",
    "            # rank start from 1 for visualization\n",
    "            pred_val = _rec.pred_endrank.values[0]\n",
    "            \n",
    "            #pred_val = _rec.pred_endrank.values\n",
    "            #make sure shape match, 100 samples\n",
    "            \n",
    "            #newsamples[:, pos + npredict - 1] = pred_val + 1\n",
    "            newsamples[:, pos] = pred_val + 1\n",
    "            #print('startlap:', startlap, 'predrank:', pred_val)\n",
    "\n",
    "    target.samples = newsamples\n",
    "    \n",
    "    print('target samples:', target.samples.shape)\n",
    "\n",
    "    #plot_prob_forecasts_ex([tss[0]],[target],output)\n",
    "    \n",
    "    return target,tss[0]\n",
    "\n",
    "\n",
    "#\n",
    "# different idx format to bymloutput\n",
    "#\n",
    "def long_predict_bydf(output, dfin):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        test_ds\n",
    "        predictor\n",
    "    \n",
    "    \"\"\"\n",
    "    def get_start(idx):\n",
    "        td = forecasts[idx].start_date - start_time\n",
    "        return td.days*24*60 + td.seconds//60\n",
    "    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor= _predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    start_time, row = next(tss[0].iterrows())\n",
    "\n",
    "    first_start = get_start(-1)\n",
    "    last_start = get_start(0)\n",
    "    print('first start:', first_start, 'last start:', last_start)    \n",
    "    \n",
    "    import copy\n",
    "    target = copy.deepcopy(forecasts[-1])\n",
    "\n",
    "    #100, 10\n",
    "    nsample, npredict = target.samples.shape\n",
    "    print('sampel# x predictlen: ', nsample, npredict)\n",
    "    \n",
    "    newsamples = np.zeros((nsample, last_start - first_start + npredict))\n",
    "    newsamples[:,:] = np.nan\n",
    "    \n",
    "    for idx in range(len(forecasts)):\n",
    "        #copy samples\n",
    "        start_pos = get_start(idx)\n",
    "\n",
    "        pos = start_pos - first_start + npredict - 1\n",
    "        #copy sample to block\n",
    "        #newsamples[:, pos:pos + npredict] = forecasts[idx].samples\n",
    "        #newsamples[:, pos + npredict - 1] = forecasts[idx].samples[:,-1]\n",
    "        \n",
    "        # get prediction from ml output\n",
    "        # pos = laps\n",
    "        # 1 ... 10 | 11 <- start pos in forecasts\n",
    "        # 0 ...  9 | 10 <- 9 is the startlap\n",
    "        #\n",
    "        startlap = start_pos  - 1\n",
    "        #print('start pos:', start_pos, 'pos:',pos, 'startlap:', startlap)\n",
    "        \n",
    "        _rec = dfin[dfin['startlap']== startlap]\n",
    "        if len(_rec) > 0:\n",
    "            # rank start from 1 for visualization\n",
    "            pred_val = _rec.pred_endrank.values[0]\n",
    "            \n",
    "            #pred_val = _rec.pred_endrank.values\n",
    "            #make sure shape match, 100 samples\n",
    "            \n",
    "            #newsamples[:, pos + npredict - 1] = pred_val + 1\n",
    "            newsamples[:, pos] = pred_val + 1\n",
    "            #print('startlap:', startlap, 'predrank:', pred_val)\n",
    "\n",
    "    target.samples = newsamples\n",
    "    \n",
    "    print('target samples:', target.samples.shape)\n",
    "\n",
    "    #plot_prob_forecasts_ex([tss[0]],[target],output)\n",
    "    \n",
    "    return target,tss[0]\n",
    "\n",
    "def long_predict_bysamples(output, samples, tss):\n",
    "    \"\"\"\n",
    "    use the farest samples only\n",
    "    \n",
    "    input:\n",
    "        samples\n",
    "        tss\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def get_start(idx):\n",
    "        td = forecasts[idx].start_date - start_time\n",
    "        return td.days*24*60 + td.seconds//60\n",
    "    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor= _predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    start_time, row = next(tss[0].iterrows())\n",
    "\n",
    "    first_start = get_start(-1)\n",
    "    last_start = get_start(0)\n",
    "    print(first_start, last_start)    \n",
    "    \n",
    "    import copy\n",
    "    target = copy.deepcopy(forecasts[-1])\n",
    "\n",
    "    #100, 10\n",
    "    nsample, npredict = target.samples.shape\n",
    "    print('sampel# x predictlen: ', nsample, npredict)\n",
    "    \n",
    "    #sample array size: last_start - first_start + npredict\n",
    "    arraysize = last_start - first_start + npredict\n",
    "    \n",
    "    #error here\n",
    "    #target.samples = samples[:,-len(forecasts)-1:] + 1\n",
    "    #target.samples = samples[:, 10 + npredict:] + 1\n",
    "    target.samples = samples[:, first_start:first_start + arraysize] + 1\n",
    "\n",
    "    print('long_predict_bysamples==>target samples shape:', target.samples.shape)\n",
    "    #plot_prob_forecasts_ex([tss[0]],[target],output)\n",
    "    \n",
    "    return target, tss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecasts(ts_entry, forecast_entry, outputfile, \n",
    "                   colors = ['r','g','m'],\n",
    "                   plabels= ['observed','svr','arima','ranknet']):\n",
    "\n",
    "    prediction_intervals = [90.0]\n",
    "    \n",
    "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals]\n",
    "\n",
    "    figcnt = len(forecast_entry)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, figcnt, figsize=(4*figcnt,3))\n",
    "\n",
    "    for idx in range(figcnt):\n",
    "        ax = plt.subplot(1, figcnt, idx+1)\n",
    "        \n",
    "        plot_length = int(forecast_entry[idx].samples.shape[1] *1.2) \n",
    "\n",
    "        ts_entry[idx].iloc[-plot_length:,0].plot(linewidth=1, color='b',\n",
    "                                            marker='*', alpha=0.7, zorder=-1, label=plabels[0]) \n",
    "    \n",
    "    \n",
    "        forecast_entry[idx].copy_dim(0).plot(prediction_intervals=prediction_intervals, \n",
    "                                             color=colors[idx],label=plabels[idx+1], zorder=10)\n",
    "        \n",
    "        ax.set_xlabel('Lap')\n",
    "        if idx==0:\n",
    "            ax.set_ylabel('Rank')\n",
    "    \n",
    "        locs, labels = plt.xticks() \n",
    "        #plt.xticks(locs, range(len(locs)))\n",
    "        start_loc = locs[0]        \n",
    "        offset = range(0, 200, 5)\n",
    "        #new_locs = range(start_loc , start_loc+200, 10)\n",
    "        new_locs = [start_loc + x for x in offset]\n",
    "        #new_labels = [str(x-start_loc + 1) for x in new_locs]\n",
    "        new_labels = [str(x) for x in offset]\n",
    "        plt.xticks(new_locs, new_labels)\n",
    "\n",
    "        #ax.set_xlim((80,110))\n",
    "        print('xlim:', plt.xlim())\n",
    "        xl, xr = plt.xlim()\n",
    "        ax.set_xlim((xl+80,xl+110))\n",
    "        \n",
    "        yb, yu = plt.ylim()\n",
    "        print('ylim:', plt.ylim())\n",
    "        ax.set_ylim((-5,+23))\n",
    "        \n",
    "        ax.set_zorder(-1)\n",
    "        plt.grid(which=\"both\", zorder=-1)\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        l=plt.legend(prop={'size': 10},loc='upper left')\n",
    "        l.set_zorder(0.6)\n",
    "    \n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outputfile + '-%d.pdf'%0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct long prediction result\n",
    "def plot_forecasts_h(ts_entry, forecast_entry, outputfile, \n",
    "                   colors = ['r','g','m'],\n",
    "                   plabels= ['observed','svr','arima','ranknet']):\n",
    "\n",
    "    \n",
    "    #prediction_intervals = (50.0, 90.0)\n",
    "    prediction_intervals = [90.0]\n",
    "    \n",
    "    #legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals]\n",
    "\n",
    "    figcnt = len(forecast_entry)\n",
    "    \n",
    "    #fig, axs = plt.subplots(figcnt,1, figsize=(8,6))\n",
    "    fig, axs = plt.subplots(1, figcnt, figsize=(12,3*figcnt))\n",
    "\n",
    "    #colors = ['r','g','m']\n",
    "    #plabels = ['observed','svr','arima','ranknet']\n",
    "    \n",
    "    for idx in range(figcnt):\n",
    "        ax = plt.subplot(figcnt, 1, idx+1)\n",
    "        \n",
    "        #plot_length = int(forecast_entry[idx].samples.shape[1] *1.2) \n",
    "        #ts_entry[idx].iloc[-plot_length:,0].plot(linewidth=1, color='b',\n",
    "        #                                    marker='*', alpha=0.7, zorder=-1, label=plabels[0]) \n",
    "        \n",
    "        ts_entry[idx].iloc[:,0].plot(linewidth=1, color='b',\n",
    "                                            marker='*', alpha=0.7, zorder=-1, label=plabels[0]) \n",
    "        \n",
    "    \n",
    "        target = forecast_entry[idx]\n",
    "        #target = fix_target(forecast_entry[idx])\n",
    "        target.copy_dim(0).plot(prediction_intervals=prediction_intervals, \n",
    "                                             color=colors[idx],label=plabels[idx+1], zorder=10)\n",
    "        \n",
    "        ax.set_xlabel('Lap')\n",
    "        if idx==0:\n",
    "            ax.set_ylabel('Rank')\n",
    "    \n",
    "        locs, labels = plt.xticks() \n",
    "        #plt.xticks(locs, range(len(locs)))\n",
    "        start_loc = locs[0]        \n",
    "        offset = range(0, 200, 5)\n",
    "        #new_locs = range(start_loc , start_loc+200, 10)\n",
    "        new_locs = [start_loc + x for x in offset]\n",
    "        #new_labels = [str(x-start_loc + 1) for x in new_locs]\n",
    "        new_labels = [str(x) for x in offset]\n",
    "        plt.xticks(new_locs, new_labels)\n",
    "\n",
    "        ax.set_ylim((-5,+40))\n",
    "        \n",
    "        #ax.set_xlim((80,110))\n",
    "        ax.set_zorder(-1)\n",
    "        plt.grid(which=\"both\", zorder=-1)\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        l=plt.legend(prop={'size': 10},loc='upper left')\n",
    "        l.set_zorder(0.6)\n",
    "    \n",
    "        if idx==0:\n",
    "            plt.title(outputfile)\n",
    "    \n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outputfile + '.pdf')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dfout(datafile):\n",
    "    #with open('laptime_rank_timediff_fulltest-oracle-%s.pickle'%year, 'rb') as f:\n",
    "    with open(datafile, 'rb') as f:\n",
    "        # The protocol version used is detected automatically, so we do not\n",
    "        # have to specify it.\n",
    "        dfout = pickle.load(f, encoding='latin1') \n",
    "        \n",
    "        return dfout[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "years = ['2013','2014','2015','2016','2017','2018']\n",
    "#events = ['Indy500']\n",
    "events = [f'Indy500-{x}' for x in years]\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = 2\n",
    "freq = '1min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/evaluate_fulltest_fastrun_paper.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uni_ds['rank_diff'][mask] = 0\n",
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/evaluate_fulltest_fastrun_paper.py:193: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uni_ds['time_diff'][mask] = 0\n"
     ]
    }
   ],
   "source": [
    "ev._dataset_id = 'indy2013-2018-nocarid'\n",
    "ev._dataset_id = 'indy2013-2018'\n",
    "#_test_event = 'Indy500-2019'\n",
    "ev._test_event = 'Indy500-2018'\n",
    "\n",
    "ev._task_id = 'rank'  # rank,laptime, the trained model's task\n",
    "ev._run_ts = ev.COL_RANK   #COL_LAPTIME,COL_RANK\n",
    "ev._exp_id='rank'  #rank, laptime, laptim2rank, timediff2rank... \n",
    "\n",
    "ev._feature_mode = ev.FEATURE_STATUS\n",
    "ev._context_ratio = 0.\n",
    "\n",
    "ev.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# following functions works for short-term results only\n",
    "# \n",
    "\n",
    "#def get_allsamples(year=2018, model='pitmodel'):\n",
    "def get_allsamples_ex(dfx):\n",
    "    \"\"\"\n",
    "    dfx is the results of multiple runs, ret of test_model call\n",
    "    dfx[runid] -> < df, samples, tss>\n",
    "    \"\"\"\n",
    "    runs = list(dfx.keys())\n",
    "    runcnt = len(runs)\n",
    "    \n",
    "    full_samples = {}\n",
    "    full_tss = dfx[runs[0]][2]\n",
    "    carlist = list(full_tss.keys())\n",
    "    samplecnt, lapcnt = dfx[runs[0]][1][carlist[0]].shape\n",
    "    \n",
    "    print('sacmplecnt:', samplecnt, 'lapcnt:',lapcnt,'runcnt:', runcnt)\n",
    "    \n",
    "    #empty samples\n",
    "    for carid, carno in enumerate(carlist):\n",
    "        full_samples[carno] = np.zeros((runcnt, lapcnt))\n",
    "    \n",
    "    for runid in runs:\n",
    "        #one run\n",
    "        tss = dfx[runid][2]\n",
    "        forecast = dfx[runid][1]\n",
    "        \n",
    "        for carid, carno in enumerate(carlist):\n",
    "            #get mean for this run\n",
    "            forecast_mean = np.nanmean(forecast[carno], axis=0)\n",
    "            full_samples[carno][runid, :] = forecast_mean\n",
    "            \n",
    "            #if carno==3 and runid == 0:\n",
    "            #    print('forecast:',forecast_mean)\n",
    "            \n",
    "    return full_samples, full_tss\n",
    "\n",
    "   \n",
    "def get_allsamples(year=2018, model='pitmodel'):    \n",
    "    dfx = ret[f'{model}-RANK-{year}-inlap-nopitage']\n",
    "    return get_allsamples_ex(dfx)\n",
    "\n",
    "def do_rerank(dfout, short=True):\n",
    "    \"\"\"\n",
    "    carno','startlap','startrank','endrank','diff','sign','pred_endrank','pred_diff','pred_sign','endlap','pred_endlap\n",
    "    \n",
    "    output of prediction of target can be float\n",
    "    \n",
    "    resort the endrank globally\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cols=['carno','startlap','startrank','endrank','diff','sign','pred_endrank','pred_diff','pred_sign','endlap','pred_endlap']\n",
    "    colid={x:id for id,x in enumerate(cols)}\n",
    "    \n",
    "    #df = dfout.sort_values(by=['startlap','carno'])\n",
    "    print('rerank...')\n",
    "    laps = set(dfout.startlap.values)\n",
    "    \n",
    "    dfs = []\n",
    "    for lap in laps:\n",
    "        df = dfout[dfout['startlap']==lap].to_numpy()\n",
    "        \n",
    "        #print('in',df)\n",
    "        \n",
    "        idx = np.argsort(df[:,colid['pred_endrank']], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "    \n",
    "        df[:,colid['pred_endrank']] = true_rank\n",
    "        \n",
    "        #reset preds \n",
    "        df[:,colid['pred_diff']] = df[:,colid['pred_endrank']] - df[:,colid['endrank']]\n",
    "\n",
    "        for rec in df:\n",
    "            if rec[colid['pred_diff']] == 0:\n",
    "                rec[colid['pred_sign']] = 0\n",
    "            elif rec[colid['pred_diff']] > 0:\n",
    "                rec[colid['pred_sign']] = 1\n",
    "            else:\n",
    "                rec[colid['pred_sign']] = -1        \n",
    "        \n",
    "        #print('out',df)\n",
    "        if len(dfs) == 0:\n",
    "            dfs = df\n",
    "        else:\n",
    "            dfs = np.vstack((dfs, df))\n",
    "        #dfs.append(df)\n",
    "        #np.vstack(df)\n",
    "        \n",
    "    #dfret = pd.concat(dfs)\n",
    "    #data = np.array(dfs)\n",
    "    if short:\n",
    "        dfret = pd.DataFrame(dfs.astype(int), columns = cols[:-2])\n",
    "    else:\n",
    "        dfret = pd.DataFrame(dfs.astype(int), columns = cols)\n",
    "    return dfret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranknet_multirun(retdata, testcar, sampleCnt=100):\n",
    "    dfs = []\n",
    "    #for id in range(samplecnt):\n",
    "    for id in retdata.keys():\n",
    "        #ret['pitmodel-RANK-2018-inlap-nopitage']\n",
    "        df = retdata[id][0]\n",
    "        df = df[df['carno']==testcar]\n",
    "        dfs.append(df)\n",
    "\n",
    "    dfin_ranknet = pd.concat(dfs)\n",
    "\n",
    "    print('dfin_ranknet size:', len(dfin_ranknet))\n",
    "    \n",
    "    #modify to fit to ml model format\n",
    "    dfin_ranknet['startlap'] = dfin_ranknet['startlap'] - 1\n",
    "    dfin_ranknet['startrank'] = dfin_ranknet['startrank'] - 1\n",
    "    dfin_ranknet['endrank'] = dfin_ranknet['endrank'] - 1\n",
    "                \n",
    "    target_ranknet, tss_ranknet = long_predict_bymloutput_multirun('ranknet-rank', dfin_ranknet, sampleCnt=sampleCnt)                \n",
    "                \n",
    "    return target_ranknet, tss_ranknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## init predictor\n",
    "_predictor =  NaivePredictor(freq= freq, prediction_length = prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load ml models\n",
    "_trim = 0\n",
    "_include_final = True\n",
    "_include_stintlen = True\n",
    "#_include_stintlen = False\n",
    "include_str = '1' if _include_final else '0'\n",
    "stint_str = '1' if _include_stintlen else ''\n",
    "\n",
    "_plen=prediction_length\n",
    "\n",
    "#outfile=f'shortterm-dfout-mlmodels-indy500-tr2013_2017-te2018_2019-end{include_str}-rerank-t{_trim}.pickle'\n",
    "outfile=f'../result/22.PaperFinal/shortterm-dfout-mlmodels-indy500-tr2013_2017-te2018_2019-end{include_str}-rerank-t{_plen}.pickle'\n",
    "preddf = load_dfout(outfile)\n",
    "\n",
    "#outfile=f'shortterm-dfout-ranknet-indy500-tr2013_2017-te2018_2019-end{include_str}-normal-t{_trim}.pickle'\n",
    "#oracle_df = load_dfout(outfile)\n",
    "\n",
    "#ranknet\n",
    "#outfile='../result/22.PaperFinal/shortterm-dfout-ranknet-indy500-rank-inlap-nopitage-20182019-alldata.pickle'\n",
    "##outfile='shortterm-dfout-ranknet-indy500-rank-inlap-nopitage-20182019-alldata.pickle'\n",
    "#data = load_dfout(outfile)\n",
    "#ranknet_df, acc, ret = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carlist: [1, 3, 4, 6, 7, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 59, 60, 64, 66, 88, 98] len: 33\n"
     ]
    }
   ],
   "source": [
    "df = preddf['2018']['rf']\n",
    "carlist = set(list(df.carno.values))\n",
    "carlist = [int(x) for x in carlist]\n",
    "print('carlist:', carlist,'len:',len(carlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carlist=[10, 13, 30, 33]\n",
    "#carlist=[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Run models for carno= 1\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 3\n",
      "train len:0, test len:134, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=134, forecasts len=134\n",
      "11 144\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=134, forecasts len=134\n",
      "first start: 11 last start: 144\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 135)\n",
      "tss len=134, forecasts len=134\n",
      "first start: 11 last start: 144\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 135)\n",
      "tss len=134, forecasts len=134\n",
      "first start: 11 last start: 144\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 135)\n",
      "****************************************\n",
      "Run models for carno= 4\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 6\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 7\n",
      "train len:0, test len:181, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=181, forecasts len=181\n",
      "11 191\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=181, forecasts len=181\n",
      "first start: 11 last start: 191\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 182)\n",
      "tss len=181, forecasts len=181\n",
      "first start: 11 last start: 191\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 182)\n",
      "tss len=181, forecasts len=181\n",
      "first start: 11 last start: 191\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 182)\n",
      "****************************************\n",
      "Run models for carno= 9\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 10\n",
      "train len:0, test len:45, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=45, forecasts len=45\n",
      "11 55\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=45, forecasts len=45\n",
      "first start: 11 last start: 55\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 46)\n",
      "tss len=45, forecasts len=45\n",
      "first start: 11 last start: 55\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 46)\n",
      "tss len=45, forecasts len=45\n",
      "first start: 11 last start: 55\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 46)\n",
      "****************************************\n",
      "Run models for carno= 12\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 13\n",
      "train len:0, test len:55, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=55, forecasts len=55\n",
      "11 65\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=55, forecasts len=55\n",
      "first start: 11 last start: 65\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 56)\n",
      "tss len=55, forecasts len=55\n",
      "first start: 11 last start: 65\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 56)\n",
      "tss len=55, forecasts len=55\n",
      "first start: 11 last start: 65\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 56)\n",
      "****************************************\n",
      "Run models for carno= 14\n",
      "train len:0, test len:175, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=175, forecasts len=175\n",
      "11 185\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=175, forecasts len=175\n",
      "first start: 11 last start: 185\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 176)\n",
      "tss len=175, forecasts len=175\n",
      "first start: 11 last start: 185\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 176)\n",
      "tss len=175, forecasts len=175\n",
      "first start: 11 last start: 185\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 176)\n",
      "****************************************\n",
      "Run models for carno= 15\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 17\n",
      "train len:0, test len:187, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=187, forecasts len=187\n",
      "11 197\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=187, forecasts len=187\n",
      "first start: 11 last start: 197\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 188)\n",
      "tss len=187, forecasts len=187\n",
      "first start: 11 last start: 197\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 188)\n",
      "tss len=187, forecasts len=187\n",
      "first start: 11 last start: 197\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 188)\n",
      "****************************************\n",
      "Run models for carno= 18\n",
      "train len:0, test len:125, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=125, forecasts len=125\n",
      "11 135\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=125, forecasts len=125\n",
      "first start: 11 last start: 135\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 126)\n",
      "tss len=125, forecasts len=125\n",
      "first start: 11 last start: 135\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 126)\n",
      "tss len=125, forecasts len=125\n",
      "first start: 11 last start: 135\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 126)\n",
      "****************************************\n",
      "Run models for carno= 19\n",
      "train len:0, test len:187, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=187, forecasts len=187\n",
      "11 197\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=187, forecasts len=187\n",
      "first start: 11 last start: 197\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 188)\n",
      "tss len=187, forecasts len=187\n",
      "first start: 11 last start: 197\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 188)\n",
      "tss len=187, forecasts len=187\n",
      "first start: 11 last start: 197\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 188)\n",
      "****************************************\n",
      "Run models for carno= 20\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 21\n",
      "train len:0, test len:187, mae_track:0.0,mae_lap:0.0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss len=187, forecasts len=187\n",
      "11 197\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=187, forecasts len=187\n",
      "first start: 11 last start: 197\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 188)\n",
      "tss len=187, forecasts len=187\n",
      "first start: 11 last start: 197\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 188)\n",
      "tss len=187, forecasts len=187\n",
      "first start: 11 last start: 197\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 188)\n",
      "****************************************\n",
      "Run models for carno= 22\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 23\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 24\n",
      "train len:0, test len:142, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=142, forecasts len=142\n",
      "11 152\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=142, forecasts len=142\n",
      "first start: 11 last start: 152\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 143)\n",
      "tss len=142, forecasts len=142\n",
      "first start: 11 last start: 152\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 143)\n",
      "tss len=142, forecasts len=142\n",
      "first start: 11 last start: 152\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 143)\n",
      "****************************************\n",
      "Run models for carno= 25\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 26\n",
      "train len:0, test len:186, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=186, forecasts len=186\n",
      "11 196\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=186, forecasts len=186\n",
      "first start: 11 last start: 196\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 187)\n",
      "tss len=186, forecasts len=186\n",
      "first start: 11 last start: 196\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 187)\n",
      "tss len=186, forecasts len=186\n",
      "first start: 11 last start: 196\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 187)\n",
      "****************************************\n",
      "Run models for carno= 27\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 28\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 29\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 30\n",
      "train len:0, test len:34, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=34, forecasts len=34\n",
      "11 44\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=34, forecasts len=34\n",
      "first start: 11 last start: 44\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 35)\n",
      "tss len=34, forecasts len=34\n",
      "first start: 11 last start: 44\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 35)\n",
      "tss len=34, forecasts len=34\n",
      "first start: 11 last start: 44\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 35)\n",
      "****************************************\n",
      "Run models for carno= 32\n",
      "train len:0, test len:98, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=98, forecasts len=98\n",
      "11 108\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=98, forecasts len=98\n",
      "first start: 11 last start: 108\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 99)\n",
      "tss len=98, forecasts len=98\n",
      "first start: 11 last start: 108\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 99)\n",
      "tss len=98, forecasts len=98\n",
      "first start: 11 last start: 108\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 99)\n",
      "****************************************\n",
      "Run models for carno= 33\n",
      "train len:0, test len:34, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=34, forecasts len=34\n",
      "11 44\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=34, forecasts len=34\n",
      "first start: 11 last start: 44\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 35)\n",
      "tss len=34, forecasts len=34\n",
      "first start: 11 last start: 44\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 35)\n",
      "tss len=34, forecasts len=34\n",
      "first start: 11 last start: 44\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 35)\n",
      "****************************************\n",
      "Run models for carno= 59\n",
      "train len:0, test len:186, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=186, forecasts len=186\n",
      "11 196\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=186, forecasts len=186\n",
      "first start: 11 last start: 196\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 187)\n",
      "tss len=186, forecasts len=186\n",
      "first start: 11 last start: 196\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 187)\n",
      "tss len=186, forecasts len=186\n",
      "first start: 11 last start: 196\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 187)\n",
      "****************************************\n",
      "Run models for carno= 60\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 64\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 66\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 88\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "****************************************\n",
      "Run models for carno= 98\n",
      "train len:0, test len:188, mae_track:0.0,mae_lap:0.0,\n",
      "tss len=188, forecasts len=188\n",
      "11 198\n",
      "sampel# x predictlen:  100 2\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n",
      "tss len=188, forecasts len=188\n",
      "first start: 11 last start: 198\n",
      "sampel# x predictlen:  100 2\n",
      "target samples: (100, 189)\n"
     ]
    }
   ],
   "source": [
    "retdata = {}\n",
    "for carno in carlist:\n",
    "    print(\"*\"*40)\n",
    "    print('Run models for carno=', carno)\n",
    "    # create the test_ds first\n",
    "    test_cars = [carno]\n",
    "    \n",
    "    train_ds, test_ds, trainset, testset = ev.make_dataset_byevent(events_id[ev._test_event], prediction_length,freq, \n",
    "                                     oracle_mode=ev.MODE_ORACLE,\n",
    "                                     run_ts = ev._run_ts,\n",
    "                                     test_event = ev._test_event,\n",
    "                                     test_cars=test_cars,\n",
    "                                     half_moving_win = 0,\n",
    "                                     train_ratio = 0.01)\n",
    "    \n",
    "    if (len(testset) <= 10 + prediction_length):\n",
    "        print('ts too short, skip ', len(testset))\n",
    "        continue\n",
    "    \n",
    "    # run models\n",
    "    #arima\n",
    "    predictor =  RForecastPredictor(method_name='arima',freq= freq, \n",
    "                                                prediction_length = prediction_length,trunc_length=40)\n",
    "    target_arima, tss_arima = long_predict('arima-rank',predictor)\n",
    "\n",
    "    #xgb\n",
    "    df = preddf['2018']['xgb']\n",
    "    dfin_xgb = df[df['carno']==test_cars[0]]\n",
    "    target_xgb, tss_xgb = long_predict_bymloutput('xgb-rank', dfin_xgb)\n",
    "\n",
    "    #svr\n",
    "    df = preddf['2018']['svr']\n",
    "    dfin_svr = df[df['carno']==test_cars[0]]\n",
    "    target_svr, tss_svr = long_predict_bymloutput('svr-rank', dfin_svr)\n",
    "\n",
    "    #rf\n",
    "    df = preddf['2018']['rf']\n",
    "    dfin_rf = df[df['carno']==test_cars[0]]\n",
    "    target_rf, tss_rf = long_predict_bymloutput('rf-rank', dfin_rf)    \n",
    "    \n",
    "    retdata[carno] = [[tss_svr, tss_rf,tss_arima],\n",
    "                       [target_svr, target_rf,target_arima]]\n",
    "    \n",
    "alldata = retdata    \n",
    "#save predictions\n",
    "save_prefix = 'Fig3-' + ev._test_event + '-%dcars-l%d-mlmodels'%(len(carlist), _plen)\n",
    "save_data(save_prefix + '.pickle', retdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c6a2f74c8f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = oracle_ret['oracle-RANK-2018-inlap-nopitage'][0][0]\n",
    "df = df[df['carno']==12]\n",
    "df[(df['startlap']>90) & (df['startlap'] < 98)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = oracle_ret['oracle-RANK-2018-inlap-nopitage'][0][1][12]\n",
    "np.median(samples, axis=0)[90:108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(samples, axis=0)[90:108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2018'\n",
    "dfout = do_rerank(ranknetdf[year]['oracle_mean'])\n",
    "allsamples, alltss = get_allsamples(year=year, model='oracle')\n",
    "df = dfout[dfout['carno']==12]\n",
    "df[(df['startlap']>90) & (df['startlap'] < 98)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout = ranknetdf[year]['oracle_mean']\n",
    "df = dfout[dfout['carno']==12]\n",
    "df[(df['startlap']>90) & (df['startlap'] < 98)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(carlist)-set(list(retdata.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Fig3-Indy500-201898.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    alldata = pickle.load(f, encoding='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in retdata.keys():\n",
    "    alldata[k] = retdata[k]\n",
    "    \n",
    "save_data('Fig3-Indy500-2018-allcar.pickle', alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_target(target):\n",
    "    \"\"\"\n",
    "    nan at the end, remove them, and adjust the start_date\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    rec = target.samples[0,:]\n",
    "    nanCnt = np.sum(np.isnan(rec))\n",
    "    \n",
    "    if nanCnt > 1:\n",
    "        target.start_date = target.start_date + nanCnt\n",
    "        target.samples = target.samples[:,:-nanCnt]\n",
    "        \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotcar(carno):\n",
    "    #tss_arima, target_svr, target_rf,target_arima, target_oracle, target_ranknet_1run = savedata[carno]\n",
    "    tsss, targets = alldata[carno]\n",
    "    \n",
    "    #fix ranknet-mlp\n",
    "    #nt = fix_target(targets[-1])\n",
    "    #targets[-1] = nt\n",
    "    \n",
    "    plot_forecasts_h(tsss[:5], targets[:5],                    \n",
    "               'ranknet-rf-rank-forecast-%d'%carno,\n",
    "                   colors = ['y','c','g','m','r'],\n",
    "                   plabels= ['observed','SVR','RF','Arima','RrankNet-Oracle','RrankNet-MLP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotcar(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotcar(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotcar(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ploth(ts_entry, forecast_entry, outputfile='xx', \n",
    "                   colors = ['r','g','m'],\n",
    "                   plabels= ['observed','svr','arima','ranknet']):\n",
    "\n",
    "    \n",
    "    #prediction_intervals = (50.0, 90.0)\n",
    "    prediction_intervals = [90.0]\n",
    "    \n",
    "    #legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals]\n",
    "\n",
    "    figcnt = len(forecast_entry)\n",
    "    \n",
    "    #fig, axs = plt.subplots(figcnt,1, figsize=(8,6))\n",
    "    fig, axs = plt.subplots(1, figcnt, figsize=(12,3*figcnt))\n",
    "\n",
    "    #colors = ['r','g','m']\n",
    "    #plabels = ['observed','svr','arima','ranknet']\n",
    "    \n",
    "    for idx in range(figcnt):\n",
    "        ax = plt.subplot(figcnt, 1, idx+1)\n",
    "        \n",
    "        #plot_length = int(forecast_entry[idx].samples.shape[1] *1.2) \n",
    "        #ts_entry[idx].iloc[-plot_length:,0].plot(linewidth=1, color='b',\n",
    "        #                                    marker='*', alpha=0.7, zorder=-1, label=plabels[0]) \n",
    "        \n",
    "        ts_entry[idx].iloc[:,0].plot(linewidth=1, color='b',\n",
    "                                            marker='*', alpha=0.7, zorder=-1, label=plabels[0]) \n",
    "        \n",
    "    \n",
    "    \n",
    "        forecast_entry[idx].copy_dim(0).plot(prediction_intervals=prediction_intervals, \n",
    "                                             color=colors[idx],label=plabels[idx+1], zorder=10)\n",
    "        \n",
    "        ax.set_xlabel('Lap')\n",
    "        if idx==0:\n",
    "            ax.set_ylabel('Rank')\n",
    "    \n",
    "        ax.set_ylim((-5,+40))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss, target = alldata[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecasts_h(tss[:5],target[:5],\n",
    "           'test',\n",
    "               colors = ['y','c','g','m','r'],\n",
    "               plabels= ['observed','SVR','RF','Arima','RrankNet-Oracle','RrankNet-MLP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploth([tss[3]],[target[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploth([tss],[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt.samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploth([tss],[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Fig3-Indy500-2018-allcar.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    retdata = pickle.load(f, encoding='latin1') \n",
    "    \n",
    "tsss, targets = retdata[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsss, targets = alldata[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss2, target2 = tsss[4], targets[4]\n",
    "print('tss:', len(tss2), 'target:', target2.samples.shape, 'start:', target2.start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss2, target2 = tsss[3], targets[3]\n",
    "print('tss:', len(tss2), 'target:', target2.samples.shape, 'start:', target2.start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target2.samples[:,-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss, target = tsss[0], targets[0]\n",
    "print('tss:', len(tss), 'target:', target.samples.shape, 'start:', target.start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(target.samples[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.samples[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.samples[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss, target = tsss[-1], targets[-1]\n",
    "print('tss:', len(tss), 'target:', target.samples.shape, 'start:', target.start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.start_date - target2.start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retdata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcar=12\n",
    "samples = ret['pitmodel-RANK-2018-inlap-nopitage'][0][1][testcar]\n",
    "tss  = ret['pitmodel-RANK-2018-inlap-nopitage'][0][2][testcar]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.samples[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ranknet_1run, tss_ranknet_1run = long_predict_bysamples('ranknet-rank', samples, tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ranknet_1run.samples[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss13, target13 = retdata[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target13[-1].samples[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target13[-1].start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Fig3-Indy500-2018-allcar.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    retdata = pickle.load(f, encoding='latin1') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for carno in carlist:\n",
    "    tss13, target13 = retdata[carno]\n",
    "    nanCnt = np.sum(np.isnan(target13[-1].samples[0,:]))\n",
    "    nt = target13[-1].samples[:,:-nanCnt+1]\n",
    "    target13[-1].samples = nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target13[-1].samples[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss13, target13 = retdata[13]\n",
    "nanCnt = np.sum(np.isnan(target13[-1].samples[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nanCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = target13[-1].samples[:,-nanCnt-610:-nanCnt+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retdata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target13[-1].samples = nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target13[-1].samples[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retdata[13][1][-1].samples[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data('Fig3-Indy500-2018-allcar-fix.pickle', retdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target13[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = oracle_ret['oracle-RANK-2018-inlap-nopitage'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['carno']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preddf['2018']['svr']\n",
    "df[df['carno']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
