{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuickTest\n",
    "\n",
    "    makedb laptime\n",
    "    makedb gluonts\n",
    "    train model\n",
    "    evaluate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import random\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "import copy\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.model.prophet import ProphetPredictor\n",
    "from gluonts.model.r_forecast import RForecastPredictor\n",
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "from gluonts.distribution.neg_binomial import NegativeBinomialOutput\n",
    "from gluonts.distribution.student_t import StudentTOutput\n",
    "from gluonts.distribution.multivariate_gaussian import MultivariateGaussianOutput\n",
    "\n",
    "from indycar.model.NaivePredictor import NaivePredictor\n",
    "from indycar.model.deeparw import DeepARWeightEstimator\n",
    "\n",
    "import indycar.model.stint_simulator_shortterm_pitmodel as stint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make indy car completed_laps dataset\n",
    "# car_number, completed_laps, rank, elapsed_time, rank_diff, elapsed_time_diff \n",
    "def make_cl_data(dataset):\n",
    "\n",
    "    # pick up data with valid rank\n",
    "    rankdata = dataset.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "\n",
    "    # resort by car_number, lap\n",
    "    uni_ds = rankdata.sort_values(by=['car_number', 'completed_laps', 'elapsed_time'], ascending=True)    \n",
    "    #uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \"current_status\", \"track_status\", \"lap_status\",\n",
    "    #                  \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "    #                  \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "    \n",
    "    uni_ds = uni_ds.drop([\"unique_id\", \"best_lap\", \n",
    "                      \"laps_behind_leade\",\"laps_behind_prec\",\"overall_rank\",\"pit_stop_count\",\n",
    "                      \"last_pitted_lap\",\"start_position\",\"laps_led\"], axis=1)\n",
    "        \n",
    "    carnumber = set(uni_ds['car_number'])\n",
    "    print('cars:', carnumber)\n",
    "    print('#cars=', len(carnumber))\n",
    "   \n",
    "    # faster solution , uni_ds already sorted by car_number and lap\n",
    "    uni_ds['rank_diff'] = uni_ds['rank'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['rank_diff'][mask] = 0\n",
    "    \n",
    "    uni_ds['time_diff'] = uni_ds['elapsed_time'].diff()\n",
    "    mask = uni_ds.car_number != uni_ds.car_number.shift(1)\n",
    "    uni_ds['time_diff'][mask] = 0\n",
    "    \n",
    "    #df = uni_ds[['car_number','completed_laps','rank','elapsed_time','rank_diff','time_diff']]\n",
    "    #df = uni_ds[['car_number','completed_laps','rank',\n",
    "    #             'rank_diff','time_diff',\"current_status\", \"track_status\", \"lap_status\",'elapsed_time']]\n",
    "    \n",
    "    df = uni_ds[['car_number','completed_laps','time_diff','rank','track_status', 'lap_status','elapsed_time']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def make_lapstatus_data(dataset):\n",
    "    final_lap = max(dataset.completed_laps)\n",
    "    total_laps = final_lap + 1\n",
    "\n",
    "    # get records for the cars that finish the race\n",
    "    completed_car_numbers= dataset[dataset.completed_laps == final_lap].car_number.values\n",
    "    completed_car_count = len(completed_car_numbers)\n",
    "\n",
    "    print('count of completed cars:', completed_car_count)\n",
    "    print('completed cars:', completed_car_numbers)\n",
    "    \n",
    "    #pick up one of them\n",
    "    onecar = dataset[dataset['car_number']==completed_car_numbers[0]]\n",
    "    onecar = onecar.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "    return onecar[['completed_laps','track_status']]\n",
    "\n",
    "def load_data(event, year=0):\n",
    "    #inputfile = '../data/final/C_'+ event +'-' + year + '-final.csv'\n",
    "    if year>0:\n",
    "        inputfile = '../data/final/C_'+ event +'-' + year + '.csv'\n",
    "    else:\n",
    "        inputfile = '../data/final/C_'+ event +'.csv'\n",
    "    \n",
    "    #outputprefix = year +'-' + event + '-'\n",
    "    dataset = pd.read_csv(inputfile)\n",
    "    #dataset.info(verbose=True)    \n",
    "    \n",
    "    final_lap = max(dataset.completed_laps)\n",
    "    total_laps = final_lap + 1\n",
    "\n",
    "    # get records for the cars that finish the race\n",
    "    completed_car_numbers= dataset[dataset.completed_laps == final_lap].car_number.values\n",
    "    completed_car_count = len(completed_car_numbers)\n",
    "\n",
    "    print('count of completed cars:', completed_car_count)\n",
    "    print('completed cars:', completed_car_numbers)\n",
    "\n",
    "    #make a copy\n",
    "    alldata = dataset.copy()\n",
    "    dataset = dataset[dataset['car_number'].isin(completed_car_numbers)]\n",
    "    rankdata = alldata.rename_axis('MyIdx').sort_values(by=['elapsed_time','MyIdx'], ascending=True)\n",
    "    rankdata = rankdata.drop_duplicates(subset=['car_number', 'completed_laps'], keep='first')\n",
    "    \n",
    "    cldata = make_cl_data(dataset)\n",
    "    flagdata = make_lapstatus_data(dataset)\n",
    "    acldata = make_cl_data(alldata)\n",
    "\n",
    "    return alldata, rankdata, acldata, flagdata\n",
    "\n",
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def get_lap2nextpit(lap_status, maxlap=200):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        lapstatus  ; array of 0/1 indicating pitstops for each lap, nan means incomplete race\n",
    "        maxlap     ; the max lap number of the race\n",
    "    output:\n",
    "        lap2nextpit ; array of the lap gap to the next pit for each lap\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #pitstops = np.where(lap_status==1)[0]\n",
    "                    \n",
    "    pitstops = list(np.where(lap_status==1)[0])\n",
    "    #if not len(lap_status) < maxlap:\n",
    "    nans, x= nan_helper(lap_status)\n",
    "    nan_count = np.sum(nans)      \n",
    "    if nan_count == 0:\n",
    "        #complete cars\n",
    "        # the last stint, to the end\n",
    "        pitstops.append(maxlap)\n",
    "    \n",
    "    lap2nextpit = np.zeros_like(lap_status)\n",
    "    lap2nextpit[:] = np.nan\n",
    "    \n",
    "    #guard\n",
    "    if len(pitstops)==0:\n",
    "        return lap2nextpit\n",
    "    \n",
    "    idx = 0\n",
    "    for lap in range(len(lap_status)):\n",
    "        if lap < pitstops[idx]:\n",
    "            lap2nextpit[lap] = pitstops[idx] - lap\n",
    "        else:\n",
    "            idx += 1\n",
    "            if idx < len(pitstops):\n",
    "                lap2nextpit[lap] = pitstops[idx] - lap\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "    return lap2nextpit\n",
    "\n",
    "def get_lapdata(acldata):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        acldata['car_number','completed_laps','time_diff','rank','track_status', 'lap_status','elapsed_time']\n",
    "    \n",
    "        timediff: [car_number, completed_laps] -> elapsed time diff to leader\n",
    "    output:\n",
    "        lapdata = acldata[['car_number','completed_laps',\n",
    "                           'time_diff','rank','track_status', 'lap_status','time_behind']].to_numpy()\n",
    "    \"\"\"\n",
    "    COL_COMPLETED_LAPS = 1\n",
    "    COL_ELAPSED_TIME = 6\n",
    "    \n",
    "    maxlap = np.max(acldata['completed_laps'].values)\n",
    "    #'car_number','completed_laps','time_diff','rank','track_status', 'lap_status','time_behind'\n",
    "    time_behind = []\n",
    "    \n",
    "    for lap in range(1, maxlap+1):\n",
    "        this_lap = acldata[acldata['completed_laps']==lap][\n",
    "            ['car_number','completed_laps','time_diff','rank',\n",
    "             'track_status', 'lap_status','elapsed_time']].values\n",
    "        \n",
    "        min_elapsed_time = np.nanmin(this_lap[:,COL_ELAPSED_TIME].astype(np.float))\n",
    "        #print(f'lap:{lap}, min_elapsed_time:{min_elapsed_time}')\n",
    "        \n",
    "        for row in this_lap:\n",
    "            car_number = int(row[0])\n",
    "            time_diff = row[2]\n",
    "            rank = row[3]\n",
    "            track_status = row[4]\n",
    "            lap_status = row[5]\n",
    "            \n",
    "            timebehind = float(row[COL_ELAPSED_TIME]) - min_elapsed_time\n",
    "            #\n",
    "            time_behind.append([car_number, lap, time_diff,rank,track_status, lap_status,\n",
    "                                timebehind, float(row[COL_ELAPSED_TIME])])\n",
    "    \n",
    "    #return\n",
    "    lapdata = np.array(time_behind)\n",
    "    return lapdata\n",
    "\n",
    "\n",
    "\n",
    "# features: laptime, rank, track_status, lap_status, timediff\n",
    "LAPTIME = 0\n",
    "RANK = 1\n",
    "TRACK_STATUS = 2\n",
    "LAP_STATUS = 3\n",
    "TIME_BEHIND = 4\n",
    "CAUTION_LAPS_INSTINT = 5 \n",
    "LAPS_INSTINT = 6\n",
    "ELAPSED_TIME = 7\n",
    "LAP2NEXTPIT = 8\n",
    "\n",
    "_featureCnt = 9\n",
    "        \n",
    "def get_laptime_dataset(stagedata, inlap_status = 0):\n",
    "    \"\"\"\n",
    "    #add caution_laps_instint, laps_instint\n",
    "    \n",
    "    input: (alldata, rankdata, acldata, flagdata)\n",
    "    output: laptime & rank data\n",
    "    \n",
    "    [(\n",
    "    eventid,\n",
    "    carids : rowid -> carno,\n",
    "    datalist: #car_number x features x #totallaps (padded by Nan)\n",
    "        entry: [[laptime, rank, track_status, lap_status,\n",
    "                caution_laps_instint, laps_instint]]\n",
    "    )]\n",
    "    \"\"\"\n",
    "    laptime_data = []\n",
    "    for event in stagedata.keys():\n",
    "        \n",
    "        print(f'start event: {event}')\n",
    "        \n",
    "        laptime_rec = []\n",
    "        eventid = events_id[event]\n",
    "        \n",
    "        alldata, rankdata, acldata, flagdata = stagedata[event]\n",
    "        carlist = set(acldata['car_number'])\n",
    "        laplist = set(acldata['completed_laps'])\n",
    "        totalcars = len(carlist)\n",
    "        totallaps = len(laplist)\n",
    "        \n",
    "\n",
    "\n",
    "        #carnumber -> carid\n",
    "        carids={key:idx for idx, key in enumerate(carlist)}\n",
    "        decode_carids={idx:key for idx, key in enumerate(carlist)}\n",
    "\n",
    "        #init\n",
    "        lap_instint = {carids[x]:0 for x in carlist}\n",
    "        caution_instint = {carids[x]:0 for x in carlist}        \n",
    "        \n",
    "        #array: car_number x lap\n",
    "        #laptime = np.zeros((totalcars, totallaps-1))\n",
    "        #rank = np.zeros((totalcars, totallaps-1))\n",
    "        laptime = np.empty((totalcars, totallaps-1))\n",
    "        rank = np.empty((totalcars, totallaps-1))\n",
    "        laptime[:] = np.NaN\n",
    "        rank[:] = np.NaN\n",
    "        \n",
    "\n",
    "        datalist = np.empty((totalcars, _featureCnt, totallaps-1))\n",
    "        datalist[:] = np.NaN\n",
    "        \n",
    "        #lapdata = acldata[['car_number','completed_laps',\n",
    "        #                   'time_diff','rank','track_status', 'lap_status','elapsed_time']].to_numpy()\n",
    "        \n",
    "        #'car_number','completed_laps','time_diff','rank','track_status', 'lap_status','time_behind'\n",
    "        lapdata = get_lapdata(acldata)\n",
    "        \n",
    "        \n",
    "        for row in lapdata:\n",
    "            #completed_laps\n",
    "            if int(row[1]) == 0:\n",
    "                continue\n",
    "                \n",
    "            #add to data array\n",
    "            car_number = carids[int(row[0])]\n",
    "            completed_laps = int(row[1])-1\n",
    "            time_diff = float(row[2])\n",
    "            rank = int(row[3])\n",
    "            track_status = 1 if row[4]=='Y' else 0\n",
    "            lap_status = 1 if row[5]=='P' else 0\n",
    "            time_behind = float(row[6])\n",
    "            \n",
    "            datalist[car_number, LAPTIME, completed_laps] = time_diff\n",
    "            datalist[car_number, RANK, completed_laps] = rank\n",
    "            datalist[car_number, TRACK_STATUS, completed_laps] = track_status\n",
    "            datalist[car_number, LAP_STATUS, completed_laps] = lap_status\n",
    "            datalist[car_number, TIME_BEHIND, completed_laps] = time_behind\n",
    "\n",
    "            datalist[car_number, ELAPSED_TIME, completed_laps] = float(row[7])\n",
    "\n",
    "            \n",
    "            #stint status\n",
    "            if track_status == 1:\n",
    "                caution_instint[car_number] += 1\n",
    "            lap_instint[car_number] += 1\n",
    "            if lap_status == 1:\n",
    "                #new stint\n",
    "                lap_instint[car_number] = 0\n",
    "                caution_instint[car_number] = 0\n",
    "                \n",
    "                # add inlap feature into lap_Status\n",
    "                # set the previous lap to inlap status\n",
    "                \n",
    "                # what does it mean?\n",
    "                \n",
    "                if (inlap_status!=0):\n",
    "                    if inlap_status == 1:\n",
    "                        # set the previous lap of 'P'\n",
    "                        if completed_laps > 0:\n",
    "                            #datalist[car_number, LAP_STATUS, completed_laps-1] = INLAP_STATUS\n",
    "                            datalist[car_number, LAP_STATUS, completed_laps-1] = 1\n",
    "                    else:\n",
    "                        # set the next lap of 'P'\n",
    "                        if completed_laps +1 < totallaps:\n",
    "                            #datalist[car_number, LAP_STATUS, completed_laps-1] = INLAP_STATUS\n",
    "                            datalist[car_number, LAP_STATUS, completed_laps + 1] = 1\n",
    "                \n",
    "            \n",
    "            datalist[car_number, LAPS_INSTINT, completed_laps] = lap_instint[car_number]\n",
    "            datalist[car_number, CAUTION_LAPS_INSTINT, completed_laps] = caution_instint[car_number]\n",
    "                \n",
    "\n",
    "                \n",
    "        #update lap2nextpit in datalist\n",
    "        for caridx in range(datalist.shape[0]):\n",
    "            lap_status = datalist[caridx, LAP_STATUS, :]\n",
    "            #pit status\n",
    "            lap2nextpit = get_lap2nextpit(lap_status)\n",
    "            datalist[caridx, LAP2NEXTPIT, :] = lap2nextpit        \n",
    "                \n",
    "        #add one record\n",
    "        laptime_data.append([eventid, decode_carids, datalist])\n",
    "        # push this event into stage dataframe\n",
    "        print('event=%s, records=%s'%(event, datalist.shape))\n",
    "        \n",
    "    \n",
    "    return laptime_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_flag(a, bitflag):\n",
    "    return (a & bitflag) ==  bitflag\n",
    "\n",
    "#\n",
    "# remove NaN at the tail\n",
    "# there should be no nans in the middle of the ts\n",
    "COL_LAPTIME=0\n",
    "COL_RANK=1\n",
    "COL_TRACKSTATUS=2\n",
    "COL_LAPSTATUS=3\n",
    "COL_TIMEDIFF=4\n",
    "COL_CAUTION_LAPS_INSTINT=5\n",
    "COL_LAPS_INSTINT= 6\n",
    "COL_ELAPSED_TIME= 7\n",
    "\n",
    "FEATURE_STATUS = 2\n",
    "FEATURE_PITAGE = 4\n",
    "\n",
    "MODE_ORACLE = 0\n",
    "MODE_NOLAP = 1\n",
    "MODE_NOTRACK = 2\n",
    "MODE_TESTZERO = 4\n",
    "MODE_TESTCURTRACK = 8\n",
    "#MODE_STR={MODE_ORACLE:'oracle', MODE_NOLAP:'nolap',MODE_NOTRACK:'notrack',MODE_TEST:'test'}\n",
    "\n",
    "#_feature_mode = FEATURE_STATUS\n",
    "\n",
    "def make_dataset_byevent(runs, prediction_length, freq, \n",
    "                       useeid = False,\n",
    "                       run_ts=COL_LAPTIME, \n",
    "                       test_event = 'Indy500-2018',\n",
    "                       use_global_dict = True,\n",
    "                       oracle_mode = MODE_ORACLE,\n",
    "                       half_moving_win = True,\n",
    "                       train_ratio=0.8,\n",
    "                       log_transform = False,\n",
    "                       context_ratio = 0.,\n",
    "                       dorerank = True\n",
    "                ):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    oracle_mode: false to simulate prediction in real by \n",
    "        set the covariates of track and lap status as nan in the testset\n",
    "            \n",
    "    \n",
    "    \"\"\"    \n",
    "    #global setting\n",
    "    feature_mode = _feature_mode\n",
    "    \n",
    "    \n",
    "    start = pd.Timestamp(\"01-01-2019\", freq=freq)  # can be different for each time series\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #select run\n",
    "    if runs>=0:\n",
    "        _laptime_data = [laptime_data[runs].copy()]\n",
    "    else:\n",
    "        _laptime_data = laptime_data.copy()\n",
    "    \n",
    "    totalTSCnt = 0\n",
    "    totalTSLen = 0\n",
    "    test_eventid = events_id[test_event]\n",
    "    \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        #skip eid > test_eventid\n",
    "        if _data[0] > test_eventid:\n",
    "            print('skip this event:', events[_data[0]])\n",
    "            break\n",
    "        \n",
    "        if events[_data[0]] == test_event:\n",
    "            test_mode = True\n",
    "        \n",
    "        else:\n",
    "            test_mode = False\n",
    "            \n",
    "        \n",
    "        \n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        if train_len == 0:\n",
    "            #use global train_len\n",
    "            train_len = _train_len\n",
    "        \n",
    "        if context_ratio != 0.:\n",
    "            # add this part to train set\n",
    "            context_len = int(np.max(ts_len) * context_ratio)\n",
    "        else:    \n",
    "            context_len = prediction_length*2\n",
    "        if context_len < 10:\n",
    "            context_len = 10\n",
    "        \n",
    "        print(f'====event:{events[_data[0]]}, prediction_len={prediction_length},train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)},context_len={context_len}')\n",
    "\n",
    "        #rerank due to short ts removed\n",
    "        if run_ts == COL_RANK and dorerank == True:\n",
    "            sel_rows = []\n",
    "            for rowid in range(_data[2].shape[0]):\n",
    "                # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "                rec = _data[2][rowid].copy()\n",
    "                #remove nan(only tails)\n",
    "                nans, x= nan_helper(rec[run_ts,:])\n",
    "                nan_count = np.sum(nans)             \n",
    "                rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "                \n",
    "                totallen = rec.shape[1]\n",
    "                if ( totallen < train_len + prediction_length):\n",
    "                    print(f'rerank a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                    continue \n",
    "                else:\n",
    "                    sel_rows.append(rowid)\n",
    "                    \n",
    "            #get selected matrix\n",
    "            sel_idx = np.array(sel_rows)\n",
    "            selmat = _data[2][sel_idx]\n",
    "            \n",
    "            mask = np.isnan(selmat[:,COL_RANK,:])\n",
    "            \n",
    "            idx = np.argsort(selmat[:,COL_RANK,:], axis=0)\n",
    "            true_rank = np.argsort(idx, axis=0).astype(np.float)\n",
    "            true_rank[mask] = np.nan\n",
    "            \n",
    "            #set it back\n",
    "            #if _data[0]==0:\n",
    "            #    print('raw:')\n",
    "            #    print(_data[2][:,COL_RANK,0])\n",
    "            #    print('true_rank:')\n",
    "            #    print(true_rank[:,0])\n",
    "            #_data[2][sel_idx][:,COL_RANK,:] = true_rank       \n",
    "            _data[2][sel_idx,COL_RANK,:] = true_rank       \n",
    "            #if _data[0]==0:\n",
    "            #    _view = _data[2][sel_idx]\n",
    "            #    _view[:,COL_RANK,:] = true_rank\n",
    "            #    print('view:')\n",
    "            #    print(_data[2][:,COL_RANK,0])\n",
    "            #    print(_view[:,COL_RANK,0])\n",
    "            #    print('rerank:')\n",
    "            #    print(_data[2][sel_idx][:,COL_RANK,0])\n",
    "        \n",
    "        \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            \n",
    "            totalTSCnt += 1\n",
    "            totalTSLen += totallen\n",
    "            \n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                print(f'a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                continue                \n",
    "            \n",
    "            if use_global_dict:\n",
    "                carno = _data[1][rowid]\n",
    "                carid = global_carids[_data[1][rowid]]\n",
    "            else:\n",
    "                #simulation dataset, todo, fix the carids as decoder\n",
    "                carno = rowid\n",
    "                carid = rowid\n",
    "                \n",
    "            \n",
    "            if useeid:\n",
    "                static_cat = [carid, _data[0]]    \n",
    "            else:\n",
    "                static_cat = [carid]    \n",
    "                \n",
    "            #first, get target a copy    \n",
    "            # target can be COL_XXSTATUS\n",
    "            target_val = rec[run_ts,:].copy().astype(np.float32)\n",
    "            if log_transform:\n",
    "                target_val = np.log(target_val + 1.0)\n",
    "            \n",
    "            # selection of features\n",
    "            if test_flag(oracle_mode, MODE_NOTRACK):                \n",
    "                rec[COL_TRACKSTATUS, :] = 0\n",
    "            if test_flag(oracle_mode, MODE_NOLAP):                \n",
    "                rec[COL_LAPSTATUS, :] = 0\n",
    "\n",
    "            test_rec_cnt = 0\n",
    "            if not test_mode:\n",
    "                if feature_mode == FEATURE_PITAGE:  \n",
    "                    # all go to train set\n",
    "                    _train.append({'target': target_val, \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [rec[COL_TRACKSTATUS,:],\n",
    "                                       rec[COL_LAPSTATUS,:],\n",
    "                                       rec[COL_LAPS_INSTINT,:]]\n",
    "                              }\n",
    "                              )\n",
    "                else:\n",
    "                    # all go to train set\n",
    "                    _train.append({'target': target_val, \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [rec[COL_TRACKSTATUS,:],\n",
    "                                       rec[COL_LAPSTATUS,:]]\n",
    "                              }\n",
    "                              )\n",
    "                    \n",
    "            else:\n",
    "                # reset train_len\n",
    "                if context_ratio != 0.:\n",
    "                    # all go to train set\n",
    "                    #add [0, context_len] to train set \n",
    "                    if feature_mode == FEATURE_PITAGE:  \n",
    "                        _train.append({'target': target_val[:context_len], \n",
    "                                    'start': start, \n",
    "                                    'feat_static_cat': static_cat,\n",
    "                                    'feat_dynamic_real': [rec[COL_TRACKSTATUS,:context_len],\n",
    "                                           rec[COL_LAPSTATUS,:context_len],\n",
    "                                           rec[COL_LAPS_INSTINT,:context_len]               \n",
    "                                                         ]\n",
    "                                  }\n",
    "                                  )                    \n",
    "                    else:\n",
    "                        _train.append({'target': target_val[:context_len], \n",
    "                                    'start': start, \n",
    "                                    'feat_static_cat': static_cat,\n",
    "                                    'feat_dynamic_real': [rec[COL_TRACKSTATUS,:context_len],\n",
    "                                           rec[COL_LAPSTATUS,:context_len]               \n",
    "                                                         ]\n",
    "                                  }\n",
    "                                  )                    \n",
    "                \n",
    "                # testset\n",
    "                # multiple test ts(rolling window as half of the prediction_length)\n",
    "\n",
    "                step = -int(prediction_length/2) if half_moving_win else -prediction_length\n",
    "                for endpos in range(totallen, context_len+prediction_length, \n",
    "                                    step):\n",
    "\n",
    "                    track_rec = rec[COL_TRACKSTATUS, :endpos].copy()\n",
    "                    lap_rec = rec[COL_LAPSTATUS, :endpos].copy()\n",
    "                    pitage_rec = rec[COL_LAPS_INSTINT, :endpos].copy()\n",
    "\n",
    "                    # test mode\n",
    "                    if test_flag(oracle_mode, MODE_TESTCURTRACK):\n",
    "                        # since nan does not work, use cur-val instead\n",
    "                        track_rec[-prediction_length:] = track_rec[-prediction_length - 1]\n",
    "                        #track_rec[-prediction_length:] = random.randint(0,1)\n",
    "                        #lap_rec[-prediction_length:] = lap_rec[-prediction_length - 1]\n",
    "                        lap_rec[-prediction_length:] = 0\n",
    "\n",
    "                        #for pitage, just assume there is no pit\n",
    "                        start_pitage = pitage_rec[-prediction_length - 1]\n",
    "                        pitage_rec[-prediction_length:] = np.array([x+start_pitage+1 for x in range(prediction_length)])\n",
    "\n",
    "                    elif test_flag(oracle_mode, MODE_TESTZERO):\n",
    "                        #set prediction part as nan\n",
    "                        #track_rec[-prediction_length:] = np.nan\n",
    "                        #lap_rec[-prediction_length:] = np.nan\n",
    "                        track_rec[-prediction_length:] = 0\n",
    "                        lap_rec[-prediction_length:] = 0                    \n",
    "\n",
    "                        #for pitage, just assume there is no pit\n",
    "                        start_pitage = pitage_rec[-prediction_length - 1]\n",
    "                        pitage_rec[-prediction_length:] = np.array([x+start_pitage+1 for x in range(prediction_length)])\n",
    "\n",
    "                    if feature_mode == FEATURE_PITAGE:                          \n",
    "                        _test.append({'target': rec[run_ts,:endpos].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [track_rec,lap_rec,pitage_rec]\n",
    "                                #'feat_dynamic_real': [rec[COL_TRACKSTATUS,:endpos],\n",
    "                                #       rec[COL_LAPSTATUS,:endpos]] \n",
    "                                 }\n",
    "                              )                     \n",
    "                    else:\n",
    "                        _test.append({'target': rec[run_ts,:endpos].astype(np.float32), \n",
    "                                'start': start, \n",
    "                                'feat_static_cat': static_cat,\n",
    "                                'feat_dynamic_real': [track_rec,lap_rec]\n",
    "                                #'feat_dynamic_real': [rec[COL_TRACKSTATUS,:endpos],\n",
    "                                #       rec[COL_LAPSTATUS,:endpos]] \n",
    "                                 }\n",
    "                              )                     \n",
    "                        \n",
    "   \n",
    "                    test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'train len:{len(train_set)}, test len:{len(test_set)}, totsl TsCnt:{totalTSCnt}, total ts len:{totalTSLen}')\n",
    "    \n",
    "    train_ds = ListDataset(train_set, freq=freq)\n",
    "    test_ds = ListDataset(test_set, freq=freq)    \n",
    "    \n",
    "    return train_ds, test_ds, train_set, test_set\n",
    "\n",
    "def makedbs():\n",
    "    useeid = False\n",
    "    interpolate = False\n",
    "    #ipstr = '-ip' if interpolate else '-noip'\n",
    "    ipstr = '%s-%s'%('ip' if interpolate else 'noip', 'eid' if useeid else 'noeid')\n",
    "    if useeid:\n",
    "        cardinality = [len(global_carids), len(laptime_data)]\n",
    "    else:\n",
    "        cardinality = [len(global_carids)]\n",
    "\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(-1, prediction_length,freq,\n",
    "                                         useeid=useeid, run_ts=_run_ts,\n",
    "                                        test_event=_test_event, log_transform =False,\n",
    "                                        context_ratio=0, train_ratio = 0, dorerank =True)\n",
    "    \n",
    "    dbname = f'{_task_id}-oracle-{ipstr}-all-all-f{freq}-t{prediction_length}-r{_test_event}-gluonts-indy-2018.pickle'\n",
    "    #save_dataset(dbname, freq, prediction_length, cardinality,train_ds, test_ds)  \n",
    "    with open(dbname, 'wb') as f:\n",
    "        #pack [global_carids, laptime_data]\n",
    "        savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "        #savedata = [freq, train_set, test_set]\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    \n",
    "    return dbname, train_ds, test_ds\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_estimator(model, gpuid, epochs=100, batch_size = 32, \n",
    "        target_dim = 3, distr_output = None, use_feat_static = True):\n",
    "    \n",
    "    if int(gpuid) < 0:\n",
    "        ctx = \"cpu\"\n",
    "    else:\n",
    "        ctx = \"gpu(%s)\"%gpuid\n",
    "\n",
    "    if model == 'deepAR':\n",
    "        estimator = DeepAREstimator(\n",
    "            prediction_length=prediction_length,\n",
    "            context_length= context_length,\n",
    "            use_feat_static_cat=True,\n",
    "            cardinality=cardinality,\n",
    "            distr_output = distr_output,\n",
    "            freq=freq,\n",
    "            trainer=Trainer(ctx=ctx, \n",
    "                            batch_size = batch_size,\n",
    "                            epochs=epochs, \n",
    "                            learning_rate=1e-3, \n",
    "                            num_batches_per_epoch=100\n",
    "                           )\n",
    "        )\n",
    "    elif model == 'deepARW':\n",
    "        estimator = DeepARWEstimator(\n",
    "            prediction_length=prediction_length,\n",
    "            context_length= context_length,\n",
    "            use_feat_static_cat=True,\n",
    "            cardinality=cardinality,\n",
    "            distr_output = distr_output,\n",
    "            freq=freq,\n",
    "            trainer=Trainer(ctx=ctx, \n",
    "                            batch_size = batch_size,\n",
    "                            epochs=epochs, \n",
    "                            learning_rate=1e-3, \n",
    "                            num_batches_per_epoch=100\n",
    "                           )\n",
    "        )\n",
    "        \n",
    "    elif model == 'deepAR-Oracle':\n",
    "\n",
    "        if use_feat_static:\n",
    "            estimator = DeepAREstimator(\n",
    "                prediction_length=prediction_length,\n",
    "                context_length= context_length,\n",
    "                use_feat_static_cat=use_feat_static,\n",
    "                cardinality=cardinality,\n",
    "                use_feat_dynamic_real=True,\n",
    "                distr_output = distr_output,\n",
    "                freq=freq,\n",
    "                trainer=Trainer(ctx=ctx, \n",
    "                                batch_size = batch_size,\n",
    "                                epochs=epochs, \n",
    "                                learning_rate=1e-3, \n",
    "                                num_batches_per_epoch=100\n",
    "                               )\n",
    "                )\n",
    "        else:\n",
    "            estimator = DeepAREstimator(\n",
    "                prediction_length=prediction_length,\n",
    "                context_length= context_length,\n",
    "                use_feat_static_cat=use_feat_static,\n",
    "                #cardinality=cardinality,\n",
    "                use_feat_dynamic_real=True,\n",
    "                distr_output = distr_output,\n",
    "                freq=freq,\n",
    "                trainer=Trainer(ctx=ctx, \n",
    "                                batch_size = batch_size,\n",
    "                                epochs=epochs, \n",
    "                                learning_rate=1e-3, \n",
    "                                num_batches_per_epoch=100\n",
    "                               )\n",
    "                )\n",
    "    elif model == 'deepARW-Oracle':\n",
    "\n",
    "        if use_feat_static:\n",
    "            estimator = DeepARWeightEstimator(\n",
    "                prediction_length=prediction_length,\n",
    "                context_length= context_length,\n",
    "                use_feat_static_cat=use_feat_static,\n",
    "                cardinality=cardinality,\n",
    "                use_feat_dynamic_real=True,\n",
    "                distr_output = distr_output,\n",
    "                freq=freq,\n",
    "                trainer=Trainer(ctx=ctx, \n",
    "                                batch_size = batch_size,\n",
    "                                epochs=epochs, \n",
    "                                learning_rate=1e-3, \n",
    "                                #hybridize=False,\n",
    "                                num_batches_per_epoch=100\n",
    "                               )\n",
    "                )\n",
    "        else:\n",
    "            estimator = DeepARWeightEstimator(\n",
    "                prediction_length=prediction_length,\n",
    "                context_length= context_length,\n",
    "                use_feat_static_cat=use_feat_static,\n",
    "                #cardinality=cardinality,\n",
    "                use_feat_dynamic_real=True,\n",
    "                distr_output = distr_output,\n",
    "                freq=freq,\n",
    "                trainer=Trainer(ctx=ctx, \n",
    "                                batch_size = batch_size,\n",
    "                                epochs=epochs, \n",
    "                                learning_rate=1e-3, \n",
    "                                #hybridize=False,\n",
    "                                num_batches_per_epoch=100\n",
    "                               )\n",
    "                )\n",
    "            \n",
    "    elif model == 'deepAR-nocarid':\n",
    "        estimator = DeepAREstimator(\n",
    "            prediction_length=prediction_length,\n",
    "            context_length= context_length,\n",
    "            use_feat_static_cat=use_feat_static,\n",
    "            cardinality=cardinality,\n",
    "            use_feat_dynamic_real=True,\n",
    "            distr_output = distr_output,\n",
    "            freq=freq,\n",
    "            trainer=Trainer(ctx=ctx, \n",
    "                            batch_size = batch_size,\n",
    "                            epochs=epochs, \n",
    "                            learning_rate=1e-3, \n",
    "                            num_batches_per_epoch=100\n",
    "                           )\n",
    "        )\n",
    "    elif model == 'deepAR-multi':\n",
    "        estimator = DeepAREstimator(\n",
    "            prediction_length=prediction_length,\n",
    "            context_length= context_length,\n",
    "            use_feat_static_cat=use_feat_static,\n",
    "            #cardinality=cardinality,\n",
    "            use_feat_dynamic_real=True,\n",
    "            freq=freq,\n",
    "            trainer=Trainer(ctx=ctx, \n",
    "                            batch_size = batch_size,\n",
    "                            epochs=epochs, \n",
    "                            learning_rate=1e-3, \n",
    "                            num_batches_per_epoch=100\n",
    "                           ),\n",
    "            distr_output=MultivariateGaussianOutput(dim=target_dim),\n",
    "        )\n",
    "\n",
    "\n",
    "    elif model == 'simpleFF':\n",
    "        estimator = SimpleFeedForwardEstimator(\n",
    "            num_hidden_dimensions=[10],\n",
    "            prediction_length=prediction_length,\n",
    "            context_length= context_length,\n",
    "            freq=freq,\n",
    "            trainer=Trainer(ctx=ctx, \n",
    "                            batch_size = batch_size,\n",
    "                            epochs=epochs,\n",
    "                            learning_rate=1e-3,\n",
    "                            hybridize=False,\n",
    "                            num_batches_per_epoch=100\n",
    "                           )\n",
    "        )\n",
    "    elif model == 'deepFactor':\n",
    "        estimator = DeepFactorEstimator(\n",
    "            prediction_length=prediction_length,\n",
    "            context_length= context_length,\n",
    "            freq=freq,\n",
    "            trainer=Trainer(ctx=ctx, \n",
    "                            batch_size = batch_size,\n",
    "                            epochs=epochs, \n",
    "                            learning_rate=1e-3, \n",
    "                            num_batches_per_epoch=100\n",
    "                           )\n",
    "        )\n",
    "    elif model == 'deepState':\n",
    "        estimator = DeepStateEstimator(\n",
    "            prediction_length=prediction_length,\n",
    "            use_feat_static_cat=True,\n",
    "            cardinality=cardinality,\n",
    "            freq=freq,\n",
    "            trainer=Trainer(ctx=ctx, \n",
    "                            batch_size = batch_size,\n",
    "                            epochs=epochs, \n",
    "                            learning_rate=1e-3, \n",
    "                            num_batches_per_epoch=100\n",
    "                           )\n",
    "        )\n",
    "    elif model == 'ets':\n",
    "        estimator = RForecastPredictor(method_name='ets',freq= freq, prediction_length = prediction_length)\n",
    "    elif model == 'prophet':\n",
    "\n",
    "        estimator = ProphetPredictor(freq= freq, prediction_length = prediction_length)\n",
    "    elif model == 'arima':\n",
    "        estimator = RForecastPredictor(method_name='arima',freq= freq, prediction_length = prediction_length, trunc_length = 200)\n",
    "    elif model == 'naive':\n",
    "        estimator = NaivePredictor(freq= freq, prediction_length = prediction_length)\n",
    "    else:\n",
    "        logger.error('model %s not support yet, quit', model)\n",
    "        sys.exit(-1)\n",
    "\n",
    "\n",
    "    return estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_simulation(datasetid, testevent, taskid, runts, expid, predictionlen, \n",
    "               featuremode = stint.FEATURE_STATUS,\n",
    "               pitmodel = 0, \n",
    "               inlapmode=0,\n",
    "               train_len = 40):\n",
    "    #\n",
    "    # configurataion\n",
    "    #\n",
    "    # model path:  <_dataset_id>/<_task_id>-<trainid>/\n",
    "    #_dataset_id = 'indy2013-2018-nocarid'\n",
    "    \n",
    "    stint._inlap_status = inlapmode\n",
    "    \n",
    "    stint.init(pitmodel)\n",
    "    stint._dataset_id = datasetid\n",
    "    stint._test_event = testevent\n",
    "    #_test_event = 'Indy500-2019'\n",
    "\n",
    "    stint._feature_mode = featuremode\n",
    "    stint._context_ratio = 0.\n",
    "\n",
    "    stint._task_id = taskid  # rank,laptime, the trained model's task\n",
    "    stint._run_ts = runts   #COL_LAPTIME,COL_RANK\n",
    "    stint._exp_id=expid  #rank, laptime, laptim2rank, timediff2rank... \n",
    "\n",
    "    stint._use_mean = True\n",
    "    \n",
    "    stint._train_len = train_len\n",
    "    \n",
    "    \n",
    "def simulation(datasetid, testevent, taskid, runts, expid, predictionlen, \n",
    "               datamode, loopcnt, featuremode = stint.FEATURE_STATUS,\n",
    "              pitmodel = 0, model = 'oracle', inlapmode=0, train_len = 40):\n",
    "    #\n",
    "    # configurataion\n",
    "    #\n",
    "    # model path:  <_dataset_id>/<_task_id>-<trainid>/\n",
    "    #_dataset_id = 'indy2013-2018-nocarid'\n",
    "    \n",
    "    stint._inlap_status = inlapmode\n",
    "    \n",
    "    stint.init(pitmodel)\n",
    "    stint._dataset_id = datasetid\n",
    "    stint._test_event = testevent\n",
    "    #_test_event = 'Indy500-2019'\n",
    "\n",
    "    stint._feature_mode = featuremode\n",
    "    stint._context_ratio = 0.\n",
    "\n",
    "    stint._task_id = taskid  # rank,laptime, the trained model's task\n",
    "    stint._run_ts = runts   #COL_LAPTIME,COL_RANK\n",
    "    stint._exp_id=expid  #rank, laptime, laptim2rank, timediff2rank... \n",
    "\n",
    "    stint._use_mean = True\n",
    "    \n",
    "    stint._train_len = train_len\n",
    "    \n",
    "    predictor = stint.load_model(predictionlen, model,trainid='indy500',epochs = epochs, exproot='./')\n",
    "\n",
    "    ret2 = {}\n",
    "    for i in range(loopcnt):\n",
    "        #df, full_samples, full_tss\n",
    "        ret2[i] = stint.run_simulation_shortterm(predictor, predictionlen, stint.freq, datamode=datamode)\n",
    "\n",
    "    acc = []\n",
    "    for i in ret2.keys():\n",
    "        df = ret2[i][0]\n",
    "        _x = stint.get_evalret_shortterm(df)\n",
    "        acc.append(_x)\n",
    "\n",
    "    b = np.array(acc)\n",
    "    print(np.mean(b, axis=0))\n",
    "    \n",
    "    #save keys\n",
    "    #stint._pitmodel.save_keys('pitmodel-keys.pickle')\n",
    "    \n",
    "    return b, ret2\n",
    "\n",
    "def get_alldf(dfx, year=2018):\n",
    "    \n",
    "\n",
    "    #dfx = ret[f'{model}-RANK-{year}-inlap-nopitage']\n",
    "    #dfx = ret[f'{model}-TIMEDIFF-{year}-noinlap-nopitage']\n",
    "    \n",
    "    samples = dfx.keys()\n",
    "    retdfs = []\n",
    "    for id in samples:\n",
    "        df = dfx[id][0]\n",
    "        retdfs.append(df)\n",
    "        \n",
    "    if len(retdfs) > 1:\n",
    "        dfout = pd.concat(retdfs)\n",
    "    else:\n",
    "        dfout = retdfs[0]\n",
    "        \n",
    "    return dfout\n",
    "    \n",
    "def get_alldf_mode(dfx, year=2018,mode=0):\n",
    "    \"\"\"\n",
    "    mode: \n",
    "        0; mode\n",
    "        1; mean\n",
    "        2; median\n",
    "    \"\"\"\n",
    "    dfall = get_alldf(dfx, year=year)\n",
    "    \n",
    "    cars = set(dfall.carno.values)\n",
    "    startlaps = {}\n",
    "    for car in cars:\n",
    "        startlaps[car] = set(dfall[dfall['carno']==car].startlap.values)\n",
    "        \n",
    "    retdf = []\n",
    "    for car in cars:\n",
    "        for startlap in startlaps[car]:\n",
    "            dfrec = dfall[(dfall['carno']==car) & (dfall['startlap']==startlap)]\n",
    "            \n",
    "            #get mode\n",
    "            if mode == 0:\n",
    "                pred_endrank = stats.mode(dfrec.pred_endrank.values).mode[0]\n",
    "                #pred_endlap =  stats.mode(dfrec.pred_endlap.values).mode[0]\n",
    "            elif mode == 1:\n",
    "                #use mean\n",
    "                pred_endrank = np.mean(dfrec.pred_endrank.values)\n",
    "                #pred_endlap =  np.mean(dfrec.pred_endlap.values)\n",
    "            elif mode == 2:\n",
    "                #use mean\n",
    "                pred_endrank = np.median(dfrec.pred_endrank.values)\n",
    "                #pred_endlap =  np.median(dfrec.pred_endlap.values)\n",
    "            \n",
    "            firstrec = dfrec.to_numpy()[0,:]\n",
    "            firstrec[6] = pred_endrank\n",
    "            firstrec[7] = pred_endrank - firstrec[2]\n",
    "            if firstrec[7] == 0:\n",
    "                firstrec[8] = 0\n",
    "            elif firstrec[7] > 0:\n",
    "                firstrec[8] = 1\n",
    "            else:\n",
    "                firstrec[8] = -1\n",
    "                \n",
    "            #endlap, pred_endlap\n",
    "            \n",
    "        \n",
    "            retdf.append(firstrec)\n",
    "        \n",
    "    #dfout = pd.concat(retdf)\n",
    "    dfout = pd.DataFrame(retdf, columns =['carno', 'startlap', 'startrank',    \n",
    "                                         'endrank', 'diff', 'sign',\n",
    "                                         'pred_endrank', 'pred_diff', 'pred_sign',\n",
    "                                         #'endlap','pred_endlap'\n",
    "                                        ])\n",
    "    print('df size:', len(dfout))\n",
    "    return dfout\n",
    "\n",
    "def get_allsamples(dfx, year=2018):\n",
    "    \n",
    "    runs = list(dfx.keys())\n",
    "    runcnt = len(runs)\n",
    "    \n",
    "    full_samples = {}\n",
    "    full_tss = dfx[runs[0]][2]\n",
    "    carlist = list(full_tss.keys())\n",
    "    samplecnt, lapcnt = dfx[runs[0]][1][carlist[0]].shape\n",
    "    \n",
    "    print('sacmplecnt:', samplecnt, 'lapcnt:',lapcnt,'runcnt:', runcnt)\n",
    "    \n",
    "    #empty samples\n",
    "    for carid, carno in enumerate(carlist):\n",
    "        full_samples[carno] = np.zeros((runcnt, lapcnt))\n",
    "    \n",
    "    for runid in runs:\n",
    "        #one run\n",
    "        tss = dfx[runid][2]\n",
    "        forecast = dfx[runid][1]\n",
    "        \n",
    "        for carid, carno in enumerate(carlist):\n",
    "            #get mean for this run\n",
    "            forecast_mean = np.nanmean(forecast[carno], axis=0)\n",
    "            full_samples[carno][runid, :] = forecast_mean\n",
    "            \n",
    "            #if carno==3 and runid == 0:\n",
    "            #    print('forecast:',forecast_mean)\n",
    "            \n",
    "    return full_samples, full_tss\n",
    "\n",
    "#straight implementation of prisk\n",
    "def quantile_loss(target, quantile_forecast, q):\n",
    "    return 2.0 * np.nansum(\n",
    "        np.abs(\n",
    "            (quantile_forecast - target)\n",
    "            * ((target <= quantile_forecast) - q)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def abs_target_sum(target): \n",
    "    return np.nansum(np.abs(target)) \n",
    "\n",
    "def prisk(full_samples, full_tss, verbose = False):\n",
    "    carlist = full_tss.keys()\n",
    "    tss = []\n",
    "    forecasts = []\n",
    "    forecasts_mean = []\n",
    "    freq = '1min'\n",
    "    start = pd.Timestamp(\"01-01-2019\", freq=freq) \n",
    "\n",
    "    for car in carlist:\n",
    "        testcar = car\n",
    "        fc = SampleForecast(samples = full_samples[testcar][:, 12:], freq=freq, start_date=start + 12)\n",
    "\n",
    "        samples = np.mean(full_samples[testcar][:, 12:], axis =0, keepdims=True)\n",
    "        fc_mean = SampleForecast(samples = samples, freq=freq, start_date=start + 12)\n",
    "\n",
    "        index = pd.date_range(start='2019-01-01 00:00:00', freq = 'T', periods = len(full_tss[testcar]))\n",
    "        ts = pd.DataFrame(index = index, data = full_tss[testcar])    \n",
    "\n",
    "        tss.append(ts)\n",
    "        forecasts.append(fc)\n",
    "        forecasts_mean.append(fc_mean)\n",
    "\n",
    "    evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9]) \n",
    "    agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(tss))\n",
    "    if verbose:\n",
    "        print(json.dumps(agg_metrics, indent=4))  \n",
    "    \n",
    "    print(agg_metrics[\"wQuantileLoss[0.1]\"], agg_metrics[\"wQuantileLoss[0.5]\"],agg_metrics[\"wQuantileLoss[0.9]\"])\n",
    "    \n",
    "    return agg_metrics\n",
    "\n",
    "\n",
    "def prisk_direct_bysamples2(full_samples, full_tss, quantiles=[0.1,0.5,0.9], startid = 12, verbose=False):\n",
    "    \"\"\"\n",
    "    target: endrank\n",
    "    forecast: pred_endrank\n",
    "    item_id: <carno, startlap>\n",
    "    \"\"\"\n",
    "    \n",
    "    carlist = full_tss.keys()\n",
    "    \n",
    "    prisk = np.zeros((len(carlist), len(quantiles)))\n",
    "    target_sum = np.zeros((len(carlist)))\n",
    "    aggrisk = np.zeros((len(quantiles)))\n",
    "    \n",
    "    for carid, carno in enumerate(carlist):\n",
    "\n",
    "        # for this car\n",
    "        forecast = full_samples[carno]\n",
    "        target = full_tss[carno]\n",
    "        \n",
    "        #calc quantiles\n",
    "        # len(quantiles) x 1\n",
    "        quantile_forecasts = np.quantile(forecast, quantiles, axis=0)\n",
    "        \n",
    "        for idx, q in enumerate(quantiles):\n",
    "            q_forecast = quantile_forecasts[idx]\n",
    "            prisk[carid, idx] = quantile_loss(target[startid:], q_forecast[startid:], q)\n",
    "            target_sum[carid] = abs_target_sum(target[startid:])\n",
    "            \n",
    "        if verbose==True and carno==3:\n",
    "            print('target:', target[startid:])\n",
    "            print('forecast:', q_forecast[startid:])\n",
    "            print('target_sum:', target_sum[carid])\n",
    "            \n",
    "            print('quantile_forecasts:', quantile_forecasts[:,startid:])\n",
    "        \n",
    "    #agg\n",
    "    #aggrisk = np.mean(prisk, axis=0)\n",
    "    prisk_sum = np.nansum(prisk, axis=0)\n",
    "    if verbose==True:\n",
    "        print('prisk:',prisk)\n",
    "        print('prisk_sum:',prisk_sum)\n",
    "        print('target_sum:',target_sum)\n",
    "    for idx, q in enumerate(quantiles):\n",
    "        aggrisk[idx] = np.divide(prisk_sum[idx], np.sum(target_sum))\n",
    "    \n",
    "    agg_metrics = {}\n",
    "    for idx, q in enumerate(quantiles):\n",
    "        agg_metrics[f'wQuantileLoss[{q}]'] = aggrisk[idx]\n",
    "        \n",
    "    print(agg_metrics.values())\n",
    "    \n",
    "    return agg_metrics, aggrisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prisk_direct_bysamples(full_samples, full_tss, quantiles=[0.1,0.5,0.9], startid = 12, verbose=False):\n",
    "    \"\"\"\n",
    "    calculate prisk by <samples, tss> directly (equal to gluonts implementation)\n",
    "    \n",
    "    target: endrank\n",
    "    forecast: pred_endrank\n",
    "    item_id: <carno, startlap>\n",
    "    \"\"\"\n",
    "    \n",
    "    carlist = full_tss.keys()\n",
    "    \n",
    "    prisk = np.zeros((len(carlist), len(quantiles)))\n",
    "    target_sum = np.zeros((len(carlist)))\n",
    "    aggrisk = np.zeros((len(quantiles)))\n",
    "    \n",
    "    for carid, carno in enumerate(carlist):\n",
    "\n",
    "        # for this car\n",
    "        forecast = full_samples[carno]\n",
    "        target = full_tss[carno]\n",
    "        \n",
    "        #calc quantiles\n",
    "        # len(quantiles) x 1\n",
    "        quantile_forecasts = np.quantile(forecast, quantiles, axis=0)\n",
    "        \n",
    "        for idx, q in enumerate(quantiles):\n",
    "            q_forecast = quantile_forecasts[idx]\n",
    "            prisk[carid, idx] = quantile_loss(target[startid:], q_forecast[startid:], q)\n",
    "            target_sum[carid] = abs_target_sum(target[startid:])\n",
    "            \n",
    "        if verbose==True and carno==3:\n",
    "            print('target:', target[startid:])\n",
    "            print('forecast:', q_forecast[startid:])\n",
    "            print('target_sum:', target_sum[carid])\n",
    "            \n",
    "            print('quantile_forecasts:', quantile_forecasts[:,startid:])\n",
    "        \n",
    "    #agg\n",
    "    #aggrisk = np.mean(prisk, axis=0)\n",
    "    prisk_sum = np.nansum(prisk, axis=0)\n",
    "    if verbose==True:\n",
    "        print('prisk:',prisk)\n",
    "        print('prisk_sum:',prisk_sum)\n",
    "        print('target_sum:',target_sum)\n",
    "    for idx, q in enumerate(quantiles):\n",
    "        aggrisk[idx] = np.divide(prisk_sum[idx], np.sum(target_sum))\n",
    "    \n",
    "    agg_metrics = {}\n",
    "    for idx, q in enumerate(quantiles):\n",
    "        agg_metrics[f'wQuantileLoss[{q}]'] = aggrisk[idx]\n",
    "        \n",
    "    print(agg_metrics.values())\n",
    "    \n",
    "    return agg_metrics, aggrisk\n",
    "\n",
    "def clear_samples(full_samples, full_tss, clearidx):\n",
    "    \"\"\"\n",
    "    clear the laps in clearidx\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    ret_samples = copy.deepcopy(full_samples)\n",
    "    ret_tss = copy.deepcopy(full_tss)\n",
    "    \n",
    "    \n",
    "    carlist = full_tss.keys()\n",
    "    \n",
    "    for carid, carno in enumerate(carlist):\n",
    "        forecast = ret_samples[carno]\n",
    "        target = ret_tss[carno]\n",
    "        \n",
    "        forecast[:, clearidx] = np.nan\n",
    "        target[clearidx] = np.nan\n",
    "        \n",
    "        ret_samples[carno] = forecast\n",
    "        ret_tss[carno] = target\n",
    "        \n",
    "    return ret_samples, ret_tss\n",
    "\n",
    "def do_rerank(dfout, short=True):\n",
    "    \"\"\"\n",
    "    carno','startlap','startrank','endrank','diff','sign','pred_endrank','pred_diff','pred_sign','endlap','pred_endlap\n",
    "    \n",
    "    output of prediction of target can be float\n",
    "    \n",
    "    resort the endrank globally\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cols=['carno','startlap','startrank','endrank','diff','sign','pred_endrank','pred_diff','pred_sign','endlap','pred_endlap']\n",
    "    colid={x:id for id,x in enumerate(cols)}\n",
    "    \n",
    "    #df = dfout.sort_values(by=['startlap','carno'])\n",
    "    print('rerank...')\n",
    "    laps = set(dfout.startlap.values)\n",
    "    \n",
    "    dfs = []\n",
    "    for lap in laps:\n",
    "        df = dfout[dfout['startlap']==lap].to_numpy()\n",
    "        \n",
    "        #print('in',df)\n",
    "        \n",
    "        idx = np.argsort(df[:,colid['pred_endrank']], axis=0)\n",
    "        true_rank = np.argsort(idx, axis=0)\n",
    "    \n",
    "        df[:,colid['pred_endrank']] = true_rank\n",
    "        \n",
    "        #reset preds \n",
    "        df[:,colid['pred_diff']] = df[:,colid['pred_endrank']] - df[:,colid['endrank']]\n",
    "\n",
    "        for rec in df:\n",
    "            if rec[colid['pred_diff']] == 0:\n",
    "                rec[colid['pred_sign']] = 0\n",
    "            elif rec[colid['pred_diff']] > 0:\n",
    "                rec[colid['pred_sign']] = 1\n",
    "            else:\n",
    "                rec[colid['pred_sign']] = -1        \n",
    "        \n",
    "        #print('out',df)\n",
    "        if len(dfs) == 0:\n",
    "            dfs = df\n",
    "        else:\n",
    "            dfs = np.vstack((dfs, df))\n",
    "        #dfs.append(df)\n",
    "        #np.vstack(df)\n",
    "        \n",
    "    #dfret = pd.concat(dfs)\n",
    "    #data = np.array(dfs)\n",
    "    if short:\n",
    "        dfret = pd.DataFrame(dfs.astype(int), columns = cols[:-2])\n",
    "    else:\n",
    "        dfret = pd.DataFrame(dfs.astype(int), columns = cols)\n",
    "    return dfret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_predict_bymloutput_multirun(output, dfin, sampleCnt=100):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        test_ds\n",
    "        predictor\n",
    "    \n",
    "    \"\"\"\n",
    "    def get_start(idx):\n",
    "        td = forecasts[idx].start_date - start_time\n",
    "        return td.days*24*60 + td.seconds//60\n",
    "    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor=_predictor,  # predictor\n",
    "        num_samples=sampleCnt,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    start_time, row = next(tss[0].iterrows())\n",
    "\n",
    "    first_start = get_start(-1)\n",
    "    last_start = get_start(0)\n",
    "    print('first start:', first_start, 'last start:', last_start)    \n",
    "    \n",
    "    import copy\n",
    "    target = copy.deepcopy(forecasts[-1])\n",
    "\n",
    "    #100, 10\n",
    "    nsample, npredict = target.samples.shape\n",
    "    print('sampel# x predictlen: ', nsample, npredict)\n",
    "    \n",
    "    newsamples = np.zeros((nsample, last_start - first_start + npredict))\n",
    "    newsamples[:,:] = np.nan\n",
    "    \n",
    "    for idx in range(len(forecasts)):\n",
    "        #copy samples\n",
    "        start_pos = get_start(idx)\n",
    "\n",
    "        pos = start_pos - first_start + npredict - 1\n",
    "        #copy sample to block\n",
    "        #newsamples[:, pos:pos + npredict] = forecasts[idx].samples\n",
    "        #newsamples[:, pos + npredict - 1] = forecasts[idx].samples[:,-1]\n",
    "        \n",
    "        # get prediction from ml output\n",
    "        # pos = laps\n",
    "        # 1 ... 10 | 11 <- start pos in forecasts\n",
    "        # 0 ...  9 | 10 <- 9 is the startlap\n",
    "        #\n",
    "        startlap = start_pos  - 2\n",
    "        #print('start pos:', start_pos, 'pos:',pos, 'startlap:', startlap)\n",
    "        \n",
    "        _rec = dfin[dfin['startlap']== startlap]\n",
    "        if len(_rec) > 0:\n",
    "            # rank start from 1 for visualization\n",
    "            pred_val = _rec.pred_endrank.values\n",
    "            \n",
    "            #pred_val = _rec.pred_endrank.values\n",
    "            #make sure shape match, 100 samples\n",
    "            \n",
    "            #newsamples[:, pos + npredict - 1] = pred_val + 1\n",
    "            newsamples[:, pos] = pred_val + 1\n",
    "            #print('startlap:', startlap, 'predrank:', pred_val)\n",
    "\n",
    "    target.samples = newsamples\n",
    "    \n",
    "    print('multirun target samples:', target.samples.shape)\n",
    "\n",
    "    #plot_prob_forecasts_ex([tss[0]],[target],output)\n",
    "    \n",
    "    return target,tss[0]\n",
    "\n",
    "def long_predict_bymloutput(output, dfin):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        test_ds\n",
    "        predictor\n",
    "    \n",
    "    \"\"\"\n",
    "    def get_start(idx):\n",
    "        td = forecasts[idx].start_date - start_time\n",
    "        return td.days*24*60 + td.seconds//60\n",
    "    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor=_predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    start_time, row = next(tss[0].iterrows())\n",
    "\n",
    "    first_start = get_start(-1)\n",
    "    last_start = get_start(0)\n",
    "    print('first start:', first_start, 'last start:', last_start)    \n",
    "    \n",
    "    import copy\n",
    "    target = copy.deepcopy(forecasts[-1])\n",
    "\n",
    "    #100, 10\n",
    "    nsample, npredict = target.samples.shape\n",
    "    print('sampel# x predictlen: ', nsample, npredict)\n",
    "    \n",
    "    newsamples = np.zeros((nsample, last_start - first_start + npredict))\n",
    "    newsamples[:,:] = np.nan\n",
    "    \n",
    "    for idx in range(len(forecasts)):\n",
    "        #copy samples\n",
    "        start_pos = get_start(idx)\n",
    "\n",
    "        pos = start_pos - first_start + npredict - 1\n",
    "        #copy sample to block\n",
    "        #newsamples[:, pos:pos + npredict] = forecasts[idx].samples\n",
    "        #newsamples[:, pos + npredict - 1] = forecasts[idx].samples[:,-1]\n",
    "        \n",
    "        # get prediction from ml output\n",
    "        # pos = laps\n",
    "        # 1 ... 10 | 11 <- start pos in forecasts\n",
    "        # 0 ...  9 | 10 <- 9 is the startlap\n",
    "        #\n",
    "        startlap = start_pos  - 2\n",
    "        #print('start pos:', start_pos, 'pos:',pos, 'startlap:', startlap)\n",
    "        \n",
    "        _rec = dfin[dfin['startlap']== startlap]\n",
    "        if len(_rec) > 0:\n",
    "            # rank start from 1 for visualization\n",
    "            pred_val = _rec.pred_endrank.values[0]\n",
    "            \n",
    "            #pred_val = _rec.pred_endrank.values\n",
    "            #make sure shape match, 100 samples\n",
    "            \n",
    "            #newsamples[:, pos + npredict - 1] = pred_val + 1\n",
    "            newsamples[:, pos] = pred_val + 1\n",
    "            #print('startlap:', startlap, 'predrank:', pred_val)\n",
    "\n",
    "    target.samples = newsamples\n",
    "    \n",
    "    print('target samples:', target.samples.shape)\n",
    "\n",
    "    #plot_prob_forecasts_ex([tss[0]],[target],output)\n",
    "    \n",
    "    return target,tss[0]\n",
    "\n",
    "def long_predict_bysamples(output, samples, tss):\n",
    "    \"\"\"\n",
    "    use the farest samples only\n",
    "    \n",
    "    input:\n",
    "        samples\n",
    "        tss\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def get_start(idx):\n",
    "        td = forecasts[idx].start_date - start_time\n",
    "        return td.days*24*60 + td.seconds//60\n",
    "    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor=_predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    start_time, row = next(tss[0].iterrows())\n",
    "\n",
    "    first_start = get_start(-1)\n",
    "    last_start = get_start(0)\n",
    "    print(first_start, last_start)    \n",
    "    \n",
    "    import copy\n",
    "    target = copy.deepcopy(forecasts[-1])\n",
    "\n",
    "    #100, 10\n",
    "    nsample, npredict = target.samples.shape\n",
    "    print('sampel# x predictlen: ', nsample, npredict)\n",
    "    \n",
    "    #sample array size: last_start - first_start + npredict\n",
    "    arraysize = last_start - first_start + npredict\n",
    "    \n",
    "    #error here\n",
    "    #target.samples = samples[:,-len(forecasts)-1:] + 1\n",
    "    #target.samples = samples[:, 10 + npredict:] + 1\n",
    "    target.samples = samples[:, first_start:first_start + arraysize] + 1\n",
    "\n",
    "    print('long_predict_bysamples==>target samples shape:', target.samples.shape)\n",
    "    #plot_prob_forecasts_ex([tss[0]],[target],output)\n",
    "    \n",
    "    return target, tss[0]\n",
    "\n",
    "#\n",
    "# different idx format to bymloutput\n",
    "#\n",
    "def long_predict_bydf(output, dfin):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        test_ds\n",
    "        predictor\n",
    "    \n",
    "    \"\"\"\n",
    "    def get_start(idx):\n",
    "        td = forecasts[idx].start_date - start_time\n",
    "        return td.days*24*60 + td.seconds//60\n",
    "    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset\n",
    "        predictor= _predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f'tss len={len(tss)}, forecasts len={len(forecasts)}')\n",
    "    \n",
    "    start_time, row = next(tss[0].iterrows())\n",
    "\n",
    "    first_start = get_start(-1)\n",
    "    last_start = get_start(0)\n",
    "    print('first start:', first_start, 'last start:', last_start)    \n",
    "    \n",
    "    import copy\n",
    "    target = copy.deepcopy(forecasts[-1])\n",
    "\n",
    "    #100, 10\n",
    "    nsample, npredict = target.samples.shape\n",
    "    print('sampel# x predictlen: ', nsample, npredict)\n",
    "    \n",
    "    newsamples = np.zeros((nsample, last_start - first_start + npredict))\n",
    "    newsamples[:,:] = np.nan\n",
    "    \n",
    "    for idx in range(len(forecasts)):\n",
    "        #copy samples\n",
    "        start_pos = get_start(idx)\n",
    "\n",
    "        pos = start_pos - first_start + npredict - 1\n",
    "        #copy sample to block\n",
    "        #newsamples[:, pos:pos + npredict] = forecasts[idx].samples\n",
    "        #newsamples[:, pos + npredict - 1] = forecasts[idx].samples[:,-1]\n",
    "        \n",
    "        # get prediction from ml output\n",
    "        # pos = laps\n",
    "        # 1 ... 10 | 11 <- start pos in forecasts\n",
    "        # 0 ...  9 | 10 <- 9 is the startlap\n",
    "        #\n",
    "        startlap = start_pos  - 1\n",
    "        #print('start pos:', start_pos, 'pos:',pos, 'startlap:', startlap)\n",
    "        \n",
    "        _rec = dfin[dfin['startlap']== startlap]\n",
    "        if len(_rec) > 0:\n",
    "            # rank start from 1 for visualization\n",
    "            pred_val = _rec.pred_endrank.values[0]\n",
    "            \n",
    "            #pred_val = _rec.pred_endrank.values\n",
    "            #make sure shape match, 100 samples\n",
    "            \n",
    "            #newsamples[:, pos + npredict - 1] = pred_val + 1\n",
    "            newsamples[:, pos] = pred_val + 1\n",
    "            #print('startlap:', startlap, 'predrank:', pred_val)\n",
    "\n",
    "    target.samples = newsamples\n",
    "    \n",
    "    print('target samples:', target.samples.shape)\n",
    "\n",
    "    #plot_prob_forecasts_ex([tss[0]],[target],output)\n",
    "    \n",
    "    return target,tss[0]\n",
    "\n",
    "def get_ranknet_multirun(retdata, testcar, sampleCnt=100):\n",
    "    dfs = []\n",
    "    #for id in range(samplecnt):\n",
    "    for id in retdata.keys():\n",
    "        #ret['pitmodel-RANK-2018-inlap-nopitage']\n",
    "        df = retdata[id][0]\n",
    "        df = df[df['carno']==testcar]\n",
    "        dfs.append(df)\n",
    "\n",
    "    dfin_ranknet = pd.concat(dfs)\n",
    "\n",
    "    print('dfin_ranknet size:', len(dfin_ranknet))\n",
    "    \n",
    "    #modify to fit to ml model format\n",
    "    dfin_ranknet['startlap'] = dfin_ranknet['startlap'] - 1\n",
    "    dfin_ranknet['startrank'] = dfin_ranknet['startrank'] - 1\n",
    "    dfin_ranknet['endrank'] = dfin_ranknet['endrank'] - 1\n",
    "                \n",
    "    target_ranknet, tss_ranknet = long_predict_bymloutput_multirun('ranknet-rank', dfin_ranknet, sampleCnt=sampleCnt)                \n",
    "                \n",
    "    return target_ranknet, tss_ranknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ploth(ts_entry, forecast_entry, pits,caution, pitstop,outputfile,\n",
    "                   colors = ['r','g','m'],\n",
    "                   plabels= ['observed','svr','arima','ranknet'],\n",
    "                   ylabel = 'RANK'):\n",
    "\n",
    "    #plot_length = int(forecast_entry[0].samples.shape[1] *1.2) \n",
    "    #plot_length = forecast_entry[0].samples.shape[1] + 10 \n",
    "    \n",
    "    #prediction_intervals = (50.0, 90.0)\n",
    "    prediction_intervals = [90.0]\n",
    "    \n",
    "    #legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals]\n",
    "\n",
    "    figcnt = len(forecast_entry)\n",
    "    \n",
    "    #fig, axs = plt.subplots(figcnt,1, figsize=(8,6))\n",
    "    fig, axs = plt.subplots(1, figcnt, figsize=(12,3*figcnt))\n",
    "\n",
    "    #colors = ['r','g','m']\n",
    "    #plabels = ['observed','svr','arima','ranknet']\n",
    "    \n",
    "    for idx in range(figcnt):\n",
    "        ax = plt.subplot(figcnt, 1, idx+1)\n",
    "        #ax = plt.subplot(1, figcnt, idx+1)\n",
    "        #ts_entry.iloc[-plot_length:,0].plot(ax=axs, linewidth=1)  # plot the time series\n",
    "        #ts_entry.iloc[-plot_length:,0].plot(ax=axs[idx], linewidth=1)  # plot the time series\n",
    "        #plot_length = int(forecast_entry[idx].samples.shape[1] *1.2) \n",
    "        ts_entry[idx].iloc[:,0].plot(linewidth=1, color='b',\n",
    "                                            marker='*', alpha=0.7, zorder=-1, label=plabels[0]) \n",
    "\n",
    "\n",
    "        # currank\n",
    "        sv = ts_entry[idx].iloc[:,0].to_numpy()\n",
    "        start = pd.Timestamp(\"01-01-2019\", freq='1min') + 2\n",
    "        date_index = pd.date_range(start, periods = len(sv)-2, freq='1min')\n",
    "        df2 = pd.DataFrame(sv[:-2], index=date_index)        \n",
    "        df2.iloc[:,0].plot(linewidth=0.5, color='k',\n",
    "                                            marker='+', alpha=0.7, zorder=-1, label='CurRank') \n",
    "        \n",
    "        \n",
    "    #for idx in range(len(forecast_entry)):\n",
    "    #    forecast_entry[idx].copy_dim(0).plot(prediction_intervals=prediction_intervals, color='g')\n",
    "    \n",
    "        forecast_entry[idx].copy_dim(0).plot(prediction_intervals=prediction_intervals, \n",
    "                                             color=colors[idx],label=plabels[idx+1], zorder=10)\n",
    "        #forecast_entry[1].copy_dim(0).plot(prediction_intervals=prediction_intervals, color='b')\n",
    "        #forecast_entry[2].copy_dim(0).plot(prediction_intervals=prediction_intervals, color='r')\n",
    "        \n",
    "        #add mean line, compare with median\n",
    "        #if forecast_entry[idx].samples.shape[0] > 1:\n",
    "        if idx>3:\n",
    "            mean_forecast = copy.deepcopy(forecast_entry[idx])\n",
    "            mean_forecast.samples = np.mean(mean_forecast.samples, axis=0).reshape((1,-1))\n",
    "            mean_forecast.copy_dim(0).plot(prediction_intervals=prediction_intervals, \n",
    "                                                 color='g',label='use-mean', zorder=10)\n",
    "        \n",
    "        \n",
    "        if idx == figcnt-1:\n",
    "            ax.set_xlabel('Lap')\n",
    "        #if idx==0:\n",
    "        ax.set_ylabel(ylabel)\n",
    "        if idx==0:\n",
    "            plt.title(outputfile)        \n",
    "    \n",
    "        locs, labels = plt.xticks() \n",
    "        #plt.xticks(locs, range(len(locs)))\n",
    "        start_loc = locs[0]        \n",
    "        offset = range(0, 200, 5)\n",
    "        #new_locs = range(start_loc , start_loc+200, 10)\n",
    "        new_locs = [start_loc + x for x in offset]\n",
    "        #new_labels = [str(x-start_loc + 1) for x in new_locs]\n",
    "        new_labels = [str(x+1) for x in offset]\n",
    "        plt.xticks(new_locs, new_labels)\n",
    "\n",
    "        if figcnt==1 or idx < figcnt -1:\n",
    "            print('xlim:', plt.xlim())\n",
    "            xl, xr = plt.xlim()\n",
    "            xlim_h = len(ts_entry[idx])\n",
    "            \n",
    "            #xlim_h = 100\n",
    "            ax.set_xlim((xl+0,xl+xlim_h))\n",
    "        elif idx == figcnt - 1:\n",
    "            xlim_h = len(ts_entry[idx])\n",
    "            \n",
    "            #xlim_h = 100\n",
    "            ax.set_xlim((xl+0,xl+xlim_h))\n",
    "        \n",
    "        if ylabel=='RANK':\n",
    "            ax.set_ylim((-5,+40))\n",
    "        else:\n",
    "            ax.set_ylim((25,175))\n",
    "            \n",
    "        #ax.set_xlim((80,110))\n",
    "        ax.set_zorder(-1)\n",
    "        plt.grid(which=\"both\", zorder=-1)\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        l=plt.legend(prop={'size': 10},loc='upper left')\n",
    "        l.set_zorder(0.6)\n",
    "        \n",
    "        #add racestatus\n",
    "        if ylabel=='RANK':\n",
    "            ax.plot(xl+pits[:,0]-1,pits[:,1],'^',color='r', label='PitStop', linewidth=2,alpha=0.7, zorder=-1)\n",
    "            add_status(ax,xl, caution, pitstop)\n",
    "        else:\n",
    "            ax.plot(xl+pits[:,0]-1,pits[:,2],'^',color='r', label='PitStop', linewidth=2,alpha=0.7, zorder=-1)\n",
    "            add_status(ax,xl, caution, pitstop,y=27, height=3)\n",
    "        \n",
    "        \n",
    "    \n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outputfile + '.pdf')    \n",
    "    \n",
    "def plotcar(carno):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        alldata, rankdata; global data\n",
    "    \"\"\"\n",
    "    #target_svr, target_rf,target_arima, target_oracle, target_ranknet_1run = savedata[carno]\n",
    "    #target_oracle(by longpredict), tss_oracle_multirun,tss_ranknet_multirun\n",
    "    tsss, targets = alldata[carno]\n",
    "    \n",
    "    pits, cautions, caution, pitstop,ranks,laptimes = get_racestatus(carno, rankdata)\n",
    "    print(np.where(pitstop==1))\n",
    "    \n",
    "    ploth(tsss[:5], targets[:5], pits, caution, pitstop,\n",
    "               'ranknet-rf-rank-forecast-%d'%carno,\n",
    "                   colors = ['y','c','g','m','r'],\n",
    "                   plabels= ['observed','SVR','RF','Arima','RrankNet-Oracle','RrankNet-MLP'])\n",
    "    \n",
    "def plotcar_laptime(carno):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        alldata, rankdata; global data\n",
    "    \"\"\"\n",
    "    #target_svr, target_rf,target_arima, target_oracle, target_ranknet_1run = savedata[carno]\n",
    "    #target_oracle(by longpredict), tss_oracle_multirun,tss_ranknet_multirun\n",
    "    tsss, targets = alldata[carno]\n",
    "    \n",
    "    pits, cautions, caution, pitstop,ranks,laptimes = get_racestatus(carno, rankdata)\n",
    "    print(np.where(pitstop==1))\n",
    "    \n",
    "    ploth(tsss, targets, pits, caution, pitstop,\n",
    "               'ranknet-oracle-laptime-forecast-%d'%carno,\n",
    "                   colors = ['m','r'],\n",
    "                   plabels= ['observed','RrankNet-Oracle','RrankNet-MLP'],\n",
    "                ylabel='LapTime')\n",
    "    \n",
    "    \n",
    "def plotrank(outputfile, mode='RANK' ):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        alldata, rankdata; global data\n",
    "    \"\"\"\n",
    "    \n",
    "    figcnt = len(alldata)\n",
    "    fig, axs = plt.subplots(1, figcnt, figsize=(12,3*figcnt))\n",
    "\n",
    "    carlist = list(alldata.keys())\n",
    "    \n",
    "    for idx, carno in enumerate(carlist):\n",
    "        #target_svr, target_rf,target_arima, target_oracle, target_ranknet_1run = savedata[carno]\n",
    "        #target_oracle(by longpredict), tss_oracle_multirun,tss_ranknet_multirun\n",
    "        tsss, targets = alldata[carno]\n",
    "\n",
    "        pits, cautions, caution, pitstop,ranks,laptimes = get_racestatus(carno, rankdata)\n",
    "        print(np.where(pitstop==1))\n",
    "    \n",
    "        ax = plt.subplot(figcnt, 1, idx+1)\n",
    "        \n",
    "        if mode == 'RANK':\n",
    "            ax.plot(ranks, linewidth=1, color='b',marker='*', alpha=0.7, zorder=-1, label='Rank') \n",
    "            ax.set_ylim((-5,+35))\n",
    "            ax.plot(pits[:,0]-1,pits[:,1],'^',color='r', label='PitStop', linewidth=2,alpha=0.7, zorder=-1)\n",
    "            #add racestatus\n",
    "            add_status(ax,0, caution, pitstop)\n",
    "\n",
    "        else:\n",
    "            ax.plot(laptimes, linewidth=1, color='b',marker='*', alpha=0.7, zorder=-1, label='LapTime') \n",
    "            ax.set_ylim((30,140))\n",
    "            ax.plot(pits[:,0]-1,pits[:,2],'^',color='r', label='PitStop', linewidth=2,alpha=0.7, zorder=-1)\n",
    "            #add racestatus\n",
    "            add_status(ax,0, caution, pitstop,y=32, height=5)\n",
    "        \n",
    "        ax.set_xlim((0,200))\n",
    "        \n",
    "        ax.set_ylabel('car-%d'%carno)\n",
    "        \n",
    "        \n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outputfile + '.pdf')    \n",
    "    \n",
    "def plotcarx(carno):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        alldata, rankdata; global data\n",
    "    \"\"\"\n",
    "    #target_svr, target_rf,target_arima, target_oracle, target_ranknet_1run = savedata[carno]\n",
    "    #target_oracle(by longpredict), tss_oracle_multirun,tss_ranknet_multirun\n",
    "    tsss, targets = alldata[carno]\n",
    "    \n",
    "    oracle_tss, oracle_targets = oracledata[carno]\n",
    "    \n",
    "    tsss[2] = oracle_tss[1]\n",
    "    targets[2] = oracle_targets[1]\n",
    "    \n",
    "    pits, cautions, caution, pitstop,ranks,laptimes = get_racestatus(carno, rankdata)\n",
    "    print(np.where(pitstop==1))\n",
    "    \n",
    "    ploth(tsss[:5], targets[:5], pits, caution, pitstop,\n",
    "               'ranknet-rf-rank-forecast-%d'%carno,\n",
    "                   colors = ['y','c','g','m','r'],\n",
    "                   plabels= ['observed','SVR','RF','Weighted-Oracle','RrankNet-Oracle','RrankNet-MLP'])\n",
    "    \n",
    "    \n",
    "def plotoracle(alldata, carno, destdir):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        alldata, rankdata; global data\n",
    "    \"\"\"\n",
    "    \n",
    "    outputfile = destdir + 'ranknet-oracle-forecast-%d'%carno\n",
    "    \n",
    "    #target_svr, target_rf,target_arima, target_oracle, target_ranknet_1run = savedata[carno]\n",
    "    #target_oracle(by longpredict), tss_oracle_multirun,tss_ranknet_multirun\n",
    "    tsss, targets = alldata[carno]\n",
    "    \n",
    "    pits, cautions, caution, pitstop,ranks,laptimes = get_racestatus(carno, rankdata)\n",
    "    print(np.where(pitstop==1))\n",
    "    \n",
    "    ploth(tsss, targets, pits, caution, pitstop,\n",
    "               outputfile,\n",
    "               colors = ['y','c','g','m','r'],\n",
    "               plabels= ['observed','1run-samples','1run-df','multimean','norerank-multimean','mrun-samples'])    \n",
    "    \n",
    "    \n",
    "def get_racestatus(carno, rankdata):\n",
    "    df12 = rankdata[rankdata['car_number']==carno]\n",
    "    #\n",
    "    # completed_laps start from 0\n",
    "    # in array mode completed_laps=1 should indexed by 0\n",
    "    #\n",
    "    data = df12[['completed_laps','rank','last_laptime','time_behind_leader']].values\n",
    "    pitstop = df12[['lap_status']].values\n",
    "    caution = df12[['track_status']].values\n",
    "    pitstop = np.array([1 if x=='P' else 0 for x in pitstop])\n",
    "    caution = np.array([1 if x=='Y' else 0 for x in caution])\n",
    "    pitidx = np.where(pitstop == 1)\n",
    "    pits = data[pitidx]\n",
    "    yidx = np.where(caution == 1)\n",
    "    cautions = data[yidx]\n",
    "    \n",
    "    ranks = df12[['rank']].values\n",
    "    laptimes = df12[['last_laptime']].values\n",
    "\n",
    "    #return pits, cautions, caution, pitstop\n",
    "    return pits, cautions, caution[1:], pitstop[1:], ranks[1:],laptimes[1:]\n",
    "\n",
    "\n",
    "#red = '#ff8080'\n",
    "red = 'red'\n",
    "#yellow = '#8080ff'\n",
    "yellow = 'yellow'\n",
    "#green = '#80ff80'\n",
    "green = 'green'\n",
    "\n",
    "def add_status(axs,xl, caution, pitstop, maxlap= 200, y=-4, height=2):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        caution, pitstop : race status\n",
    "    \"\"\"\n",
    "    maxlap = min(len(caution), len(pitstop))\n",
    "    for lap in range(maxlap):\n",
    "        fc = green\n",
    "        if caution[lap] == 1:\n",
    "            fc = yellow\n",
    "        if pitstop[lap] == 1:\n",
    "            fc = red\n",
    "        ec = fc\n",
    "        rectangle = plt.Rectangle((lap+xl-0.5,y), 1, height, fc=fc,ec=ec)\n",
    "        #plt.gca().add_patch(rectangle)\n",
    "        axs.add_patch(rectangle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    config = [\n",
    "        _savedata,\n",
    "        _skip_overwrite,\n",
    "        _inlap_status,\n",
    "        _feature_mode,\n",
    "        _featureCnt,\n",
    "        freq ,\n",
    "        _train_len,\n",
    "        prediction_length,\n",
    "        context_ratio,\n",
    "        context_length,\n",
    "        contextlen,\n",
    "        dataset,\n",
    "        epochs,\n",
    "        gpuid,\n",
    "        _use_weighted_model,\n",
    "        trainmodel,\n",
    "        _use_cate_feature,\n",
    "        use_feat_static,\n",
    "        distroutput,\n",
    "        batch_size,\n",
    "        loopcnt,\n",
    "        _test_event,\n",
    "        testmodel,\n",
    "        pitmodel,\n",
    "        year\n",
    "    ]\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WorkRootDir = 'QuickTestOutput'\n",
    "configfile = 'weighted-noinlap-nopitage-nocate-c40-drank.ini'\n",
    "\n",
    "if configfile != '':\n",
    "    config = configparser.RawConfigParser()\n",
    "    config.read(WorkRootDir + '/' + configfile)\n",
    "\n",
    "    #set them back\n",
    "    section = \"RankNet-QuickTest\"\n",
    "    \n",
    "    _savedata = config.getboolean(section, \"_savedata\")\n",
    "    _skip_overwrite = config.getboolean(section, \"_skip_overwrite\")\n",
    "    _inlap_status = config.getint(section, \"_inlap_status\") #0\n",
    "    _feature_mode = config.getint(section, \"_feature_mode\") #FEATURE_STATUS\n",
    "    _featureCnt = config.getint(section, \"_featureCnt\") #9\n",
    "    freq = config.get(section, \"freq\") #\"1min\"\n",
    "    _train_len = config.getint(section, \"_train_len\") #40\n",
    "    prediction_length = config.getint(section, \"prediction_length\") #2\n",
    "    context_ratio = config.getfloat(section, \"context_ratio\") #0.\n",
    "    context_length =  config.getint(section, \"context_length\") #40\n",
    "    \n",
    "    dataset= config.get(section, \"dataset\") #'rank'\n",
    "    epochs = config.getint(section, \"epochs\") #1000\n",
    "    gpuid = config.getint(section, \"gpuid\") #5\n",
    "    _use_weighted_model = config.getboolean(section, \"_use_weighted_model\")\n",
    "    trainmodel = config.get(section, \"trainmodel\") #'deepARW-Oracle' if _use_weighted_model else 'deepAR-Oracle'\n",
    "    \n",
    "    _use_cate_feature = config.getboolean(section, \"_use_cate_feature\")\n",
    "    \n",
    "    distroutput = config.get(section, \"distroutput\") #'student'\n",
    "    batch_size = config.getint(section, \"batch_size\") #32\n",
    "    loopcnt = config.getint(section, \"loopcnt\") #2\n",
    "    _test_event = config.get(section, \"_test_event\") #'Indy500-2018'\n",
    "    testmodel = config.get(section, \"testmodel\") #'oracle'\n",
    "    pitmodel = config.get(section, \"pitmodel\") #'oracle'\n",
    "    year = config.get(section, \"year\") #'2018'\n",
    "    \n",
    "    contextlen = context_length\n",
    "    use_feat_static = _use_cate_feature \n",
    "\n",
    "    #config1 = get_config()\n",
    "    \n",
    "else:\n",
    "    #\n",
    "    # global settings\n",
    "    #\n",
    "    #_savedata = False\n",
    "    _savedata = True\n",
    "    _skip_overwrite = True\n",
    "\n",
    "    #inlap status = \n",
    "    # 0 , no inlap\n",
    "    # 1 , set previous lap\n",
    "    # 2 , set the next lap\n",
    "    _inlap_status = 0\n",
    "\n",
    "    #\n",
    "    # featuremode in [FEATURE_STATUS, FEATURE_PITAGE]:\n",
    "    #\n",
    "    _feature_mode = FEATURE_STATUS\n",
    "    _featureCnt = 9\n",
    "\n",
    "    #\n",
    "    # training parameters\n",
    "    #\n",
    "    freq = \"1min\"\n",
    "    _train_len = 40\n",
    "    prediction_length = 2\n",
    "\n",
    "    context_ratio = 0.\n",
    "    context_length =  40\n",
    "    contextlen = context_length\n",
    "\n",
    "    dataset='rank'\n",
    "    epochs = 1000\n",
    "    #epochs = 10\n",
    "    gpuid = 5\n",
    "\n",
    "    #'deepAR-Oracle','deepARW-Oracle'\n",
    "    _use_weighted_model = True\n",
    "    trainmodel = 'deepARW-Oracle' if _use_weighted_model else 'deepAR-Oracle'\n",
    "\n",
    "    _use_cate_feature = False\n",
    "    use_feat_static = _use_cate_feature \n",
    "\n",
    "    distroutput = 'student'\n",
    "    batch_size = 32\n",
    "\n",
    "\n",
    "    #\n",
    "    # test parameters\n",
    "    #\n",
    "    loopcnt = 2\n",
    "    _test_event = 'Indy500-2018'\n",
    "    testmodel = 'oracle'\n",
    "    pitmodel = 'oracle'\n",
    "    year = '2018'\n",
    "    \n",
    "    #config2 = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkconfig = [0 if config1[idx] == config2[idx] else 1 for idx in range(len(config1))]\n",
    "#print(checkconfig)\n",
    "#print(config1)\n",
    "#print(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# string map\n",
    "#\n",
    "inlapstr = {0:'noinlap',1:'inlap',2:'outlap'}\n",
    "featurestr = {FEATURE_STATUS:'nopitage',FEATURE_PITAGE:'pitage'}\n",
    "weightstr = {True:'weighted',False:'noweighted'}\n",
    "catestr = {True:'cate',False:'nocate'}\n",
    "\n",
    "#\n",
    "# input data parameters\n",
    "#\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "events = [f'Indy500-{x}' for x in years]\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "dbid = f'Indy500_{years[0]}_{years[-1]}_v{_featureCnt}_p{_inlap_status}'\n",
    "_dataset_id = '%s-%s'%(inlapstr[_inlap_status], featurestr[_feature_mode])\n",
    "\n",
    "\n",
    "#\n",
    "# internal parameters\n",
    "#\n",
    "distr_outputs ={'student':StudentTOutput(),\n",
    "                'negbin':NegativeBinomialOutput()\n",
    "                }\n",
    "distr_output = distr_outputs[distroutput]\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "experimentid = f'{weightstr[_use_weighted_model]}-{inlapstr[_inlap_status]}-{featurestr[_feature_mode]}-{catestr[_use_cate_feature]}-c{context_length}'\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "outputRoot = f\"{WorkRootDir}/{experimentid}/\"\n",
    "\n",
    "\n",
    "# standard output file names\n",
    "LAPTIME_DATASET = f'laptime_rank_timediff_pit-oracle-{dbid}.pickle' \n",
    "STAGE_DATASET = f'stagedata-{dbid}.pickle' \n",
    "EVALUATION_RESULT_DF = f'evaluation_result_d{dataset}.csv'\n",
    "LONG_FORECASTING_DFS = f'long_forecasting_dfs_d{dataset}.pickle'\n",
    "FORECAST_FIGS_DIR = f'forecast-figs-d{dataset}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. make laptime dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load laptime and stage dataset: QuickTestOutput/weighted-noinlap-nopitage-nocate-c40/laptime_rank_timediff_pit-oracle-Indy500_2013_2019_v9_p0.pickle QuickTestOutput/weighted-noinlap-nopitage-nocate-c40/stagedata-Indy500_2013_2019_v9_p0.pickle\n"
     ]
    }
   ],
   "source": [
    "stagedata = {}\n",
    "global_carids = {}\n",
    "os.makedirs(outputRoot, exist_ok=True)\n",
    "\n",
    "#check the dest files first\n",
    "if _skip_overwrite and os.path.exists(outputRoot + LAPTIME_DATASET) and os.path.exists(outputRoot + STAGE_DATASET):\n",
    "        #\n",
    "        # load data\n",
    "        #\n",
    "        print('Load laptime and stage dataset:',outputRoot + LAPTIME_DATASET, outputRoot + STAGE_DATASET)\n",
    "        with open(outputRoot + LAPTIME_DATASET, 'rb') as f:\n",
    "            global_carids, laptime_data = pickle.load(f, encoding='latin1') \n",
    "        with open(outputRoot + STAGE_DATASET, 'rb') as f:\n",
    "            stagedata = pickle.load(f, encoding='latin1') \n",
    "    \n",
    "else:    \n",
    "    cur_carid = 0\n",
    "    for event in events:\n",
    "        #dataid = f'{event}-{year}'\n",
    "        #alldata, rankdata, acldata, flagdata\n",
    "        stagedata[event] = load_data(event)\n",
    "\n",
    "        alldata, rankdata, acldata, flagdata = stagedata[event]\n",
    "        carlist = set(acldata['car_number'])\n",
    "        laplist = set(acldata['completed_laps'])\n",
    "        print('%s: carno=%d, lapnum=%d'%(event, len(carlist), len(laplist)))\n",
    "\n",
    "        #build the carid map\n",
    "        for car in carlist:\n",
    "            if car not in global_carids:\n",
    "                global_carids[car] = cur_carid\n",
    "                cur_carid += 1\n",
    "\n",
    "    laptime_data = get_laptime_dataset(stagedata,inlap_status = _inlap_status)\n",
    "\n",
    "    if _savedata:\n",
    "        import pickle\n",
    "        #stintdf.to_csv('laptime-%s.csv'%year)\n",
    "        #savefile = outputRoot + f'laptime_rank_timediff_pit-oracle-{dbid}.pickle' \n",
    "        savefile = outputRoot + LAPTIME_DATASET\n",
    "        print(savefile)\n",
    "        with open(savefile, 'wb') as f:\n",
    "            #pack [global_carids, laptime_data]\n",
    "            savedata = [global_carids, laptime_data]\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        #savefile = outputRoot + f'stagedata-{dbid}.pickle' \n",
    "        savefile = outputRoot + STAGE_DATASET\n",
    "        print(savefile)\n",
    "        with open(savefile, 'wb') as f:\n",
    "            #pack [global_carids, laptime_data]\n",
    "            savedata = stagedata\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. make gluonts db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Gluonts Dataset: QuickTestOutput/weighted-noinlap-nopitage-nocate-c40/noinlap-nopitage/rank-indy500/gluontsdb-rank-oracle-noip-noeid-all-all-f1min-t2-rIndy500-2018-indy-2018.pickle\n",
      ".......loaded data, freq= 1min prediction_length= 2\n"
     ]
    }
   ],
   "source": [
    "outdir = outputRoot + _dataset_id\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "if dataset == 'laptime':\n",
    "    subdir = 'laptime-indy500'\n",
    "    os.makedirs(f'{outdir}/{subdir}', exist_ok=True)\n",
    "    _run_ts = COL_LAPTIME\n",
    "elif dataset == 'timediff':\n",
    "    subdir = 'timediff-indy500'\n",
    "    os.makedirs(f'{outdir}/{subdir}', exist_ok=True)\n",
    "    _run_ts = COL_TIMEDIFF\n",
    "elif dataset == 'rank':\n",
    "    subdir = 'rank-indy500'\n",
    "    os.makedirs(f'{outdir}/{subdir}', exist_ok=True)\n",
    "    _run_ts = COL_RANK\n",
    "else:\n",
    "    print('error, dataset not support: ', dataset)\n",
    "    \n",
    "_task_dir = f'{outdir}/{subdir}/'\n",
    "\n",
    "#\n",
    "#dbname, train_ds, test_ds = makedbs()   \n",
    "#\n",
    "useeid = False\n",
    "interpolate = False\n",
    "#ipstr = '-ip' if interpolate else '-noip'\n",
    "ipstr = '%s-%s'%('ip' if interpolate else 'noip', 'eid' if useeid else 'noeid')\n",
    "dbname = _task_dir + f'gluontsdb-{dataset}-oracle-{ipstr}-all-all-f{freq}-t{prediction_length}-r{_test_event}-indy-{year}.pickle'\n",
    "\n",
    "#check the dest files first\n",
    "if _skip_overwrite and os.path.exists(dbname):\n",
    "        print('Load Gluonts Dataset:',dbname)\n",
    "        with open(dbname, 'rb') as f:\n",
    "            freq, prediction_length, cardinality, train_ds, test_ds = pickle.load(f, encoding='latin1') \n",
    "        print('.......loaded data, freq=', freq, 'prediction_length=', prediction_length)\n",
    "        \n",
    "else:\n",
    "    if useeid:\n",
    "        cardinality = [len(global_carids), len(laptime_data)]\n",
    "    else:\n",
    "        cardinality = [len(global_carids)]\n",
    "\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(-1, prediction_length,freq,\n",
    "                                         useeid=useeid, run_ts=_run_ts,\n",
    "                                        test_event=_test_event, log_transform =False,\n",
    "                                        context_ratio=0, train_ratio = 0, dorerank =True)\n",
    "\n",
    "\n",
    "    if _savedata:\n",
    "        print('Save Gluonts Dataset:',dbname)\n",
    "        \n",
    "        with open(dbname, 'wb') as f:\n",
    "            savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "            pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint found at: QuickTestOutput/weighted-noinlap-nopitage-nocate-c40/noinlap-nopitage/rank-indy500/deepARW-Oracle-rank-all-indy-f1min-t2-e1000-r1_oracle_t2\n"
     ]
    }
   ],
   "source": [
    "id='oracle'\n",
    "run=1\n",
    "runid=f'{trainmodel}-{dataset}-all-indy-f1min-t{prediction_length}-e{epochs}-r{run}_{id}_t{prediction_length}'\n",
    "modelfile = _task_dir + runid\n",
    "\n",
    "if _skip_overwrite and os.path.exists(modelfile):\n",
    "    print('Model checkpoint found at:',modelfile)\n",
    "\n",
    "else:\n",
    "    #get target dim\n",
    "    entry = next(iter(train_ds))\n",
    "    target_dim = entry['target'].shape\n",
    "    target_dim = target_dim[0] if len(target_dim) > 1 else 1\n",
    "    print('target_dim:%s', target_dim)\n",
    "\n",
    "    estimator = init_estimator(trainmodel, gpuid, \n",
    "            epochs, batch_size,target_dim, distr_output = distr_output,use_feat_static = use_feat_static)\n",
    "\n",
    "    predictor = estimator.train(train_ds)\n",
    "\n",
    "    if _savedata:\n",
    "        os.makedirs(modelfile, exist_ok=True)\n",
    "\n",
    "        print('Start to save the model to %s', modelfile)\n",
    "        predictor.serialize(Path(modelfile))\n",
    "        print('End of saving the model.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Simulation Results: QuickTestOutput/weighted-noinlap-nopitage-nocate-c40/shortterm-dfout-oracle-indy500-rank-noinlap-nopitage-2018-oracle-l2-alldata-weighted.pickle\n",
      ".......loaded data, ret keys= dict_keys(['oracle-rank-2018-noinlap-nopitage'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/stint_simulator_shortterm_pitmodel.py:197: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uni_ds['rank_diff'][mask] = 0\n",
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/stint_simulator_shortterm_pitmodel.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uni_ds['time_diff'][mask] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init: load dataset laptime_rank_timediff_pit-oracle-Indy500_2013_2019_v9_p0.pickle with 7 races, 58 cars\n"
     ]
    }
   ],
   "source": [
    "lapmode = _inlap_status\n",
    "fmode = _feature_mode\n",
    "runts = dataset\n",
    "mid = f'{testmodel}-%s-%s-%s-%s'%(runts, year, inlapstr[lapmode], featurestr[fmode])\n",
    "datasetid = outputRoot + _dataset_id\n",
    "simulation_outfile=outputRoot + f'shortterm-dfout-oracle-indy500-{dataset}-{inlapstr[_inlap_status]}-{featurestr[_feature_mode]}-2018-oracle-l{loopcnt}-alldata-weighted.pickle'\n",
    "if _skip_overwrite and os.path.exists(simulation_outfile):\n",
    "    print('Load Simulation Results:',simulation_outfile)\n",
    "    with open(simulation_outfile, 'rb') as f:\n",
    "        dfs,acc,ret,pret = pickle.load(f, encoding='latin1') \n",
    "    print('.......loaded data, ret keys=', ret.keys())\n",
    "    \n",
    "    # init the stint module\n",
    "    init_simulation(datasetid, _test_event, 'rank',stint.COL_RANK,'rank',prediction_length, \n",
    "                    pitmodel=pitmodel, inlapmode=lapmode,featuremode =fmode,\n",
    "                    train_len = _train_len)    \n",
    "\n",
    "else:\n",
    "    #run simulation\n",
    "    acc, ret, pret = {}, {}, {}\n",
    "\n",
    "    #lapmode = _inlap_status\n",
    "    #fmode = _feature_mode\n",
    "    #runts = dataset\n",
    "    #mid = f'{testmodel}-%s-%s-%s-%s'%(runts, year, inlapstr[lapmode], featurestr[fmode])\n",
    "\n",
    "    if runts == 'rank':\n",
    "        acc[mid], ret[mid] = simulation(datasetid, _test_event, \n",
    "                    'rank',stint.COL_RANK,'rank',\n",
    "                   prediction_length, stint.MODE_ORACLE,loopcnt, \n",
    "                      pitmodel=pitmodel, model=testmodel, inlapmode=lapmode,featuremode =fmode,\n",
    "                    train_len = _train_len)        \n",
    "    else:\n",
    "        acc[mid], ret[mid] = simulation(datasetid, _test_event, \n",
    "                    'timediff',stint.COL_TIMEDIFF,'timediff2rank',\n",
    "                   prediction_length, stint.MODE_ORACLE,loopcnt, \n",
    "                      pitmodel=pitmodel, model=testmodel, inlapmode=lapmode,featuremode =fmode,\n",
    "                    train_len = _train_len)\n",
    "\n",
    "    allsamples, alltss = get_allsamples(ret[mid], year=year)\n",
    "    _, pret[mid]= prisk_direct_bysamples(allsamples, alltss)\n",
    "    print(pret[mid])\n",
    "\n",
    "    dfs={}\n",
    "\n",
    "    mode=1\n",
    "    df = get_alldf_mode(ret[mid], year=year,mode=mode)\n",
    "    name = '%s_%s'%(testmodel, 'mean' if mode==1 else ('mode' if mode==0 else 'median'))\n",
    "    if year not in dfs:\n",
    "        dfs[year] = {}\n",
    "    dfs[year][name] = df\n",
    "\n",
    "    _trim = 0\n",
    "    _include_final = True\n",
    "    _include_stintlen = True\n",
    "    include_str = '1' if _include_final else '0'\n",
    "    stint_str = '1' if _include_stintlen else ''            \n",
    "    #simulation_outfile=outputRoot + f'shortterm-dfout-oracle-indy500-{dataset}-{inlapstr[_inlap_status]}-{featurestr[_feature_mode]}-2018-oracle-l{loopcnt}-alldata-weighted.pickle'\n",
    "\n",
    "    with open(simulation_outfile, 'wb') as f:\n",
    "        savedata = [dfs,acc,ret,pret]\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Evaluation Results: QuickTestOutput/weighted-noinlap-nopitage-nocate-c40/evaluation_result_drank.csv\n"
     ]
    }
   ],
   "source": [
    "if _skip_overwrite and os.path.exists(outputRoot + EVALUATION_RESULT_DF):\n",
    "    print('Load Evaluation Results:',outputRoot + EVALUATION_RESULT_DF)\n",
    "    oracle_eval_result = pd.read_csv(outputRoot + EVALUATION_RESULT_DF)\n",
    "\n",
    "else:    \n",
    "    # get pit laps, pit-covered-laps\n",
    "    # pitdata[year] = [pitlaps, pitcoveredlaps]\n",
    "    with open('pitcoveredlaps-g1.pickle', 'rb') as f:\n",
    "        # The protocol version used is detected automatically, so we do not\n",
    "        # have to specify it.\n",
    "        pitdata = pickle.load(f, encoding='latin1') \n",
    "        \n",
    "    #\n",
    "    # Model,SignAcc,MAE,50-Risk,90-Risk\n",
    "    # \n",
    "    cols = ['Year','Model','laptype','SignAcc','MAE','50-Risk','90-Risk']\n",
    "    plen = prediction_length\n",
    "    usemeanstr='mean'\n",
    "\n",
    "    #load data\n",
    "    # dfs,acc,ret,pret\n",
    "    ranknetdf = dfs   \n",
    "    \n",
    "    retdata = []\n",
    "\n",
    "    #oracle\n",
    "    dfx = ret[mid]\n",
    "    allsamples, alltss = get_allsamples(dfx, year=year)\n",
    "    #_, pret[mid]= prisk_direct_bysamples(ret[mid][0][1], ret[mid][0][2])\n",
    "    _, prisk_vals = prisk_direct_bysamples(allsamples, alltss)\n",
    "\n",
    "    dfout = do_rerank(ranknetdf[year]['oracle_mean'])\n",
    "    accret = stint.get_evalret_shortterm(dfout)[0]\n",
    "    #fsamples, ftss = runs2samples_ex(ranknet_ret[f'oracle-RANK-{year}-inlap-nopitage'],[])\n",
    "    #_, prisk_vals = prisk_direct_bysamples(fsamples, ftss)\n",
    "    retdata.append([year,'Oracle','all', accret[0], accret[1], prisk_vals[1], prisk_vals[2]])\n",
    "\n",
    "    for laptype in ['normal','pit']:\n",
    "        # select the set\n",
    "        pitcoveredlaps = pitdata[year][1]\n",
    "        normallaps = set([x for x in range(1,201)]) - pitcoveredlaps\n",
    "\n",
    "        if laptype == 'normal':\n",
    "            sellaps = normallaps\n",
    "            clearlaps = pitcoveredlaps\n",
    "        else:\n",
    "            sellaps = pitcoveredlaps\n",
    "            clearlaps = normallaps\n",
    "\n",
    "\n",
    "        # pitcoveredlaps start idx = 1\n",
    "        startlaps = [x-plen-1 for x in sellaps]\n",
    "        #sellapidx = np.array([x-1 for x in sellaps])\n",
    "        clearidx = np.array([x-1 for x in clearlaps])\n",
    "        print('sellaps:', len(sellaps), 'clearlaps:',len(clearlaps))\n",
    "\n",
    "        #oracle\n",
    "        #outfile=f'shortterm-dfout-ranknet-indy500-rank-inlap-nopitage-20182019-oracle-l10-alldata-weighted.pickle'\n",
    "        #_all = load_dfout_all(outfile)[0]\n",
    "        #ranknetdf, acc, ret, pret = _all[0],_all[1],_all[2],_all[3]\n",
    "\n",
    "        dfout = do_rerank(ranknetdf[year]['oracle_mean'])\n",
    "\n",
    "        allsamples, alltss = get_allsamples(dfx, year=year)\n",
    "\n",
    "\n",
    "        allsamples, alltss = clear_samples(allsamples, alltss,clearidx)\n",
    "\n",
    "        _, prisk_vals = prisk_direct_bysamples(allsamples, alltss)\n",
    "\n",
    "        dfout = dfout[dfout['startlap'].isin(startlaps)]\n",
    "        accret = stint.get_evalret_shortterm(dfout)[0]\n",
    "\n",
    "        print(year, laptype,'RankNet-Oracle',accret[0], accret[1], prisk_vals[1], prisk_vals[2])\n",
    "        retdata.append([year, 'Oracle',laptype, accret[0], accret[1], prisk_vals[1], prisk_vals[2]])\n",
    "\n",
    "    oracle_eval_result = pd.DataFrame(data=retdata, columns=cols)\n",
    "    if _savedata:\n",
    "        oracle_eval_result.to_csv(outputRoot + EVALUATION_RESULT_DF)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Model</th>\n",
       "      <th>laptype</th>\n",
       "      <th>SignAcc</th>\n",
       "      <th>MAE</th>\n",
       "      <th>50-Risk</th>\n",
       "      <th>90-Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>all</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>1.019850</td>\n",
       "      <td>0.080683</td>\n",
       "      <td>0.076730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.443532</td>\n",
       "      <td>0.039162</td>\n",
       "      <td>0.036285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>pit</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>1.350825</td>\n",
       "      <td>0.106123</td>\n",
       "      <td>0.101510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Year   Model laptype   SignAcc       MAE   50-Risk   90-Risk\n",
       "0           0  2018  Oracle     all  0.877660  1.019850  0.080683  0.076730\n",
       "1           1  2018  Oracle  normal  0.893939  0.443532  0.039162  0.036285\n",
       "2           2  2018  Oracle     pit  0.868852  1.350825  0.106123  0.101510"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle_eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Draw forecasting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Long Forecasting Data: QuickTestOutput/weighted-noinlap-nopitage-nocate-c40/long_forecasting_dfs_drank.pickle\n",
      ".......loaded data, alldata keys= dict_keys([1, 3, 4, 6, 7, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 59, 60, 64, 66, 88, 98])\n"
     ]
    }
   ],
   "source": [
    "if _skip_overwrite and os.path.exists(outputRoot + LONG_FORECASTING_DFS):\n",
    "    fname = outputRoot + LONG_FORECASTING_DFS\n",
    "    print('Load Long Forecasting Data:',fname)\n",
    "    with open(fname, 'rb') as f:\n",
    "        alldata = pickle.load(f, encoding='latin1') \n",
    "    print('.......loaded data, alldata keys=', alldata.keys())\n",
    "\n",
    "else:    \n",
    "\n",
    "    oracle_ret = ret    \n",
    "    mid = f'{testmodel}-%s-%s-%s-%s'%(runts, year, inlapstr[lapmode], featurestr[fmode])\n",
    "    print('eval mid:', mid, 'oracle_ret keys:', ret.keys())\n",
    "\n",
    "    ## init predictor\n",
    "    _predictor =  NaivePredictor(freq= freq, prediction_length = prediction_length)\n",
    "    \n",
    "    oracle_dfout = do_rerank(dfs[year]['oracle_mean'])\n",
    "    carlist = set(list(oracle_dfout.carno.values))\n",
    "    carlist = [int(x) for x in carlist]\n",
    "    print('carlist:', carlist,'len:',len(carlist))\n",
    "    \n",
    "    #carlist = [13, 7, 3, 12]\n",
    "    #carlist = [13]    \n",
    "    \n",
    "    retdata = {}\n",
    "    for carno in carlist:\n",
    "        print(\"*\"*40)\n",
    "        print('Run models for carno=', carno)\n",
    "        # create the test_ds first\n",
    "        test_cars = [carno]\n",
    "\n",
    "        train_ds, test_ds, trainset, testset = stint.make_dataset_byevent(events_id[_test_event], \n",
    "                                         prediction_length,freq, \n",
    "                                         oracle_mode=stint.MODE_ORACLE,\n",
    "                                         run_ts = _run_ts,\n",
    "                                         test_event = _test_event,\n",
    "                                         test_cars=test_cars,\n",
    "                                         half_moving_win = 0,\n",
    "                                         train_ratio = 0.01)\n",
    "\n",
    "        if (len(testset) <= 10 + prediction_length):\n",
    "            print('ts too short, skip ', len(testset))\n",
    "            continue\n",
    "\n",
    "        #by first run samples\n",
    "        samples = oracle_ret[mid][0][1][test_cars[0]]\n",
    "        tss  = oracle_ret[mid][0][2][test_cars[0]]\n",
    "        target_oracle1, tss_oracle1 = long_predict_bysamples('1run-samples', samples, tss)\n",
    "\n",
    "        #by first run output df(_use_mean = true, already reranked)\n",
    "        df = oracle_ret[mid][0][0]\n",
    "        dfin_oracle = df[df['carno']==test_cars[0]]\n",
    "        target_oracle2, tss_oracle2 = long_predict_bydf('oracle-1run-dfout', dfin_oracle)        \n",
    "\n",
    "\n",
    "        #by multi-run mean at oracle_dfout\n",
    "        df = oracle_dfout\n",
    "        dfin_oracle = df[df['carno']==test_cars[0]]\n",
    "        target_oracle3, tss_oracle3 = long_predict_bydf('oracle-multimean', dfin_oracle)        \n",
    "\n",
    "\n",
    "        #no rerank\n",
    "        df = ranknetdf['2018']['oracle_mean']\n",
    "        dfin_oracle = df[df['carno']==test_cars[0]]\n",
    "        target_oracle4, tss_oracle4 = long_predict_bydf('oracle-norerank-multimean', dfin_oracle)        \n",
    "\n",
    "\n",
    "        #by multiple runs\n",
    "        target_oracle_multirun, tss_oracle_multirun = get_ranknet_multirun(\n",
    "                                oracle_ret[mid], \n",
    "                                test_cars[0],sampleCnt=loopcnt)\n",
    "\n",
    "        retdata[carno] = [[tss_oracle1,tss_oracle2,tss_oracle3,tss_oracle4,tss_oracle_multirun],\n",
    "                           [target_oracle1,target_oracle2,target_oracle3,target_oracle4,target_oracle_multirun]]\n",
    "\n",
    "    alldata = retdata    \n",
    "\n",
    "    if _savedata:\n",
    "        with open(outputRoot + LONG_FORECASTING_DFS, 'wb') as f:\n",
    "            pickle.dump(alldata, f, pickle.HIGHEST_PROTOCOL)  \n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Forecasting Figures at: QuickTestOutput/weighted-noinlap-nopitage-nocate-c40/forecast-figs-drank/\n"
     ]
    }
   ],
   "source": [
    "destdir = outputRoot + FORECAST_FIGS_DIR\n",
    "\n",
    "if _skip_overwrite and os.path.exists(destdir):\n",
    "    print('Long Forecasting Figures at:',destdir)\n",
    "\n",
    "else:\n",
    "    with open('stagedata-Indy500_2013_2019_v9_p0.pickle', 'rb') as f:\n",
    "        stagedata = pickle.load(f, encoding='latin1') \n",
    "        _alldata, rankdata, _acldata, _flagdata = stagedata['Indy500-2018']\n",
    "\n",
    "    #destdir = outputRoot + 'oracle-forecast-figs/'\n",
    "    os.makedirs(destdir, exist_ok=True)\n",
    "        \n",
    "    for carno in alldata:\n",
    "        plotoracle(alldata, carno, destdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotoracle(alldata, 13)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotoracle(alldata, 3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QuickTestOutput/weighted-noinlap-nopitage-nocate-c40/'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputRoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
