{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate MLP-pitmodel\n",
    "\n",
    "base: 18./ make_pitstop_dataset-nextpit\n",
    "\n",
    "build a pitstop dataset with <cautions_laps, pitage, gap2nextpit>\n",
    "gluonts interface of Dataset = Iterable[DataEntry], DataEntry = Dict(str, any)\n",
    "\n",
    "+ input pitstop dataset, remove pitstops with pit_oncaution = 1, refer to lapstatus_dataset-fastrun\n",
    "+ context_length = 1, prediction_length = 1\n",
    "+ target : gap to nextpit\n",
    "+ covariates are: cautions_laps, pitage, (carid, eid)\n",
    "+ modeling the distribution of nextpit-gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import random\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import inspect\n",
    "from scipy import stats\n",
    "from pathlib import Path \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pathlib import Path\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.distribution.neg_binomial import NegativeBinomialOutput\n",
    "from gluonts.distribution.student_t import StudentTOutput\n",
    "from gluonts.model.forecast import SampleForecast\n",
    "\n",
    "#from indycar.model.mlp import MLPEstimator\n",
    "from indycar.model.mlp import MLPEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch_hdd/hpda/indycar/notebook/22.PaperFinal'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def test_flag(a, bitflag):\n",
    "    return (a & bitflag) ==  bitflag\n",
    "\n",
    "#\n",
    "# remove NaN at the tail\n",
    "# there should be no nans in the middle of the ts\n",
    "COL_LAPTIME=0\n",
    "COL_RANK=1\n",
    "COL_TRACKSTATUS=2\n",
    "COL_LAPSTATUS=3\n",
    "COL_TIMEDIFF=4\n",
    "COL_CAUTION_LAPS_INSTINT=5\n",
    "COL_LAPS_INSTINT= 6\n",
    "COL_ELAPSED_TIME= 7\n",
    "COL_LAP2NEXTPIT = 8\n",
    "\n",
    "\n",
    "MODE_ORACLE = 0\n",
    "MODE_NOLAP = 1\n",
    "MODE_NOTRACK = 2\n",
    "MODE_TESTZERO = 4\n",
    "MODE_TESTCURTRACK = 8\n",
    "#MODE_STR={MODE_ORACLE:'oracle', MODE_NOLAP:'nolap',MODE_NOTRACK:'notrack',MODE_TEST:'test'}\n",
    "\n",
    "def split_ts(rec, carno, eid):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        ts\n",
    "    output:\n",
    "        nextpit records\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    pitstops = np.where(rec[COL_LAPSTATUS,:] == 1)[0]\n",
    "    \n",
    "    if len(pitstops)==0:\n",
    "        print('no pit ts')\n",
    "        return output\n",
    "    \n",
    "    #pit_oncaution = np.zeros_like((pitstops))\n",
    "    #for pit in pitstops:\n",
    "    #    if rec[COL_TRACKSTATUS,:] == 1:\n",
    "    #        pit_oncaution = 1\n",
    "    pit_oncaution = np.zeros_like((rec[COL_LAP2NEXTPIT,:]))\n",
    "    stint_len = np.zeros_like((rec[COL_LAP2NEXTPIT,:]))\n",
    "    pos = 0\n",
    "    for pit in pitstops:\n",
    "        if rec[COL_TRACKSTATUS,pit] == 1:\n",
    "            #next pit is oncaution\n",
    "            # set pos -> pit as oncaution\n",
    "            pit_oncaution[pos:pit] = 1\n",
    "        else:\n",
    "            pit_oncaution[pos:pit] = 0\n",
    "            \n",
    "        stint_len[pos:pit] = pit - pos\n",
    "        pos = pit\n",
    "        \n",
    "            \n",
    "    #prepare output : lap2nextpit, CAUTION_LAPS_INSTINT,LAPS_INSTINT, pit_oncaution, carno, eid, lap, stintlen\n",
    "    totallen = pitstops[-1]\n",
    "    #output = np.zeros((totallen, 6 ))\n",
    "    #for idx in range(totallen):\n",
    "    #    output[idx, 0] = rec[COL_LAP2NEXTPIT ,idx]\n",
    "    #    output[idx, 1] = rec[COL_CAUTION_LAPS_INSTINT ,idx]\n",
    "    #    output[idx, 2] = rec[COL_LAPS_INSTINT ,idx]\n",
    "    #    output[idx, 3] = pit_oncaution[idx]\n",
    "    #    output[idx, 4] = carno\n",
    "    #    output[idx, 5] = eid\n",
    "        \n",
    "    for idx in range(totallen):\n",
    "        output.append([ rec[COL_LAP2NEXTPIT ,idx]\n",
    "                        ,rec[COL_CAUTION_LAPS_INSTINT ,idx]\n",
    "                        ,rec[COL_LAPS_INSTINT ,idx]\n",
    "                        ,pit_oncaution[idx]\n",
    "                        ,carno\n",
    "                        ,eid\n",
    "                        ,idx\n",
    "                        ,stint_len[idx]\n",
    "                      ])\n",
    "        \n",
    "    return output\n",
    "\n",
    "def make_dataset_byevent(test_event = 'Indy500-2018'):\n",
    "    \"\"\"\n",
    "    split the ts to train and test part by the ratio\n",
    "    \n",
    "    oracle_mode: false to simulate prediction in real by \n",
    "        set the covariates of track and lap status as nan in the testset\n",
    "            \n",
    "    \n",
    "    \"\"\"    \n",
    "    useeid = False\n",
    "    run_ts = COL_LAP2NEXTPIT\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    #_data: eventid, carids, datalist[carnumbers, features, lapnumber]->[laptime, rank, track, lap]]\n",
    "    for _data in laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "        \n",
    "        if events[_data[0]] == test_event:\n",
    "            test_mode = True\n",
    "        else:\n",
    "            test_mode = False\n",
    "            \n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "            \n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "            \n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "            \n",
    "            carno = _data[1][rowid]\n",
    "            carid = global_carids[_data[1][rowid]]\n",
    "            \n",
    "            eid = _data[0]\n",
    "            \n",
    "            # all go to train set\n",
    "            output = split_ts(rec, carno, eid)\n",
    "            #if len(output) == 0:\n",
    "            #    continue\n",
    "            \n",
    "            test_rec_cnt = 0\n",
    "            if not test_mode:\n",
    "                _train.extend(output)\n",
    "                \n",
    "            else:\n",
    "                _test.extend(output)\n",
    "                test_rec_cnt += 1\n",
    "            \n",
    "            #add one ts\n",
    "            print(f'carno:{carno}, totallen:{totallen}, nancount:{nan_count}, test_reccnt:{test_rec_cnt}')\n",
    "\n",
    "        train_set.extend(_train)\n",
    "        test_set.extend(_test)\n",
    "\n",
    "    print(f'train len:{len(train_set)}, test len:{len(test_set)}')\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "def save_dataset(datafile,freq, prediction_length, cardinality, train_ds, test_ds):\n",
    "    with open(datafile, 'wb') as f:\n",
    "        #pack [global_carids, laptime_data]\n",
    "        savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "        #savedata = [freq, train_set, test_set]\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_inlap_status = 0\n",
    "#years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "#events = ['Indy500']\n",
    "events = [f'Indy500-{x}' for x in years]\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "dbid = f'Indy500_{years[0]}_{years[-1]}_v9_p{_inlap_status}'\n",
    "testevent = 'Indy500-2018'\n",
    "# start from here\n",
    "import pickle\n",
    "#with open('laptime_rank_timediff_fulltest-oracle-%s.pickle'%year, 'rb') as f:\n",
    "with open(f'laptime_rank_timediff_pit-oracle-{dbid}.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    global_carids, laptime_data = pickle.load(f, encoding='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carno:1, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:4, totallen:0, nancount:200, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:6, totallen:30, nancount:170, test_reccnt:0\n",
      "carno:7, totallen:177, nancount:23, test_reccnt:0\n",
      "carno:8, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:187, nancount:13, test_reccnt:0\n",
      "carno:11, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:170, nancount:30, test_reccnt:0\n",
      "carno:16, totallen:179, nancount:21, test_reccnt:0\n",
      "carno:18, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:19, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:21, totallen:170, nancount:30, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:191, nancount:9, test_reccnt:0\n",
      "carno:41, totallen:178, nancount:22, test_reccnt:0\n",
      "carno:55, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:60, totallen:168, nancount:32, test_reccnt:0\n",
      "carno:63, totallen:45, nancount:155, test_reccnt:0\n",
      "carno:77, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:78, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:81, totallen:182, nancount:18, test_reccnt:0\n",
      "carno:83, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:91, totallen:43, nancount:157, test_reccnt:0\n",
      "carno:98, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:6, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:7, totallen:189, nancount:11, test_reccnt:0\n",
      "carno:8, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:9, totallen:152, nancount:48, test_reccnt:0\n",
      "carno:10, totallen:175, nancount:25, test_reccnt:0\n",
      "carno:11, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:43, nancount:157, test_reccnt:0\n",
      "carno:16, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:17, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:18, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:19, totallen:193, nancount:7, test_reccnt:0\n",
      "carno:20, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:33, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:34, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:41, totallen:187, nancount:13, test_reccnt:0\n",
      "carno:63, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:67, totallen:122, nancount:78, test_reccnt:0\n",
      "carno:68, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:77, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:83, totallen:148, nancount:52, test_reccnt:0\n",
      "carno:91, totallen:86, nancount:114, test_reccnt:0\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:7, totallen:200, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:8, totallen:0, nancount:200, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:149, nancount:51, test_reccnt:0\n",
      "carno:11, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:17, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:18, totallen:115, nancount:85, test_reccnt:0\n",
      "carno:19, totallen:115, nancount:85, test_reccnt:0\n",
      "carno:20, totallen:100, nancount:100, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:24, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:25, totallen:197, nancount:3, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:32, totallen:99, nancount:101, test_reccnt:0\n",
      "carno:41, totallen:169, nancount:31, test_reccnt:0\n",
      "no pit ts\n",
      "carno:43, totallen:0, nancount:200, test_reccnt:0\n",
      "carno:48, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:63, totallen:178, nancount:22, test_reccnt:0\n",
      "carno:83, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:88, totallen:61, nancount:139, test_reccnt:0\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:47, nancount:153, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:99, nancount:101, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:7, totallen:125, nancount:75, test_reccnt:0\n",
      "carno:8, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:11, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:162, nancount:38, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:16, totallen:192, nancount:8, test_reccnt:0\n",
      "carno:18, totallen:114, nancount:86, test_reccnt:0\n",
      "carno:19, totallen:193, nancount:7, test_reccnt:0\n",
      "carno:20, totallen:97, nancount:103, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:193, nancount:7, test_reccnt:0\n",
      "carno:24, totallen:65, nancount:135, test_reccnt:0\n",
      "carno:25, totallen:108, nancount:92, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:29, totallen:179, nancount:21, test_reccnt:0\n",
      "carno:35, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:41, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:42, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:61, totallen:190, nancount:10, test_reccnt:0\n",
      "carno:63, totallen:195, nancount:5, test_reccnt:0\n",
      "carno:77, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:88, totallen:194, nancount:6, test_reccnt:0\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:2, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:3, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:4, totallen:56, nancount:144, test_reccnt:0\n",
      "carno:5, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:7, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:8, totallen:200, nancount:0, test_reccnt:0\n",
      "no pit ts\n",
      "carno:9, totallen:28, nancount:172, test_reccnt:0\n",
      "carno:10, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:11, totallen:174, nancount:26, test_reccnt:0\n",
      "carno:12, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:16, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:17, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:18, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:19, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:24, totallen:113, nancount:87, test_reccnt:0\n",
      "carno:26, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:112, nancount:88, test_reccnt:0\n",
      "carno:29, totallen:167, nancount:33, test_reccnt:0\n",
      "carno:40, totallen:133, nancount:67, test_reccnt:0\n",
      "carno:44, totallen:97, nancount:103, test_reccnt:0\n",
      "carno:50, totallen:56, nancount:144, test_reccnt:0\n",
      "carno:63, totallen:186, nancount:14, test_reccnt:0\n",
      "carno:77, totallen:33, nancount:167, test_reccnt:0\n",
      "carno:83, totallen:123, nancount:77, test_reccnt:0\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:1, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:3, totallen:145, nancount:55, test_reccnt:1\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:6, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:7, totallen:184, nancount:16, test_reccnt:1\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:10, totallen:52, nancount:148, test_reccnt:1\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:13, totallen:49, nancount:151, test_reccnt:1\n",
      "carno:14, totallen:171, nancount:29, test_reccnt:1\n",
      "carno:15, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:17, totallen:190, nancount:10, test_reccnt:1\n",
      "carno:18, totallen:132, nancount:68, test_reccnt:1\n",
      "carno:19, totallen:196, nancount:4, test_reccnt:1\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:21, totallen:190, nancount:10, test_reccnt:1\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:23, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:24, totallen:124, nancount:76, test_reccnt:1\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:26, totallen:189, nancount:11, test_reccnt:1\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:29, totallen:200, nancount:0, test_reccnt:1\n",
      "no pit ts\n",
      "carno:30, totallen:32, nancount:168, test_reccnt:1\n",
      "carno:32, totallen:109, nancount:91, test_reccnt:1\n",
      "carno:33, totallen:45, nancount:155, test_reccnt:1\n",
      "carno:59, totallen:195, nancount:5, test_reccnt:1\n",
      "carno:60, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:64, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:66, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:88, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:98, totallen:200, nancount:0, test_reccnt:1\n",
      "carno:2, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:3, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:4, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:5, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:7, totallen:183, nancount:17, test_reccnt:0\n",
      "carno:9, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:10, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:12, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:14, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:15, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:18, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:19, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:20, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:21, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:22, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:23, totallen:181, nancount:19, test_reccnt:0\n",
      "carno:24, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:25, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:26, totallen:169, nancount:31, test_reccnt:0\n",
      "carno:27, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:28, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:30, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:32, totallen:66, nancount:134, test_reccnt:0\n",
      "carno:33, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:39, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:42, totallen:183, nancount:17, test_reccnt:0\n",
      "carno:48, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:60, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:63, totallen:200, nancount:0, test_reccnt:0\n",
      "carno:77, totallen:184, nancount:16, test_reccnt:0\n",
      "carno:81, totallen:54, nancount:146, test_reccnt:0\n",
      "no pit ts\n",
      "carno:88, totallen:0, nancount:200, test_reccnt:0\n",
      "carno:98, totallen:180, nancount:20, test_reccnt:0\n",
      "train len:30284, test len:4920\n"
     ]
    }
   ],
   "source": [
    "train, test =  make_dataset_byevent(test_event = 'Indy500-2018')\n",
    "#prepare output : lap2nextpit, CAUTION_LAPS_INSTINT,LAPS_INSTINT, pit_oncaution, carno, eid, lap\n",
    "df_train = pd.DataFrame(train,columns=['lap2nextpit', 'caution_laps','pitage', 'pit_oncaution', \n",
    "                 'carno','eid','lap','stint_len'])\n",
    "df_test = pd.DataFrame(test,columns=['lap2nextpit', 'caution_laps','pitage', 'pit_oncaution', \n",
    "                 'carno','eid','lap','stint_len'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datafile = f'pitstop_nextpit_dataset-{dbid}-t{testevent}.pickle'\n",
    "#with open(datafile, 'wb') as f:\n",
    "#    savedata = [df_train, df_test, events, testevent]\n",
    "#    pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lap2nextpit</th>\n",
       "      <th>caution_laps</th>\n",
       "      <th>pitage</th>\n",
       "      <th>pit_oncaution</th>\n",
       "      <th>carno</th>\n",
       "      <th>eid</th>\n",
       "      <th>lap</th>\n",
       "      <th>stint_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30279</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30280</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30281</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>176</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30282</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>177</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30283</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>178</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30284 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lap2nextpit  caution_laps  pitage  pit_oncaution  carno  eid  lap  \\\n",
       "0             30.0           0.0     1.0            0.0      1    0    0   \n",
       "1             29.0           0.0     2.0            0.0      1    0    1   \n",
       "2             28.0           0.0     3.0            0.0      1    0    2   \n",
       "3             27.0           1.0     4.0            0.0      1    0    3   \n",
       "4             26.0           2.0     5.0            0.0      1    0    4   \n",
       "...            ...           ...     ...            ...    ...  ...  ...   \n",
       "30279          2.0           0.0     0.0            1.0     98    6  174   \n",
       "30280          1.0           1.0     1.0            1.0     98    6  175   \n",
       "30281          2.0           0.0     0.0            1.0     98    6  176   \n",
       "30282          1.0           1.0     1.0            1.0     98    6  177   \n",
       "30283          1.0           0.0     0.0            1.0     98    6  178   \n",
       "\n",
       "       stint_len  \n",
       "0           30.0  \n",
       "1           30.0  \n",
       "2           30.0  \n",
       "3           30.0  \n",
       "4           30.0  \n",
       "...          ...  \n",
       "30279        2.0  \n",
       "30280        2.0  \n",
       "30281        2.0  \n",
       "30282        2.0  \n",
       "30283        1.0  \n",
       "\n",
       "[30284 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make gluonts\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "def makedb(data, scaler='standard', perm = True):\n",
    "    db = []\n",
    "    start = pd.Timestamp(\"01-01-2019\", freq='1min')  # can be different for each time series\n",
    "    \n",
    "    scalers = {'minmax':MinMaxScaler(), 'standard':StandardScaler()}\n",
    "    \n",
    "    if isinstance(scaler, str):\n",
    "        if scaler in scalers:\n",
    "            scaler = scalers[scaler]\n",
    "            scaler.fit(data)\n",
    "            df = scaler.transform(data)\n",
    "        else:\n",
    "            # no scaler\n",
    "            df = data\n",
    "    else:\n",
    "        #use input scaler\n",
    "        #scaler.fit(data)\n",
    "        df = scaler.transform(data)\n",
    "        \n",
    "    \n",
    "    #permute\n",
    "    if perm:\n",
    "        perm = np.random.permutation(len(df))\n",
    "        df = df[perm]\n",
    "    \n",
    "    for x in df:\n",
    "        \n",
    "        #db.append({'target':np.array(x[0]), 'feat':[np.array(x[1]),np.array(x[2])]})\n",
    "        db.append({'target':np.array([x[0]]), 'feat':np.array([x[1],x[2]]),\n",
    "                  \"start\":start, 'forecast_start':start})\n",
    "        #db.append({'target':np.array(x[0]).reshape((1,-1)), 'feat':[np.array(x[1]).reshape((1,-1)),np.array(x[2]).reshape((1,-1))]})\n",
    "        \n",
    "    return db, scaler, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fulltestdb(scaler, maxgap=60):\n",
    "    db = []\n",
    "    start = pd.Timestamp(\"01-01-2019\", freq='1min')  # can be different for each time series\n",
    "\n",
    "    data = []\n",
    "    for caution_lap in range(maxgap):\n",
    "        for pitage in range(caution_lap, maxgap):\n",
    "            data.append([0.,caution_lap, pitage ])\n",
    "    data = np.array(data)\n",
    "    \n",
    "    if not isinstance(scaler, str):\n",
    "        df = scaler.transform(data)\n",
    "    else:\n",
    "        df = data\n",
    "    \n",
    "    #data\n",
    "    print(f'make full testdb: {len(df)} records')\n",
    "    for x in df:\n",
    "        db.append({'target':np.array([x[0]]), 'feat':np.array([x[1],x[2]]),\n",
    "                  \"start\":start, 'forecast_start':start})\n",
    "            \n",
    "    return db, scaler, df, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, layers=[10,10,5], output = 'student', dropout = .5, id='all',\n",
    "               outputfile=''):\n",
    "    distr_outputs ={'student':StudentTOutput(),  \n",
    "                    'negbin':NegativeBinomialOutput() \n",
    "                   }\n",
    "    if not output in distr_outputs:\n",
    "        print(f'distr_output: {output} not found error.')\n",
    "        return\n",
    "    \n",
    "    distr_output = distr_outputs[output]\n",
    "    \n",
    "    modelid = 'mlp-d%s-e%s-l%s-%s-d%s'%(id, epochs, '-'.join([str(x) for x in layers]), output, dropout)\n",
    "    \n",
    "    estimator = MLPEstimator(\n",
    "        num_hidden_dimensions=layers,\n",
    "        prediction_length=1,\n",
    "        context_length=1,\n",
    "        freq='1min',\n",
    "        dropout = dropout,\n",
    "        distr_output = distr_output,\n",
    "        trainer=Trainer(ctx=\"gpu(0)\", \n",
    "                        batch_size = 32,\n",
    "                        epochs= epochs,\n",
    "                        learning_rate=1e-3,\n",
    "                        hybridize=False,\n",
    "                        num_batches_per_epoch=100\n",
    "                       )\n",
    "    )    \n",
    "\n",
    "    predictor = estimator.train(train_ds)\n",
    "\n",
    "    if outputfile != '':\n",
    "        outfile = outputfile + '-' + modelid\n",
    "        if not os.path.exists(outfile):\n",
    "            os.mkdir(outfile)\n",
    "        print('save trained model to', outfile)\n",
    "        predictor.serialize(Path(outfile)) \n",
    "    \n",
    "    return predictor, modelid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(predictor, test_ds):\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset    \n",
    "        predictor=predictor,  # predictor                                  \n",
    "        num_samples=1000,  # number of sample paths we want for evaluation \n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)     \n",
    "    evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9]) \n",
    "    agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n",
    "    print(json.dumps(agg_metrics, indent=4)) \n",
    "    return tss, forecasts, agg_metrics\n",
    "\n",
    "\n",
    "def raw_eval(tss, forecasts):\n",
    "    \"\"\"\n",
    "    scaler\n",
    "    \"\"\"\n",
    "    rec = np.zeros((3))\n",
    "\n",
    "    truth, pred = [],[]\n",
    "    #go through the dataset\n",
    "    for idx in range(len(tss)):\n",
    "        rec[0] = list(tss[idx].values)[0]\n",
    "    \n",
    "        if isinstance(scaler, str):\n",
    "            truth.append(int(rec[0]))\n",
    "        else:\n",
    "            truth.append(int(scaler.inverse_transform(rec)[0]))\n",
    "    \n",
    "        rec[0] = np.mean(forecasts[idx].samples)\n",
    "        \n",
    "        if isinstance(scaler, str):\n",
    "            pred.append(int(rec[0]))    \n",
    "        else:\n",
    "            pred.append(int(scaler.inverse_transform(rec)[0]))        \n",
    "\n",
    "    #get mae\n",
    "    mae = mean_absolute_error(truth, pred)\n",
    "    print('mae = ', mae)\n",
    "    return mae\n",
    "    \n",
    "\n",
    "def save_model(predictor, outdir):\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    \n",
    "    predictor.serialize(Path(outdir)) \n",
    "\n",
    "def get_pred(tss, forecasts, idx,raw_forecast = False):\n",
    "    rec = np.zeros((3))\n",
    "    rec[0] = list(tss[idx].values)[0]\n",
    "    \n",
    "    if isinstance(scaler, str):\n",
    "        truth = int(rec[0])\n",
    "    else:\n",
    "        truth = int(scaler.inverse_transform(rec)[0])\n",
    "    \n",
    "    ret = []\n",
    "    for sample in forecasts[idx].samples:\n",
    "        rec[0] = sample\n",
    "        if isinstance(scaler, str) or raw_forecast:\n",
    "            ret.append(int(rec[0]))    \n",
    "        else:\n",
    "            ret.append(int(scaler.inverse_transform(rec)[0]))    \n",
    "        \n",
    "    print('idx:', idx, 't:', truth, 'p:', int(np.mean(ret)))\n",
    "    plt.hist(ret, bins=range(min(ret),max(ret)+1), alpha=0.7, label='%s'%idx)\n",
    "    return truth, ret\n",
    "\n",
    "def run_test(tss, forecasts, testlist, raw_forecast = False):\n",
    "    for idx in testlist:\n",
    "        get_pred(tss, forecasts, idx, raw_forecast)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_full_pitmodel(mid, runid, maxgap=60):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        p[mid]; predictor\n",
    "        runid ; 'all' or 'sel' of the trainning set\n",
    "    \"\"\"\n",
    "    \n",
    "    #get scaler\n",
    "    scaler = _data[runid][4]\n",
    "\n",
    "    # make full test set\n",
    "    test_ds, _, _, test_all = make_fulltestdb(scaler, maxgap = maxgap)\n",
    "\n",
    "    tss,forecasts, _ = eval_model(p[mid], test_ds)\n",
    "\n",
    "    pitmodel = PitModel()\n",
    "\n",
    "    #pitmodel.save_model(f'pitmodel-m{maxgap}-{mid}.pickle', test_all, forecasts, scaler)\n",
    "    pitmodel.save_model(f'pitmodel-m{maxgap}-{mid}-1k.pickle', test_all, forecasts, scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24973 13976\n"
     ]
    }
   ],
   "source": [
    "_trainmodel = False\n",
    "\n",
    "train_sel = df_train[(df_train['pit_oncaution']==0) &(df_train['stint_len']>23)]\n",
    "train_sel_2013_2017 = train_sel[train_sel['eid']<5]\n",
    "train_all_2013_2017 = df_train[df_train['eid']<5]\n",
    "\n",
    "print(len(train_all_2013_2017), len(train_sel_2013_2017))    \n",
    "\n",
    "test_sel = df_test[(df_test['pit_oncaution']==0) &(df_test['stint_len']>23)]\n",
    "test_all = df_test\n",
    "\n",
    "_data = {}\n",
    "#model store\n",
    "p, t, s, e = {}, {} ,{}, {}\n",
    "\n",
    "# negbin, use no sclaer\n",
    "#train_ds, scaler = makedb(train_sel[['lap2nextpit','caution_laps','pitage']].values, scaler='')\n",
    "#train_ds, scaler = makedb(train_sel[['lap2nextpit','caution_laps','pitage']].values, scaler='minmax')\n",
    "train_ds, scaler, train_set = makedb(train_sel[['lap2nextpit','caution_laps','pitage']].values, scaler='standard')\n",
    "test_ds, _, test_set = makedb(test_sel[['lap2nextpit','caution_laps','pitage']].values, scaler, perm=False)\n",
    "\n",
    "# selected db\n",
    "trainset = train_sel_2013_2017[['lap2nextpit','caution_laps','pitage']].values\n",
    "testset = test_sel[['lap2nextpit','caution_laps','pitage']].values\n",
    "train_ds, scaler, _ = makedb(trainset, scaler='standard')\n",
    "test_ds, _, _ = makedb(testset, scaler, perm=False)\n",
    "\n",
    "_data['sel'] = [trainset, testset, train_ds, test_ds, scaler]\n",
    "\n",
    "\n",
    "# selected db\n",
    "trainset = train_all_2013_2017[['lap2nextpit','caution_laps','pitage']].values\n",
    "testset = test_all[['lap2nextpit','caution_laps','pitage']].values\n",
    "train_ds, scaler, _ = makedb(trainset, scaler='standard')\n",
    "test_ds, _, _ = makedb(testset, scaler, perm=False)\n",
    "\n",
    "_data['all'] = [trainset, testset, train_ds, test_ds, scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _trainmodel == True:\n",
    "    #trainset, testset, train_ds, test_ds, scaler = _data['all']\n",
    "    trainset, testset, train_ds, test_ds, scaler = _data['sel']\n",
    "    #pm, mid = train_model(500,dropout = 0.1,id='sel',outputfile = 'savemodle')\n",
    "    pm, mid = train_model(500,dropout = 0.1,id='sel',outputfile = 'savemodel')\n",
    "\n",
    "    #t[mid],s[mid], e[mid] = eval_model(pm, test_ds)\n",
    "    p[mid] = pm\n",
    "\n",
    "    #mae = raw_eval(t[mid],s[mid])\n",
    "    #run_test(t[mid], s[mid], [31,816,846,856])\n",
    "\n",
    "    #save_full_pitmodel(mid, 'sel', maxgap=65)\n",
    "\n",
    "    ### run train on all data\n",
    "    #trainset, testset, train_ds, test_ds, scaler = _data['all']\n",
    "    ##pm, mid = train_model(500,dropout = 0.1,id='all',outputfile = 'savemodle')\n",
    "    #pm, mid = train_model(5,dropout = 0.1,id='all',outputfile = 'savemodel')\n",
    "    ##t[mid],s[mid], e[mid] = eval_model(pm, test_ds)\n",
    "    #p[mid] = pm\n",
    "\n",
    "    #mae = raw_eval(t[mid],s[mid])\n",
    "    #run_test(t[mid], s[mid], [31,816,846,856])\n",
    "    #save_full_pitmodel(mid, 'all', maxgap=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# test on each car separately and save model data\n",
    "#\n",
    "#load model\n",
    "mid = 'dsel-e500-l10-10-5-student-d0.1'\n",
    "modelfile = f'savemodel-mlp-{mid}'\n",
    "predictor =  Predictor.deserialize(Path(modelfile))\n",
    "\n",
    "# eval on each car in test_event\n",
    "trainset, testset, train_ds, test_ds, scaler = _data['sel']\n",
    "carlist = set(df_test['carno'].values)\n",
    "\n",
    "alldata  = {}\n",
    "for carno in carlist:\n",
    "    acar = df_test[df_test['carno']==carno]\n",
    "      \n",
    "    #prepare test set\n",
    "    test_ds, _, test_set = makedb(acar[['lap2nextpit','caution_laps','pitage']].values, scaler, perm=False)\n",
    "\n",
    "    # run prediction\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_ds,  # test dataset    \n",
    "        predictor=predictor,  # predictor                                  \n",
    "        num_samples=100,  # number of sample paths we want for evaluation \n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    \n",
    "    # save data\n",
    "    data = predictor.prediction_net.savedata\n",
    "    alldata[carno] = data\n",
    "    predictor.prediction_net.reset_savedata()\n",
    "    \n",
    "#save all in one file\n",
    "savefile = f'PitModel-savedata_{mid}.pickle'\n",
    "with open(savefile, 'wb') as f: \n",
    "    pickle.dump(alldata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile = 'PitModel-savedata_dsel-e500-l10-10-5-student-d0.1.pickle'\n",
    "with open(savefile, 'rb') as f: \n",
    "    alldata = pickle.load(f, encoding='latin1') \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 3, 4, 6, 7, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 59, 60, 64, 66, 88, 98])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = alldata[12]['mlpoutput']\n",
    "len(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5613816, -1.5766785]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.6255078 , -0.68457186, -0.46825197, -0.518488  ,\n",
       "         -0.9469865 ]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpoutput = alldata[12]['mlpoutput']\n",
    "print(len(mlpoutput))\n",
    "\n",
    "mlpoutput[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.23615313e+00,  2.54198104e-01,  3.67092848e+00],\n",
       "       [ 1.13235927e+00,  2.43951127e-01,  3.74481869e+00],\n",
       "       [ 1.02856517e+00,  2.34070629e-01,  3.81988335e+00],\n",
       "       [ 9.24771309e-01,  2.24546850e-01,  3.89605451e+00],\n",
       "       [ 8.20977449e-01,  2.15370238e-01,  3.97326517e+00],\n",
       "       [ 7.17183471e-01,  2.06531227e-01,  4.05145073e+00],\n",
       "       [ 6.36848867e-01,  2.09689304e-01,  4.08367348e+00],\n",
       "       [ 5.49282670e-01,  2.13657677e-01,  4.15266800e+00],\n",
       "       [ 4.54483688e-01,  2.13643044e-01,  4.25413370e+00],\n",
       "       [ 3.59684885e-01,  2.13628381e-01,  4.35682201e+00],\n",
       "       [ 2.64885902e-01,  2.13613704e-01,  4.46062660e+00],\n",
       "       [ 1.70086935e-01,  2.13599026e-01,  4.56544828e+00],\n",
       "       [ 7.52880424e-02,  2.13584349e-01,  4.67119360e+00],\n",
       "       [-1.95109248e-02,  2.13569671e-01,  4.77777767e+00],\n",
       "       [-1.10752173e-01,  2.13712960e-01,  4.87988472e+00],\n",
       "       [-2.03185767e-01,  2.17365474e-01,  4.98375034e+00],\n",
       "       [-2.99104959e-01,  2.29087815e-01,  5.10039711e+00],\n",
       "       [-4.06374872e-01,  2.39319369e-01,  5.23786497e+00],\n",
       "       [-4.95453119e-01,  2.27788970e-01,  5.44221687e+00],\n",
       "       [-6.16553783e-01,  2.32855409e-01,  5.61743069e+00],\n",
       "       [-7.42382705e-01,  2.40492165e-01,  5.78904152e+00],\n",
       "       [-8.22333872e-01,  2.27785736e-01,  5.97808075e+00],\n",
       "       [-9.05608773e-01,  2.19314724e-01,  6.16299820e+00],\n",
       "       [-9.81001914e-01,  2.10158825e-01,  6.34667253e+00],\n",
       "       [-1.05245185e+00,  2.00421661e-01,  6.53081226e+00],\n",
       "       [-1.12390184e+00,  1.91093773e-01,  6.71532297e+00],\n",
       "       [-1.19535184e+00,  1.82161510e-01,  6.90014315e+00],\n",
       "       [-1.26680195e+00,  1.73611537e-01,  7.08522129e+00],\n",
       "       [-1.33825195e+00,  1.65430456e-01,  7.27051258e+00],\n",
       "       [-1.40970182e+00,  1.57605246e-01,  7.45598173e+00],\n",
       "       [-1.48115218e+00,  1.50123015e-01,  7.64159966e+00],\n",
       "       [ 1.34997916e+00,  2.58699507e-01,  3.60328460e+00],\n",
       "       [ 1.23615313e+00,  2.54198104e-01,  3.67092848e+00],\n",
       "       [ 1.13235927e+00,  2.43951127e-01,  3.74481869e+00],\n",
       "       [ 1.02856517e+00,  2.34070629e-01,  3.81988335e+00],\n",
       "       [ 9.24771309e-01,  2.24546850e-01,  3.89605451e+00],\n",
       "       [ 8.20977449e-01,  2.15370238e-01,  3.97326517e+00],\n",
       "       [ 7.17183471e-01,  2.06531227e-01,  4.05145073e+00],\n",
       "       [ 6.36848867e-01,  2.09689304e-01,  4.08367348e+00],\n",
       "       [ 5.49282670e-01,  2.13657677e-01,  4.15266800e+00],\n",
       "       [ 4.54483688e-01,  2.13643044e-01,  4.25413370e+00],\n",
       "       [ 3.59684885e-01,  2.13628381e-01,  4.35682201e+00],\n",
       "       [ 2.64885902e-01,  2.13613704e-01,  4.46062660e+00],\n",
       "       [ 1.70086935e-01,  2.13599026e-01,  4.56544828e+00],\n",
       "       [ 7.52880424e-02,  2.13584349e-01,  4.67119360e+00],\n",
       "       [-1.95109248e-02,  2.13569671e-01,  4.77777767e+00],\n",
       "       [-1.10752173e-01,  2.13712960e-01,  4.87988472e+00],\n",
       "       [-7.85453022e-02,  2.28430569e-01,  4.80854893e+00],\n",
       "       [-1.33882597e-01,  2.33859345e-01,  4.87882233e+00],\n",
       "       [ 1.34997916e+00,  2.58699507e-01,  3.60328460e+00],\n",
       "       [ 1.41100764e+00,  2.54173487e-01,  3.61720824e+00],\n",
       "       [ 1.36420548e+00,  2.51051843e-01,  3.65567303e+00],\n",
       "       [ 1.31740308e+00,  2.47963995e-01,  3.69449019e+00],\n",
       "       [ 1.27060068e+00,  2.44909704e-01,  3.73364925e+00],\n",
       "       [ 1.15545559e+00,  2.47734606e-01,  3.79224372e+00],\n",
       "       [ 1.04031038e+00,  2.50588119e-01,  3.85153246e+00],\n",
       "       [ 9.25165176e-01,  2.53470600e-01,  3.91148329e+00],\n",
       "       [ 8.78362954e-01,  2.50356525e-01,  3.95232677e+00],\n",
       "       [ 8.31560671e-01,  2.47276202e-01,  3.99344826e+00],\n",
       "       [ 7.84758270e-01,  2.44229361e-01,  4.03483820e+00],\n",
       "       [ 7.37955987e-01,  2.41215706e-01,  4.07648754e+00],\n",
       "       [ 6.91153586e-01,  2.38234922e-01,  4.11838627e+00],\n",
       "       [ 5.76110125e-01,  2.41026282e-01,  4.18071365e+00],\n",
       "       [ 4.88144577e-01,  2.53156185e-01,  4.20400715e+00],\n",
       "       [ 3.85777056e-01,  2.51151800e-01,  4.31951714e+00],\n",
       "       [ 2.88407981e-01,  2.50742167e-01,  4.43060589e+00],\n",
       "       [ 1.91038921e-01,  2.50333011e-01,  4.54289913e+00],\n",
       "       [ 1.55450985e-01,  2.45824069e-01,  4.61062431e+00],\n",
       "       [ 1.28055558e-01,  2.46775791e-01,  4.63443375e+00],\n",
       "       [ 1.00660205e-01,  2.47730792e-01,  4.65828705e+00],\n",
       "       [ 7.32649565e-02,  2.48689011e-01,  4.68218327e+00],\n",
       "       [ 4.58696038e-02,  2.49650553e-01,  4.70612144e+00],\n",
       "       [-4.26858440e-02,  2.55210429e-01,  4.77277088e+00],\n",
       "       [-1.02139018e-01,  2.48814017e-01,  4.84950829e+00],\n",
       "       [-2.16243565e-01,  2.27804169e-01,  5.07086945e+00],\n",
       "       [-3.30348074e-01,  2.08388790e-01,  5.29464912e+00],\n",
       "       [-4.43760693e-01,  1.90553501e-01,  5.51953077e+00],\n",
       "       [-5.77894151e-01,  1.95432022e-01,  5.65949488e+00],\n",
       "       [-7.20519662e-01,  2.03079715e-01,  5.79138708e+00],\n",
       "       [-8.01081181e-01,  1.92467257e-01,  5.95828533e+00],\n",
       "       [-8.79023731e-01,  1.85295925e-01,  6.12572432e+00],\n",
       "       [-9.58245039e-01,  1.79088101e-01,  6.29263115e+00],\n",
       "       [-1.03746641e+00,  1.73070744e-01,  6.45992565e+00],\n",
       "       [-1.11668777e+00,  1.67239144e-01,  6.62754869e+00],\n",
       "       [-1.18634713e+00,  1.59756556e-01,  6.79550219e+00],\n",
       "       [-1.25257289e+00,  1.51957780e-01,  6.96370983e+00],\n",
       "       [-1.31879878e+00,  1.44512847e-01,  7.13211823e+00],\n",
       "       [-1.38502455e+00,  1.37408137e-01,  7.30069447e+00],\n",
       "       [-1.45125043e+00,  1.30630344e-01,  7.46941423e+00],\n",
       "       [-1.51747596e+00,  1.24166541e-01,  7.63825369e+00],\n",
       "       [-1.58370197e+00,  1.18003950e-01,  7.80719709e+00],\n",
       "       [-1.64992762e+00,  1.12130389e-01,  7.97622585e+00],\n",
       "       [-1.71615362e+00,  1.06533885e-01,  8.14532757e+00],\n",
       "       [ 1.34997916e+00,  2.58699507e-01,  3.60328460e+00],\n",
       "       [ 1.23615313e+00,  2.54198104e-01,  3.67092848e+00],\n",
       "       [ 1.13235927e+00,  2.43951127e-01,  3.74481869e+00],\n",
       "       [ 1.02856517e+00,  2.34070629e-01,  3.81988335e+00],\n",
       "       [ 9.24771309e-01,  2.24546850e-01,  3.89605451e+00],\n",
       "       [ 8.20977449e-01,  2.15370238e-01,  3.97326517e+00],\n",
       "       [ 7.17183471e-01,  2.06531227e-01,  4.05145073e+00],\n",
       "       [ 6.36848867e-01,  2.09689304e-01,  4.08367348e+00],\n",
       "       [ 5.49282670e-01,  2.13657677e-01,  4.15266800e+00],\n",
       "       [ 4.54483688e-01,  2.13643044e-01,  4.25413370e+00],\n",
       "       [ 3.59684885e-01,  2.13628381e-01,  4.35682201e+00],\n",
       "       [ 2.64885902e-01,  2.13613704e-01,  4.46062660e+00],\n",
       "       [ 1.70086935e-01,  2.13599026e-01,  4.56544828e+00],\n",
       "       [ 7.52880424e-02,  2.13584349e-01,  4.67119360e+00],\n",
       "       [-1.95109248e-02,  2.13569671e-01,  4.77777767e+00],\n",
       "       [-1.10752173e-01,  2.13712960e-01,  4.87988472e+00],\n",
       "       [-2.03185767e-01,  2.17365474e-01,  4.98375034e+00],\n",
       "       [-2.99104959e-01,  2.29087815e-01,  5.10039711e+00],\n",
       "       [-4.06374872e-01,  2.39319369e-01,  5.23786497e+00],\n",
       "       [-4.95453119e-01,  2.27788970e-01,  5.44221687e+00],\n",
       "       [-6.16553783e-01,  2.32855409e-01,  5.61743069e+00],\n",
       "       [-7.42382705e-01,  2.40492165e-01,  5.78904152e+00],\n",
       "       [-8.22333872e-01,  2.27785736e-01,  5.97808075e+00],\n",
       "       [-9.05608773e-01,  2.19314724e-01,  6.16299820e+00],\n",
       "       [-9.81001914e-01,  2.10158825e-01,  6.34667253e+00],\n",
       "       [-1.05245185e+00,  2.00421661e-01,  6.53081226e+00],\n",
       "       [-1.12390184e+00,  1.91093773e-01,  6.71532297e+00],\n",
       "       [-1.19535184e+00,  1.82161510e-01,  6.90014315e+00],\n",
       "       [-1.26680195e+00,  1.73611537e-01,  7.08522129e+00],\n",
       "       [-1.33825195e+00,  1.65430456e-01,  7.27051258e+00],\n",
       "       [-1.40970182e+00,  1.57605246e-01,  7.45598173e+00],\n",
       "       [-1.48115218e+00,  1.50123015e-01,  7.64159966e+00],\n",
       "       [-1.55260205e+00,  1.42971143e-01,  7.82734060e+00],\n",
       "       [-1.62405205e+00,  1.36137262e-01,  8.01318359e+00],\n",
       "       [-1.69550204e+00,  1.29609331e-01,  8.19911194e+00],\n",
       "       [ 1.34997916e+00,  2.58699507e-01,  3.60328460e+00],\n",
       "       [ 1.23615313e+00,  2.54198104e-01,  3.67092848e+00],\n",
       "       [ 1.13235927e+00,  2.43951127e-01,  3.74481869e+00],\n",
       "       [ 1.02856517e+00,  2.34070629e-01,  3.81988335e+00],\n",
       "       [ 9.24771309e-01,  2.24546850e-01,  3.89605451e+00],\n",
       "       [ 8.20977449e-01,  2.15370238e-01,  3.97326517e+00],\n",
       "       [ 7.17183471e-01,  2.06531227e-01,  4.05145073e+00],\n",
       "       [ 6.36848867e-01,  2.09689304e-01,  4.08367348e+00],\n",
       "       [ 5.49282670e-01,  2.13657677e-01,  4.15266800e+00],\n",
       "       [ 4.54483688e-01,  2.13643044e-01,  4.25413370e+00],\n",
       "       [ 5.19988596e-01,  2.55028129e-01,  4.08641148e+00],\n",
       "       [ 4.74131942e-01,  2.72090882e-01,  4.11264229e+00],\n",
       "       [ 3.98260832e-01,  2.74868757e-01,  4.18867683e+00],\n",
       "       [ 3.26165795e-01,  2.75809109e-01,  4.26992130e+00],\n",
       "       [ 2.55767405e-01,  2.76847005e-01,  4.34954166e+00],\n",
       "       [ 2.06836209e-01,  2.67050683e-01,  4.43711996e+00],\n",
       "       [ 1.04751691e-01,  2.64631569e-01,  4.55698061e+00],\n",
       "       [ 6.86013550e-02,  2.59506434e-01,  4.62781572e+00],\n",
       "       [ 3.31306905e-02,  2.54932582e-01,  4.69536018e+00],\n",
       "       [ 5.73536754e-03,  2.55915225e-01,  4.71932125e+00],\n",
       "       [-2.16599479e-02,  2.56901234e-01,  4.74332333e+00],\n",
       "       [-4.90553305e-02,  2.57890642e-01,  4.76736450e+00],\n",
       "       [-7.35432357e-02,  2.57482737e-01,  4.79245949e+00],\n",
       "       [-8.51340592e-02,  2.51935035e-01,  4.81911945e+00],\n",
       "       [-1.72271878e-01,  2.36108348e-01,  4.97858906e+00],\n",
       "       [-2.16243565e-01,  2.27804169e-01,  5.07086945e+00],\n",
       "       [-2.60215163e-01,  2.19761044e-01,  5.16356659e+00],\n",
       "       [-3.04186821e-01,  2.11972803e-01,  5.25664425e+00],\n",
       "       [-3.48158538e-01,  2.04433218e-01,  5.35007143e+00],\n",
       "       [-3.92130017e-01,  1.97136298e-01,  5.44381666e+00],\n",
       "       [-4.36101735e-01,  1.90075696e-01,  5.53785324e+00],\n",
       "       [-5.04192531e-01,  1.90892458e-01,  5.61348820e+00],\n",
       "       [-6.77049398e-01,  1.97209507e-01,  5.77498913e+00],\n",
       "       [-7.84004211e-01,  1.93738326e-01,  5.92745304e+00],\n",
       "       [-8.60236049e-01,  1.85525879e-01,  6.09612465e+00],\n",
       "       [-9.39457417e-01,  1.79311022e-01,  6.26295519e+00],\n",
       "       [-1.01867878e+00,  1.73286796e-01,  6.43018579e+00],\n",
       "       [-1.09790027e+00,  1.67448476e-01,  6.59775496e+00],\n",
       "       [-1.17299306e+00,  1.60997033e-01,  6.76563311e+00],\n",
       "       [-1.23921895e+00,  1.53142288e-01,  6.93380165e+00],\n",
       "       [-1.30544448e+00,  1.45643488e-01,  7.10217619e+00],\n",
       "       [-1.37167025e+00,  1.38486966e-01,  7.27072477e+00]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpoutput = alldata[12]['theta']\n",
    "\n",
    "theta = np.array([[x.asnumpy().reshape(-1)[0] for x in alldata[12]['theta'][id]] \n",
    "                  for id in range(len(alldata[12]['theta']))])\n",
    "\n",
    "print(len(theta))\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lap2nextpit</th>\n",
       "      <th>caution_laps</th>\n",
       "      <th>pitage</th>\n",
       "      <th>pit_oncaution</th>\n",
       "      <th>carno</th>\n",
       "      <th>eid</th>\n",
       "      <th>lap</th>\n",
       "      <th>stint_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>167</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>168</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>169</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lap2nextpit  caution_laps  pitage  pit_oncaution  carno  eid  lap  \\\n",
       "1028         31.0           0.0     1.0            0.0     12    5    0   \n",
       "1029         30.0           0.0     2.0            0.0     12    5    1   \n",
       "1030         29.0           0.0     3.0            0.0     12    5    2   \n",
       "1031         28.0           0.0     4.0            0.0     12    5    3   \n",
       "1032         27.0           0.0     5.0            0.0     12    5    4   \n",
       "...           ...           ...     ...            ...    ...  ...  ...   \n",
       "1193          5.0          20.0    37.0            0.0     12    5  165   \n",
       "1194          4.0          20.0    38.0            0.0     12    5  166   \n",
       "1195          3.0          20.0    39.0            0.0     12    5  167   \n",
       "1196          2.0          20.0    40.0            0.0     12    5  168   \n",
       "1197          1.0          20.0    41.0            0.0     12    5  169   \n",
       "\n",
       "      stint_len  \n",
       "1028       31.0  \n",
       "1029       31.0  \n",
       "1030       31.0  \n",
       "1031       31.0  \n",
       "1032       31.0  \n",
       "...         ...  \n",
       "1193       42.0  \n",
       "1194       42.0  \n",
       "1195       42.0  \n",
       "1196       42.0  \n",
       "1197       42.0  \n",
       "\n",
       "[170 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['carno']==12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('PitModel-savedata_testset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
