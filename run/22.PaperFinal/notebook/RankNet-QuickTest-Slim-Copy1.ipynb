{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuickTest Slim\n",
    "\n",
    "based on : RankNet-QuickTest-Joint\n",
    "\n",
    "    makedb laptime\n",
    "    makedb gluonts\n",
    "    train model\n",
    "    evaluate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n",
      "INFO:root:Using GPU\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import random\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "import copy\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.deep_factor import DeepFactorEstimator\n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.model.prophet import ProphetPredictor\n",
    "from gluonts.model.r_forecast import RForecastPredictor\n",
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "from gluonts.distribution.neg_binomial import NegativeBinomialOutput\n",
    "from gluonts.distribution.student_t import StudentTOutput\n",
    "from gluonts.distribution.multivariate_gaussian import MultivariateGaussianOutput\n",
    "\n",
    "from indycar.model.NaivePredictor import NaivePredictor\n",
    "from indycar.model.deeparw import DeepARWeightEstimator\n",
    "\n",
    "#import indycar.model.stint_simulator_shortterm_pitmodel as stint\n",
    "import indycar.model.quicktest_simulator as stint\n",
    "\n",
    "# import all functions \n",
    "#from indycar.model.global_variables import _hi\n",
    "import indycar.model.global_variables as gvar\n",
    "from indycar.model.quicktest_modules import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WorkRootDir = 'QuickTestOutput'\n",
    "#reference\n",
    "#configname = 'weighted-noinlap-nopitage-nocate-c60-drank'\n",
    "#configname = 'weighted-noinlap-S0LTYP0T-nocate-c60-drank-pitmodel'\n",
    "configname = 'weighted-noinlap-S0LTYP0T-nocate-c60-drank-oracle'\n",
    "configfile = f'{configname}.ini'\n",
    "\n",
    "if configfile != '':\n",
    "    config = configparser.RawConfigParser()\n",
    "    config.read(WorkRootDir + '/' + configfile)\n",
    "\n",
    "    #set them back\n",
    "    section = \"RankNet-QuickTest\"\n",
    "    \n",
    "    _savedata = config.getboolean(section, \"_savedata\")\n",
    "    _skip_overwrite = config.getboolean(section, \"_skip_overwrite\")\n",
    "    _inlap_status = config.getint(section, \"_inlap_status\") #0\n",
    "    _feature_mode = config.getint(section, \"_feature_mode\") #FEATURE_STATUS\n",
    "    _featureCnt = config.getint(section, \"_featureCnt\") #9\n",
    "    freq = config.get(section, \"freq\") #\"1min\"\n",
    "    _train_len = config.getint(section, \"_train_len\") #40\n",
    "    prediction_length = config.getint(section, \"prediction_length\") #2\n",
    "    context_ratio = config.getfloat(section, \"context_ratio\") #0.\n",
    "    context_length =  config.getint(section, \"context_length\") #40\n",
    "    \n",
    "    dataset= config.get(section, \"dataset\") #'rank'\n",
    "    epochs = config.getint(section, \"epochs\") #1000\n",
    "    gpuid = config.getint(section, \"gpuid\") #5\n",
    "    _use_weighted_model = config.getboolean(section, \"_use_weighted_model\")\n",
    "    trainmodel = config.get(section, \"trainmodel\") #'deepARW-Oracle' if _use_weighted_model else 'deepAR-Oracle'\n",
    "    \n",
    "    _use_cate_feature = config.getboolean(section, \"_use_cate_feature\")\n",
    "    \n",
    "    distroutput = config.get(section, \"distroutput\") #'student'\n",
    "    batch_size = config.getint(section, \"batch_size\") #32\n",
    "    loopcnt = config.getint(section, \"loopcnt\") #2\n",
    "    _test_event = config.get(section, \"_test_event\") #'Indy500-2018'\n",
    "    testmodel = config.get(section, \"testmodel\") #'oracle'\n",
    "    pitmodel = config.get(section, \"pitmodel\") #'oracle'\n",
    "    year = config.get(section, \"year\") #'2018'\n",
    "    \n",
    "    contextlen = context_length\n",
    "    use_feat_static = _use_cate_feature \n",
    "\n",
    "    #config1 = get_config()\n",
    "    \n",
    "else:\n",
    "    print('Warning, please use config file')\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current configfile: weighted-noinlap-S0LTYP0T-nocate-c60-drank-oracle.ini\n",
      "FEATURE_STATUS FEATURE_LEADER_PITCNT FEATURE_TOTAL_PITCNT FEATURE_SHIFT_TRACKSTATUS FEATURE_SHIFT_LAPSTATUS FEATURE_SHIFT_TOTAL_PITCNT\n",
      "feature_mode: 378 S0LTYP0T\n",
      "testmodel: oracle\n",
      "pitmodel: oracle\n",
      "year: 2018\n",
      "test_event: Indy500-2018\n"
     ]
    }
   ],
   "source": [
    "# debug test\n",
    "#_skip_overwrite = False\n",
    "_debugstr = '-debug'\n",
    "gpuid = 5\n",
    "epochs = 1000\n",
    "\n",
    "# new added parameters\n",
    "_test_train_len = 40\n",
    "_joint_train = False\n",
    "_pitmodel_bias = 0\n",
    "\n",
    "#_test_event = 'Indy500-2019'\n",
    "#year = '2019'\n",
    "#_test_event = 'Phoenix-2018'\n",
    "#year = '2018'\n",
    "\n",
    "\n",
    "#shortterm, stint\n",
    "#_forecast_mode = 'stint'\n",
    "_forecast_mode = 'shortterm'\n",
    "\n",
    "# bias of the pitmodel\n",
    "#_pitmodel_bias = 4\n",
    "\n",
    "#train model: [deepARW-Oracle, deepAR]\n",
    "\n",
    "# test the standard deepAR model training and testing\n",
    "\n",
    "# DeepAR\n",
    "#trainmodel = 'deepAR'\n",
    "#testmodel = 'standard'\n",
    "\n",
    "# Joint \n",
    "#trainmodel = 'deepAR-multi'\n",
    "#testmodel = 'joint'\n",
    "#_joint_train = True\n",
    "#loopcnt = 2\n",
    "\n",
    "# transformer\n",
    "#trainmodel = 'Transformer-Oracle'\n",
    "#testmodel = 'Transformer-Oracle'\n",
    "#trainmodel = 'Transformer'\n",
    "#testmodel = 'Transformer'\n",
    "#_joint_train = False\n",
    "loopcnt = 2\n",
    "\n",
    "\n",
    "if testmodel == 'pitmodel':\n",
    "    testmodel = 'pitmodel%s'%(_pitmodel_bias if _pitmodel_bias!=0 else '')\n",
    "\n",
    "#featurestr = {FEATURE_STATUS:'nopitage',FEATURE_PITAGE:'pitage',FEATURE_LEADERPITCNT:'leaderpitcnt'}\n",
    "#cur_featurestr = featurestr[_feature_mode]\n",
    "print('current configfile:', configfile)\n",
    "cur_featurestr = decode_feature_mode(_feature_mode)\n",
    "print('feature_mode:', _feature_mode, cur_featurestr)\n",
    "print('testmodel:', testmodel)\n",
    "print('pitmodel:', pitmodel)\n",
    "print('year:', year)\n",
    "print('test_event:', _test_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# string map\n",
    "#\n",
    "inlapstr = {0:'noinlap',1:'inlap',2:'outlap'}\n",
    "weightstr = {True:'weighted',False:'noweighted'}\n",
    "catestr = {True:'cate',False:'nocate'}\n",
    "\n",
    "#\n",
    "# input data parameters\n",
    "#\n",
    "#events = ['Phoenix','Indy500','Texas','Iowa','Pocono','Gateway']\n",
    "#events_totalmiles=[256,500,372,268,500,310]\n",
    "#events_laplen = [1.022,2.5,1.5,0.894,2.5,1.25]\n",
    "events_info = {\n",
    "    'Phoenix':(256, 1.022),'Indy500':(500,2.5),'Texas':(372,1.5),\n",
    "    'Iowa':(268,0.894),'Pocono':(500,2.5),'Gateway':(310,1.25)\n",
    "}\n",
    "\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "events = [f'Indy500-{x}' for x in years]\n",
    "\n",
    "events.extend(['Phoenix-2018'])\n",
    "\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "\n",
    "#dbid = f'Indy500_{years[0]}_{years[-1]}_v{_featureCnt}_p{_inlap_status}'\n",
    "dbid = f'IndyCar_d{len(events)}_v{_featureCnt}_p{_inlap_status}'\n",
    "_dataset_id = '%s-%s'%(inlapstr[_inlap_status], cur_featurestr)\n",
    "\n",
    "\n",
    "#\n",
    "# internal parameters\n",
    "#\n",
    "distr_outputs ={'student':StudentTOutput(),\n",
    "                'negbin':NegativeBinomialOutput()\n",
    "                }\n",
    "distr_output = distr_outputs[distroutput]\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "experimentid = f'{weightstr[_use_weighted_model]}-{inlapstr[_inlap_status]}-{cur_featurestr}-{catestr[_use_cate_feature]}-c{context_length}{_debugstr}'\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "outputRoot = f\"{WorkRootDir}/{experimentid}/\"\n",
    "\n",
    "\n",
    "# standard output file names\n",
    "LAPTIME_DATASET = f'{outputRoot}/laptime_rank_timediff_pit-oracle-{dbid}.pickle' \n",
    "STAGE_DATASET = f'{outputRoot}/stagedata-{dbid}.pickle' \n",
    "# year related\n",
    "SIMULATION_OUTFILE = f'{outputRoot}/{_test_event}/{_forecast_mode}-dfout-{trainmodel}-indy500-{dataset}-{inlapstr[_inlap_status]}-{cur_featurestr}-{testmodel}-l{loopcnt}-alldata.pickle'\n",
    "EVALUATION_RESULT_DF = f'{outputRoot}/{_test_event}/{_forecast_mode}-evaluation_result_d{dataset}_m{testmodel}.csv'\n",
    "LONG_FORECASTING_DFS = f'{outputRoot}/{_test_event}/{_forecast_mode}-long_forecasting_dfs_d{dataset}_m{testmodel}.pickle'\n",
    "FORECAST_FIGS_DIR = f'{outputRoot}/{_test_event}/{_forecast_mode}-forecast-figs-d{dataset}_m{testmodel}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global vars\n",
    "gvar._savedata =                            _savedata\n",
    "gvar._skip_overwrite =                      _skip_overwrite\n",
    "gvar._inlap_status =                        _inlap_status\n",
    "gvar._feature_mode =                        _feature_mode\n",
    "gvar._featureCnt =                          _featureCnt\n",
    "gvar.freq  =                                freq \n",
    "gvar._train_len =                           _train_len\n",
    "gvar.prediction_length =                    prediction_length\n",
    "gvar.context_ratio =                        context_ratio\n",
    "gvar.context_length =                       context_length\n",
    "gvar.contextlen =                           contextlen\n",
    "gvar.dataset =                              dataset\n",
    "gvar.epochs =                               epochs\n",
    "gvar.gpuid =                                gpuid\n",
    "gvar._use_weighted_model =                  _use_weighted_model\n",
    "gvar.trainmodel =                           trainmodel\n",
    "gvar._use_cate_feature =                    _use_cate_feature\n",
    "gvar.use_feat_static =                      use_feat_static\n",
    "gvar.distroutput =                          distroutput\n",
    "gvar.batch_size =                           batch_size\n",
    "gvar.loopcnt =                              loopcnt\n",
    "gvar._test_event =                          _test_event\n",
    "gvar.testmodel =                            testmodel\n",
    "gvar.pitmodel =                             pitmodel\n",
    "gvar.year =                                year\n",
    "gvar._forecast_mode = _forecast_mode\n",
    "gvar._test_train_len = _test_train_len\n",
    "gvar._joint_train = _joint_train\n",
    "gvar._pitmodel_bias = _pitmodel_bias\n",
    "gvar.events = events\n",
    "gvar.events_id  = events_id\n",
    "gvar.events_info = events_info\n",
    "\n",
    "\n",
    "gvar.maxlap = get_event_info(_test_event)[0]\n",
    "gvar.dbid = dbid\n",
    "gvar.LAPTIME_DATASET = LAPTIME_DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. make laptime dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load laptime and stage dataset: QuickTestOutput/weighted-noinlap-S0LTYP0T-nocate-c60-debug//laptime_rank_timediff_pit-oracle-IndyCar_d8_v9_p0.pickle QuickTestOutput/weighted-noinlap-S0LTYP0T-nocate-c60-debug//stagedata-IndyCar_d8_v9_p0.pickle\n"
     ]
    }
   ],
   "source": [
    "stagedata = {}\n",
    "global_carids = {}\n",
    "os.makedirs(outputRoot, exist_ok=True)\n",
    "os.makedirs(f'{outputRoot}/{_test_event}', exist_ok=True)\n",
    "\n",
    "#check the dest files first\n",
    "if _skip_overwrite and os.path.exists(LAPTIME_DATASET) and os.path.exists(STAGE_DATASET):\n",
    "        #\n",
    "        # load data\n",
    "        #\n",
    "        print('Load laptime and stage dataset:',LAPTIME_DATASET, STAGE_DATASET)\n",
    "        with open(LAPTIME_DATASET, 'rb') as f:\n",
    "            global_carids, laptime_data = pickle.load(f, encoding='latin1') \n",
    "        with open(STAGE_DATASET, 'rb') as f:\n",
    "            stagedata = pickle.load(f, encoding='latin1') \n",
    "    \n",
    "else:    \n",
    "    cur_carid = 0\n",
    "    for event in events:\n",
    "        #dataid = f'{event}-{year}'\n",
    "        #alldata, rankdata, acldata, flagdata\n",
    "        stagedata[event] = load_data(event)\n",
    "\n",
    "        alldata, rankdata, acldata, flagdata = stagedata[event]\n",
    "        carlist = set(acldata['car_number'])\n",
    "        laplist = set(acldata['completed_laps'])\n",
    "        print('%s: carno=%d, lapnum=%d'%(event, len(carlist), len(laplist)))\n",
    "\n",
    "        #build the carid map\n",
    "        for car in carlist:\n",
    "            if car not in global_carids:\n",
    "                global_carids[car] = cur_carid\n",
    "                cur_carid += 1\n",
    "\n",
    "    laptime_data = get_laptime_dataset(stagedata, inlap_status = _inlap_status)\n",
    "\n",
    "    if _savedata:\n",
    "        import pickle\n",
    "        #stintdf.to_csv('laptime-%s.csv'%year)\n",
    "        #savefile = outputRoot + f'laptime_rank_timediff_pit-oracle-{dbid}.pickle' \n",
    "        savefile = LAPTIME_DATASET\n",
    "        print(savefile)\n",
    "        with open(savefile, 'wb') as f:\n",
    "            #pack [global_carids, laptime_data]\n",
    "            savedata = [global_carids, laptime_data]\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        #savefile = outputRoot + f'stagedata-{dbid}.pickle' \n",
    "        savefile = STAGE_DATASET\n",
    "        print(savefile)\n",
    "        with open(savefile, 'wb') as f:\n",
    "            #pack [global_carids, laptime_data]\n",
    "            savedata = stagedata\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)    \n",
    "        \n",
    "#update global var\n",
    "gvar.global_carids = global_carids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. make gluonts db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Gluonts Dataset: QuickTestOutput/weighted-noinlap-S0LTYP0T-nocate-c60-debug/noinlap-S0LTYP0T/rank-indy500/gluontsdb-rank-oracle-noip-noeid-all-all-f1min-t2-rIndy500-2018-indy-2018.pickle\n",
      ".......loaded data, freq= 1min prediction_length= 2\n",
      "Load New Laptime Dataset: QuickTestOutput/weighted-noinlap-S0LTYP0T-nocate-c60-debug/noinlap-S0LTYP0T/rank-indy500/gluontsdb-rank-oracle-noip-noeid-all-all-f1min-t2-rIndy500-2018-indy-2018-newlaptimedata.pickle\n"
     ]
    }
   ],
   "source": [
    "outdir = outputRoot + _dataset_id\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "if dataset == 'laptime':\n",
    "    subdir = 'laptime-indy500'\n",
    "    os.makedirs(f'{outdir}/{subdir}', exist_ok=True)\n",
    "    _run_ts = COL_LAPTIME\n",
    "elif dataset == 'timediff':\n",
    "    subdir = 'timediff-indy500'\n",
    "    os.makedirs(f'{outdir}/{subdir}', exist_ok=True)\n",
    "    _run_ts = COL_TIMEDIFF\n",
    "elif dataset == 'rank':\n",
    "    subdir = 'rank-indy500'\n",
    "    os.makedirs(f'{outdir}/{subdir}', exist_ok=True)\n",
    "    _run_ts = COL_RANK\n",
    "else:\n",
    "    print('error, dataset not support: ', dataset)\n",
    "    \n",
    "_task_dir = f'{outdir}/{subdir}/'\n",
    "\n",
    "#\n",
    "#dbname, train_ds, test_ds = makedbs()   \n",
    "#\n",
    "useeid = False\n",
    "interpolate = False\n",
    "#ipstr = '-ip' if interpolate else '-noip'\n",
    "ipstr = '%s-%s'%('ip' if interpolate else 'noip', 'eid' if useeid else 'noeid')\n",
    "jointstr = '-joint' if _joint_train else ''\n",
    "\n",
    "dbname = _task_dir + f'gluontsdb-{dataset}-oracle-{ipstr}-all-all-f{freq}-t{prediction_length}-r{_test_event}-indy-{year}{jointstr}.pickle'\n",
    "laptimedb = _task_dir + f'gluontsdb-{dataset}-oracle-{ipstr}-all-all-f{freq}-t{prediction_length}-r{_test_event}-indy-{year}-newlaptimedata.pickle'\n",
    "\n",
    "#check the dest files first\n",
    "if _skip_overwrite and os.path.exists(dbname) and os.path.exists(laptimedb):\n",
    "        print('Load Gluonts Dataset:',dbname)\n",
    "        with open(dbname, 'rb') as f:\n",
    "            freq, prediction_length, cardinality, train_ds, test_ds = pickle.load(f, encoding='latin1') \n",
    "        print('.......loaded data, freq=', freq, 'prediction_length=', prediction_length)\n",
    "        print('Load New Laptime Dataset:',laptimedb)\n",
    "        with open(laptimedb, 'rb') as f:\n",
    "            prepared_laptimedata = pickle.load(f, encoding='latin1') \n",
    "        \n",
    "else:\n",
    "    if useeid:\n",
    "        cardinality = [len(global_carids), len(laptime_data)]\n",
    "    else:\n",
    "        cardinality = [len(global_carids)]\n",
    "\n",
    "    prepared_laptimedata = prepare_laptimedata(laptime_data,\n",
    "                           prediction_length, freq, test_event = _test_event,\n",
    "                           train_ratio=0, context_ratio = 0.,shift_len = prediction_length)\n",
    "\n",
    "    train_ds, test_ds,_,_ = make_dataset_byevent(prepared_laptimedata, \n",
    "                                        prediction_length,freq,\n",
    "                                         useeid=useeid, run_ts=_run_ts,\n",
    "                                        test_event=_test_event, log_transform =False,\n",
    "                                        context_ratio=0, train_ratio = 0, joint_train = _joint_train)    \n",
    "\n",
    "\n",
    "    if _savedata:\n",
    "        print('Save Gluonts Dataset:',dbname)\n",
    "        with open(dbname, 'wb') as f:\n",
    "            savedata = [freq, prediction_length, cardinality, train_ds, test_ds]\n",
    "            pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print('Save preprocessed laptime Dataset:',laptimedb)\n",
    "        with open(laptimedb, 'wb') as f:\n",
    "            pickle.dump(prepared_laptimedata, f, pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint found at: QuickTestOutput/weighted-noinlap-S0LTYP0T-nocate-c60-debug/noinlap-S0LTYP0T/rank-indy500/deepARW-Oracle-rank-all-indy-f1min-t2-e1000-r1_oracle_t2\n"
     ]
    }
   ],
   "source": [
    "id='oracle'\n",
    "run=1\n",
    "runid=f'{trainmodel}-{dataset}-all-indy-f1min-t{prediction_length}-e{epochs}-r{run}_{id}_t{prediction_length}'\n",
    "modelfile = _task_dir + runid\n",
    "\n",
    "if _skip_overwrite and os.path.exists(modelfile):\n",
    "    print('Model checkpoint found at:',modelfile)\n",
    "\n",
    "else:\n",
    "    #get target dim\n",
    "    entry = next(iter(train_ds))\n",
    "    target_dim = entry['target'].shape\n",
    "    target_dim = target_dim[0] if len(target_dim) > 1 else 1\n",
    "    print('target_dim:%s', target_dim)\n",
    "\n",
    "    estimator = init_estimator(trainmodel, gpuid, \n",
    "            epochs, batch_size,target_dim, distr_output = distr_output,use_feat_static = use_feat_static)\n",
    "\n",
    "    predictor = estimator.train(train_ds)\n",
    "\n",
    "    if _savedata:\n",
    "        os.makedirs(modelfile, exist_ok=True)\n",
    "\n",
    "        print('Start to save the model to %s', modelfile)\n",
    "        predictor.serialize(Path(modelfile))\n",
    "        print('End of saving the model.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/quicktest_simulator.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uni_ds['rank_diff'][mask] = 0\n",
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/quicktest_simulator.py:696: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uni_ds['time_diff'][mask] = 0\n",
      "INFO:root:Using GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init: load dataset QuickTestOutput/weighted-noinlap-S0LTYP0T-nocate-c60-debug//laptime_rank_timediff_pit-oracle-IndyCar_d8_v9_p0.pickle with 8 races, 58 cars\n",
      "Set a new global laptime_data, test_event=Indy500-2018, cnt=6, shape=(33, 15, 200)\n",
      "predicting model=oracle, plen=2\n",
      "loading model...deepARW-Oracle-rank-all-indy-f1min-t2-e1000-r1_oracle_t2...done!, ctx:gpu(0)\n",
      "sim_init: input laptime_data, shape= 6 (33, 15, 200) 5\n",
      "sim_init: after laptime_data, shape= 6 (33, 19, 200)\n",
      "evalbyrank: True\n",
      "sim_init: input laptime_data, shape= 6 (33, 19, 200) 5\n",
      "sim_init: after laptime_data, shape= 6 (33, 19, 200)\n",
      "evalbyrank: True\n",
      "model: acc={0.88}, mae={0.69}, rmse={1.63},r2={0.96}, {188}\n",
      "            naive: acc={0.72}, mae={1.34}, rmse={3.25},r2={0.85}\n",
      "model: acc={0.88}, mae={0.69}, rmse={1.62},r2={0.96}, {188}\n",
      "            naive: acc={0.72}, mae={1.34}, rmse={3.25},r2={0.85}\n",
      "[[0.87765957 0.6911985  1.62592472 0.96309055]\n",
      " [0.71808511 1.33932584 3.24896987 0.85262365]]\n",
      "sacmplecnt: 100 lapcnt: 500 runcnt: 2\n",
      "dict_values([0.05195661407111209, 0.05529125688965741, 0.05250675996973955])\n",
      "[0.05195661 0.05529126 0.05250676]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/quicktest_modules.py:1686: RuntimeWarning: Mean of empty slice\n",
      "  forecast_mean = np.nanmean(forecast[carno], axis=0)\n",
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/quicktest_modules.py:1699: RuntimeWarning: invalid value encountered in less_equal\n",
      "  * ((target <= quantile_forecast) - q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df size: 5340\n"
     ]
    }
   ],
   "source": [
    "lapmode = _inlap_status\n",
    "fmode = _feature_mode\n",
    "runts = dataset\n",
    "mid = f'{testmodel}-%s-%s-%s-%s'%(runts, year, inlapstr[lapmode], cur_featurestr)\n",
    "datasetid = outputRoot + _dataset_id\n",
    "\n",
    "if _skip_overwrite and os.path.exists(SIMULATION_OUTFILE):\n",
    "    print('Load Simulation Results:',SIMULATION_OUTFILE)\n",
    "    with open(SIMULATION_OUTFILE, 'rb') as f:\n",
    "        dfs,acc,ret,pret = pickle.load(f, encoding='latin1') \n",
    "    print('.......loaded data, ret keys=', ret.keys())\n",
    "    \n",
    "    \n",
    "    # init the stint module\n",
    "    #\n",
    "    # in test mode, set all train_len = 40 to unify the evaluation results\n",
    "    #\n",
    "    init_simulation(datasetid, _test_event, 'rank',stint.COL_RANK,'rank',prediction_length, \n",
    "                    pitmodel=pitmodel, inlapmode=lapmode,featuremode =fmode,\n",
    "                    train_len = _test_train_len, pitmodel_bias= _pitmodel_bias)    \n",
    "\n",
    "else:\n",
    "    #run simulation\n",
    "    acc, ret, pret = {}, {}, {}\n",
    "\n",
    "    #lapmode = _inlap_status\n",
    "    #fmode = _feature_mode\n",
    "    #runts = dataset\n",
    "    #mid = f'{testmodel}-%s-%s-%s-%s'%(runts, year, inlapstr[lapmode], featurestr[fmode])\n",
    "\n",
    "    if runts == 'rank':\n",
    "        acc[mid], ret[mid] = simulation(datasetid, _test_event, \n",
    "                    'rank',stint.COL_RANK,'rank',\n",
    "                   prediction_length, stint.MODE_ORACLE,loopcnt, \n",
    "                      pitmodel=pitmodel, model=testmodel, inlapmode=lapmode,featuremode =fmode,\n",
    "                    train_len = _test_train_len, forecastmode = _forecast_mode, joint_train = _joint_train,\n",
    "                    pitmodel_bias= _pitmodel_bias, prepared_laptimedata = prepared_laptimedata,\n",
    "                    epochs = epochs)\n",
    "    else:\n",
    "        acc[mid], ret[mid] = simulation(datasetid, _test_event, \n",
    "                    'timediff',stint.COL_TIMEDIFF,'timediff2rank',\n",
    "                   prediction_length, stint.MODE_ORACLE,loopcnt, \n",
    "                      pitmodel=pitmodel, model=testmodel, inlapmode=lapmode,featuremode =fmode,\n",
    "                    train_len = _test_train_len, forecastmode = _forecast_mode, joint_train = _joint_train,\n",
    "                    pitmodel_bias= _pitmodel_bias, prepared_laptimedata = prepared_laptimedata,\n",
    "                    epochs = epochs)\n",
    "\n",
    "    if _forecast_mode == 'shortterm':\n",
    "        allsamples, alltss = get_allsamples(ret[mid], year=year)\n",
    "        _, pret[mid]= prisk_direct_bysamples(allsamples, alltss)\n",
    "        print(pret[mid])\n",
    "    \n",
    "\n",
    "    dfs={}\n",
    "\n",
    "    mode=1\n",
    "    df = get_alldf_mode(ret[mid], year=year,mode=mode, forecast_mode = _forecast_mode)\n",
    "    name = '%s_%s'%(testmodel, 'mean' if mode==1 else ('mode' if mode==0 else 'median'))\n",
    "    if year not in dfs:\n",
    "        dfs[year] = {}\n",
    "    dfs[year][name] = df\n",
    "\n",
    "    _trim = 0\n",
    "    _include_final = True\n",
    "    _include_stintlen = True\n",
    "    include_str = '1' if _include_final else '0'\n",
    "    stint_str = '1' if _include_stintlen else ''            \n",
    "    #simulation_outfile=outputRoot + f'shortterm-dfout-oracle-indy500-{dataset}-{inlapstr[_inlap_status]}-{featurestr[_feature_mode]}-2018-oracle-l{loopcnt}-alldata-weighted.pickle'\n",
    "\n",
    "    with open(SIMULATION_OUTFILE, 'wb') as f:\n",
    "        savedata = [dfs,acc,ret,pret]\n",
    "        pickle.dump(savedata, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "#alias\n",
    "ranknetdf = dfs   \n",
    "ranknet_ret = ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indy500-2018'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sacmplecnt: 100 lapcnt: 500 runcnt: 2\n",
      "dict_values([0.05195661407111209, 0.05529125688965741, 0.05250675996973955])\n",
      "rerank...\n",
      "model: acc={0.89}, mae={0.69}, rmse={1.63},r2={0.96}, {188}\n",
      "            naive: acc={0.72}, mae={1.34}, rmse={3.25},r2={0.85}\n",
      "sellaps: 78 clearlaps: 122\n",
      "rerank...\n",
      "sacmplecnt: 100 lapcnt: 500 runcnt: 2\n",
      "dict_values([0.025577740639334375, 0.028142801265867802, 0.025912057746328626])\n",
      "model: acc={0.92}, mae={0.31}, rmse={0.87},r2={0.99}, {66}\n",
      "            naive: acc={0.88}, mae={0.29}, rmse={0.92},r2={0.99}\n",
      "2018 normal RankNet-oracle 0.9242424242410239 0.3069815195071869 0.028142801265867802 0.025912057746328626\n",
      "sellaps: 122 clearlaps: 78\n",
      "rerank...\n",
      "sacmplecnt: 100 lapcnt: 500 runcnt: 2\n",
      "dict_values([0.06811863793817129, 0.07192479466678284, 0.06880101958562997])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/quicktest_modules.py:1686: RuntimeWarning: Mean of empty slice\n",
      "  forecast_mean = np.nanmean(forecast[carno], axis=0)\n",
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/quicktest_modules.py:1699: RuntimeWarning: invalid value encountered in less_equal\n",
      "  * ((target <= quantile_forecast) - q)\n",
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/quicktest_modules.py:1686: RuntimeWarning: Mean of empty slice\n",
      "  forecast_mean = np.nanmean(forecast[carno], axis=0)\n",
      "/N/u/pengb/hpda/indycar/predictor/src/indycar/model/quicktest_modules.py:1699: RuntimeWarning: invalid value encountered in less_equal\n",
      "  * ((target <= quantile_forecast) - q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: acc={0.87}, mae={0.91}, rmse={1.93},r2={0.95}, {122}\n",
      "            naive: acc={0.63}, mae={1.94}, rmse={4.02},r2={0.76}\n",
      "2018 pit RankNet-oracle 0.8688524590156813 0.9080188679245284 0.07192479466678284 0.06880101958562997\n"
     ]
    }
   ],
   "source": [
    "if _skip_overwrite and os.path.exists(EVALUATION_RESULT_DF):\n",
    "    print('Load Evaluation Results:',EVALUATION_RESULT_DF)\n",
    "    oracle_eval_result = pd.read_csv(EVALUATION_RESULT_DF)\n",
    "\n",
    "else:    \n",
    "    ##-------------------------------------------------------------------------------\n",
    "    if _forecast_mode == 'shortterm':\n",
    "\n",
    "        # get pit laps, pit-covered-laps\n",
    "        # pitdata[year] = [pitlaps, pitcoveredlaps]\n",
    "        with open('pitcoveredlaps-g1.pickle', 'rb') as f:\n",
    "            # The protocol version used is detected automatically, so we do not\n",
    "            # have to specify it.\n",
    "            pitdata = pickle.load(f, encoding='latin1') \n",
    "\n",
    "        #\n",
    "        # Model,SignAcc,MAE,50-Risk,90-Risk\n",
    "        # \n",
    "        cols = ['Year','Model','ExpID','laptype','Top1Acc','MAE','50-Risk','90-Risk']\n",
    "        plen = prediction_length\n",
    "        usemeanstr='mean'\n",
    "\n",
    "        #load data\n",
    "        # dfs,acc,ret,pret\n",
    "\n",
    "        retdata = []\n",
    "\n",
    "        #oracle\n",
    "        dfx = ret[mid]\n",
    "        allsamples, alltss = get_allsamples(dfx, year=year)\n",
    "        #_, pret[mid]= prisk_direct_bysamples(ret[mid][0][1], ret[mid][0][2])\n",
    "        _, prisk_vals = prisk_direct_bysamples(allsamples, alltss)\n",
    "\n",
    "        dfout = do_rerank(ranknetdf[year][f'{testmodel}_mean'])\n",
    "        accret = stint.get_evalret_shortterm(dfout)[0]\n",
    "        #fsamples, ftss = runs2samples_ex(ranknet_ret[f'oracle-RANK-{year}-inlap-nopitage'],[])\n",
    "        #_, prisk_vals = prisk_direct_bysamples(fsamples, ftss)\n",
    "        retdata.append([year,f'{testmodel}',configname,'all', accret[0], accret[1], prisk_vals[1], prisk_vals[2]])\n",
    "\n",
    "        for laptype in ['normal','pit']:\n",
    "            # select the set\n",
    "            pitcoveredlaps = pitdata[year][1]\n",
    "            normallaps = set([x for x in range(1,201)]) - pitcoveredlaps\n",
    "\n",
    "            if laptype == 'normal':\n",
    "                sellaps = normallaps\n",
    "                clearlaps = pitcoveredlaps\n",
    "            else:\n",
    "                sellaps = pitcoveredlaps\n",
    "                clearlaps = normallaps\n",
    "\n",
    "\n",
    "            # pitcoveredlaps start idx = 1\n",
    "            startlaps = [x-plen-1 for x in sellaps]\n",
    "            #sellapidx = np.array([x-1 for x in sellaps])\n",
    "            clearidx = np.array([x-1 for x in clearlaps])\n",
    "            print('sellaps:', len(sellaps), 'clearlaps:',len(clearlaps))\n",
    "\n",
    "            #oracle\n",
    "            #outfile=f'shortterm-dfout-ranknet-indy500-rank-inlap-nopitage-20182019-oracle-l10-alldata-weighted.pickle'\n",
    "            #_all = load_dfout_all(outfile)[0]\n",
    "            #ranknetdf, acc, ret, pret = _all[0],_all[1],_all[2],_all[3]\n",
    "\n",
    "            dfout = do_rerank(ranknetdf[year][f'{testmodel}_mean'])\n",
    "\n",
    "            allsamples, alltss = get_allsamples(dfx, year=year)\n",
    "\n",
    "\n",
    "            allsamples, alltss = clear_samples(allsamples, alltss,clearidx)\n",
    "\n",
    "            _, prisk_vals = prisk_direct_bysamples(allsamples, alltss)\n",
    "\n",
    "            dfout = dfout[dfout['startlap'].isin(startlaps)]\n",
    "            accret = stint.get_evalret_shortterm(dfout)[0]\n",
    "\n",
    "            print(year, laptype,f'RankNet-{testmodel}',accret[0], accret[1], prisk_vals[1], prisk_vals[2])\n",
    "            retdata.append([year, f'{testmodel}',configname,laptype, accret[0], accret[1], prisk_vals[1], prisk_vals[2]])\n",
    "            \n",
    "    ##-------------------------------------------------------------------------------\n",
    "    elif _forecast_mode == 'stint':\n",
    "        if testmodel == 'oracle':\n",
    "            datafile=f'stint-dfout-mlmodels-indy500-tr2013_2017-te2018_2019-end1-oracle-t0-tuned.pickle'\n",
    "        else:\n",
    "            datafile=f'stint-dfout-mlmodels-indy500-tr2013_2017-te2018_2019-end1-normal-t0-tuned.pickle'\n",
    "        #preddf = load_dfout(outfile)\n",
    "        with open(datafile, 'rb') as f:\n",
    "            preddf = pickle.load(f, encoding='latin1')[0] \n",
    "        #preddf_oracle = load_dfout(outfile)\n",
    "        ranknet_ret = ret \n",
    "\n",
    "        errlist = {}\n",
    "        errcnt, errlist[year] = cmp_df(ranknetdf[year][f'{testmodel}_mean'], preddf[year]['lasso'])\n",
    "        \n",
    "        retdata = []\n",
    "        #\n",
    "        # Model,SignAcc,MAE,50-Risk,90-Risk\n",
    "        # \n",
    "        cols = ['Year','Model','ExpID','laptype','SignAcc','MAE','50-Risk','90-Risk']\n",
    "        models = {'currank':'CurRank','rf':'RandomForest','svr_lin':'SVM','xgb':'XGBoost'}\n",
    "\n",
    "        for clf in ['currank','rf','svr_lin','xgb']:\n",
    "            print('year:',year,'clf:',clf)\n",
    "            dfout, accret = eval_sync(preddf[year][clf],errlist[year])\n",
    "            fsamples, ftss = df2samples_ex(dfout)\n",
    "            _, prisk_vals = prisk_direct_bysamples(fsamples, ftss)\n",
    "\n",
    "            retdata.append([year,models[clf],configname,'all', accret[0], accret[1], prisk_vals[1], prisk_vals[2]])\n",
    "            \n",
    "        #ml models -oracle\n",
    "        #for clf in ['rf','svr_lin','xgb']:\n",
    "        #    print('year:',year,'clf:',clf)\n",
    "        #    dfout, accret = eval_sync(preddf_oracle[year][clf],errlist[year])\n",
    "        #    fsamples, ftss = df2samples(dfout)\n",
    "        #    _, prisk_vals = prisk_direct_bysamples(fsamples, ftss)\n",
    "        #    retdata.append([year,models[clf]+'-Oracle',configname,'all',accret[0], accret[1], prisk_vals[1], prisk_vals[2]])\n",
    "\n",
    "        dfout, accret = eval_sync(ranknetdf[year][f'{testmodel}_mean'], errlist[year],force2int=True)\n",
    "        #fsamples, ftss = df2samples(dfout)\n",
    "        fsamples, ftss = runs2samples(ranknet_ret[mid],errlist[f'{year}'])\n",
    "        _, prisk_vals = prisk_direct_bysamples(fsamples, ftss)\n",
    "        retdata.append([year,f'{testmodel}',configname,'all',accret[0], accret[1], prisk_vals[1], prisk_vals[2]])\n",
    "\n",
    "        #dfout, accret = eval_sync(ranknetdf[year]['oracle_mean'], errlist[year],force2int=True)\n",
    "        ##fsamples, ftss = df2samples(dfout)\n",
    "        #fsamples, ftss = runs2samples(ranknet_ret[f'oracle-TIMEDIFF-{year}-noinlap-nopitage'],errlist[f'{year}'])\n",
    "        #_, prisk_vals = prisk_direct_bysamples(fsamples, ftss)\n",
    "        #retdata.append([year,'RankNet-Oracle',accret[0], accret[1], prisk_vals[1], prisk_vals[2]])\n",
    "\n",
    "    oracle_eval_result = pd.DataFrame(data=retdata, columns=cols)\n",
    "    if _savedata:\n",
    "        oracle_eval_result.to_csv(EVALUATION_RESULT_DF)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Draw forecasting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _forecast_mode == 'shortterm' and _joint_train == False:\n",
    "    if _skip_overwrite and os.path.exists(LONG_FORECASTING_DFS):\n",
    "        fname = LONG_FORECASTING_DFS\n",
    "        print('Load Long Forecasting Data:',fname)\n",
    "        with open(fname, 'rb') as f:\n",
    "            alldata = pickle.load(f, encoding='latin1') \n",
    "        print('.......loaded data, alldata keys=', alldata.keys())\n",
    "\n",
    "    else:    \n",
    "\n",
    "        oracle_ret = ret    \n",
    "        mid = f'{testmodel}-%s-%s-%s-%s'%(runts, year, inlapstr[lapmode], cur_featurestr)\n",
    "        print('eval mid:', mid, f'{testmodel}_ret keys:', ret.keys())\n",
    "\n",
    "        ## init predictor\n",
    "        _predictor =  NaivePredictor(freq= freq, prediction_length = prediction_length)\n",
    "\n",
    "        oracle_dfout = do_rerank(dfs[year][f'{testmodel}_mean'])\n",
    "        carlist = set(list(oracle_dfout.carno.values))\n",
    "        carlist = [int(x) for x in carlist]\n",
    "        print('carlist:', carlist,'len:',len(carlist))\n",
    "\n",
    "        #carlist = [13, 7, 3, 12]\n",
    "        #carlist = [13]    \n",
    "\n",
    "        retdata = {}\n",
    "        for carno in carlist:\n",
    "            print(\"*\"*40)\n",
    "            print('Run models for carno=', carno)\n",
    "            # create the test_ds first\n",
    "            test_cars = [carno]\n",
    "\n",
    "            #train_ds, test_ds, trainset, testset = stint.make_dataset_byevent(events_id[_test_event], \n",
    "            #                                 prediction_length,freq, \n",
    "            #                                 oracle_mode=stint.MODE_ORACLE,\n",
    "            #                                 run_ts = _run_ts,\n",
    "            #                                 test_event = _test_event,\n",
    "            #                                 test_cars=test_cars,\n",
    "            #                                 half_moving_win = 0,\n",
    "            #                                 train_ratio = 0.01)\n",
    "\n",
    "            train_ds, test_ds, trainset, testset = make_dataset_byevent(prepared_laptimedata, prediction_length,freq,\n",
    "                                             useeid=useeid, run_ts=_run_ts,\n",
    "                                            test_event=_test_event, log_transform =False,\n",
    "                                            context_ratio=0, train_ratio = 0,\n",
    "                                            joint_train = _joint_train,\n",
    "                                            test_cars = test_cars)    \n",
    "\n",
    "\n",
    "            if (len(testset) <= 10 + prediction_length):\n",
    "                print('ts too short, skip ', len(testset))\n",
    "                continue\n",
    "\n",
    "            #by first run samples\n",
    "            samples = oracle_ret[mid][0][1][test_cars[0]]\n",
    "            tss  = oracle_ret[mid][0][2][test_cars[0]]\n",
    "            target_oracle1, tss_oracle1 = long_predict_bysamples('1run-samples', samples, tss, test_ds, _predictor)\n",
    "\n",
    "            #by first run output df(_use_mean = true, already reranked)\n",
    "            df = oracle_ret[mid][0][0]\n",
    "            dfin_oracle = df[df['carno']==test_cars[0]]\n",
    "            target_oracle2, tss_oracle2 = long_predict_bydf(f'{testmodel}-1run-dfout', dfin_oracle, test_ds, _predictor)        \n",
    "\n",
    "\n",
    "            #by multi-run mean at oracle_dfout\n",
    "            df = oracle_dfout\n",
    "            dfin_oracle = df[df['carno']==test_cars[0]]\n",
    "            target_oracle3, tss_oracle3 = long_predict_bydf(f'{testmodel}-multimean', dfin_oracle, test_ds, _predictor)        \n",
    "\n",
    "\n",
    "            #no rerank\n",
    "            df = ranknetdf[year][f'{testmodel}_mean']\n",
    "            dfin_oracle = df[df['carno']==test_cars[0]]\n",
    "            target_oracle4, tss_oracle4 = long_predict_bydf(f'{testmodel}-norerank-multimean', dfin_oracle, test_ds, _predictor)        \n",
    "\n",
    "\n",
    "            #by multiple runs\n",
    "            target_oracle_multirun, tss_oracle_multirun = get_ranknet_multirun(\n",
    "                                    oracle_ret[mid], \n",
    "                                    test_cars[0], test_ds, _predictor,sampleCnt=loopcnt)\n",
    "\n",
    "            retdata[carno] = [[tss_oracle1,tss_oracle2,tss_oracle3,tss_oracle4,tss_oracle_multirun],\n",
    "                               [target_oracle1,target_oracle2,target_oracle3,target_oracle4,target_oracle_multirun]]\n",
    "\n",
    "        alldata = retdata    \n",
    "\n",
    "        if _savedata:\n",
    "            with open(LONG_FORECASTING_DFS, 'wb') as f:\n",
    "                pickle.dump(alldata, f, pickle.HIGHEST_PROTOCOL)  \n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    if _forecast_mode == 'shortterm' and _joint_train == False:\n",
    "        destdir = FORECAST_FIGS_DIR\n",
    "\n",
    "        if _skip_overwrite and os.path.exists(destdir):\n",
    "            print('Long Forecasting Figures at:',destdir)\n",
    "\n",
    "        else:\n",
    "            with open('stagedata-Indy500_2013_2019_v9_p0.pickle', 'rb') as f:\n",
    "                stagedata = pickle.load(f, encoding='latin1') \n",
    "                _alldata, rankdata, _acldata, _flagdata = stagedata[_test_event]\n",
    "\n",
    "            #destdir = outputRoot + 'oracle-forecast-figs/'\n",
    "            os.makedirs(destdir, exist_ok=True)\n",
    "\n",
    "            for carno in alldata:\n",
    "                plotoracle(alldata, carno, destdir)\n",
    "\n",
    "            #draw summary result\n",
    "            outputfile = destdir + f'{configname}'\n",
    "            plotallcars(alldata, outputfile, drawid = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotoracle(alldata, 3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputRoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Model</th>\n",
       "      <th>ExpID</th>\n",
       "      <th>laptype</th>\n",
       "      <th>Top1Acc</th>\n",
       "      <th>MAE</th>\n",
       "      <th>50-Risk</th>\n",
       "      <th>90-Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>oracle</td>\n",
       "      <td>weighted-noinlap-S0LTYP0T-nocate-c60-drank-oracle</td>\n",
       "      <td>all</td>\n",
       "      <td>0.953782</td>\n",
       "      <td>0.282643</td>\n",
       "      <td>0.037373</td>\n",
       "      <td>0.034896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>oracle</td>\n",
       "      <td>weighted-noinlap-S0LTYP0T-nocate-c60-drank-oracle</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.228253</td>\n",
       "      <td>0.036884</td>\n",
       "      <td>0.034360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>oracle</td>\n",
       "      <td>weighted-noinlap-S0LTYP0T-nocate-c60-drank-oracle</td>\n",
       "      <td>pit</td>\n",
       "      <td>0.942623</td>\n",
       "      <td>0.306053</td>\n",
       "      <td>0.040336</td>\n",
       "      <td>0.037775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Model                                              ExpID laptype  \\\n",
       "0  2018  oracle  weighted-noinlap-S0LTYP0T-nocate-c60-drank-oracle     all   \n",
       "1  2018  oracle  weighted-noinlap-S0LTYP0T-nocate-c60-drank-oracle  normal   \n",
       "2  2018  oracle  weighted-noinlap-S0LTYP0T-nocate-c60-drank-oracle     pit   \n",
       "\n",
       "    Top1Acc       MAE   50-Risk   90-Risk  \n",
       "0  0.953782  0.282643  0.037373  0.034896  \n",
       "1  0.969697  0.228253  0.036884  0.034360  \n",
       "2  0.942623  0.306053  0.040336  0.037775  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
