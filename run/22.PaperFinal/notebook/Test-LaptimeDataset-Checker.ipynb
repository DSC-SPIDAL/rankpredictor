{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the contents in laptime dataset\n",
    "\n",
    "base:   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import random\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import pickle\n",
    "import json\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import ipdb; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "def test_flag(a, bitflag):\n",
    "    return (a & bitflag) ==  bitflag\n",
    "\n",
    "#check for car12\n",
    "def check_laptimedata(_laptime_data, check_carno = 12, train_ratio=0):\n",
    "    \n",
    "    run_ts = COL_RANK\n",
    "    totalTSCnt = 0\n",
    "    totalTSLen = 0        \n",
    "    \n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "\n",
    "        if events[_data[0]] == _test_event:\n",
    "            test_mode = True\n",
    "        else:\n",
    "            test_mode = False\n",
    "\n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        if train_len == 0:\n",
    "            #use global train_len\n",
    "            train_len = _train_len\n",
    "\n",
    "        if context_ratio != 0.:\n",
    "            # add this part to train set\n",
    "            context_len = int(np.max(ts_len) * context_ratio)\n",
    "        else:    \n",
    "            context_len = prediction_length*2\n",
    "        if context_len < 10:\n",
    "            context_len = 10\n",
    "\n",
    "        print(f'after ====event:{events[_data[0]]}, prediction_len={prediction_length},train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)},context_len={context_len}')\n",
    "\n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "\n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "\n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "\n",
    "            totalTSCnt += 1\n",
    "            totalTSLen += totallen\n",
    "\n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                print(f'a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                continue                \n",
    "\n",
    "            carno = _data[1][rowid]\n",
    "            #carid = global_carids[_data[1][rowid]]\n",
    "\n",
    "            if carno == check_carno:\n",
    "                #show content in rec\n",
    "\n",
    "                #rank\n",
    "                print('rank:',rec[COL_RANK,:] )\n",
    "\n",
    "                #pitlaps\n",
    "                pits = np.where(rec[COL_LAPSTATUS,:]==1)\n",
    "                print('pits:', pits)\n",
    "                \n",
    "                \n",
    "def adjustrank_laptimedata(_laptime_data):\n",
    "    \n",
    "    run_ts = COL_RANK\n",
    "    \n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "\n",
    "        if events[_data[0]] == _test_event:\n",
    "            test_mode = True\n",
    "        else:\n",
    "            test_mode = False\n",
    "\n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        if train_len == 0:\n",
    "            #use global train_len\n",
    "            train_len = _train_len\n",
    "\n",
    "        if context_ratio != 0.:\n",
    "            # add this part to train set\n",
    "            context_len = int(np.max(ts_len) * context_ratio)\n",
    "        else:    \n",
    "            context_len = prediction_length*2\n",
    "        if context_len < 10:\n",
    "            context_len = 10\n",
    "\n",
    "        print(f'after ====event:{events[_data[0]]}, prediction_len={prediction_length},train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)},context_len={context_len}')\n",
    "\n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "\n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "\n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "\n",
    "            totalTSCnt += 1\n",
    "            totalTSLen += totallen\n",
    "\n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                print(f'a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                continue                \n",
    "\n",
    "            carno = _data[1][rowid]\n",
    "            #carid = global_carids[_data[1][rowid]]\n",
    "\n",
    "            if carno == check_carno:\n",
    "                #show content in rec\n",
    "\n",
    "                #rank\n",
    "                print('rank:',rec[COL_RANK,:] )\n",
    "\n",
    "                #pitlaps\n",
    "                pits = np.where(rec[COL_LAPSTATUS,:]==1)\n",
    "                print('pits:', pits)                \n",
    "                \n",
    "def diff_laptimedata(lapdata1, lapdata2):\n",
    "    \"\"\"\n",
    "    compare two laptime datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_events(lapdata):\n",
    "        return [events[x[0]] for x in lapdata]\n",
    "    \n",
    "    \n",
    "    #1. check events\n",
    "    events1 = get_events(lapdata1)\n",
    "    events2 = get_events(lapdata1)\n",
    "\n",
    "    events_cnt = min(len(events1, events2))\n",
    "    \n",
    "    print(events1, events2)\n",
    "    \n",
    "    #2. check features\n",
    "    run_ts = COL_RANK\n",
    "    \n",
    "    for _data in _laptime_data:\n",
    "        _train = []\n",
    "        _test = []\n",
    "\n",
    "        if events[_data[0]] == _test_event:\n",
    "            test_mode = True\n",
    "        else:\n",
    "            test_mode = False\n",
    "\n",
    "        #statistics on the ts length\n",
    "        ts_len = [ _entry.shape[1] for _entry in _data[2]]\n",
    "        train_len = int(np.max(ts_len) * train_ratio)\n",
    "        if train_len == 0:\n",
    "            #use global train_len\n",
    "            train_len = _train_len\n",
    "\n",
    "        if context_ratio != 0.:\n",
    "            # add this part to train set\n",
    "            context_len = int(np.max(ts_len) * context_ratio)\n",
    "        else:    \n",
    "            context_len = prediction_length*2\n",
    "        if context_len < 10:\n",
    "            context_len = 10\n",
    "\n",
    "        print(f'after ====event:{events[_data[0]]}, prediction_len={prediction_length},train_len={train_len}, max_len={np.max(ts_len)}, min_len={np.min(ts_len)},context_len={context_len}')\n",
    "\n",
    "        # process for each ts\n",
    "        for rowid in range(_data[2].shape[0]):\n",
    "            # rec[features, lapnumber] -> [laptime, rank, track_status, lap_status,timediff]]\n",
    "            rec = _data[2][rowid].copy()\n",
    "\n",
    "            #remove nan(only tails)\n",
    "            nans, x= nan_helper(rec[run_ts,:])\n",
    "            nan_count = np.sum(nans)             \n",
    "            rec = rec[:, ~np.isnan(rec[run_ts,:])]\n",
    "\n",
    "            # remove short ts\n",
    "            totallen = rec.shape[1]\n",
    "\n",
    "            totalTSCnt += 1\n",
    "            totalTSLen += totallen\n",
    "\n",
    "            if ( totallen < train_len + prediction_length):\n",
    "                print(f'a short ts: carid={_data[1][rowid]}，len={totallen}')\n",
    "                continue                \n",
    "\n",
    "            carno = _data[1][rowid]\n",
    "            #carid = global_carids[_data[1][rowid]]\n",
    "\n",
    "            if carno == check_carno:\n",
    "                #show content in rec\n",
    "\n",
    "                #rank\n",
    "                print('rank:',rec[COL_RANK,:] )\n",
    "\n",
    "                #pitlaps\n",
    "                pits = np.where(rec[COL_LAPSTATUS,:]==1)\n",
    "                print('pits:', pits)                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_LAPTIME=0\n",
    "COL_RANK=1\n",
    "COL_TRACKSTATUS=2\n",
    "COL_LAPSTATUS=3\n",
    "COL_TIMEDIFF=4\n",
    "COL_CAUTION_LAPS_INSTINT=5\n",
    "COL_LAPS_INSTINT= 6\n",
    "COL_ELAPSED_TIME= 7\n",
    "COL_LAP2NEXTPIT = 8\n",
    "#_featureCnt = 9\n",
    "\n",
    "# added new features\n",
    "COL_LEADER_PITCNT = 9\n",
    "\n",
    "FEATURE_STATUS = 2\n",
    "FEATURE_PITAGE = 4\n",
    "FEATURE_LEADERPITCNT = 8\n",
    "\n",
    "#inlap status = \n",
    "# 0 , no inlap\n",
    "# 1 , set previous lap\n",
    "# 2 , set the next lap\n",
    "_inlap_status = 0\n",
    "\n",
    "#\n",
    "# featuremode in [FEATURE_STATUS, FEATURE_PITAGE]:\n",
    "#\n",
    "_feature_mode = FEATURE_LEADERPITCNT\n",
    "_featureCnt = 9\n",
    "\n",
    "#\n",
    "# training parameters\n",
    "#\n",
    "freq = \"1min\"\n",
    "_train_len = 40\n",
    "prediction_length = 2\n",
    "\n",
    "context_ratio = 0.\n",
    "context_length =  40\n",
    "contextlen = context_length\n",
    "\n",
    "dataset='rank'\n",
    "_run_ts = COL_RANK\n",
    "\n",
    "_test_event = 'Indy500-2018'\n",
    "year = '2018'\n",
    "\n",
    "#\n",
    "# string map\n",
    "#\n",
    "inlapstr = {0:'noinlap',1:'inlap',2:'outlap'}\n",
    "featurestr = {FEATURE_STATUS:'nopitage',FEATURE_PITAGE:'pitage',FEATURE_LEADERPITCNT:'leaderpitcnt'}\n",
    "weightstr = {True:'weighted',False:'noweighted'}\n",
    "catestr = {True:'cate',False:'nocate'}\n",
    "\n",
    "#\n",
    "# input data parameters\n",
    "#\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "events = [f'Indy500-{x}' for x in years]\n",
    "events_id={key:idx for idx, key in enumerate(events)}\n",
    "dbid = f'Indy500_{years[0]}_{years[-1]}_v{_featureCnt}_p{_inlap_status}'\n",
    "_dataset_id = '%s-%s'%(inlapstr[_inlap_status], featurestr[_feature_mode])\n",
    "\n",
    "# standard output file names\n",
    "LAPTIME_DATASET = f'laptime_rank_timediff_pit-oracle-{dbid}.pickle' \n",
    "STAGE_DATASET = f'stagedata-{dbid}.pickle' \n",
    "EVALUATION_RESULT_DF = f'evaluation_result_d{dataset}.csv'\n",
    "LONG_FORECASTING_DFS = f'long_forecasting_dfs_d{dataset}.pickle'\n",
    "FORECAST_FIGS_DIR = f'forecast-figs-d{dataset}/'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Laptime Dataset: test//gluontsdb-rank-oracle-noip-noeid-all-all-f1min-t2-rIndy500-2018-indy-2018-newlaptimedata.pickle\n",
      "Load New Laptime Dataset: test//gluontsdb-rank-oracle-noip-noeid-all-all-f1min-t2-rIndy500-2018-indy-2018-newlaptimedata.pickle\n"
     ]
    }
   ],
   "source": [
    "outdir = 'test/'\n",
    "outputRoot = outdir\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "_task_dir = f'{outdir}/'\n",
    "\n",
    "useeid = False\n",
    "interpolate = False\n",
    "#ipstr = '-ip' if interpolate else '-noip'\n",
    "ipstr = '%s-%s'%('ip' if interpolate else 'noip', 'eid' if useeid else 'noeid')\n",
    "dbname = _task_dir + f'gluontsdb-{dataset}-oracle-{ipstr}-all-all-f{freq}-t{prediction_length}-r{_test_event}-indy-{year}.pickle'\n",
    "laptimedb = _task_dir + f'gluontsdb-{dataset}-oracle-{ipstr}-all-all-f{freq}-t{prediction_length}-r{_test_event}-indy-{year}-newlaptimedata.pickle'\n",
    "\n",
    "print('Load Laptime Dataset:',laptimedb)\n",
    "with open(_task_dir + LAPTIME_DATASET, 'rb') as f:\n",
    "    global_carids, laptime_data = pickle.load(f, encoding='latin1') \n",
    "\n",
    "print('Load New Laptime Dataset:',laptimedb)\n",
    "with open(laptimedb, 'rb') as f:\n",
    "    prepared_laptimedata = pickle.load(f, encoding='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after ====event:Indy500-2013, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "rank: [ 4.  4.  4.  4.  4.  4.  5.  7.  7.  7.  7.  7.  7.  8.  8.  8.  8.  7.\n",
      "  7.  7.  7.  7.  7.  7.  7.  7.  7.  6.  5.  2.  0.  0.  4. 12. 11. 11.\n",
      " 11.  9. 10. 10. 10.  9.  9.  9.  9.  9.  7.  8.  9.  9.  8.  8.  8.  8.\n",
      "  8.  8.  7.  7.  4.  4.  4.  4.  4.  4.  4.  4.  3.  3.  3.  3.  3.  2.\n",
      "  2.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 22. 24.\n",
      " 17. 15.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  7.  9.  9.  9.  9.  9.\n",
      "  9. 10. 10.  9.  9.  9.  9.  9.  8.  8.  8.  8. 16. 16. 15. 12. 10. 10.\n",
      " 12. 12. 13. 13. 13. 13. 13. 12. 12. 11. 11. 11. 12. 12. 12. 12. 11. 11.\n",
      " 11. 11. 11. 11. 11. 11. 10.  8.  4.  7. 16. 16. 15. 14. 14. 15. 15. 15.\n",
      " 15. 15. 15. 15. 14. 12. 12. 12. 12. 12. 11. 11. 10. 10. 10.  7.  7.  6.\n",
      "  4.  3.  2.  2.  4. 11. 11. 11. 10. 11. 11. 11. 11. 12. 11. 12. 19. 18.\n",
      " 18. 18.]\n",
      "pits: (array([ 32,  57,  88, 120, 153, 184, 195]),)\n",
      "after ====event:Indy500-2014, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "rank: [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  1.  0.  3.  5.  2.  2.  2.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  1.  1.  1. 14. 12.  5.  3.  5.  4.  4.  4.  5.  5.  5.\n",
      "  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "  5.  4.  3.  4.  6.  6.  6.  6.  6.  6.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "  6.  6.  6.  6.  6.  6.  5.  5.  6.  6.  6.  6.  6.  5.  4.  2.  1.  1.\n",
      "  1.  6. 14. 18. 18. 18. 18. 18. 18. 17. 17. 17. 17. 17. 17. 17. 17. 17.\n",
      " 17. 16. 16. 14. 13. 13. 13. 13.  9. 12. 12. 12. 12. 14. 14. 14. 14. 14.\n",
      " 14. 14. 13. 13. 13. 14. 14.  9. 13. 13. 13. 12. 12. 10. 10. 10. 10. 10.\n",
      " 10. 10. 11. 10. 10. 10. 10. 10. 10. 10.  9.  9.  8.  7.  8.  7.  7.  7.\n",
      "  7.  7.]\n",
      "pits: (array([ 30,  61,  93, 126, 128, 152, 169, 191]),)\n",
      "after ====event:Indy500-2015, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "after ====event:Indy500-2016, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "rank: [ 4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  5.  5.  5.  6.  6.\n",
      "  6.  7.  7.  7.  7.  7.  8.  8.  8.  6.  4.  1.  3. 10.  8.  8.  8.  8.\n",
      "  8.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.  8.  8.  8. 17. 31.\n",
      " 31. 30. 29. 29. 29. 29. 27. 27. 27. 26. 26.  3.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  4.  4.  4.  5.  5.  6.  6.  7.  8.  8.  8.  8.  8.  8.\n",
      " 29. 29. 29. 28. 28. 28. 28. 28. 27. 25. 25. 25. 25. 23. 23. 23. 21. 19.\n",
      " 19. 19. 19. 19. 19. 19. 17. 17. 14. 13. 13. 12. 12. 13. 14. 14. 14. 15.\n",
      " 15. 15. 15. 17. 17. 17. 17. 15. 14. 14. 13. 13. 12. 12. 12. 11. 11. 11.\n",
      " 11. 11. 11. 10.  8. 12. 11. 10.  9.  6.  6.  6.  6.  8.  7.  6.  9.  9.\n",
      "  9.  8.  8.  7.  7.  9.  8.  9.  9.  9.  9. 10. 12. 13. 14. 17. 17. 18.\n",
      " 18. 18. 18. 18. 17. 16. 15. 14. 14. 13. 13. 12. 11. 10.  9.  7.  9.  8.\n",
      "  8.  9.]\n",
      "pits: (array([ 30,  47,  52,  90,  97, 116, 148, 163]),)\n",
      "after ====event:Indy500-2017, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "rank: [ 1.  2.  3.  3.  4.  6.  6.  6.  6.  9.  9.  9.  9.  9. 10. 10. 10. 10.\n",
      " 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.  5.  8. 11.  9.  9.  9.  9.  9.\n",
      "  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10.  9.  9.\n",
      "  9.  9.  7. 22. 22. 22. 20. 20. 20. 20. 19. 18. 19. 19. 18. 20. 20. 20.\n",
      " 20. 20. 21. 16. 15. 15. 15. 15. 15.  0.  0.  1.  1.  2.  4.  7.  7.  8.\n",
      "  8.  8.  9.  9.  8.  8.  8.  8.  8.  8.  8.  8.  8.  7. 22. 24. 24. 24.\n",
      " 23. 23. 22. 21. 18. 12.  4.  4.  4.  4.  4.  4.  4.  6.  6.  6.  6.  6.\n",
      "  6.  6.  6.  8.  8.  8.  8.  8.  8.  8.  7.  7. 13. 13. 13. 14. 14. 14.\n",
      " 14. 14. 14. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
      " 10. 10. 11. 10.  9.  7. 10. 10. 10. 11. 12. 12. 13. 13. 12. 12. 12. 11.\n",
      " 11. 11. 11.]\n",
      "pits: (array([ 29,  54,  56,  68, 104, 138, 167]),)\n",
      "after ====event:Indy500-2018, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "rank: [ 2.  2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  4.  2.  4. 18. 10.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  4.  4.  4.  4.\n",
      "  4.  6.  6.  6.  6.  6.  6.  6.  6.  5.  5.  5.  5.  5.  5.  4.  4.  4.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  2.\n",
      "  2.  1.  1.  1. 13.  9.  8.  8.  8.  8.  6.  6.  6.  5.  5.  2.  2.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  2. 11.  7.  6.  6.  5.  4.  4.  3.  2.  2.  2.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  8. 16. 13. 10.  9.  8.  7.  7.  7.  6.\n",
      "  6.  5.  5.  5.  4.  4.  4.  4.  4.  4.  4.  4.  4.  3.  3.  1.  1.  1.\n",
      "  1.  1.]\n",
      "pits: (array([ 31,  49,  93, 128, 170]),)\n"
     ]
    }
   ],
   "source": [
    "check_laptimedata(prepared_laptimedata, check_carno=12)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after ====event:Indy500-2013, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "a short ts: carid=4，len=3\n",
      "a short ts: carid=6，len=34\n",
      "rank: [ 5.  5.  5.  5.  5.  5.  6.  8.  8.  8.  8.  8.  8.  9.  9.  9.  9.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  7.  6.  3.  1.  1.  5. 13. 12. 12.\n",
      " 12. 10. 11. 11. 11. 10. 10. 10. 10. 10.  8.  9. 10. 10.  9.  9.  9.  9.\n",
      "  9.  9.  8.  8.  5.  5.  5.  5.  5.  5.  5.  5.  4.  4.  4.  4.  4.  3.\n",
      "  3.  3.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. 23. 25.\n",
      " 18. 16.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  8. 10. 10. 10. 10. 10.\n",
      " 10. 11. 11. 10. 10. 10. 10. 10.  9.  9.  9.  9. 17. 17. 16. 13. 11. 11.\n",
      " 13. 13. 14. 14. 14. 14. 14. 13. 13. 12. 12. 12. 13. 13. 13. 13. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 11.  9.  5.  8. 17. 17. 16. 15. 15. 16. 16. 16.\n",
      " 16. 16. 16. 16. 15. 13. 13. 13. 13. 13. 12. 12. 11. 11. 11.  8.  8.  7.\n",
      "  5.  4.  3.  3.  5. 12. 12. 12. 11. 12. 12. 12. 12. 13. 12. 13. 20. 19.\n",
      " 19. 19.]\n",
      "pits: (array([ 32,  57,  88, 120, 153, 184, 195]),)\n",
      "after ====event:Indy500-2014, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "rank: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  2.  1.  4.  6.  3.  3.  3.  2.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  2.  2.  2.  2. 15. 13.  6.  4.  6.  5.  5.  5.  6.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  6.  5.  4.  5.  7.  7.  7.  7.  7.  7.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  7.  7.  7.  7.  7.  7.  6.  6.  7.  7.  7.  7.  7.  6.  5.  3.  2.  2.\n",
      "  2.  7. 15. 19. 19. 19. 19. 19. 19. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 17. 17. 15. 14. 14. 14. 14. 10. 13. 13. 13. 13. 15. 15. 15. 15. 15.\n",
      " 15. 15. 14. 14. 14. 15. 15. 10. 14. 14. 14. 13. 13. 11. 11. 11. 11. 11.\n",
      " 11. 11. 12. 11. 11. 11. 11. 11. 11. 11. 10. 10.  9.  8.  9.  8.  8.  8.\n",
      "  8.  8.]\n",
      "pits: (array([ 30,  61,  93, 126, 128, 152, 169, 191]),)\n",
      "after ====event:Indy500-2015, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "a short ts: carid=8，len=0\n",
      "a short ts: carid=43，len=0\n",
      "after ====event:Indy500-2016, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "rank: [ 5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  6.  6.  6.  7.  7.\n",
      "  7.  8.  8.  8.  8.  8.  9.  9.  9.  7.  5.  2.  4. 11.  9.  9.  9.  9.\n",
      "  9.  9. 10. 11. 11. 11. 11. 11. 11. 11. 11. 11.  9.  9.  9.  9. 18. 32.\n",
      " 32. 31. 30. 30. 30. 30. 28. 28. 28. 27. 27.  4.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  2.  3.  5.  5.  5.  6.  6.  7.  7.  8.  9.  9.  9.  9.  9.  9.\n",
      " 30. 30. 30. 29. 29. 29. 29. 29. 28. 26. 26. 26. 26. 24. 24. 24. 22. 20.\n",
      " 20. 20. 20. 20. 20. 20. 18. 18. 15. 14. 14. 13. 13. 14. 15. 15. 15. 16.\n",
      " 16. 16. 16. 18. 18. 18. 18. 16. 15. 15. 14. 14. 13. 13. 13. 12. 12. 12.\n",
      " 12. 12. 12. 11.  9. 13. 12. 11. 10.  7.  7.  7.  7.  9.  8.  7. 10. 10.\n",
      " 10.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 11. 13. 14. 15. 18. 18. 19.\n",
      " 19. 19. 19. 19. 18. 17. 16. 15. 15. 14. 14. 13. 12. 11. 10.  8. 10.  9.\n",
      "  9. 10.]\n",
      "pits: (array([ 30,  47,  52,  90,  97, 116, 148, 163]),)\n",
      "after ====event:Indy500-2017, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "rank: [ 2.  3.  4.  4.  5.  7.  7.  7.  7. 10. 10. 10. 10. 10. 11. 11. 11. 11.\n",
      " 11. 11. 11. 11. 11. 11. 11. 11. 11. 10.  6.  9. 12. 10. 10. 10. 10. 10.\n",
      " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 11. 11. 11. 11. 11. 10. 10.\n",
      " 10. 10.  8. 23. 23. 23. 21. 21. 21. 21. 20. 19. 20. 20. 19. 21. 21. 21.\n",
      " 21. 21. 22. 17. 16. 16. 16. 16. 16.  1.  1.  2.  2.  3.  5.  8.  8.  9.\n",
      "  9.  9. 10. 10.  9.  9.  9.  9.  9.  9.  9.  9.  9.  8. 23. 25. 25. 25.\n",
      " 24. 24. 23. 22. 19. 13.  5.  5.  5.  5.  5.  5.  5.  7.  7.  7.  7.  7.\n",
      "  7.  7.  7.  9.  9.  9.  9.  9.  9.  9.  8.  8. 14. 14. 14. 15. 15. 15.\n",
      " 15. 15. 15. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11.\n",
      " 11. 11. 12. 11. 10.  8. 11. 11. 11. 12. 13. 13. 14. 14. 13. 13. 13. 12.\n",
      " 12. 12. 12.]\n",
      "pits: (array([ 29,  54,  56,  68, 104, 138, 167]),)\n",
      "after ====event:Indy500-2018, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "rank: [ 2.  2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  4.  2.  4. 18. 10.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  4.  4.  4.  4.\n",
      "  4.  6.  6.  6.  6.  6.  6.  6.  6.  5.  5.  5.  5.  5.  5.  4.  4.  4.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  2.\n",
      "  2.  1.  1.  1. 13.  9.  8.  8.  8.  8.  6.  6.  6.  5.  5.  2.  2.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  2. 11.  7.  6.  6.  5.  4.  4.  3.  2.  2.  2.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  8. 16. 13. 10.  9.  8.  7.  7.  7.  6.\n",
      "  6.  5.  5.  5.  4.  4.  4.  4.  4.  4.  4.  4.  4.  3.  3.  1.  1.  1.\n",
      "  1.  1.]\n",
      "pits: (array([ 31,  49,  93, 128, 170]),)\n",
      "after ====event:Indy500-2019, prediction_len=2,train_len=40, max_len=200, min_len=200,context_len=10\n",
      "rank: [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  1.  1.  1.  9. 13.\n",
      "  6.  4.  4.  3.  3.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  3.  3.  2.  2.  2.  1.  2. 12.  8.  8.  8.\n",
      "  7.  7.  6.  6.  6. 10. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21.\n",
      " 21. 21. 21. 21. 21. 21. 21. 21. 21. 20. 20. 16. 15. 12.  8.  9. 20. 19.\n",
      " 19. 18. 17. 17. 17. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 17. 17. 17. 15. 12. 10. 13. 19. 19. 19. 18. 18. 17. 17. 17.\n",
      " 16. 16. 16. 16. 16. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 14. 12.  8.  5.  2.  1.  1.  1.  3. 12. 12. 12. 12.\n",
      " 12.  9.  9.  9.  9.  9.  9.  6.  6.  6.  6.  6.  6.  6.  6.  5.  5.  5.\n",
      "  5.  5.]\n",
      "pits: (array([ 34,  67, 105, 135, 175, 179]),)\n",
      "a short ts: carid=88，len=4\n"
     ]
    }
   ],
   "source": [
    "check_laptimedata(laptime_data, check_carno=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
