{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stage_model_classifier\n",
    "\n",
    "base: 14./stage_model_classifier_withneighbor-newfeatures\n",
    "\n",
    "prediction models of sign classifiers on stage dataset\n",
    "\n",
    "data format:\n",
    "    target , eventid ,    car_number,    stageid,     features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulid regression model\n",
    "#classifiers = ['currank','avgrank','dice','lr','lrl1','lsvc','lsvcl2','rf','lrbias','xgb']\n",
    "classifiers = ['currank','avgrank','dice','lr','lsvc','lsvcl2','rf','lrbias','xgb']\n",
    "def get_classifier(classifier = 'lr'):\n",
    "    \n",
    "    class_weight = None\n",
    "    \n",
    "    if classifier == \"lsvc\":\n",
    "        clf = LinearSVC(penalty='l1',dual=False, tol=1e-3, class_weight=class_weight )\n",
    "    elif classifier == \"lsvcl2\":\n",
    "        clf = LinearSVC(penalty='l2', tol=1e-4, class_weight=class_weight)\n",
    "    elif classifier == 'rf':\n",
    "        #clf = RandomForestClassifier(n_estimators=100, n_jobs=4,criterion='entropy', min_samples_split=1,class_weight = class_weight)\n",
    "        clf = RandomForestClassifier(n_estimators=100, n_jobs=-1,criterion='entropy', class_weight = class_weight)\n",
    "    elif classifier == 'lr':\n",
    "        clf = LogisticRegression(class_weight = class_weight, n_jobs=-1, fit_intercept = False, verbose = 0)\n",
    "    elif classifier == 'lrbias':\n",
    "        clf = LogisticRegression(class_weight = class_weight, n_jobs=-1, fit_intercept = True, verbose = 1)\n",
    "    elif classifier == 'lrl1':\n",
    "        clf = LogisticRegression(class_weight = class_weight, penalty='l1',n_jobs=-1)\n",
    "    elif classifier == 'xgb':\n",
    "        clf = xgb.XGBClassifier(booster = 'gbtree', nthread = -1, subsample = 1, \n",
    "                                n_estimators = 600, colsample_bytree = 1, max_depth = 6, min_child_weight = 1)\n",
    "    elif classifier == 'dice':\n",
    "        clf = RandomDice('1234')\n",
    "    elif classifier == 'currank':\n",
    "        clf = CurRank()\n",
    "    elif classifier == 'avgrank':\n",
    "        clf = AverageRank()        \n",
    "    else:\n",
    "        clf = None\n",
    "        \n",
    "    return clf\n",
    "\n",
    "\n",
    "class CurRank():\n",
    "    \"\"\"\n",
    "    predict with current rank\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    def predict(self, test_x):\n",
    "        pred_y = [0 for x in range(test_x.shape[0])]\n",
    "        return np.array(pred_y)\n",
    "    \n",
    "class AverageRank():\n",
    "    \"\"\"\n",
    "    print('[*] predict with average rankchg (change_in_rank_all):idx = 15')\n",
    "    change_in_rank_all = test[:,15]\n",
    "    pred_y_avg = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in change_in_rank_all])\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    def predict(self, test_x):\n",
    "        pred_y = []\n",
    "        for x in test_x:\n",
    "            #13, change_in_rank_all\n",
    "            pred_y.append(x[13])\n",
    "        pred_y_avg = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in pred_y])\n",
    "        return np.array(pred_y_avg)   \n",
    "\n",
    "class RandomDice():\n",
    "    \"\"\"\n",
    "    a random dice model\n",
    "    \"\"\"\n",
    "    def __init__(self, seed='1234'):\n",
    "        self.dist = []\n",
    "        self.val = []\n",
    "        random.seed(seed)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        total = y.shape[0]\n",
    "        yval = set(y)\n",
    "        \n",
    "        ratio = 0.\n",
    "        for val in yval:\n",
    "            self.val.append(val)\n",
    "            ratio += np.sum(y==val)*1.0 / total\n",
    "            self.dist.append(ratio)\n",
    "            \n",
    "    def predict(self, test_x):\n",
    "        pred_y = []\n",
    "        for x in test_x:\n",
    "            dice = random.random()\n",
    "            #search in self.dist\n",
    "            find_idx = -1\n",
    "            for idx, ratio in enumerate(self.dist):\n",
    "                if dice <= ratio:\n",
    "                    find_idx = idx\n",
    "                    break\n",
    "            \n",
    "            #or the last one match\n",
    "            pred_y.append(self.val[find_idx])\n",
    "            \n",
    "        return np.array(pred_y)\n",
    "\n",
    "def evaluate(test_y, pred_y):\n",
    "    precision = metrics.precision_score(test_y, pred_y, average=None) \n",
    "    recall = metrics.recall_score(test_y, pred_y, average=None)\n",
    "    f1 = metrics.f1_score(test_y, pred_y, average=None)\n",
    "    accuracy = metrics.accuracy_score(test_y, pred_y)\n",
    "    print('precision=%s, recall=%s, f1=%s, accuracy=%.2f'%(precision,recall, f1, accuracy))\n",
    "    return accuracy\n",
    "    \n",
    "#\n",
    "#features\n",
    "#    cols=[Myidx, 'target','eventid','car_number','stageid',\n",
    "#             'firststage','pit_in_caution','start_position',\n",
    "#             'start_rank','start_rank_ratio','top_pack','bottom_pack',\n",
    "#             'average_rank','average_rank_all',\n",
    "#             'change_in_rank','change_in_rank_all','rate_of_change','rate_of_change_all']    \n",
    "def split_by_eventid(stagedata, eventid):\n",
    "    \"\"\"\n",
    "    split by eventid\n",
    "    \"\"\"\n",
    "    #if not eventid in stagedata:\n",
    "    #    print('error, %d not found in stagedata'%eventid)\n",
    "    #    return\n",
    "    \n",
    "    train = stagedata[stagedata['eventid'] != eventid].to_numpy()\n",
    "    test  = stagedata[stagedata['eventid'] == eventid].to_numpy()\n",
    "\n",
    "    #2:car_number\n",
    "    train_x = train[:,2:]\n",
    "    train_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in train[:,1]])\n",
    "    test_x = test[:,2:]\n",
    "    test_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in test[:,1]])\n",
    "    \n",
    "    return train, test, train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def split_by_stageid(stagedata, stageid):\n",
    "    \"\"\"\n",
    "    split by stageid\n",
    "    \"\"\"\n",
    "    #if not eventid in stagedata:\n",
    "    #    print('error, %d not found in stagedata'%eventid)\n",
    "    #    return\n",
    "    \n",
    "    train = stagedata[stagedata['stageid'] <= stageid].to_numpy()\n",
    "    test  = stagedata[stagedata['stageid'] > stageid].to_numpy()\n",
    "\n",
    "    train_x = train[:,2:]\n",
    "    train_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in train[:,1]])\n",
    "    test_x = test[:,2:]\n",
    "    test_y = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in test[:,1]])\n",
    "    \n",
    "    return train, test, train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "### baseline\n",
    "def baseline_model():\n",
    "    #1. predict with current rank, rankchg = 0\n",
    "    print('[*] predict with current rank, rankchg = 0')\n",
    "    pred_y_simple = np.zeros_like(test_y)\n",
    "    score1 = evaluate(test_y, pred_y_simple)\n",
    "\n",
    "    #2. predict with average rankchg (change_in_rank_all):idx = 15\n",
    "    print('[*] predict with average rankchg (change_in_rank_all):idx = 15')\n",
    "    change_in_rank_all = test[:,15]\n",
    "    pred_y_avg = np.array([1 if x > 0 else (-1 if x < 0 else 0) for x in change_in_rank_all])\n",
    "    score2 = evaluate(test_y, pred_y_avg)\n",
    "    return score1, score2\n",
    "\n",
    "def classifier_model(name='lr'):\n",
    "    ### test learning models\n",
    "    print('[*] predict with %s model'%name)\n",
    "    clf = get_classifier(name)\n",
    "    clf.fit(train_x, train_y)\n",
    "\n",
    "    pred_y = clf.predict(test_x)\n",
    "    score = evaluate(test_y, pred_y)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 35 columns):\n",
      "Unnamed: 0                   1313 non-null int64\n",
      "target                       1313 non-null int64\n",
      "eventid                      1313 non-null int64\n",
      "car_number                   1313 non-null int64\n",
      "stageid                      1313 non-null int64\n",
      "firststage                   1313 non-null int64\n",
      "pit_in_caution               1313 non-null int64\n",
      "start_position               1313 non-null int64\n",
      "start_rank                   1313 non-null int64\n",
      "start_rank_ratio             1313 non-null float64\n",
      "top_pack                     1313 non-null int64\n",
      "bottom_pack                  1313 non-null int64\n",
      "average_rank                 1313 non-null float64\n",
      "average_rank_all             1313 non-null float64\n",
      "change_in_rank               1313 non-null int64\n",
      "change_in_rank_all           1313 non-null float64\n",
      "rate_of_change               1313 non-null int64\n",
      "rate_of_change_all           1313 non-null float64\n",
      "laptime_green_mean_prev      1313 non-null float64\n",
      "laptime_green_std_prev       1313 non-null float64\n",
      "laptime_green_mean_all       1313 non-null float64\n",
      "laptime_green_std_all        1313 non-null float64\n",
      "laptime_mean_prev            1313 non-null float64\n",
      "laptime_std_prev             1313 non-null float64\n",
      "laptime_mean_all             1313 non-null float64\n",
      "laptime_std_all              1313 non-null float64\n",
      "laps_prev                    1313 non-null int64\n",
      "laps_after_last_pitstop      1313 non-null int64\n",
      "pittime_prev                 1313 non-null float64\n",
      "prev_nb0_change_in_rank      1313 non-null int64\n",
      "prev_nb1_change_in_rank      1313 non-null int64\n",
      "prev_nb2_change_in_rank      1313 non-null int64\n",
      "follow_nb0_change_in_rank    1313 non-null int64\n",
      "follow_nb1_change_in_rank    1313 non-null int64\n",
      "follow_nb2_change_in_rank    1313 non-null int64\n",
      "dtypes: float64(14), int64(21)\n",
      "memory usage: 359.1 KB\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "_trim = 2\n",
    "_include_final = False\n",
    "include_str = '1' if _include_final else '0'\n",
    "suffix = f'indy500-2013-2019-end{include_str}-t{_trim}'\n",
    "output_file = f'stage-indy500-2013-2019-end{include_str}-t{_trim}.csv'\n",
    "stagedata = pd.read_csv(output_file)\n",
    "\n",
    "\n",
    "stagedata.fillna(0, inplace=True)\n",
    "stagedata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>eventid</th>\n",
       "      <th>car_number</th>\n",
       "      <th>stageid</th>\n",
       "      <th>firststage</th>\n",
       "      <th>pit_in_caution</th>\n",
       "      <th>start_position</th>\n",
       "      <th>start_rank</th>\n",
       "      <th>start_rank_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>laptime_std_all</th>\n",
       "      <th>laps_prev</th>\n",
       "      <th>laps_after_last_pitstop</th>\n",
       "      <th>pittime_prev</th>\n",
       "      <th>prev_nb0_change_in_rank</th>\n",
       "      <th>prev_nb1_change_in_rank</th>\n",
       "      <th>prev_nb2_change_in_rank</th>\n",
       "      <th>follow_nb0_change_in_rank</th>\n",
       "      <th>follow_nb1_change_in_rank</th>\n",
       "      <th>follow_nb2_change_in_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>23.559273</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>66.08150</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>24.168072</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>62.06770</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>22.044163</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>91.23935</td>\n",
       "      <td>-3</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>19.526487</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>61.19415</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>...</td>\n",
       "      <td>17.837355</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>60.85410</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  target  eventid  car_number  stageid  firststage  \\\n",
       "0           1       0        0           1        1           1   \n",
       "1           2       0        0           1        2           1   \n",
       "2           3       0        0           1        3           1   \n",
       "3           4      -1        0           1        4           1   \n",
       "4           5       1        0           1        5           1   \n",
       "\n",
       "   pit_in_caution  start_position  start_rank  start_rank_ratio  ...  \\\n",
       "0               0               7           3          0.090909  ...   \n",
       "1               1               7           3          0.090909  ...   \n",
       "2               0               7           3          0.090909  ...   \n",
       "3               0               7           3          0.090909  ...   \n",
       "4               0               7           2          0.060606  ...   \n",
       "\n",
       "   laptime_std_all  laps_prev  laps_after_last_pitstop  pittime_prev  \\\n",
       "0        23.559273         29                       29      66.08150   \n",
       "1        24.168072         27                       25      62.06770   \n",
       "2        22.044163         32                       30      91.23935   \n",
       "3        19.526487         32                       30      61.19415   \n",
       "4        17.837355         30                       28      60.85410   \n",
       "\n",
       "   prev_nb0_change_in_rank  prev_nb1_change_in_rank  prev_nb2_change_in_rank  \\\n",
       "0                        2                       -1                        0   \n",
       "1                        0                       -2                        0   \n",
       "2                       -3                       -8                        0   \n",
       "3                       -2                       -1                        0   \n",
       "4                       -2                        0                        0   \n",
       "\n",
       "   follow_nb0_change_in_rank  follow_nb1_change_in_rank  \\\n",
       "0                          2                          2   \n",
       "1                          0                          4   \n",
       "2                         -8                          3   \n",
       "3                          0                         -5   \n",
       "4                          1                          0   \n",
       "\n",
       "   follow_nb2_change_in_rank  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                         -3  \n",
       "4                         -3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stagedata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['runid', 'trainsize', 'testsize', 'testdistribution', 'currank', 'avgrank', 'dice', 'lr', 'lsvc', 'lsvcl2', 'rf', 'lrbias', 'xgb']\n",
      "Testset = Indy500-2013\n",
      "[*] predict with currank model\n",
      "precision=[0.        0.1746988 0.       ], recall=[0. 1. 0.], f1=[0.        0.2974359 0.       ], accuracy=0.17\n",
      "[*] predict with avgrank model\n",
      "precision=[0.42201835 0.25       0.20408163], recall=[0.56790123 0.06896552 0.17857143], f1=[0.48421053 0.10810811 0.19047619], accuracy=0.35\n",
      "[*] predict with dice model\n",
      "precision=[0.52173913 0.26666667 0.36363636], recall=[0.59259259 0.27586207 0.28571429], f1=[0.55491329 0.27118644 0.32      ], accuracy=0.43\n",
      "[*] predict with lr model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.625      0.         0.44871795], recall=[0.67901235 0.         0.625     ], f1=[0.65088757 0.         0.52238806], accuracy=0.54\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.63333333 0.         0.46052632], recall=[0.7037037 0.        0.625    ], f1=[0.66666667 0.         0.53030303], accuracy=0.55\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[1.         0.         0.33939394], recall=[0.01234568 0.         1.        ], f1=[0.02439024 0.         0.50678733], accuracy=0.34\n",
      "[*] predict with rf model\n",
      "precision=[0.62857143 1.         0.55      ], recall=[0.81481481 0.03448276 0.58928571], f1=[0.70967742 0.06666667 0.56896552], accuracy=0.60\n",
      "[*] predict with lrbias model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.62921348 0.         0.45454545], recall=[0.69135802 0.         0.625     ], f1=[0.65882353 0.         0.52631579], accuracy=0.55\n",
      "[*] predict with xgb model\n",
      "precision=[0.65116279 0.33333333 0.51470588], recall=[0.69135802 0.13793103 0.625     ], f1=[0.67065868 0.19512195 0.56451613], accuracy=0.57\n",
      "rec:['Indy500-2013', 1147, 166, '+:56,0:29,-:81', 0.1746987951807229, 0.3493975903614458, 0.43373493975903615, 0.5421686746987951, 0.5542168674698795, 0.3433734939759036, 0.6024096385542169, 0.5481927710843374, 0.572289156626506]\n",
      "Testset = Indy500-2014\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.14871795 0.        ], recall=[0. 1. 0.], f1=[0.         0.25892857 0.        ], accuracy=0.15\n",
      "[*] predict with avgrank model\n",
      "precision=[0.51694915 0.         0.25396825], recall=[0.56481481 0.         0.27586207], f1=[0.53982301 0.         0.26446281], accuracy=0.39\n",
      "[*] predict with dice model\n",
      "precision=[0.60952381 0.11764706 0.33928571], recall=[0.59259259 0.13793103 0.32758621], f1=[0.60093897 0.12698413 0.33333333], accuracy=0.45\n",
      "[*] predict with lr model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.66141732 0.         0.44117647], recall=[0.77777778 0.         0.51724138], f1=[0.71489362 0.         0.47619048], accuracy=0.58\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.61016949 0.         0.37662338], recall=[0.66666667 0.         0.5       ], f1=[0.63716814 0.         0.42962963], accuracy=0.52\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.6875     0.34782609 0.48333333], recall=[0.71296296 0.27586207 0.5       ], f1=[0.7        0.30769231 0.49152542], accuracy=0.58\n",
      "[*] predict with rf model\n",
      "precision=[0.61038961 0.15384615 0.36363636], recall=[0.43518519 0.27586207 0.4137931 ], f1=[0.50810811 0.19753086 0.38709677], accuracy=0.41\n",
      "[*] predict with lrbias model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.65648855 0.         0.453125  ], recall=[0.7962963 0.        0.5      ], f1=[0.71966527 0.         0.47540984], accuracy=0.59\n",
      "[*] predict with xgb model\n",
      "precision=[0.71111111 0.1686747  0.3880597 ], recall=[0.2962963  0.48275862 0.44827586], f1=[0.41830065 0.25       0.416     ], accuracy=0.37\n",
      "rec:['Indy500-2014', 1118, 195, '+:58,0:29,-:108', 0.14871794871794872, 0.39487179487179486, 0.4461538461538462, 0.5846153846153846, 0.517948717948718, 0.5846153846153846, 0.40512820512820513, 0.5897435897435898, 0.36923076923076925]\n",
      "Testset = Indy500-2015\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.15568862 0.        ], recall=[0. 1. 0.], f1=[0.         0.26943005 0.        ], accuracy=0.16\n",
      "[*] predict with avgrank model\n",
      "precision=[0.47191011 0.33333333 0.26984127], recall=[0.53846154 0.19230769 0.26984127], f1=[0.50299401 0.24390244 0.26984127], accuracy=0.38\n",
      "[*] predict with dice model\n",
      "precision=[0.45652174 0.06666667 0.4       ], recall=[0.53846154 0.07692308 0.28571429], f1=[0.49411765 0.07142857 0.33333333], accuracy=0.37\n",
      "[*] predict with lr model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.52238806 0.         0.63636364], recall=[0.8974359  0.         0.33333333], f1=[0.66037736 0.         0.4375    ], accuracy=0.54\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.5530303 0.        0.6969697], recall=[0.93589744 0.         0.36507937], f1=[0.6952381  0.         0.47916667], accuracy=0.57\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.47852761 0.         1.        ], recall=[1.         0.         0.06349206], f1=[0.6473029  0.         0.11940299], accuracy=0.49\n",
      "[*] predict with rf model\n",
      "precision=[0.55645161 0.14285714 0.63888889], recall=[0.88461538 0.03846154 0.36507937], f1=[0.68316832 0.06060606 0.46464646], accuracy=0.56\n",
      "[*] predict with lrbias model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.51851852 0.         0.625     ], recall=[0.8974359  0.         0.31746032], f1=[0.657277   0.         0.42105263], accuracy=0.54\n",
      "[*] predict with xgb model\n",
      "precision=[0.57731959 0.17391304 0.59574468], recall=[0.71794872 0.15384615 0.44444444], f1=[0.64       0.16326531 0.50909091], accuracy=0.53\n",
      "rec:['Indy500-2015', 1146, 167, '+:63,0:26,-:78', 0.15568862275449102, 0.38323353293413176, 0.3712574850299401, 0.5449101796407185, 0.5748502994011976, 0.49101796407185627, 0.5568862275449101, 0.5389221556886228, 0.5269461077844312]\n",
      "Testset = Indy500-2016\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.15929204 0.        ], recall=[0. 1. 0.], f1=[0.         0.27480916 0.        ], accuracy=0.16\n",
      "[*] predict with avgrank model\n",
      "precision=[0.42519685 0.13333333 0.28571429], recall=[0.48648649 0.05555556 0.30379747], f1=[0.45378151 0.07843137 0.29447853], accuracy=0.35\n",
      "[*] predict with dice model\n",
      "precision=[0.504      0.19512195 0.4       ], recall=[0.56756757 0.22222222 0.30379747], f1=[0.53389831 0.20779221 0.34532374], accuracy=0.42\n",
      "[*] predict with lr model\n",
      "precision=[0.56962025 0.28571429 0.68085106], recall=[0.81081081 0.16666667 0.40506329], f1=[0.66914498 0.21052632 0.50793651], accuracy=0.57\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.58682635 0.17647059 0.78571429], recall=[0.88288288 0.08333333 0.41772152], f1=[0.70503597 0.11320755 0.54545455], accuracy=0.59\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.         0.1978022  0.44360902], recall=[0.         0.5        0.74683544], f1=[0.         0.28346457 0.55660377], accuracy=0.34\n",
      "[*] predict with rf model\n",
      "precision=[0.58227848 0.1        0.53448276], recall=[0.82882883 0.02777778 0.39240506], f1=[0.68401487 0.04347826 0.45255474], accuracy=0.55\n",
      "[*] predict with lrbias model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.56875    0.33333333 0.6875    ], recall=[0.81981982 0.16666667 0.41772152], f1=[0.67158672 0.22222222 0.51968504], accuracy=0.58\n",
      "[*] predict with xgb model\n",
      "precision=[0.536      0.125      0.44155844], recall=[0.6036036  0.08333333 0.43037975], f1=[0.56779661 0.1        0.43589744], accuracy=0.46\n",
      "rec:['Indy500-2016', 1087, 226, '+:79,0:36,-:111', 0.1592920353982301, 0.35398230088495575, 0.42035398230088494, 0.5663716814159292, 0.5929203539823009, 0.3407079646017699, 0.5486725663716814, 0.5752212389380531, 0.46017699115044247]\n",
      "Testset = Indy500-2017\n",
      "[*] predict with currank model\n",
      "precision=[0.        0.2744186 0.       ], recall=[0. 1. 0.], f1=[0.         0.43065693 0.        ], accuracy=0.27\n",
      "[*] predict with avgrank model\n",
      "precision=[0.39007092 0.3125     0.27586207], recall=[0.59782609 0.08474576 0.25      ], f1=[0.472103   0.13333333 0.26229508], accuracy=0.35\n",
      "[*] predict with dice model\n",
      "precision=[0.43697479 0.29411765 0.24193548], recall=[0.56521739 0.16949153 0.234375  ], f1=[0.492891   0.21505376 0.23809524], accuracy=0.36\n",
      "[*] predict with lr model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.3968254  0.21052632 0.47368421], recall=[0.27173913 0.40677966 0.28125   ], f1=[0.32258065 0.27745665 0.35294118], accuracy=0.31\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.38961039 0.20588235 0.5       ], recall=[0.32608696 0.3559322  0.28125   ], f1=[0.35502959 0.26086957 0.36      ], accuracy=0.32\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.45454545 0.26612903 0.33333333], recall=[0.10869565 0.55932203 0.359375  ], f1=[0.1754386  0.36065574 0.34586466], accuracy=0.31\n",
      "[*] predict with rf model\n",
      "precision=[0.48       0.23076923 0.51923077], recall=[0.7826087  0.05084746 0.421875  ], f1=[0.59504132 0.08333333 0.46551724], accuracy=0.47\n",
      "[*] predict with lrbias model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.38596491 0.20338983 0.475     ], recall=[0.23913043 0.40677966 0.296875  ], f1=[0.29530201 0.27118644 0.36538462], accuracy=0.30\n",
      "[*] predict with xgb model\n",
      "precision=[0.5        0.33333333 0.51785714], recall=[0.68478261 0.18644068 0.453125  ], f1=[0.57798165 0.23913043 0.48333333], accuracy=0.48\n",
      "rec:['Indy500-2017', 1098, 215, '+:64,0:59,-:92', 0.2744186046511628, 0.35348837209302325, 0.3581395348837209, 0.3116279069767442, 0.3209302325581395, 0.30697674418604654, 0.4744186046511628, 0.3023255813953488, 0.4790697674418605]\n",
      "Testset = Indy500-2018\n",
      "[*] predict with currank model\n",
      "precision=[0.        0.1572327 0.       ], recall=[0. 1. 0.], f1=[0.         0.27173913 0.        ], accuracy=0.16\n",
      "[*] predict with avgrank model\n",
      "precision=[0.39047619 0.25       0.21052632], recall=[0.58571429 0.16       0.125     ], f1=[0.46857143 0.19512195 0.15686275], accuracy=0.33\n",
      "[*] predict with dice model\n",
      "precision=[0.50561798 0.17857143 0.5       ], recall=[0.64285714 0.2        0.328125  ], f1=[0.56603774 0.18867925 0.39622642], accuracy=0.45\n",
      "[*] predict with lr model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.5505618  1.         0.56521739], recall=[0.7      0.04     0.609375], f1=[0.6163522  0.07692308 0.58646617], accuracy=0.56\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.57608696 0.         0.56716418], recall=[0.75714286 0.         0.59375   ], f1=[0.65432099 0.         0.58015267], accuracy=0.57\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.         0.38461538 0.41780822], recall=[0.       0.2      0.953125], f1=[0.         0.26315789 0.58095238], accuracy=0.42\n",
      "[*] predict with rf model\n",
      "precision=[0.56989247 0.2        0.57377049], recall=[0.75714286 0.04       0.546875  ], f1=[0.65030675 0.06666667 0.56      ], accuracy=0.56\n",
      "[*] predict with lrbias model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.54545455 0.         0.54929577], recall=[0.68571429 0.         0.609375  ], f1=[0.60759494 0.         0.57777778], accuracy=0.55\n",
      "[*] predict with xgb model\n",
      "precision=[0.56       0.26315789 0.6       ], recall=[0.6      0.2      0.609375], f1=[0.57931034 0.22727273 0.60465116], accuracy=0.54\n",
      "rec:['Indy500-2018', 1154, 159, '+:64,0:25,-:70', 0.15723270440251572, 0.3333333333333333, 0.44654088050314467, 0.559748427672956, 0.5723270440251572, 0.41509433962264153, 0.559748427672956, 0.5471698113207547, 0.5408805031446541]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-01b470a37dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meventid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testset = %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0meventsname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meventid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_by_eventid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstagedata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meventid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "cols = ['runid','trainsize','testsize','testdistribution']\n",
    "cols.extend(classifiers)\n",
    "print('cols:%s'%cols)\n",
    "retdf = pd.DataFrame([],columns=cols)\n",
    "\n",
    "\n",
    "events = set(stagedata['eventid'])\n",
    "\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "#events = ['Indy500']\n",
    "eventsname = [f'Indy500-{x}' for x in years]\n",
    "events_id={key:idx for idx, key in enumerate(eventsname)}\n",
    "\n",
    "\n",
    "for eventid in events:\n",
    "    print('Testset = %s'%eventsname[eventid])\n",
    "    \n",
    "    train, test, train_x, train_y, test_x, test_y = split_by_eventid(stagedata, eventid)\n",
    "    test_distribution = '+:%d,0:%d,-:%d'%(np.sum(test_y>0),np.sum(test_y==0),np.sum(test_y<0))\n",
    "    #print('Testset by stageid= %s, trainsize=%d, testsize=%d, dist=%s'%\n",
    "    #      (stageid, train_x.shape[0], test_x.shape[0], test_distribution))\n",
    "    \n",
    "    #record\n",
    "    rec = [eventsname[eventid],train_x.shape[0],test_x.shape[0],test_distribution]\n",
    "    \n",
    "    acc = [0 for x in range(len(classifiers))]\n",
    "    for idx, clf in enumerate(classifiers):\n",
    "        acc[idx] = classifier_model(clf)\n",
    "\n",
    "    rec.extend(acc)\n",
    "    print('rec:%s'%rec)\n",
    "    \n",
    "    #new df\n",
    "    df = pd.DataFrame([rec],columns=cols)\n",
    "    retdf = pd.concat([retdf, df])        \n",
    "    \n",
    "retdf.to_csv('crossvalid_stagedata_splitbyevent%s.csv'%suffix)\n",
    "df_event = retdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stagedata[(stagedata['eventid']==5) & (stagedata['car_number']==12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['runid', 'trainsize', 'testsize', 'testdistribution', 'currank', 'avgrank', 'dice', 'lr', 'lsvc', 'lsvcl2', 'rf', 'lrbias', 'xgb']\n",
      "Testset = Indy500-2018\n",
      "[*] predict with currank model\n",
      "precision=[0.        0.1572327 0.       ], recall=[0. 1. 0.], f1=[0.         0.27173913 0.        ], accuracy=0.16\n",
      "[*] predict with avgrank model\n",
      "precision=[0.39047619 0.25       0.21052632], recall=[0.58571429 0.16       0.125     ], f1=[0.46857143 0.19512195 0.15686275], accuracy=0.33\n",
      "[*] predict with dice model\n",
      "precision=[0.50561798 0.17857143 0.5       ], recall=[0.64285714 0.2        0.328125  ], f1=[0.56603774 0.18867925 0.39622642], accuracy=0.45\n",
      "[*] predict with lr model\n",
      "precision=[0.58666667 1.         0.55421687], recall=[0.62857143 0.04       0.71875   ], f1=[0.60689655 0.07692308 0.62585034], accuracy=0.57\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.61971831 1.         0.55172414], recall=[0.62857143 0.04       0.75      ], f1=[0.62411348 0.07692308 0.63576159], accuracy=0.58\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.46808511 0.3125     0.5       ], recall=[0.94285714 0.2        0.015625  ], f1=[0.62559242 0.24390244 0.03030303], accuracy=0.45\n",
      "[*] predict with rf model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.58823529 0.         0.58108108], recall=[0.71428571 0.         0.671875  ], f1=[0.64516129 0.         0.62318841], accuracy=0.58\n",
      "[*] predict with lrbias model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.59722222 0.5        0.55294118], recall=[0.61428571 0.04       0.734375  ], f1=[0.6056338  0.07407407 0.63087248], accuracy=0.57\n",
      "[*] predict with xgb model\n",
      "precision=[0.56060606 0.17647059 0.56578947], recall=[0.52857143 0.12       0.671875  ], f1=[0.54411765 0.14285714 0.61428571], accuracy=0.52\n",
      "rec:['Indy500-2018', 969, 159, '+:64,0:25,-:70', 0.15723270440251572, 0.3333333333333333, 0.44654088050314467, 0.5723270440251572, 0.5849056603773585, 0.4528301886792453, 0.5849056603773585, 0.5723270440251572, 0.5220125786163522]\n",
      "Testset = Indy500-2019\n",
      "[*] predict with currank model\n",
      "precision=[0.         0.21621622 0.        ], recall=[0. 1. 0.], f1=[0.         0.35555556 0.        ], accuracy=0.22\n",
      "[*] predict with avgrank model\n",
      "precision=[0.46956522 0.41666667 0.22413793], recall=[0.63529412 0.125      0.21666667], f1=[0.54       0.19230769 0.22033898], accuracy=0.39\n",
      "[*] predict with dice model\n",
      "precision=[0.47572816 0.21875    0.36      ], recall=[0.57647059 0.175      0.3       ], f1=[0.5212766  0.19444444 0.32727273], accuracy=0.40\n",
      "[*] predict with lr model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.57575758 0.25       0.42608696], recall=[0.44705882 0.025      0.81666667], f1=[0.50331126 0.04545455 0.56      ], accuracy=0.48\n",
      "[*] predict with lsvc model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.52542373 0.44444444 0.41880342], recall=[0.36470588 0.1        0.81666667], f1=[0.43055556 0.16326531 0.55367232], accuracy=0.45\n",
      "[*] predict with lsvcl2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_ssd/hpda/anaconda3/envs/gluonts/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.59701493 0.28888889 0.47945205], recall=[0.47058824 0.325      0.58333333], f1=[0.52631579 0.30588235 0.52631579], accuracy=0.48\n",
      "[*] predict with rf model\n",
      "precision=[0.57281553 0.         0.49382716], recall=[0.69411765 0.         0.66666667], f1=[0.62765957 0.         0.56737589], accuracy=0.54\n",
      "[*] predict with lrbias model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=[0.57575758 0.16666667 0.42477876], recall=[0.44705882 0.025      0.8       ], f1=[0.50331126 0.04347826 0.55491329], accuracy=0.47\n",
      "[*] predict with xgb model\n",
      "precision=[0.53191489 0.33333333 0.45882353], recall=[0.58823529 0.05       0.65      ], f1=[0.55865922 0.08695652 0.53793103], accuracy=0.49\n",
      "rec:['Indy500-2019', 969, 185, '+:60,0:40,-:85', 0.21621621621621623, 0.3891891891891892, 0.4, 0.4756756756756757, 0.4540540540540541, 0.4756756756756757, 0.5351351351351351, 0.4702702702702703, 0.4918918918918919]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runid</th>\n",
       "      <th>trainsize</th>\n",
       "      <th>testsize</th>\n",
       "      <th>testdistribution</th>\n",
       "      <th>currank</th>\n",
       "      <th>avgrank</th>\n",
       "      <th>dice</th>\n",
       "      <th>lr</th>\n",
       "      <th>lsvc</th>\n",
       "      <th>lsvcl2</th>\n",
       "      <th>rf</th>\n",
       "      <th>lrbias</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500-2018</td>\n",
       "      <td>969</td>\n",
       "      <td>159</td>\n",
       "      <td>+:64,0:25,-:70</td>\n",
       "      <td>0.157233</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.446541</td>\n",
       "      <td>0.572327</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.572327</td>\n",
       "      <td>0.522013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indy500-2019</td>\n",
       "      <td>969</td>\n",
       "      <td>185</td>\n",
       "      <td>+:60,0:40,-:85</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.389189</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.475676</td>\n",
       "      <td>0.454054</td>\n",
       "      <td>0.475676</td>\n",
       "      <td>0.535135</td>\n",
       "      <td>0.470270</td>\n",
       "      <td>0.491892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          runid trainsize testsize testdistribution   currank   avgrank  \\\n",
       "0  Indy500-2018       969      159   +:64,0:25,-:70  0.157233  0.333333   \n",
       "0  Indy500-2019       969      185   +:60,0:40,-:85  0.216216  0.389189   \n",
       "\n",
       "       dice        lr      lsvc    lsvcl2        rf    lrbias       xgb  \n",
       "0  0.446541  0.572327  0.584906  0.452830  0.584906  0.572327  0.522013  \n",
       "0  0.400000  0.475676  0.454054  0.475676  0.535135  0.470270  0.491892  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### fix train\n",
    "#load data\n",
    "_trim = 2\n",
    "_include_final = False\n",
    "include_str = '1' if _include_final else '0'\n",
    "suffix = f'indy500-2013-2019-end{include_str}-t{_trim}'\n",
    "output_file = f'stage-indy500-2013-2019-end{include_str}-t{_trim}.csv'\n",
    "stagedata = pd.read_csv(output_file)\n",
    "stagedata.fillna(0, inplace=True)\n",
    "#stagedata.info()\n",
    "\n",
    "cols = ['runid','trainsize','testsize','testdistribution']\n",
    "cols.extend(classifiers)\n",
    "print('cols:%s'%cols)\n",
    "retdf = pd.DataFrame([],columns=cols)\n",
    "\n",
    "\n",
    "events = set(stagedata['eventid'])\n",
    "\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019']\n",
    "#events = ['Indy500']\n",
    "eventsname = [f'Indy500-{x}' for x in years]\n",
    "events_id={key:idx for idx, key in enumerate(eventsname)}\n",
    "\n",
    "#first \n",
    "eventid = events_id['Indy500-2018']\n",
    "ignore_eventid = events_id['Indy500-2019']\n",
    "stdata_2018 = stagedata[stagedata['eventid']!=ignore_eventid]\n",
    "\n",
    "print('Testset = %s'%eventsname[eventid])\n",
    "\n",
    "train, test, train_x, train_y, test_x, test_y = split_by_eventid(stdata_2018, eventid)\n",
    "test_distribution = '+:%d,0:%d,-:%d'%(np.sum(test_y>0),np.sum(test_y==0),np.sum(test_y<0))\n",
    "#print('Testset by stageid= %s, trainsize=%d, testsize=%d, dist=%s'%\n",
    "#      (stageid, train_x.shape[0], test_x.shape[0], test_distribution))\n",
    "\n",
    "#record\n",
    "rec = [eventsname[eventid],train_x.shape[0],test_x.shape[0],test_distribution]\n",
    "\n",
    "acc = [0 for x in range(len(classifiers))]\n",
    "for idx, clf in enumerate(classifiers):\n",
    "    acc[idx] = classifier_model(clf)\n",
    "\n",
    "rec.extend(acc)\n",
    "print('rec:%s'%rec)\n",
    "\n",
    "#new df\n",
    "df = pd.DataFrame([rec],columns=cols)\n",
    "retdf = pd.concat([retdf, df])        \n",
    "\n",
    "\n",
    "eventid = events_id['Indy500-2019']\n",
    "ignore_eventid = events_id['Indy500-2018']\n",
    "stdata_2019 = stagedata[stagedata['eventid']!=ignore_eventid]\n",
    "\n",
    "print('Testset = %s'%eventsname[eventid])\n",
    "\n",
    "train2, test2, train_x2, train_y2, test_x, test_y = split_by_eventid(stdata_2019, eventid)\n",
    "test_distribution = '+:%d,0:%d,-:%d'%(np.sum(test_y>0),np.sum(test_y==0),np.sum(test_y<0))\n",
    "\n",
    "#record\n",
    "rec = [eventsname[eventid],train_x.shape[0],test_x.shape[0],test_distribution]\n",
    "\n",
    "acc = [0 for x in range(len(classifiers))]\n",
    "for idx, clf in enumerate(classifiers):\n",
    "    acc[idx] = classifier_model(clf)\n",
    "\n",
    "rec.extend(acc)\n",
    "print('rec:%s'%rec)\n",
    "\n",
    "#new df\n",
    "df = pd.DataFrame([rec],columns=cols)\n",
    "retdf = pd.concat([retdf, df]) \n",
    "retdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retdf.to_csv('stint_classifier_result_t2013-2017.csv', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
